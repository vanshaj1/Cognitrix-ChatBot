Video ID,Transcript,Video Link,Video Link + Transcript
OBYuDazM4Hk,so good morning again and welcome to the second lecture of memory design and test course uh today we will look at memory types and optimizations and uh we will look at uh hopefully we will also get to look at the the design flow or the signal flow inside the memory a typical signal flow inside the memory and then subsequently if time permits we will also get to look at one of the data sheets so that we get a view of what kind of features are usually available inside a memory so uh but before we enter into all that why do we need to talk of memories and uh why why all this huha in the first place so the reality is that there is memory some kind of memory very widely spread out in the entire system there are very fast resistors and data paths uh there are memories which are operating at processor speed uh which are inside the processor there are level two caches level three caches and then off chip memories like drams and hard disks so memories are so so pervasive in our Electronics ecosystem that uh how they function how to make use of them how to design better memories all this understanding can help us really LeapFrog and transition into next level of uh PPA efficiency CPA all of you remember what is PPA yes yeah Power performance and area for any vlsi system these are the three parameters which which should which a designer should always keep Insight one should always have a site of how is the performance of the system evolving how is the area which would result in cost of the system evolving and how is the power changing uh so all of us understand why all these three parameters are important PPA all three are important why hello yes why is power important to reduce the losses like heated more power consumes which will be caused yes if most power consumes uh there are multiple things all of us are using mobile devices portable devices if our tips and of our systems consume more power then we have to recharge our devices more often or to reduce that frequency I have to use a bigger battery bigger battery means because more system cost uh power also means uh whatever power is consumed also means heat dissipated so if the power consumption is very high then I also have to put in place sufficient mechanisms to dissipate that heat to you know to remove away that heat from the uh system level so uh if you have very high power consuming system you will have to have complex cooling mechanisms like liquid cooling so in in the last course the DVD course you also talked about how Qualcomm chips and the the most advanced application processors actually tout about or or you know claim uh good efficiency because they are using liquid cooling technology so as so power is therefore very important performance I think all of us very well understand why is performance important so we can say performance mainly includes functionality and the frequency of operation so the functionality that we need should be as it is and the frequency of operation the desired frequency of operation at which the chip should operate yeah that is also fixed so why is it important so should we keep it inside uh so performance ultimately burns down to the user experience so uh if the higher is a performance so we can operate the chips at a higher frequency and then get the results at the faster rate the throughput would be the throughput would be higher the latency that the that the customer or a user experience will be lesser so overall user experience improves he or she is ready to pay a higher price you're ready to pay a higher price for a higher higher performing Intel chipset is it not so performance also is important that means that what kind of Revenue we will earn an area why is area important oh vaishna we're saying area is old in vlsi good to reduce the cost to reduce the cost why why does area reduce the cost we get less step areas so the Silicon substrate is constantly so yeah okay if you have letter type area then we if we reduce the area then we can increase the lots of feature by adding some more transistors okay we can we can do more integration yes what else so the size of the device is also decreases actually so let's see like faster okay latency will also decrease I think interesting sir cost reduce costs yeah that is what I'm asking how does cost reduce when you reduce area he can have more dice more dyes on the side on the same business because the cost of the wafer remains constant if you can have more dies on the same Vapor you have more selling chips additionally we also discussed and we also reviewed that yield is inversely proportional to area so the area is less then what happens your yield improves yield improves means that if there were 90 out of 100 dies that were functional earlier now 92 would be functional with a two percent Improvement in yield so not only do you get more chips per Wafers you get more functional chips per wafer so overall profitability increases significantly therefore we say that area is gold in the LSi but for Memories We will say something else what would we say it's a diamond yes for memories area is Diamond why because you see memories are everywhere in fact in advanced socs uh for the likes of uh you know the trips that are used in um self-driving cars for example for advanced socs or for even Advanced processors up to 70 or even 80 percent of Chip area is from memories so if 80 of your chip area is memory then to save area in memories is still more important and that is why when we talk of memories we say area is diamond um so we're changing the Paradigm that area is area becomes all the much more important parameter when we talk of memories is that clear any questions,https://www.youtube.com/watch?v=OBYuDazM4Hk,"Link: https://www.youtube.com/watch?v=OBYuDazM4Hk
Transcript: so good morning again and welcome to the second lecture of memory design and test course uh today we will look at memory types and optimizations and uh we will look at uh hopefully we will also get to look at the the design flow or the signal flow inside the memory a typical signal flow inside the memory and then subsequently if time permits we will also get to look at one of the data sheets so that we get a view of what kind of features are usually available inside a memory so uh but before we enter into all that why do we need to talk of memories and uh why why all this huha in the first place so the reality is that there is memory some kind of memory very widely spread out in the entire system there are very fast resistors and data paths uh there are memories which are operating at processor speed uh which are inside the processor there are level two caches level three caches and then off chip memories like drams and hard disks so memories are so so pervasive in our Electronics ecosystem that uh how they function how to make use of them how to design better memories all this understanding can help us really LeapFrog and transition into next level of uh PPA efficiency CPA all of you remember what is PPA yes yeah Power performance and area for any vlsi system these are the three parameters which which should which a designer should always keep Insight one should always have a site of how is the performance of the system evolving how is the area which would result in cost of the system evolving and how is the power changing uh so all of us understand why all these three parameters are important PPA all three are important why hello yes why is power important to reduce the losses like heated more power consumes which will be caused yes if most power consumes uh there are multiple things all of us are using mobile devices portable devices if our tips and of our systems consume more power then we have to recharge our devices more often or to reduce that frequency I have to use a bigger battery bigger battery means because more system cost uh power also means uh whatever power is consumed also means heat dissipated so if the power consumption is very high then I also have to put in place sufficient mechanisms to dissipate that heat to you know to remove away that heat from the uh system level so uh if you have very high power consuming system you will have to have complex cooling mechanisms like liquid cooling so in in the last course the DVD course you also talked about how Qualcomm chips and the the most advanced application processors actually tout about or or you know claim uh good efficiency because they are using liquid cooling technology so as so power is therefore very important performance I think all of us very well understand why is performance important so we can say performance mainly includes functionality and the frequency of operation so the functionality that we need should be as it is and the frequency of operation the desired frequency of operation at which the chip should operate yeah that is also fixed so why is it important so should we keep it inside uh so performance ultimately burns down to the user experience so uh if the higher is a performance so we can operate the chips at a higher frequency and then get the results at the faster rate the throughput would be the throughput would be higher the latency that the that the customer or a user experience will be lesser so overall user experience improves he or she is ready to pay a higher price you're ready to pay a higher price for a higher higher performing Intel chipset is it not so performance also is important that means that what kind of Revenue we will earn an area why is area important oh vaishna we're saying area is old in vlsi good to reduce the cost to reduce the cost why why does area reduce the cost we get less step areas so the Silicon substrate is constantly so yeah okay if you have letter type area then we if we reduce the area then we can increase the lots of feature by adding some more transistors okay we can we can do more integration yes what else so the size of the device is also decreases actually so let's see like faster okay latency will also decrease I think interesting sir cost reduce costs yeah that is what I'm asking how does cost reduce when you reduce area he can have more dice more dyes on the side on the same business because the cost of the wafer remains constant if you can have more dies on the same Vapor you have more selling chips additionally we also discussed and we also reviewed that yield is inversely proportional to area so the area is less then what happens your yield improves yield improves means that if there were 90 out of 100 dies that were functional earlier now 92 would be functional with a two percent Improvement in yield so not only do you get more chips per Wafers you get more functional chips per wafer so overall profitability increases significantly therefore we say that area is gold in the LSi but for Memories We will say something else what would we say it's a diamond yes for memories area is Diamond why because you see memories are everywhere in fact in advanced socs uh for the likes of uh you know the trips that are used in um self-driving cars for example for advanced socs or for even Advanced processors up to 70 or even 80 percent of Chip area is from memories so if 80 of your chip area is memory then to save area in memories is still more important and that is why when we talk of memories we say area is diamond um so we're changing the Paradigm that area is area becomes all the much more important parameter when we talk of memories is that clear any questions"
9o2RmJTn6SQ,uh now while we saw that memories are used across the entire range of system hierarchy we also need to understand that there are many different kinds of memories that we talk about on that we design so the most common memory that we know of is SRAM we talked about it even in the last part of the DVD course then we talk about drams all of you know what is a drum s used uh dhiram is basically a single uh transistor based memory uh cell which is backed up by a capacitor which uh statically uh which dynamically stores the charge uh which in in fact uh stores the single bit of information where are these answers like I asked you have you heard of drams and and I'm sure you have when you purchase your phone what what what is the dram specification there or the ramps [Music] okay and and as you like he said dramas uh is based on a one transistor cell and uh due to this it is much much denser than an extra for SRAM we already saw in the previous class also and we will we will see in much more detail in this class that uh srams uh the most commonly used cell is a six transistor set so six transistors mean some area whereas dram if it is just one transistor and one capacitor since it's just one one transistor it's denser okay and the memories area is Diamond so drams are very important so this is about the excess pattern they are random access memories what does random access mean you can write or read from any particular location at any particular time yes I will give an address and the memory and I can read or write any location so there are srams the drams we already discussed srams would be typically used as caches for example or L1 cache L2 cache and so on where you have an instruction which may carry an address and you want to write a dart address so this is about the drams and srams but there are also non-random access memories that we have in our system so FIFA what does C4 stand for where do you think a people would be used in a system [Music] um so when we so when we are using a frequency uh conversion like uh pin we are using like there is a change in frequency from one system to another we are using them a b okay good so that is definitely one application of a V4 where we transition from one frequency Island to another frequency Island very good where else so have you have all of you understood this this concept the frequency transition concept have all of you understood no okay so let us say that uh so all of us understand uh dvss and the v in DVD also we talked about voltage Islands we said that depending on the system requirements depending on the performance requirements from a particular system I may operate some part of the chip at higher voltage another part at a lower voltage you remember this we discussed all that yes yes so when we do that then we operate system at different operational voltages naturally the frequency at which those those different voltage Islands would operate would also be different so there is one part of the chip which is operating at let us say one gigahertz another part of the trip which is operating at 800 megahertz now if there is some information transfer that has to happen from one part to the other do you realize that there will be some extra data that could be coming from one side to be absorbed by the other side for that we need to keep some buffers those buffers are usually first and first out kind of buffers that whatever data was written into the written onto the bus first will be stored and then that will be pushed on the bus later on that will be pushed on the bus first the data that comes afterwards will only be pushed on the second cycle and so on so that is first in first out this is the queuing mechanism which you would use in uh what do you say a clock uh clock synchronization across two different domains so uh how big a FIFA would you need oh sir it can be application yes it is largely application dependent it depends on the kind of variation and frequency like what are the two different frequencies that you are merging and also on the uh how frequently are you expected to do this data transfer between two domains if it so happens that you are transferring data in every cycle then it can't it can't really happen that we use a FIFA to take care of it because then uh if I'm sending one giga bytes of data from one uh from one part of the chip and the other part of the chip can accept only 800 Mega bytes of data then uh 200 megabytes of data we were ending up losing so uh they have to we understand that uh not every cycle would require data transfer and therefore we can still operate two different parts of the chip at different frequencies if we require it in such a way that uh data transfer rate has to be similar then uh both parts should operate at the same frequency then a FIFA would not help but a fifo can help when there is a probability of empty cycles and in those empty Cycles the slower frequency system would pick up the data from the fifo is this part here hello are you able to any questions on this if you don't tell me I will simply move forward okay so let me see if I can use the Whiteboard to explain it again foreign are you able to see my whiteboard yes sir yes what we are saying is let us say there is one system which is operating at um 800 megahertz and there is another system which is operating at let us say one gigahertz and there is a bus that connects them so at the interface of the bus you will apply you will use what is we call as a C4 foreign because those two are asynchronous domains so there could be a time when this is operating at one gigahertz and this is operating at 800 megahertz that kind of a thing also exists so you have fifo on both the sides now we understand that neither of the two systems would want to communicate to the other system at the full frequency f okay they want to communicate it at the required frequency s but the activity factor or the number of cycles in which they will want to write is not 100 percent typically this activity factor is of the order of 0.1 0.2 at most okay so you consider this probability Factor and then you say okay if this is the kind of uh data that I have to send from this port to that port then since I am transmitting at one gigahertz and an activity factor of 0.1 let us say I will have 100 megahertz or 100 megabytes of data to be sent per second um on this side the system is operating at 800 megahertz so it will accept up to 800 megabytes of data per second the system is matched now let us say the activity factor is this thing clear that if you're sending less data just at a higher frequency then you'll still be able to send transmit all the data because the capacity of the accepting system is still much larger than the data being sent are you able to see this yes sir yes now let us say the activity Factor was one now what happens or let us say 0.9 now what happens I am sending 900 megabytes of data per second but this part of the system can only accept 800 megabytes of data per second so what happens to 100 megabytes we lose it we will lose it so this kind of an arrangement cannot work which means that this system cannot operate at 800 megahertz the system has to operate at 900 megahertz so while FIFA could help when the capacity was matching across the two zones if the capacity mismatch happens then you have to change the frequency of operation of the slower system then the C4 is insufficient are you able to see this so you you mean to say that if the receiver is having the higher frequency we can give the input at a lower frequency also right I'm sorry uh if the receiver is having a one gigahertz frequency so if you want to give the data to that so we can apply the data at lesser than that frequency yes so now you are able to see the full picture is this clearest I I was assuming that you were able to see my full whiteboard but it was not the case so is it better now yes sir any questions here is this the same concept of synchronizer like uh yes we use some extra flip flop to change uh interact with the two different frequencies yes so over here we are saying we're not using a flip flop because flip flop is larger in area we instead use a fifo it is denser okay the receiver has to be at the free operating at a frequency lesser or equal to yes listen so you have to you have to always match the data rate the data transfer rate that's that's the Baseline that's what I wanted to to emphasize by talking about in it in this details is that okay so how do we overcome this challenge I mean we increase the frequency of the receiver set or we use something else like we don't use fifo or something else so uh you cannot do anything else you have to change the frequency okay how to be able to match it yeah no other memory type or nothing else will be able to match it okay okay just sir people can only divide the frequency uh or can also multiply because raghav said it will give the frequency in subdivision but in the second case when you showed it required some higher frequency so can we use the FIFA for in the reverse fifo cannot generate data fifo has a limited capacity it can store only as many number of words in it if the other side needs more data then how do we do it we can't do it so vaishnav is asking what is the exact internal structure of E4 so vaishnav do you know what the exact internal structure of an SRAM is not yet huh so we'll come into that don't worry so that was about fifo now what about last and first out I've already given you know we use it whenever we want to implement Stacks in our system we use last and first outline of a memory so what is happening in these last and first outs and first and first out is you do not really look for an address from the user you maintain an internal Point Internal pointer which addresses the locations that that need to be addressed for a fifo you have a read pointer and a right pointer and and an output which you would call as an overflow output so the right pointer means I have to write in this location a read pointer means I have to read from this location and uh overflow means my uh the the mismatch of 900 megabytes versus Asian megabytes that you were talking about is there therefore the there is a system failure um lifo also you will have a read pointer and a right pointer and uh the right pointer uh like the right pointer would would be very close to read pointer at all times because you're talking about last and first out in C4 read pointer and right pointer can be far far away depending on the size of the fifo shift resistors you know what is a shift resistor so temporary data storage yes temporary data storage just in the lines of uh what you say synchronizers as mine was telling about that to synchronize between two clock domains we use shift resistors yeah if you have if you do not if it is about the same so okay when we were talking about these two clock domains when you're talking about these two clock domains we said that the frequency is different but there can be a case where I have two systems or two voltage Islands both operating at one gigahertz just that they are far away just that they are far away from each other so there would be latency between them in such a case what happens if there is a latency between two domains then all that you need to do is you need to use just one or two layers of data storage depending on the latency size in such a case you use shift registers or flip flops otherwise you would if if there is a frequency difference also then you necessarily need a C4 to be put in this is that okay latency so to overcome that latency between these two voltage Islands we use shift registers yeah latency means that uh okay I'm operating at one gigahertz but to transfer data from one one part of the chip to the other I take 200 picoseconds so when the clock Edge comes on that side my data is not yet ready there so I need very small temporary storage just one word or two words and for that I use shift resistor to match up to that yeah okay synchronizing okay and then we come to the next part which is content addressable memories who will tell me what a contenderizable memory is so in this we will search for the address it will search for the content the address so in in content addressable memories you give the content that you want to find so you are saying uh let us say there is a there is a memory which stores names of all the students in this class and someone wants to see that is there a student named Akash in the class or not and then they may need another additional information what is akasha's role number let us say so we have the content available with us we want to search at what location are details of Akash stored the location at which those details are stored I will then give out some data on that from that location what would that data output data be that will be his role number um so in that what is happening is I am inside the memory doing the comparison it's in rating what is called as a match signal and then giving the output considering that as the desired address are you able to see this so this is content addressable memory I do not have the address location which I want to read I do not even know about it but I know the content that I want to match so I give that match content over there and the location all the locations for which this address will be matched there will be a read operation that is initiated is that okay you have your hand raised uh so I I just want to clarify a statement about shift register in fifo like in shift register due to latency we are we are using shift registers so you could also use a fifo there that's why I was confused yeah shift registers are are if you just need to have a few words then shift to the structure mode area efficient than fee Force but if you need more number of words then fifos are more area efficient based on flip flops thank you okay so content addressable memories any questions about that so like in this we are trying to uh go the reverse way from the content to the address but like further content matching also there would be some kind of reading from a particular location that which it matches wouldn't it be like yeah there will be some reading we will so in a typical uh SRAM cell you have to have a separate like if it was a typical SRAM then you will have to read you will have to compare and then say whether it's the match or not so you'll have to if it's a 100 100 word Ram you will have to do 100 Cycles to do even one comparison am I right yes sir but in a cam what happens is every memory cell has a comparator in itself there is comparison having happening in every memory cell so you just throw the data that you want to compare to the entire memory array and whichever word there is a match the memory memory array will highlight oh there's a match here okay so so the operation uh when we throw the data and the cell picking up that data and comparing it what is that operation called it will be reading writing that is called compare that is compare okay that is separate kind of category yeah okay okay and do you realize that if I have to do this kind of uh operation uh it will be very high very high speed obviously and instead of 100 Cycles I could do that compare in one cycle only but it is much more area penalty because now there is a comparator in every cell and it is also much more power hungry because you're doing so many comparisons in parallel so the peak over consumption is also very very high yes sir yeah so overall throughput is very high but those challenges also exist so your getting good on the axis of performance but really sacrificing big things on Power and area scams are therefore uh used in very close association with processors they're also called tightly coupled memories at times they're very tightly coupled to processors almost as a part of the processor very commonly used for lookup tables and they're also used in routers for example communication domain routers where you know that okay my destination is America now which port to send my next data package to so I search for America and I identify which quote America is programmed at and so on so that is contended to sell memories again non-random access I do not give any address to the memory I just give a content and that content the the remaining information on that Con on that address matched address is given out to the user so so just a small point so like when we are throwing the data to the whole array kind of thing so every location uh comparison is done parallely or at every location in the array yes okay that's why the performance thing comes in because everything is parallel oh yes got it so thank you okay then all these were what we were discussing till now were volatile memories what does volatile memory mean that when you power off the system the information would go away it is volatile but we need non-volatile memories also that is what you have in your cell phone also uh 128 gigabytes 64 gigabytes of memory in your cell phones um so that non-volatile memory is is a different range of memories altogether and again non-volatile memories are two types one is non-volatile read write memory and another is read only memory we'll come to ROMs later but where do you think non-volatile read write memories are used e problems eeproms flash do you know what they are boot sequence pen drives pen drives okay pen drives are what kind of memory pen drivers flash kind of memories what are eeproms and eeproms electrically electrically programmable electrically programmable ROM and electrically erasable and programmable wrong so flash is actually a eeprom only a different kind a different density we will look at it in detail in the later part of the course in the second half of the course you look at caches and drams so we will see why flashes so much higher density than regular eeproms for example so how has the flash technology completely changed the way we use storage in advanced systems today so eproms electrically programmable ROM where do you need it why do you need it so like someone mentioned the boot sequence like once we show the instructions and they need to table automatically be read and we don't have to write into this B was just write the instructions once and then it's hardwired yes so eproms are usually used for uh instruction storage if in fact if it so happens that you are very clear about what your boot sequence would be throughout the life cycle of the product you will not even use the eprom he promised less dense than a ROM so you would use you instead use a mask programmed ROM that is much denser but typically we understand that system upgrade may happen or tomorrow I may want to add some additional features into my uh into my chip or enable a new set of features which are there in the debug mode today but once we validate them on Silicon we will want to enable them so the first few Lots the first few months you give only the vanilla feature you program the e-prom in such a way that you that only the vanilla features are available and when you're down the line when you're well tested the additional testable features or additional features you had on the chip you offered them all through the customer buy just changing the program on your eeprom so they're also used and uh what is mass program ROM read only memory you understand what is mass programmed so from the name like it to me uh comes like that other kind of fabrication time only you are kind of like programming it like at the mass level itself like you are directly at the you are like uh fabricating it such that you get that at that time chip fabrication itself but I'm sure yeah so is this point clear to everyone when we are saying Mass programmable or mass program it means that at the time of Designing the mask for that particular chip I already decide what is the data that needs to be stored so can you ever change the content of a mass reliable mosque programmed ROM ance no but because it is mass programmed we are already preempting what data needs to be written into the ROM there it is much much denser than eproms and eeproms hmm and uh the ROMs are again so typically any any dive would have at most one ROM so is that every die would have hundreds of Islams some would be like for uh register files another set would be for L1 cache another set would be for L2 cache L3 cache and so on ROMs typically the entire chip would have only one that too only for the purpose of storing the boot code which was pre-established before the system was even manufactured and why do you think we need a programmable ROM in programmable from some sections of the code memory is being stored and uh if there is uh if there is some over there updates so then this programmable ROM can be used so this is this is still a read-only memory you can't change the contents programmable ROM means for example let us say there is some part of the system which is failing you want to disable it or you want to send little higher voltage to it so that it starts to work now since this part is already failing or you suspect that it would fail in the field you've already programmed calibrate the system in such a way that this chip would generate a higher voltage than regular these theorems are fuse based and they are typically used for calibrating the system so that it operates at an Optimum say voltage or frequency or throughput so what exactly the difference with the eeprom and this problem I am not able to get right okay e problem is electrically programmable you can apply a voltage of 12 volts to the chip and you can get it going Fusion may not be electrically programmable fuse ROM you will actually have to physically blow away the fuse blow away the fuse means you will actually have to throw a laser at a particular place then rate the Heat and burn away the metal from there so that the connection to vdd or to ground is removed something like that so but both are used for the same purpose functionality wise yeah but fuse programmed uh you do it you do fuse programming inside the Fab itself eprom you can do at the customer end okay so so like in this Mass program uh the instructions that we need to be for example boot sequence they are fabricated uh at the Fab itself similar is for this problem also no no okay problem will not store instructions from will only store calibration data what is that actually what does that mean suppose my chip is manufactured in slow lot I now want to operate this particular chip or this entire lot at 1.14 volts instead of 1.1 volts so that I get the required frequency this is a one-time programmation that you will do at the in the Fab by blowing away some fuses this is not about storing new set of instructions or a particular set of instructions is that okay so like after I have fabricated at a particular lot I am then I'm doing kind of initial kind of fabrication step for uh this to make it okay after the fabrication has happened I estimate what lot the device is at yes sir now I simply fix that okay if it is a fast lot then the leakage is going to be very high so I have to lower down the voltage of application so that leakage comes under control because it's already fast performance is not an issue for me so I will trim I will say that okay instead of operating at 1.3 volts operate the chip at 1.26 volts okay and this calibration will be done using this prom yes okay so clear for everyone yeah yes any questions please feel free to ask so and this last step of the problem will be done and also in the Fab itself yes okay so uh hello yes Shiva yeah sir uh I was able to understand like uh prom is used for storing desynchronization information as you told like if tell like if we have made a chip in fast load and we will okay okay so we do not make a Japan faster that's manufactured we categorize it it is in a first load we identified that it is in the past lot yes so so uh how P Rom is used there like to store the information like we need to use it in like lower voltages yeah so what I will do is uh the voltage Regulators on the chip they always have some calibration bits okay so I will make my logic in such a way that the information from the P Rom goes and triggers those calibration bits in such a way that this voltage regulator now generates only 1.26 volts instead of 1.3 volts or 1.14 volts instead of 1.1 volt okay okay yes similarly let us say when we are in the memory design course let us say there is some location inside the memory that is failing I can add some additional redundant memory in the in the overall chip and say that if this particular location is failing uh if if this failing location is addressed then instead of a point reaching out to that failing location go to this replacement location yes this again is programmed by using p ROMs yes sir okay okay thank you yeah anything is great so now whatever be these all these kinds of memories whether it is uh P Rom or ROM or fifo or SRAM or dram or Flash whatever it is uh there is a structure so yes please yes but can I say that the P Rom is storing the information of like which cell is working properly and how many extra cells are available to us so that it can allocate in the future um Freedom will not do those evaluation with us theorem will only store the location of the failing himself for example and the sharing location now there will be some Logic on the chip which would say okay if this location is failing let us redirect the addressing to that other location so there will be a controlling unit also in the memory section oh yes and control this oh yes we will look at the insides of the memory in just a little while I was about to go there on,https://www.youtube.com/watch?v=9o2RmJTn6SQ,"Link: https://www.youtube.com/watch?v=9o2RmJTn6SQ
Transcript: uh now while we saw that memories are used across the entire range of system hierarchy we also need to understand that there are many different kinds of memories that we talk about on that we design so the most common memory that we know of is SRAM we talked about it even in the last part of the DVD course then we talk about drams all of you know what is a drum s used uh dhiram is basically a single uh transistor based memory uh cell which is backed up by a capacitor which uh statically uh which dynamically stores the charge uh which in in fact uh stores the single bit of information where are these answers like I asked you have you heard of drams and and I'm sure you have when you purchase your phone what what what is the dram specification there or the ramps [Music] okay and and as you like he said dramas uh is based on a one transistor cell and uh due to this it is much much denser than an extra for SRAM we already saw in the previous class also and we will we will see in much more detail in this class that uh srams uh the most commonly used cell is a six transistor set so six transistors mean some area whereas dram if it is just one transistor and one capacitor since it's just one one transistor it's denser okay and the memories area is Diamond so drams are very important so this is about the excess pattern they are random access memories what does random access mean you can write or read from any particular location at any particular time yes I will give an address and the memory and I can read or write any location so there are srams the drams we already discussed srams would be typically used as caches for example or L1 cache L2 cache and so on where you have an instruction which may carry an address and you want to write a dart address so this is about the drams and srams but there are also non-random access memories that we have in our system so FIFA what does C4 stand for where do you think a people would be used in a system [Music] um so when we so when we are using a frequency uh conversion like uh pin we are using like there is a change in frequency from one system to another we are using them a b okay good so that is definitely one application of a V4 where we transition from one frequency Island to another frequency Island very good where else so have you have all of you understood this this concept the frequency transition concept have all of you understood no okay so let us say that uh so all of us understand uh dvss and the v in DVD also we talked about voltage Islands we said that depending on the system requirements depending on the performance requirements from a particular system I may operate some part of the chip at higher voltage another part at a lower voltage you remember this we discussed all that yes yes so when we do that then we operate system at different operational voltages naturally the frequency at which those those different voltage Islands would operate would also be different so there is one part of the chip which is operating at let us say one gigahertz another part of the trip which is operating at 800 megahertz now if there is some information transfer that has to happen from one part to the other do you realize that there will be some extra data that could be coming from one side to be absorbed by the other side for that we need to keep some buffers those buffers are usually first and first out kind of buffers that whatever data was written into the written onto the bus first will be stored and then that will be pushed on the bus later on that will be pushed on the bus first the data that comes afterwards will only be pushed on the second cycle and so on so that is first in first out this is the queuing mechanism which you would use in uh what do you say a clock uh clock synchronization across two different domains so uh how big a FIFA would you need oh sir it can be application yes it is largely application dependent it depends on the kind of variation and frequency like what are the two different frequencies that you are merging and also on the uh how frequently are you expected to do this data transfer between two domains if it so happens that you are transferring data in every cycle then it can't it can't really happen that we use a FIFA to take care of it because then uh if I'm sending one giga bytes of data from one uh from one part of the chip and the other part of the chip can accept only 800 Mega bytes of data then uh 200 megabytes of data we were ending up losing so uh they have to we understand that uh not every cycle would require data transfer and therefore we can still operate two different parts of the chip at different frequencies if we require it in such a way that uh data transfer rate has to be similar then uh both parts should operate at the same frequency then a FIFA would not help but a fifo can help when there is a probability of empty cycles and in those empty Cycles the slower frequency system would pick up the data from the fifo is this part here hello are you able to any questions on this if you don't tell me I will simply move forward okay so let me see if I can use the Whiteboard to explain it again foreign are you able to see my whiteboard yes sir yes what we are saying is let us say there is one system which is operating at um 800 megahertz and there is another system which is operating at let us say one gigahertz and there is a bus that connects them so at the interface of the bus you will apply you will use what is we call as a C4 foreign because those two are asynchronous domains so there could be a time when this is operating at one gigahertz and this is operating at 800 megahertz that kind of a thing also exists so you have fifo on both the sides now we understand that neither of the two systems would want to communicate to the other system at the full frequency f okay they want to communicate it at the required frequency s but the activity factor or the number of cycles in which they will want to write is not 100 percent typically this activity factor is of the order of 0.1 0.2 at most okay so you consider this probability Factor and then you say okay if this is the kind of uh data that I have to send from this port to that port then since I am transmitting at one gigahertz and an activity factor of 0.1 let us say I will have 100 megahertz or 100 megabytes of data to be sent per second um on this side the system is operating at 800 megahertz so it will accept up to 800 megabytes of data per second the system is matched now let us say the activity factor is this thing clear that if you're sending less data just at a higher frequency then you'll still be able to send transmit all the data because the capacity of the accepting system is still much larger than the data being sent are you able to see this yes sir yes now let us say the activity Factor was one now what happens or let us say 0.9 now what happens I am sending 900 megabytes of data per second but this part of the system can only accept 800 megabytes of data per second so what happens to 100 megabytes we lose it we will lose it so this kind of an arrangement cannot work which means that this system cannot operate at 800 megahertz the system has to operate at 900 megahertz so while FIFA could help when the capacity was matching across the two zones if the capacity mismatch happens then you have to change the frequency of operation of the slower system then the C4 is insufficient are you able to see this so you you mean to say that if the receiver is having the higher frequency we can give the input at a lower frequency also right I'm sorry uh if the receiver is having a one gigahertz frequency so if you want to give the data to that so we can apply the data at lesser than that frequency yes so now you are able to see the full picture is this clearest I I was assuming that you were able to see my full whiteboard but it was not the case so is it better now yes sir any questions here is this the same concept of synchronizer like uh yes we use some extra flip flop to change uh interact with the two different frequencies yes so over here we are saying we're not using a flip flop because flip flop is larger in area we instead use a fifo it is denser okay the receiver has to be at the free operating at a frequency lesser or equal to yes listen so you have to you have to always match the data rate the data transfer rate that's that's the Baseline that's what I wanted to to emphasize by talking about in it in this details is that okay so how do we overcome this challenge I mean we increase the frequency of the receiver set or we use something else like we don't use fifo or something else so uh you cannot do anything else you have to change the frequency okay how to be able to match it yeah no other memory type or nothing else will be able to match it okay okay just sir people can only divide the frequency uh or can also multiply because raghav said it will give the frequency in subdivision but in the second case when you showed it required some higher frequency so can we use the FIFA for in the reverse fifo cannot generate data fifo has a limited capacity it can store only as many number of words in it if the other side needs more data then how do we do it we can't do it so vaishnav is asking what is the exact internal structure of E4 so vaishnav do you know what the exact internal structure of an SRAM is not yet huh so we'll come into that don't worry so that was about fifo now what about last and first out I've already given you know we use it whenever we want to implement Stacks in our system we use last and first outline of a memory so what is happening in these last and first outs and first and first out is you do not really look for an address from the user you maintain an internal Point Internal pointer which addresses the locations that that need to be addressed for a fifo you have a read pointer and a right pointer and and an output which you would call as an overflow output so the right pointer means I have to write in this location a read pointer means I have to read from this location and uh overflow means my uh the the mismatch of 900 megabytes versus Asian megabytes that you were talking about is there therefore the there is a system failure um lifo also you will have a read pointer and a right pointer and uh the right pointer uh like the right pointer would would be very close to read pointer at all times because you're talking about last and first out in C4 read pointer and right pointer can be far far away depending on the size of the fifo shift resistors you know what is a shift resistor so temporary data storage yes temporary data storage just in the lines of uh what you say synchronizers as mine was telling about that to synchronize between two clock domains we use shift resistors yeah if you have if you do not if it is about the same so okay when we were talking about these two clock domains when you're talking about these two clock domains we said that the frequency is different but there can be a case where I have two systems or two voltage Islands both operating at one gigahertz just that they are far away just that they are far away from each other so there would be latency between them in such a case what happens if there is a latency between two domains then all that you need to do is you need to use just one or two layers of data storage depending on the latency size in such a case you use shift registers or flip flops otherwise you would if if there is a frequency difference also then you necessarily need a C4 to be put in this is that okay latency so to overcome that latency between these two voltage Islands we use shift registers yeah latency means that uh okay I'm operating at one gigahertz but to transfer data from one one part of the chip to the other I take 200 picoseconds so when the clock Edge comes on that side my data is not yet ready there so I need very small temporary storage just one word or two words and for that I use shift resistor to match up to that yeah okay synchronizing okay and then we come to the next part which is content addressable memories who will tell me what a contenderizable memory is so in this we will search for the address it will search for the content the address so in in content addressable memories you give the content that you want to find so you are saying uh let us say there is a there is a memory which stores names of all the students in this class and someone wants to see that is there a student named Akash in the class or not and then they may need another additional information what is akasha's role number let us say so we have the content available with us we want to search at what location are details of Akash stored the location at which those details are stored I will then give out some data on that from that location what would that data output data be that will be his role number um so in that what is happening is I am inside the memory doing the comparison it's in rating what is called as a match signal and then giving the output considering that as the desired address are you able to see this so this is content addressable memory I do not have the address location which I want to read I do not even know about it but I know the content that I want to match so I give that match content over there and the location all the locations for which this address will be matched there will be a read operation that is initiated is that okay you have your hand raised uh so I I just want to clarify a statement about shift register in fifo like in shift register due to latency we are we are using shift registers so you could also use a fifo there that's why I was confused yeah shift registers are are if you just need to have a few words then shift to the structure mode area efficient than fee Force but if you need more number of words then fifos are more area efficient based on flip flops thank you okay so content addressable memories any questions about that so like in this we are trying to uh go the reverse way from the content to the address but like further content matching also there would be some kind of reading from a particular location that which it matches wouldn't it be like yeah there will be some reading we will so in a typical uh SRAM cell you have to have a separate like if it was a typical SRAM then you will have to read you will have to compare and then say whether it's the match or not so you'll have to if it's a 100 100 word Ram you will have to do 100 Cycles to do even one comparison am I right yes sir but in a cam what happens is every memory cell has a comparator in itself there is comparison having happening in every memory cell so you just throw the data that you want to compare to the entire memory array and whichever word there is a match the memory memory array will highlight oh there's a match here okay so so the operation uh when we throw the data and the cell picking up that data and comparing it what is that operation called it will be reading writing that is called compare that is compare okay that is separate kind of category yeah okay okay and do you realize that if I have to do this kind of uh operation uh it will be very high very high speed obviously and instead of 100 Cycles I could do that compare in one cycle only but it is much more area penalty because now there is a comparator in every cell and it is also much more power hungry because you're doing so many comparisons in parallel so the peak over consumption is also very very high yes sir yeah so overall throughput is very high but those challenges also exist so your getting good on the axis of performance but really sacrificing big things on Power and area scams are therefore uh used in very close association with processors they're also called tightly coupled memories at times they're very tightly coupled to processors almost as a part of the processor very commonly used for lookup tables and they're also used in routers for example communication domain routers where you know that okay my destination is America now which port to send my next data package to so I search for America and I identify which quote America is programmed at and so on so that is contended to sell memories again non-random access I do not give any address to the memory I just give 
a content and that content the the remaining information on that Con on that address matched address is given out to the user so so just a small point so like when we are throwing the data to the whole array kind of thing so every location uh comparison is done parallely or at every location in the array yes okay that's why the performance thing comes in because everything is parallel oh yes got it so thank you okay then all these were what we were discussing till now were volatile memories what does volatile memory mean that when you power off the system the information would go away it is volatile but we need non-volatile memories also that is what you have in your cell phone also uh 128 gigabytes 64 gigabytes of memory in your cell phones um so that non-volatile memory is is a different range of memories altogether and again non-volatile memories are two types one is non-volatile read write memory and another is read only memory we'll come to ROMs later but where do you think non-volatile read write memories are used e problems eeproms flash do you know what they are boot sequence pen drives pen drives okay pen drives are what kind of memory pen drivers flash kind of memories what are eeproms and eeproms electrically electrically programmable electrically programmable ROM and electrically erasable and programmable wrong so flash is actually a eeprom only a different kind a different density we will look at it in detail in the later part of the course in the second half of the course you look at caches and drams so we will see why flashes so much higher density than regular eeproms for example so how has the flash technology completely changed the way we use storage in advanced systems today so eproms electrically programmable ROM where do you need it why do you need it so like someone mentioned the boot sequence like once we show the instructions and they need to table automatically be read and we don't have to write into this B was just write the instructions once and then it's hardwired yes so eproms are usually used for uh instruction storage if in fact if it so happens that you are very clear about what your boot sequence would be throughout the life cycle of the product you will not even use the eprom he promised less dense than a ROM so you would use you instead use a mask programmed ROM that is much denser but typically we understand that system upgrade may happen or tomorrow I may want to add some additional features into my uh into my chip or enable a new set of features which are there in the debug mode today but once we validate them on Silicon we will want to enable them so the first few Lots the first few months you give only the vanilla feature you program the e-prom in such a way that you that only the vanilla features are available and when you're down the line when you're well tested the additional testable features or additional features you had on the chip you offered them all through the customer buy just changing the program on your eeprom so they're also used and uh what is mass program ROM read only memory you understand what is mass programmed so from the name like it to me uh comes like that other kind of fabrication time only you are kind of like programming it like at the mass level itself like you are directly at the you are like uh fabricating it such that you get that at that time chip fabrication itself but I'm sure yeah so is this point clear to everyone when we are saying Mass programmable or mass program it means that at the time of Designing the mask for that particular chip I already decide what is the data that needs to be stored so can you ever change the content of a mass reliable mosque programmed ROM ance no but because it is mass programmed we are already preempting what data needs to be written into the ROM there it is much much denser than eproms and eeproms hmm and uh the ROMs are again so typically any any dive would have at most one ROM so is that every die would have hundreds of Islams some would be like for uh register files another set would be for L1 cache another set would be for L2 cache L3 cache and so on ROMs typically the entire chip would have only one that too only for the purpose of storing the boot code which was pre-established before the system was even manufactured and why do you think we need a programmable ROM in programmable from some sections of the code memory is being stored and uh if there is uh if there is some over there updates so then this programmable ROM can be used so this is this is still a read-only memory you can't change the contents programmable ROM means for example let us say there is some part of the system which is failing you want to disable it or you want to send little higher voltage to it so that it starts to work now since this part is already failing or you suspect that it would fail in the field you've already programmed calibrate the system in such a way that this chip would generate a higher voltage than regular these theorems are fuse based and they are typically used for calibrating the system so that it operates at an Optimum say voltage or frequency or throughput so what exactly the difference with the eeprom and this problem I am not able to get right okay e problem is electrically programmable you can apply a voltage of 12 volts to the chip and you can get it going Fusion may not be electrically programmable fuse ROM you will actually have to physically blow away the fuse blow away the fuse means you will actually have to throw a laser at a particular place then rate the Heat and burn away the metal from there so that the connection to vdd or to ground is removed something like that so but both are used for the same purpose functionality wise yeah but fuse programmed uh you do it you do fuse programming inside the Fab itself eprom you can do at the customer end okay so so like in this Mass program uh the instructions that we need to be for example boot sequence they are fabricated uh at the Fab itself similar is for this problem also no no okay problem will not store instructions from will only store calibration data what is that actually what does that mean suppose my chip is manufactured in slow lot I now want to operate this particular chip or this entire lot at 1.14 volts instead of 1.1 volts so that I get the required frequency this is a one-time programmation that you will do at the in the Fab by blowing away some fuses this is not about storing new set of instructions or a particular set of instructions is that okay so like after I have fabricated at a particular lot I am then I'm doing kind of initial kind of fabrication step for uh this to make it okay after the fabrication has happened I estimate what lot the device is at yes sir now I simply fix that okay if it is a fast lot then the leakage is going to be very high so I have to lower down the voltage of application so that leakage comes under control because it's already fast performance is not an issue for me so I will trim I will say that okay instead of operating at 1.3 volts operate the chip at 1.26 volts okay and this calibration will be done using this prom yes okay so clear for everyone yeah yes any questions please feel free to ask so and this last step of the problem will be done and also in the Fab itself yes okay so uh hello yes Shiva yeah sir uh I was able to understand like uh prom is used for storing desynchronization information as you told like if tell like if we have made a chip in fast load and we will okay okay so we do not make a Japan faster that's manufactured we categorize it it is in a first load we identified that it is in the past lot yes so so uh how P Rom is used there like to store the information like we need to use it in like lower voltages yeah so what I will do is uh the voltage Regulators on the chip they always have some calibration bits okay so I will make my logic in such a way that the information from the P Rom goes and triggers those calibration bits in such a way that this voltage regulator now generates only 1.26 volts instead of 1.3 volts or 1.14 volts instead of 1.1 volt okay okay yes similarly let us say when we are in the memory design course let us say there is some location inside the memory that is failing I can add some additional redundant memory in the in the overall chip and say that if this particular location is failing uh if if this failing location is addressed then instead of a point reaching out to that failing location go to this replacement location yes this again is programmed by using p ROMs yes sir okay okay thank you yeah anything is great so now whatever be these all these kinds of memories whether it is uh P Rom or ROM or fifo or SRAM or dram or Flash whatever it is uh there is a structure so yes please yes but can I say that the P Rom is storing the information of like which cell is working properly and how many extra cells are available to us so that it can allocate in the future um Freedom will not do those evaluation with us theorem will only store the location of the failing himself for example and the sharing location now there will be some Logic on the chip which would say okay if this location is failing let us redirect the addressing to that other location so there will be a controlling unit also in the memory section oh yes and control this oh yes we will look at the insides of the memory in just a little while I was about to go there on"
rEYKLt1pMAI,in fact so but before we go there let's just have a quick look at you know how srams drams and Flash compare on various access so srams are very very fast they have uh access times at times of the order of hundreds of picoseconds in Advanced Technologies drams are fast their excess times is all the order of nanoseconds tens of nanoseconds Flash is much slower if you want to access a flash the access time is of the order of a few micro seconds so flash cannot really be used as a cache for cash purposes you need an SRAM only L2 or L3 cache you could think of drams but not even not flash there there is another reason why flash cannot be used in in L1 or L2 caches why because look at the third row the parameter called endurance endurance means how many reads and rights can I do on this particular memory for srams and Iran's it's almost infinite but for flash it's it's of the order of say tens of thousands now how does that limit Slash from being used as a cache because if you can for example if you can do only one lakh writes onto a flash you have a chip that is operating at uh one gigahertz and memory activity factor is 0.1 gigahertz activities after 0.1 how many accessors do you need to the memory within one second quickly 0.1 giga 100 million um of this hundred million cycles per second let us say only 10 percent were right Cycles so how many write Cycles 10 million 10 10 million how many times did we say a flash could read or write could you write into the Flash so in less than a second the trip will be done are you able to see this so even if I improve the speed of flash so that it matches the speed of the processor due to endurance reasons I cannot use Flash as a Dash flash however is a very very good and dense uh means of data storage uh in the non-volatile space is that okay are you able to see this aspect how did this endurance decide for um okay so for now you can say that and endurance is decided by some reason but we know for Flash that endurance is low right so if you would do the course course of solid state devices and and study about reliability mechanisms there you will see that when us when a device is operated at a very high voltage its reliability degrades very significantly so you can use the device at a very high voltage only for a short duration of time as you will see in the later part of the course when we design flashes and when we do read and write in the flashes we operate the memory at very high voltages 12 volts 15 volts 18 volts um so the device degradation is very fast and therefore flashes have low endurance is that okay so then uh another thing is that drams require refresh drams are Dynamic Random Access Memories as we discussed just a little while back drams would store information on capacitors in form of charge so capacitors uh would not be able to replenish any loss of charge due to leakage and all devices leak so after some time the charge on the dram capacitor would would kind of go so weak that you cannot read that dram capacitor so what we do is we write into the dram capacitor at every defined predefined frequency this right operation or this periodic right operation is called refresh and that is the reason why dram also consumes more power than srams and Flash memories is that okay we will go into much more detail of what Refreshers and how it is done but for now just comparing these three types and arriving at a conclusion that I I can use S transfer Alvin A2 caches drams for L2 L3 caches flash for main mem for for final storage are you able to see this this is where we started today's session from are you able to see the logic behind usage the way we use the Vishal so the L1 and L2 caches are volatile processor actually interact mostly with them so isn't it a bad thing like whenever the power is lost this interaction will administrate will get high yes you lose that data generally generally in some application we store the instruction in processor itself so those instructions will never erased it if I'm not wrong because the power is lost the processor goes off but again when the power is on like in the case of Arduino if I say if I program uh if I remove this power supply again connected it will hold the program which I had uploaded okay so what happens in subsystems is that there would be some non-volatile memory also placed on the chip so the power down sequence involves storing the present state of the processor onto that non-volatile memory and the boot up operation involves recovering that information from the non-volatile memory and booting the system up in the desired manner okay so whenever the power is on this booting will load this instruction in volatile yes okay Akash [Music] and it also requires a periodic pressure but still we use dram is that it because uh Sam consumes more area due to that trade-off yes drams are much denser than srams and in memories area is Diamond diamonds harshit so what does scalable mean you're coming we're just coming to that so scalable means uh so what is technology scaling foreign yeah we are able to reduce the size of devices and still maintain the frequency of operation or get a better frequency of operation better power and all that that is what scaling meant reduce being able to reduce the size of devices so while srams is only transistors based all transistors so you can scale it flash as you will see later is also only transistors primarily so you can scale that also to some extent but drams drams we're talking about transistors and capacitors so capacitors if you reduce their area what happens the value of the capacitor reduces so you can now store lesser charge onto the capacitor so scalability goes for a task because lesser charge means I have to so lesser charge means that that charge the charge would become not readable much earlier than than previous implementation previous technology so it means that the refresh frequency has to be increased it means memory would not be accessible for all those refreshed Cycles which means that overall throughput that I can expect from this particular memory would reduce so that is why we are saying that it is bad in terms of scalability does that help yes sir so if we are using uh like capacitors with lesser areas why the frequency of refreshing is increasing so if the capacitor is of lesser area what happens the value of the capacitor will decrease reduces the value of the capacitor reduces even if we say I keep the same voltage what happens to the charge stored on the capacitor it will also decrease it will reduce now let us say the devices are also leaking exactly the same way as earlier technology in fact device leakage increases as you scale let us say it is the same as the earlier technology now what happens now we will not able to read like it will leak more it will reach more so I will need to refresh faster okay okay yes or no clear everyone is clear okay in Flash you said we use some high voltages because because of his endurance is good but he was saying that the power is low yeah because you use other schemes so that even in the presence of that high voltage uh the currents are low okay overall overall you do lots of things in parallel when you go to that high voltage and therefore you still need lesser power only you will see you'll come to the flash implementation later okay,https://www.youtube.com/watch?v=rEYKLt1pMAI,"Link: https://www.youtube.com/watch?v=rEYKLt1pMAI
Transcript: in fact so but before we go there let's just have a quick look at you know how srams drams and Flash compare on various access so srams are very very fast they have uh access times at times of the order of hundreds of picoseconds in Advanced Technologies drams are fast their excess times is all the order of nanoseconds tens of nanoseconds Flash is much slower if you want to access a flash the access time is of the order of a few micro seconds so flash cannot really be used as a cache for cash purposes you need an SRAM only L2 or L3 cache you could think of drams but not even not flash there there is another reason why flash cannot be used in in L1 or L2 caches why because look at the third row the parameter called endurance endurance means how many reads and rights can I do on this particular memory for srams and Iran's it's almost infinite but for flash it's it's of the order of say tens of thousands now how does that limit Slash from being used as a cache because if you can for example if you can do only one lakh writes onto a flash you have a chip that is operating at uh one gigahertz and memory activity factor is 0.1 gigahertz activities after 0.1 how many accessors do you need to the memory within one second quickly 0.1 giga 100 million um of this hundred million cycles per second let us say only 10 percent were right Cycles so how many write Cycles 10 million 10 10 million how many times did we say a flash could read or write could you write into the Flash so in less than a second the trip will be done are you able to see this so even if I improve the speed of flash so that it matches the speed of the processor due to endurance reasons I cannot use Flash as a Dash flash however is a very very good and dense uh means of data storage uh in the non-volatile space is that okay are you able to see this aspect how did this endurance decide for um okay so for now you can say that and endurance is decided by some reason but we know for Flash that endurance is low right so if you would do the course course of solid state devices and and study about reliability mechanisms there you will see that when us when a device is operated at a very high voltage its reliability degrades very significantly so you can use the device at a very high voltage only for a short duration of time as you will see in the later part of the course when we design flashes and when we do read and write in the flashes we operate the memory at very high voltages 12 volts 15 volts 18 volts um so the device degradation is very fast and therefore flashes have low endurance is that okay so then uh another thing is that drams require refresh drams are Dynamic Random Access Memories as we discussed just a little while back drams would store information on capacitors in form of charge so capacitors uh would not be able to replenish any loss of charge due to leakage and all devices leak so after some time the charge on the dram capacitor would would kind of go so weak that you cannot read that dram capacitor so what we do is we write into the dram capacitor at every defined predefined frequency this right operation or this periodic right operation is called refresh and that is the reason why dram also consumes more power than srams and Flash memories is that okay we will go into much more detail of what Refreshers and how it is done but for now just comparing these three types and arriving at a conclusion that I I can use S transfer Alvin A2 caches drams for L2 L3 caches flash for main mem for for final storage are you able to see this this is where we started today's session from are you able to see the logic behind usage the way we use the Vishal so the L1 and L2 caches are volatile processor actually interact mostly with them so isn't it a bad thing like whenever the power is lost this interaction will administrate will get high yes you lose that data generally generally in some application we store the instruction in processor itself so those instructions will never erased it if I'm not wrong because the power is lost the processor goes off but again when the power is on like in the case of Arduino if I say if I program uh if I remove this power supply again connected it will hold the program which I had uploaded okay so what happens in subsystems is that there would be some non-volatile memory also placed on the chip so the power down sequence involves storing the present state of the processor onto that non-volatile memory and the boot up operation involves recovering that information from the non-volatile memory and booting the system up in the desired manner okay so whenever the power is on this booting will load this instruction in volatile yes okay Akash [Music] and it also requires a periodic pressure but still we use dram is that it because uh Sam consumes more area due to that trade-off yes drams are much denser than srams and in memories area is Diamond diamonds harshit so what does scalable mean you're coming we're just coming to that so scalable means uh so what is technology scaling foreign yeah we are able to reduce the size of devices and still maintain the frequency of operation or get a better frequency of operation better power and all that that is what scaling meant reduce being able to reduce the size of devices so while srams is only transistors based all transistors so you can scale it flash as you will see later is also only transistors primarily so you can scale that also to some extent but drams drams we're talking about transistors and capacitors so capacitors if you reduce their area what happens the value of the capacitor reduces so you can now store lesser charge onto the capacitor so scalability goes for a task because lesser charge means I have to so lesser charge means that that charge the charge would become not readable much earlier than than previous implementation previous technology so it means that the refresh frequency has to be increased it means memory would not be accessible for all those refreshed Cycles which means that overall throughput that I can expect from this particular memory would reduce so that is why we are saying that it is bad in terms of scalability does that help yes sir so if we are using uh like capacitors with lesser areas why the frequency of refreshing is increasing so if the capacitor is of lesser area what happens the value of the capacitor will decrease reduces the value of the capacitor reduces even if we say I keep the same voltage what happens to the charge stored on the capacitor it will also decrease it will reduce now let us say the devices are also leaking exactly the same way as earlier technology in fact device leakage increases as you scale let us say it is the same as the earlier technology now what happens now we will not able to read like it will leak more it will reach more so I will need to refresh faster okay okay yes or no clear everyone is clear okay in Flash you said we use some high voltages because because of his endurance is good but he was saying that the power is low yeah because you use other schemes so that even in the presence of that high voltage uh the currents are low okay overall overall you do lots of things in parallel when you go to that high voltage and therefore you still need lesser power only you will see you'll come to the flash implementation later okay"
p6Aq5wKpd-g,so yes there's a question okay so uh now as I was mentioning whether it is a flash or a fifo or an SRAM or a dram there is one structure a common common structure to the memories all these memories memories are typically organized as arrays huh so as many rows and as many columns the number of rows and columns can be different they could be the same so on the row side you need to have a decoder address decoder to select the desired row desired location um and on the column side you need to have what we call as an IO interface which would receive data to be written and give out the data output so IU circuits are required in addition to that to manage the aspect ratio of the memory you will also have what is called as a column multiplexer so typically whichever memory you talk about these three components would actually exist in fact there would be an additional component over here which we can we can place it over here which is called as control block so all the control signals would come to this block whether I want to read or write signals like clock signals like let us say sleep Etc would come to this control block this control block is in those terms a kind of a brain for the memory okay so when signals come to this control block this control block uh sends out uh signals across the board to Max uh to the max block to the i o block to the decoders so that they can operate in the desired manner if it's a read cycle the sense amplifiers and the io would get activated if it's a right cycle the right driver would get activated so the control block is kind of The Mastermind of the memory everyone follows whatever the control block says hmm and in those terms the control Block in one way manages what we call as the state machine of the memory you don't need to go into the details of the state machine what I want to my intent of sharing the state machine with you only is that memory could be in multiple States it could be an idle State simply waiting for the next clock cycle it could be in three task stage getting ready for the next clock cycle it could be in ready States okay I'm ready now give me the new address it could be in read stage oh I am doing the read operation it could be in right state I am doing right operation it could be an outputting stage where read operation has happened completely but my uh output latches will now throw out the data hmm and it could mean standby state where we say that memory can't be accessed even if you give it a clock it isn't standby it's it's it's not being used and these are just few representative stages there could be other states like test there could be other states like uh sleep there could be other states like scan so all these different states of operation of the memory are controlled by the control block over here any questions so so the different states in the memory would be I will be deciding exactly where the control would be also be getting some kind of a deciding that which state to remember here but what will be the deciding factor like which state you should go in you tell me so I mean is it like the control will be like the uh it will be uh like communicating with the processor and so the processor will give the signal whether I want to read some location some address location or not is it not yes sir so that read signal is coming to the control block okay and then it is passing to the decoder or the i o whatever the kind of operation it is masterminding it is it is managing the entire show for the processor now so like it is the interface between we can say the memory and the processor so if you want to call your brain as the interface between the between your body and the outside environment yes we can call it as an interface okay and so by the memory do I uh call this the array the memory or this whole decoder this whole infrastructure as the memory so the entire thing is called a memory the array is called memory array okay so this is a bit actually we are reading bit right here generally in the case uh if you have the byte addressable memory like uh if I am correlating it with the ca course we have Mar and MDR I suppose the input of the decoder may be Mar register and the output of this i o may be MDR so MDR will will will be of 8-bit something size that depends so uh okay the processor that you're looking at you are you are looking at it only in terms of how many bits um memories could have let us say for example if you also want to implement what is called as error correction codes you have heard about error correction codes we pass some code to check like uh there's the code like when we receive some signal we check it there is a signal element with parity or something yeah so we encode any data and at the receiver end and then we send it and then at the receiver end we decode it and we also do some validation checks if there is an error we will be able to tell that there was an error in the transmission and some number of Errors you will also be able to correct so that is why it is called as error correction codes so instead of storing say 32 bits you would store 39 bits inside the memory and then apply ECC Logic on it okay so uh in in CA you talked about MDR and Mar where addresses were also let us say eight bits only and data bus was also only eight bits but for an SRAM if there are 100 uh or 1000 locations how many address bits do you need to decode 12 10 or 9 or 10. we'll need 10 locations 10 addresses so what that means is that your uh that your system processor will send overall memory address and two cycles that does not mean that your memory will have only eight address bits the processor has to send all the required bits how it sends it it is the protocol that the processor will set okay got it I'm sorry God is understand huh so control in those terms is the brain of the memory it tells what needs to be done so like your brain tells your hand how it needs to move how how your leg needs to move how your head needs to move everything in the same way control kind of manages the entire orchestrates the operation of the memory at all times so yes so just uh like you mentioned about the error correction code so select one of this team is for example this is a bitter B scheme also but if I am moving towards the higher more kind of error correction then the number of states that I need to store also increases yeah so will will I basically the memory would be specifically designing for that uh more kind of accuracy or like the same kind of array and it would be controlled by this control Legion depending on how it needs to control so if as a system designer for example you want to design a automotive chip so as a system designer you say that I want better be kind of decoding there then you know that you will need this kind of storage space so you order a larger memory you place a larger memory there okay okay so my memory would also be like application specific for the uh and that error correction will be in an application like what happened so there is some processor that wants that are error correction codes another one doesn't want to waste area and time on it because the application is such so they will not use it they will use a smaller memory so memory will not do any magic memory is there just to store the information if you have to store more bits because you want error correction then you lead the larger memory Okay so a complex State machine is what a memory would usually involve and the signal flow inside the memory would look something like this you have as I said address clock rewrite all those signals coming here the clock generator would generate an internal clock pre-decoding addresses addresses will generate an additional or internal set of addresses they will go to a post decoder they will generate what we call as a word line okay the word line would select the memory cells in in the entire row so all these memory cells in this row would get selected the memory cells will themselves discharge what we call as bit lines BL okay they will go to what we call as sense amplifiers since amplifiers will be enabled through a control signal called let us say send span amplifier sa enable and the output will be thrown out through the output buffers I very quickly ran you through this this signal flow who will now repeat it for me maybe I can do that yeah please uh so once uh whenever a read operation is required the clock generator or generates a clock signal along with uh also we'll have the address uh of the memory location and this address and the clock are being fed to the uh decoder which decodes the word uh the word line which has to be active from which the particular word uh or other sequence of bits are selected and once the word line is set High then uh the bit lines are charged or discharged accordingly and then these are available at the ends of the sense amplifier and uh during this read operation the send sum for enable is also set high and uh uh the output the output of the sense amplifier uh determines which bit is read from the memory cell and these are sent to the buffers very good thank you Ranjit is this clear to everyone anyone else has wants to go through this flow again or has a question two decoders the pre-decoder will decode the address of CPU like whatever it is gives and the post decoder what it Executives [Music] okay so let us say I have 1000 words in the memory um uh to decode 10 bits how many how big a nand gate do you need 10 input nand gate you've already done the DVD course do you want to generate a 10 input nand Gates 10 a 10 size of nmos it will be very slow also and it can fail such a long stack you're operating at one volt only and 10 nmoses each one of them will have some voltage drop across themselves so what you how do you implement it an input nand gate we also saw that example in the previous course how do you generate a large large input and gate or a nand gate you do it in stages you say okay I will use three input nand gates in the first stage they will lead to some out some number of outputs and I will use a three input nand gate at the second stage also something like that so pre-decoding is the first stage of address decoding post recording is the second stage of address decoding the Mind 3D code and post record would decode your 10 bits of address into one output so generally SD card which we have in the phone will carry only the array part or the complete this architecture you tell me uh what comes to my mind is I think it should carry the uh all architecture because I think if we just add the array then we need to have the i o ports and all also earphones yeah so you have in in terms of sdram or something you will see there are only eight data databits that are available on the on the chip so but your dram array would have how many columns thousands of columns how will you access so you have to have all these control circuitry everything in there that is what a memory is otherwise you would call it a memory array so so the clock is first like the clock is at the very first time is fled directly into this post recorder right block is fed directly to the clock signal is only fed into this post decoder I just wanted to do with the cloud generator okay and the clock generator uh then feeds the clock into the post decoder yeah it would generate some other internal clocks one of the antenna clock goes to the post decoder so is the clock only going to the post recorded so my question was this no this is a super simplified representation for the first glimpse of operation inside the memory okay answer uh like after the sense amplifier you have user output buffer so what exactly it is offering here the automotive so a sense amplifier would say generate some output 0 or 1 sure but the output may actually see a load of 200 picofarads okay okay good if you want to drive that bigger load you need some buffer okay okay sir okay so buffer is just a buffer okay fine answer the latch here this latch after the sense amplifier yeah we will see okay so okay just know that there is a latch the purpose of it we will see data okay so answer just one more thing like uh when we have enabled the whole word line so bmd for example we have to read from a particular Cellular location so we do the uh read from a bit line for example as you said so uh like before that reading operation start it will also enable that sense enable signal like only when then um before or after we will see later okay so now there is enable signal that comes okay yes I will so can't we just say the pre-decoder is deciding whether to read or write says it is in the control block no so do the pre-decoder and post recorder are deciding the like the bit line which bit line which we should bring in which so we should arrive no that's I am confused are deciding which word line to select okay yeah okay yes sir so after like we post DEC order and pre-degoder decides which word line to select then how do we commit the bit line exactly which deadline to be selected in that particular word line okay so if you noticed in the one of the previous slides I said there is something called a column maths in the i o so that is a column Max is also a kind of a decoder or a encoder so we'll use that to select the bit line Okay so so again as I said this is not the memory this is a super super super simplified representation of a memory just to give you a quick glimpse of what happens there but I am so happy that all these questions are coming it means sir I I want to add one thing like it may be correct or wrong uh what comes to my mind is 32-bit resistor 60 64 bit uh we have PC right so if we add this address basis so the columns will the rows will increase the columns will not increase so by this the essay the sense amplifier will not increase so I think it is Advantage for them for that reason we are moving for higher addresses okay now we will see we will talk about it in the next class every time we will talk about this uh how how the increase in addressing results and change in the size of the memory array we'll look at it in the next class okay listen so remind me also that we have to I will anyway pick it up that is scheduled for the next class but if I don't go in the required detail you can remind here's the tunnel amplifier um don't worry when will you come to the memory cell and the next to next class we will talk about what happens on the bit lines and the read operation is happening we will discuss the bit lines we will discharge the bit lines and that differential and charge you know one of the bit lines will discharge the other one would remain at vdd this differential we would amplify in the sense amplifier we'll come to that don't worry but I'm happy that these questions are coming that was the intent of taking you through this this animation the purpose is solved okay so this was a semblance of read operation if you want to do a write again it is something similar you would use the clock generation you will do pre-decoding Post decoding you will generate the word line but now instead of the sense amplifier you have what you call as a right buffer right driver hmm and this right driver makes one of the bit line to zero the other bit nine to one and when the word line is selected I am able to write information inside the memory cell okay so this wordline selection path remains exactly the same but for the right operation because the data is coming from outside this path gets enabled okay and as we were talking about you know they were asking about how many clocks are there and is clock only going to the post decoder you see I'm talking about a right clock over here I'm showing it as coming from here but actually it is the clock generation or the cloud generation circuitry that sends the right clock okay any questions so uh in a memory where which can which is able to read and write uh perform both the operations so we use sense amplifier and this right buffer uh simultaneously uh not simultaneously we have both of them placed next to each other we use them based on what operation is required yes sir yes so not simultaneously yes okay we have to help so for every bit line uh do we need a right buffer and a and a sense amplifier or like only two for all the bit lines when we talk about this aspect ratio and the concept of column marks in the next class and later when we will talk about IO design that is when we will see how to you know what is the uh like you may have them on every bit line or you may not have them in a very bit line you may have them on a cluster of bit lines so that is that that is a design flexibility that we have with us yes okay okay and as designers that is the freedom that you should exercise later tala you had a question yes sir uh I have a question in the writing operation there are two parts like uh right buffer and a pre-decorder also has an input so so we are this writing operation what is go where does the information go from the D part or so just like the read operation also had two parts there was a row decoder and uh line generation circuit and there was an output uh determination circuit which is called the sense amplifier over here there is a row decoder and line generation circuit and there is a input input conditioning circuit which is called right driver which helps to write inside the memory cell similar most of my question is that like what ghost means the information which you are writing goes through the right buffer or through the pre-depoter side you tell me where is the deep and Sean yeah it will go from the ribofrothead and what will go um you're writing on one particular address now that address will come from come to go to the pre-decoders and the post decoder okay [Music] sir in the uh in the uh in IO we have Mark says right so in the read operation uh I assume I assume it as n is to one now its reverse one is to n type of mux yeah so this would be a Max DMX so you have to have encoding and decoding both implemented in the i o region is that okay yes sir yeah so we will stop here,https://www.youtube.com/watch?v=p6Aq5wKpd-g,"Link: https://www.youtube.com/watch?v=p6Aq5wKpd-g
Transcript: so yes there's a question okay so uh now as I was mentioning whether it is a flash or a fifo or an SRAM or a dram there is one structure a common common structure to the memories all these memories memories are typically organized as arrays huh so as many rows and as many columns the number of rows and columns can be different they could be the same so on the row side you need to have a decoder address decoder to select the desired row desired location um and on the column side you need to have what we call as an IO interface which would receive data to be written and give out the data output so IU circuits are required in addition to that to manage the aspect ratio of the memory you will also have what is called as a column multiplexer so typically whichever memory you talk about these three components would actually exist in fact there would be an additional component over here which we can we can place it over here which is called as control block so all the control signals would come to this block whether I want to read or write signals like clock signals like let us say sleep Etc would come to this control block this control block is in those terms a kind of a brain for the memory okay so when signals come to this control block this control block uh sends out uh signals across the board to Max uh to the max block to the i o block to the decoders so that they can operate in the desired manner if it's a read cycle the sense amplifiers and the io would get activated if it's a right cycle the right driver would get activated so the control block is kind of The Mastermind of the memory everyone follows whatever the control block says hmm and in those terms the control Block in one way manages what we call as the state machine of the memory you don't need to go into the details of the state machine what I want to my intent of sharing the state machine with you only is that memory could be in multiple States it could be an idle State simply waiting for the next clock cycle it could be in three task stage getting ready for the next clock cycle it could be in ready States okay I'm ready now give me the new address it could be in read stage oh I am doing the read operation it could be in right state I am doing right operation it could be an outputting stage where read operation has happened completely but my uh output latches will now throw out the data hmm and it could mean standby state where we say that memory can't be accessed even if you give it a clock it isn't standby it's it's it's not being used and these are just few representative stages there could be other states like test there could be other states like uh sleep there could be other states like scan so all these different states of operation of the memory are controlled by the control block over here any questions so so the different states in the memory would be I will be deciding exactly where the control would be also be getting some kind of a deciding that which state to remember here but what will be the deciding factor like which state you should go in you tell me so I mean is it like the control will be like the uh it will be uh like communicating with the processor and so the processor will give the signal whether I want to read some location some address location or not is it not yes sir so that read signal is coming to the control block okay and then it is passing to the decoder or the i o whatever the kind of operation it is masterminding it is it is managing the entire show for the processor now so like it is the interface between we can say the memory and the processor so if you want to call your brain as the interface between the between your body and the outside environment yes we can call it as an interface okay and so by the memory do I uh call this the array the memory or this whole decoder this whole infrastructure as the memory so the entire thing is called a memory the array is called memory array okay so this is a bit actually we are reading bit right here generally in the case uh if you have the byte addressable memory like uh if I am correlating it with the ca course we have Mar and MDR I suppose the input of the decoder may be Mar register and the output of this i o may be MDR so MDR will will will be of 8-bit something size that depends so uh okay the processor that you're looking at you are you are looking at it only in terms of how many bits um memories could have let us say for example if you also want to implement what is called as error correction codes you have heard about error correction codes we pass some code to check like uh there's the code like when we receive some signal we check it there is a signal element with parity or something yeah so we encode any data and at the receiver end and then we send it and then at the receiver end we decode it and we also do some validation checks if there is an error we will be able to tell that there was an error in the transmission and some number of Errors you will also be able to correct so that is why it is called as error correction codes so instead of storing say 32 bits you would store 39 bits inside the memory and then apply ECC Logic on it okay so uh in in CA you talked about MDR and Mar where addresses were also let us say eight bits only and data bus was also only eight bits but for an SRAM if there are 100 uh or 1000 locations how many address bits do you need to decode 12 10 or 9 or 10. we'll need 10 locations 10 addresses so what that means is that your uh that your system processor will send overall memory address and two cycles that does not mean that your memory will have only eight address bits the processor has to send all the required bits how it sends it it is the protocol that the processor will set okay got it I'm sorry God is understand huh so control in those terms is the brain of the memory it tells what needs to be done so like your brain tells your hand how it needs to move how how your leg needs to move how your head needs to move everything in the same way control kind of manages the entire orchestrates the operation of the memory at all times so yes so just uh like you mentioned about the error correction code so select one of this team is for example this is a bitter B scheme also but if I am moving towards the higher more kind of error correction then the number of states that I need to store also increases yeah so will will I basically the memory would be specifically designing for that uh more kind of accuracy or like the same kind of array and it would be controlled by this control Legion depending on how it needs to control so if as a system designer for example you want to design a automotive chip so as a system designer you say that I want better be kind of decoding there then you know that you will need this kind of storage space so you order a larger memory you place a larger memory there okay okay so my memory would also be like application specific for the uh and that error correction will be in an application like what happened so there is some processor that wants that are error correction codes another one doesn't want to waste area and time on it because the application is such so they will not use it they will use a smaller memory so memory will not do any magic memory is there just to store the information if you have to store more bits because you want error correction then you lead the larger memory Okay so a complex State machine is what a memory would usually involve and the signal flow inside the memory would look something like this you have as I said address clock rewrite all those signals coming here the clock generator would generate an internal clock pre-decoding addresses addresses will generate an additional or internal set of addresses they will go to a post decoder they will generate what we call as a word line okay the word line would select the memory cells in in the entire row so all these memory cells in this row would get selected the memory cells will themselves discharge what we call as bit lines BL okay they will go to what we call as sense amplifiers since amplifiers will be enabled through a control signal called let us say send span amplifier sa enable and the output will be thrown out through the output buffers I very quickly ran you through this this signal flow who will now repeat it for me maybe I can do that yeah please uh so once uh whenever a read operation is required the clock generator or generates a clock signal along with uh also we'll have the address uh of the memory location and this address and the clock are being fed to the uh decoder which decodes the word uh the word line which has to be active from which the particular word uh or other sequence of bits are selected and once the word line is set High then uh the bit lines are charged or discharged accordingly and then these are available at the ends of the sense amplifier and uh during this read operation the send sum for enable is also set high and uh uh the output the output of the sense amplifier uh determines which bit is read from the memory cell and these are sent to the buffers very good thank you Ranjit is this clear to everyone anyone else has wants to go through this flow again or has a question two decoders the pre-decoder will decode the address of CPU like whatever it is gives and the post decoder what it Executives [Music] okay so let us say I have 1000 words in the memory um uh to decode 10 bits how many how big a nand gate do you need 10 input nand gate you've already done the DVD course do you want to generate a 10 input nand Gates 10 a 10 size of nmos it will be very slow also and it can fail such a long stack you're operating at one volt only and 10 nmoses each one of them will have some voltage drop across themselves so what you how do you implement it an input nand gate we also saw that example in the previous course how do you generate a large large input and gate or a nand gate you do it in stages you say okay I will use three input nand gates in the first stage they will lead to some out some number of outputs and I will use a three input nand gate at the second stage also something like that so pre-decoding is the first stage of address decoding post recording is the second stage of address decoding the Mind 3D code and post record would decode your 10 bits of address into one output so generally SD card which we have in the phone will carry only the array part or the complete this architecture you tell me uh what comes to my mind is I think it should carry the uh all architecture because I think if we just add the array then we need to have the i o ports and all also earphones yeah so you have in in terms of sdram or something you will see there are only eight data databits that are available on the on the chip so but your dram array would have how many columns thousands of columns how will you access so you have to have all these control circuitry everything in there that is what a memory is otherwise you would call it a memory array so so the clock is first like the clock is at the very first time is fled directly into this post recorder right block is fed directly to the clock signal is only fed into this post decoder I just wanted to do with the cloud generator okay and the clock generator uh then feeds the clock into the post decoder yeah it would generate some other internal clocks one of the antenna clock goes to the post decoder so is the clock only going to the post recorded so my question was this no this is a super simplified representation for the first glimpse of operation inside the memory okay answer uh like after the sense amplifier you have user output buffer so what exactly it is offering here the automotive so a sense amplifier would say generate some output 0 or 1 sure but the output may actually see a load of 200 picofarads okay okay good if you want to drive that bigger load you need some buffer okay okay sir okay so buffer is just a buffer okay fine answer the latch here this latch after the sense amplifier yeah we will see okay so okay just know that there is a latch the purpose of it we will see data okay so answer just one more thing like uh when we have enabled the whole word line so bmd for example we have to read from a particular Cellular location so we do the uh read from a bit line for example as you said so uh like before that reading operation start it will also enable that sense enable signal like only when then um before or after we will see later okay so now there is enable signal that comes okay yes I will so can't we just say the pre-decoder is deciding whether to read or write says it is in the control block no so do the pre-decoder and post recorder are deciding the like the bit line which bit line which we should bring in which so we should arrive no that's I am confused are deciding which word line to select okay yeah okay yes sir so after like we post DEC order and pre-degoder decides which word line to select then how do we commit the bit line exactly which deadline to be selected in that particular word line okay so if you noticed in the one of the previous slides I said there is something called a column maths in the i o so that is a column Max is also a kind of a decoder or a encoder so we'll use that to select the bit line Okay so so again as I said this is not the memory this is a super super super simplified representation of a memory just to give you a quick glimpse of what happens there but I am so happy that all these questions are coming it means sir I I want to add one thing like it may be correct or wrong uh what comes to my mind is 32-bit resistor 60 64 bit uh we have PC right so if we add this address basis so the columns will the rows will increase the columns will not increase so by this the essay the sense amplifier will not increase so I think it is Advantage for them for that reason we are moving for higher addresses okay now we will see we will talk about it in the next class every time we will talk about this uh how how the increase in addressing results and change in the size of the memory array we'll look at it in the next class okay listen so remind me also that we have to I will anyway pick it up that is scheduled for the next class but if I don't go in the required detail you can remind here's the tunnel amplifier um don't worry when will you come to the memory cell and the next to next class we will talk about what happens on the bit lines and the read operation is happening we will discuss the bit lines we will discharge the bit lines and that differential and charge you know one of the bit lines will discharge the other one would remain at vdd this differential we would amplify in the sense amplifier we'll come to that don't worry but I'm happy that these questions are coming that was the intent of taking you through this this animation the purpose is solved okay so this was a semblance of read operation if you want to do a write again it is something similar you would use the clock generation you will do pre-decoding Post decoding you will generate the word line but now instead of the sense amplifier you have what you call as a right buffer right driver hmm and this right driver makes one of the bit line to zero the other bit nine to one and when the word line is selected I am able to write information inside the memory cell okay so this wordline selection path remains exactly the same but for the right operation because the data is coming from outside this path gets enabled okay and as we were talking about you know they were asking about how many clocks are there and is clock only going to the post decoder you see I'm talking about a right clock over here I'm showing it as coming from here but actually it is the clock generation or the cloud generation circuitry that sends the right clock okay any questions so uh in a memory where which can which is able to read and write uh perform both the operations so we use sense amplifier and this right buffer uh simultaneously uh not simultaneously we have both of them placed next to each other we use them based on what operation is required yes sir yes so not simultaneously yes okay we have to help so for every bit line uh do we need a right buffer and a and a sense amplifier or like only two for all the bit lines when 
we talk about this aspect ratio and the concept of column marks in the next class and later when we will talk about IO design that is when we will see how to you know what is the uh like you may have them on every bit line or you may not have them in a very bit line you may have them on a cluster of bit lines so that is that that is a design flexibility that we have with us yes okay okay and as designers that is the freedom that you should exercise later tala you had a question yes sir uh I have a question in the writing operation there are two parts like uh right buffer and a pre-decorder also has an input so so we are this writing operation what is go where does the information go from the D part or so just like the read operation also had two parts there was a row decoder and uh line generation circuit and there was an output uh determination circuit which is called the sense amplifier over here there is a row decoder and line generation circuit and there is a input input conditioning circuit which is called right driver which helps to write inside the memory cell similar most of my question is that like what ghost means the information which you are writing goes through the right buffer or through the pre-depoter side you tell me where is the deep and Sean yeah it will go from the ribofrothead and what will go um you're writing on one particular address now that address will come from come to go to the pre-decoders and the post decoder okay [Music] sir in the uh in the uh in IO we have Mark says right so in the read operation uh I assume I assume it as n is to one now its reverse one is to n type of mux yeah so this would be a Max DMX so you have to have encoding and decoding both implemented in the i o region is that okay yes sir yeah so we will stop here"
3MptvF9YkGk,now let us look at the signal flow in terms of timing diagrams we said that clock comes clock leads to generation of what is it called as cki and CK internal okay in a little while after decoding happens they will generate what is called as word line and reference word line and on the io side we will generate a right clock the same signal that I kept as W clock in the previous slide when the right clock gets selected what happens uh bit lines because the right driver would do something one of the bit lines would discharge the other bit line will remain at 1. the reference bit line would also discharge and after the word line slash reference word line are selected are generated what happens we generate a signal which is called as write detect which kind of sensors that the contents in one reference cell have been written hmm after I detectors received we generate a reset signal after the research you know we had done until the right operation getting completed in the previous slide now I'll be talking adding an additional step of reset once we know that this ensemplifier has operated once we know that the write detect has come once we know that the memory operation the intended operation of this particular cycle has been operated memory it says generates an a reset internally okay so uh this is true for almost all the embedded exams even drams even Flash so this is called as sales timing means that memory times itself and tells now I can reset the memory like I can now be reseted um so what why is it important because now I am not dependent on external clocks duty cycle the external clock frequency does not impact my memory operation let us see how why this is important now after this reset comes what happens the clock internal reset subsequently word lines get reset bitline is pre-charged and after the bit lines are also pre-charged everything is done write it goes down and reset goes down okay now your memory is all ready you know this was the initial State the state and the initial state are the same are you able to see this now your red memory is ready to accept the next clock Edge now why is this sequencing important to be kept separate from um external clock any ideas you have a question a server firstly I didn't understand what is this internal clock okay we will come to that anything else and then what is the difference between the reference word line and the word line and what is the difference between the bit line and the reference right bit line okay anything else uh that's it sir okay so any other questions so everything else is clearer okay so uh Ranjit the question that you posed actually has the answer to my question in the net search uh we do not use external clock for generating all the internal signals there are two reasons behind it one is that internally the clock would need inside the memory the clock needs to go to numerous places we said that the clock would go to the all the row decoders we said the clock will go to all the iOS you see we talked about that that there is a write clock that has to go to the iOS to activate the right driver we said there's a clock that goes to the row decoders to activate the row decoders word line generation and so on yes so if we use the external clock to do all that then the total load on the external clock will be humongous okay it is absolutely unacceptable for any IP for any IP whether it is a memory or a PLL or or a standard cell so we talked about standard cells in the previous course but I'm saying even plls ADC Dax that you may do in in mixed signal courses even even for those the input capacitance of any pin has a limit you cannot keep that input capacitance Beyond a particular threshold for some technology it could be 10 Center farads for another it could be 25 cent the farads for some it would be 30 pentofarads or 50 pentofarads but you will see there is always a limit okay and if you travel clock throughout the memory the way we need it to be traveled uh that capacitance would go so high that this would not work so you somehow need to buffer it and somehow you need to generate some internal clock so does this part help that there has to be some buffering something which is internal to the memory and not the external clock yes sir now when we are generating The Sentinel clock we want to do something else we want to say that see now memory for that matter you will realize as you proceed that the memory read operation and write operation can be very slow which means that you want to keep the word line on for a significant amount of time and the remaining reset operation can actually happen very very fast so the low period of the clock need not be very high so you want a very long high period of the clock with very small low period of the clock that is what the memory requirement is however when you talk of a PLL what is the typical duty cycle you would want it to operate at a typical clock generator any clock signal that you would have seen any oscillator what does it do it says almost 50 High Time almost 50 percent low time is it not the case yes sir yeah so now let us take the example that my memory needed two nanoseconds of high period and 0.5 nanoseconds of low period so in fact totally my memory could operate in 2.5 nanosecond let us say that is the fastest speed at which memory could operate can we say this now this is a hypothetical case and this is too much simplification also okay but let us say that in total 2.5 nanoseconds our memory could have operated of which 0.5 could have been low period and 2 could have been the preferred High period that is how my word line wanted it to be let us say that however if the clock generator's duty cycle is 50 percent what will be the frequency uh what will be the time that uh the clock generator will take two nanoseconds for the high time because that is what is required and because this is two nanoseconds the load time will also be two nanoseconds so the clock will clock frequency will now be 4 nanoseconds are you able to see this yes sir so what has happened even though I could operate at 400 megahertz because my I do not have an internal clock I said my out external clock will be used internally to the memory after buffering so maximum speed at which my system can Now operate is only 250 megahertz even though memory could operate at 400 megahertz and this 250 megahertz is constrained because of the memory only now foreign yes so what do we want to say we tell the user okay see we know the memory can operate at 2.5 nanoseconds and we need to duty cycle of 80 percent but you don't worry we will generate this internal duty cycle internally only you don't worry about it you operate at 400 megahertz you keep an external duty cycle which is at 50 only so the external clock would be like this okay but internally my cqi would would have a much longer High period does this make sense yes sir so that is also the reason why we need to generate the reset internally because if we were to use the external clock as the reset then this constraint would set in so this two nanosecond which you said uh will it take two nanosecond every time or because it depends on the reset right so the high time may change on the reset because reset is uh lowering that cki right yeah but reset will come only after okay so when we will answer unzip other questions we will see that so reset or san will come only after my write detect has come is it not yes sir where does right what does write attack depend on okay CK you know it depends upon the writing amount of time the speed of my memory cell yes you see so all this is actually driven by the speed of the memory cell actually why I why I ask is some base cell will be nearer to that decoded some are right so the time taken to this move these signals bit to bit may be different I assume yes you're right but you are assuming that all bit cells are symmetrical exactly same what if the cell Which is closest to the to the i o is also slow it could take more time than the cell which was farther away so the the in the array all beetles are not identical ah we talked about it in DVD also now you write your name 10 times more will it be identical 10 times yes sir some difference will be there so the same thing would happen with thousands and millions of copies of the memory cells also now so you cannot deterministically say that the cell which is closer to the io is also faster so what do you need to do when should the right attack signal come when should the right attack signal come everyone so when the right operation has been successfully done then we have written into the bit cell into any bit cell or all the bit cells so I mean uh the one we are targeting the address maybe the one address may have 32-bit cells a one word could be 32-bit Widener yes sir it has to be all Goods it has to be all the websites hmm so what does this mean that right detect should come after the worst case cell has also been written into are you able to see this so but we would be writing at a only not only at the whole word right we would be writing only at a particular time so do you know which word has the worst case cell but I ask you to write your name hundred times raghav can you tell me that tenth one will be the will be the worst one no so the first one would be the worst one hundredth one could be the worst one got it but how much space do you need to leave for writing your name otherwise yes sir so is this clear and this also takes us to the question that Ranjit asked why what is this ref transport line and what is this ref transmit line see the actual word into which I would be reading or writing may not be the worst word or some bit of that word could be the verse but we do not know so as memory designers what we do is we add a reference word line and a reference bit line reference word line is very similar to the real world line we will talk more about it later and reference bit line is also very similar to the real bit line in terms of total capacitors there is some modification we do but that is what we will talk about later and what we do is we ensure that the cells on the reference bit line and the reference word line ensure that they are the slowest ones through design somehow we will talk about it okay and that is what we use to generate the right detect so they are kind of references they ensure that worst case cell is also written in two or worst case cell is also correctly read that is why they are called reference wait lines and reference reference word and reference bit line Does this answer your question uh yes sir but here if we look at the bit lines so the reference bit line is much faster as compared to the bit line so yeah this doesn't ensure the required function you know so yeah look at it like this after the write detect signal comes how long how long does it take for the word line to get deselected uh okay it takes enough amount of time so that the clock so we have to keep that margin also in the picture we don't want to waste time this is just a cartoon it is fairly representative but it is still a cartoon the exact exact uh uh you know correlation so this is just a sequencing that I wanted to share with you yes but the exact delay between two different signals that would be different this is not even representative of that this is just a sequencing diagram yes sir okay yeah ragas you have a question uh yes sir so what is the word clock I mean signal does here this is right clock yes sir so I mean CK my I mean the right operation will be controlled by this right clock the right driver is controlled by the right clock okay don't worry again these are just nomenclatures I have just used some name so any any questions further any further questions because then I would want you to take you to the data sheet as to how a memory data sheet looks like I was not able to clearly understand the significance of the reset signal I was able to get that we are resetting the memory to this original position but exactly what crucial role to a sling I was not able to get that okay you you could understand that we wanted a duty cycle which is independent of the external clock yes sir yes sir so how do you bring the clock to low internal clock to low how do you create that duty cycle you need some signals no okay uh so sir like uh initially I was getting the 50 50 percent but uh based on my like reference word line I generate that high period I get the idea of that hyper how high that however the period should be and based upon that I'd select this reset signal which will basically uh determine by that low period yeah okay okay sir okay so for every memory uh the reset could come at a different time yes sir answer one more thing so are these these were reference word line reference bit line they are part of they are like actual bit lines uh in this memory array in this whole memory structure yeah what else because I was thinking that every bit line has that so but it would be I was not able to structure that how exactly they would be part of this whole design so we will see how how and where they are placed later don't forget okay the seventh year lecture that is when we will see this okay yeah anything else so the right data is telling us the right operation has completed and the verse cell also or if you now generate the reset then by the time online gets deselected right operation would be successfully completed everywhere Okay so okay so now that takes me to uh what we call as memory data sheet what is a data sheet what do you understand by the term data sheet have you seen a data sheet earlier sir why can't you use write detect as a reset signal I mean that's what you do during the read cycle yeah okay I understand,https://www.youtube.com/watch?v=3MptvF9YkGk,"Link: https://www.youtube.com/watch?v=3MptvF9YkGk
Transcript: now let us look at the signal flow in terms of timing diagrams we said that clock comes clock leads to generation of what is it called as cki and CK internal okay in a little while after decoding happens they will generate what is called as word line and reference word line and on the io side we will generate a right clock the same signal that I kept as W clock in the previous slide when the right clock gets selected what happens uh bit lines because the right driver would do something one of the bit lines would discharge the other bit line will remain at 1. the reference bit line would also discharge and after the word line slash reference word line are selected are generated what happens we generate a signal which is called as write detect which kind of sensors that the contents in one reference cell have been written hmm after I detectors received we generate a reset signal after the research you know we had done until the right operation getting completed in the previous slide now I'll be talking adding an additional step of reset once we know that this ensemplifier has operated once we know that the write detect has come once we know that the memory operation the intended operation of this particular cycle has been operated memory it says generates an a reset internally okay so uh this is true for almost all the embedded exams even drams even Flash so this is called as sales timing means that memory times itself and tells now I can reset the memory like I can now be reseted um so what why is it important because now I am not dependent on external clocks duty cycle the external clock frequency does not impact my memory operation let us see how why this is important now after this reset comes what happens the clock internal reset subsequently word lines get reset bitline is pre-charged and after the bit lines are also pre-charged everything is done write it goes down and reset goes down okay now your memory is all ready you know this was the initial State the state and the initial state are the same are you able to see this now your red memory is ready to accept the next clock Edge now why is this sequencing important to be kept separate from um external clock any ideas you have a question a server firstly I didn't understand what is this internal clock okay we will come to that anything else and then what is the difference between the reference word line and the word line and what is the difference between the bit line and the reference right bit line okay anything else uh that's it sir okay so any other questions so everything else is clearer okay so uh Ranjit the question that you posed actually has the answer to my question in the net search uh we do not use external clock for generating all the internal signals there are two reasons behind it one is that internally the clock would need inside the memory the clock needs to go to numerous places we said that the clock would go to the all the row decoders we said the clock will go to all the iOS you see we talked about that that there is a write clock that has to go to the iOS to activate the right driver we said there's a clock that goes to the row decoders to activate the row decoders word line generation and so on yes so if we use the external clock to do all that then the total load on the external clock will be humongous okay it is absolutely unacceptable for any IP for any IP whether it is a memory or a PLL or or a standard cell so we talked about standard cells in the previous course but I'm saying even plls ADC Dax that you may do in in mixed signal courses even even for those the input capacitance of any pin has a limit you cannot keep that input capacitance Beyond a particular threshold for some technology it could be 10 Center farads for another it could be 25 cent the farads for some it would be 30 pentofarads or 50 pentofarads but you will see there is always a limit okay and if you travel clock throughout the memory the way we need it to be traveled uh that capacitance would go so high that this would not work so you somehow need to buffer it and somehow you need to generate some internal clock so does this part help that there has to be some buffering something which is internal to the memory and not the external clock yes sir now when we are generating The Sentinel clock we want to do something else we want to say that see now memory for that matter you will realize as you proceed that the memory read operation and write operation can be very slow which means that you want to keep the word line on for a significant amount of time and the remaining reset operation can actually happen very very fast so the low period of the clock need not be very high so you want a very long high period of the clock with very small low period of the clock that is what the memory requirement is however when you talk of a PLL what is the typical duty cycle you would want it to operate at a typical clock generator any clock signal that you would have seen any oscillator what does it do it says almost 50 High Time almost 50 percent low time is it not the case yes sir yeah so now let us take the example that my memory needed two nanoseconds of high period and 0.5 nanoseconds of low period so in fact totally my memory could operate in 2.5 nanosecond let us say that is the fastest speed at which memory could operate can we say this now this is a hypothetical case and this is too much simplification also okay but let us say that in total 2.5 nanoseconds our memory could have operated of which 0.5 could have been low period and 2 could have been the preferred High period that is how my word line wanted it to be let us say that however if the clock generator's duty cycle is 50 percent what will be the frequency uh what will be the time that uh the clock generator will take two nanoseconds for the high time because that is what is required and because this is two nanoseconds the load time will also be two nanoseconds so the clock will clock frequency will now be 4 nanoseconds are you able to see this yes sir so what has happened even though I could operate at 400 megahertz because my I do not have an internal clock I said my out external clock will be used internally to the memory after buffering so maximum speed at which my system can Now operate is only 250 megahertz even though memory could operate at 400 megahertz and this 250 megahertz is constrained because of the memory only now foreign yes so what do we want to say we tell the user okay see we know the memory can operate at 2.5 nanoseconds and we need to duty cycle of 80 percent but you don't worry we will generate this internal duty cycle internally only you don't worry about it you operate at 400 megahertz you keep an external duty cycle which is at 50 only so the external clock would be like this okay but internally my cqi would would have a much longer High period does this make sense yes sir so that is also the reason why we need to generate the reset internally because if we were to use the external clock as the reset then this constraint would set in so this two nanosecond which you said uh will it take two nanosecond every time or because it depends on the reset right so the high time may change on the reset because reset is uh lowering that cki right yeah but reset will come only after okay so when we will answer unzip other questions we will see that so reset or san will come only after my write detect has come is it not yes sir where does right what does write attack depend on okay CK you know it depends upon the writing amount of time the speed of my memory cell yes you see so all this is actually driven by the speed of the memory cell actually why I why I ask is some base cell will be nearer to that decoded some are right so the time taken to this move these signals bit to bit may be different I assume yes you're right but you are assuming that all bit cells are symmetrical exactly same what if the cell Which is closest to the to the i o is also slow it could take more time than the cell which was farther away so the the in the array all beetles are not identical ah we talked about it in DVD also now you write your name 10 times more will it be identical 10 times yes sir some difference will be there so the same thing would happen with thousands and millions of copies of the memory cells also now so you cannot deterministically say that the cell which is closer to the io is also faster so what do you need to do when should the right attack signal come when should the right attack signal come everyone so when the right operation has been successfully done then we have written into the bit cell into any bit cell or all the bit cells so I mean uh the one we are targeting the address maybe the one address may have 32-bit cells a one word could be 32-bit Widener yes sir it has to be all Goods it has to be all the websites hmm so what does this mean that right detect should come after the worst case cell has also been written into are you able to see this so but we would be writing at a only not only at the whole word right we would be writing only at a particular time so do you know which word has the worst case cell but I ask you to write your name hundred times raghav can you tell me that tenth one will be the will be the worst one no so the first one would be the worst one hundredth one could be the worst one got it but how much space do you need to leave for writing your name otherwise yes sir so is this clear and this also takes us to the question that Ranjit asked why what is this ref transport line and what is this ref transmit line see the actual word into which I would be reading or writing may not be the worst word or some bit of that word could be the verse but we do not know so as memory designers what we do is we add a reference word line and a reference bit line reference word line is very similar to the real world line we will talk more about it later and reference bit line is also very similar to the real bit line in terms of total capacitors there is some modification we do but that is what we will talk about later and what we do is we ensure that the cells on the reference bit line and the reference word line ensure that they are the slowest ones through design somehow we will talk about it okay and that is what we use to generate the right detect so they are kind of references they ensure that worst case cell is also written in two or worst case cell is also correctly read that is why they are called reference wait lines and reference reference word and reference bit line Does this answer your question uh yes sir but here if we look at the bit lines so the reference bit line is much faster as compared to the bit line so yeah this doesn't ensure the required function you know so yeah look at it like this after the write detect signal comes how long how long does it take for the word line to get deselected uh okay it takes enough amount of time so that the clock so we have to keep that margin also in the picture we don't want to waste time this is just a cartoon it is fairly representative but it is still a cartoon the exact exact uh uh you know correlation so this is just a sequencing that I wanted to share with you yes but the exact delay between two different signals that would be different this is not even representative of that this is just a sequencing diagram yes sir okay yeah ragas you have a question uh yes sir so what is the word clock I mean signal does here this is right clock yes sir so I mean CK my I mean the right operation will be controlled by this right clock the right driver is controlled by the right clock okay don't worry again these are just nomenclatures I have just used some name so any any questions further any further questions because then I would want you to take you to the data sheet as to how a memory data sheet looks like I was not able to clearly understand the significance of the reset signal I was able to get that we are resetting the memory to this original position but exactly what crucial role to a sling I was not able to get that okay you you could understand that we wanted a duty cycle which is independent of the external clock yes sir yes sir so how do you bring the clock to low internal clock to low how do you create that duty cycle you need some signals no okay uh so sir like uh initially I was getting the 50 50 percent but uh based on my like reference word line I generate that high period I get the idea of that hyper how high that however the period should be and based upon that I'd select this reset signal which will basically uh determine by that low period yeah okay okay sir okay so for every memory uh the reset could come at a different time yes sir answer one more thing so are these these were reference word line reference bit line they are part of they are like actual bit lines uh in this memory array in this whole memory structure yeah what else because I was thinking that every bit line has that so but it would be I was not able to structure that how exactly they would be part of this whole design so we will see how how and where they are placed later don't forget okay the seventh year lecture that is when we will see this okay yeah anything else so the right data is telling us the right operation has completed and the verse cell also or if you now generate the reset then by the time online gets deselected right operation would be successfully completed everywhere Okay so okay so now that takes me to uh what we call as memory data sheet what is a data sheet what do you understand by the term data sheet have you seen a data sheet earlier sir why can't you use write detect as a reset signal I mean that's what you do during the read cycle yeah okay I understand"
bdapjpFeUX8,hmm yeah what do you understand by the term data sheet have you seen data sheets of stuff of circuits earlier what does the data sheet typically have specifications of that device specification of the device what does what do you mean by the term specification animesh um so all all the data that a programmer or somebody who is working on it may need to make full use of that device hmm may not necessarily be specification but it is all the information it may not be complete specification that is but it still has all the information so that someone can use it yes so for a memory what kind of information would you need to be able to use a memory oh sir it could be the Opera operating voltage the temperature then the total number of alloble read or writes the capacity the right time so the right time the retain yeah the read and the right times the typical minimum okay and some also maybe like in the previous class I showed us that it could exist in different states so maybe like that also okay interesting clock frequency okay endurance endurance srams unlimited endurance okay but yes classically you will need it yes so capacitance values the Maybe very interesting we just talked about it that the input capacitance has to be within a particular limit yes right so size and PVD conditions size and pvt conditions very good and um okay very good so shall we look at one memory data sheet yeah someone was saying something speeds yeah frequency we talked about yeah speed we talked about reads read write CDs what do we talk about when we talk of circuits area someone said size yeah area area is very important yes and marriage what do you mean by figure of Merit so uh noise margin values and what will a user do with that but yeah okay let us assume that some for somewhere you will need SNR or a data sheet of a PLL for example or a ADC you will need SNR also yes definitely versions version okay that is also important because as the version changes timings and functionality may change yes capacity capacity yes okay the leakage leakage yes and the power consumption power consumption when it's an ideal state or in like operating differently yeah in all the various States what is the kind of power consumption yeah and leakage also the same so you should definitely talk about all the three at least EPA performance power and area all three should be clearly evident in the data sheet okay what else supply voltages for operating this might be some load how much load it can okay the load range and everything yes so timing conceals standing constraints timing constraints yes we talked about frequency and speed and everything yes a technology node which nanometer 65 or 90. yes which technology it is so you should be looking at the right data sheet when you are designing something into your circuit yes thank you very good so shall we look at one data sheet you've almost covered all of it but what we need to put there so is it okay if you move to a data sheet now yes sir okay so this is a data sheet uh this is from SD microelectronics they have very kindly allowed us to use it and for your purposes so look at it you talked about version which version it is it also talks about which data was it generated the version may be 3.2 and the date so that how old is this version and you see it also talks about something five and two words 774 bits uh it says synchronous single port SRAM with eight multiplexer inputs so Phi 1 2 cross 74 and 8. and then there is also a prefix CMOS m55 which could be the terms that they use for technology St that St is the one that developed St is the vendor for this particular memory spht single port high density uh LL typically could stand for low leakage and so on so there's a first page where you need to have at least this kind of information there then you see now okay so this is this is a memory data sheet in PDF format but uh typically memory data sheet you know when you will generate a memory instance memory data sheet may be available in either PDF or HTML or text or maybe all these kinds of formats it will be made available to you when you purchase a memory from a vendor it could be in any format but what we are interested to look at over here is what are the typical details that are that are given in a data sheet so that when we ourselves either become memory designers or want to become you know system Architects whatever and we want to use memories what are the important things that we need to look at someone having done this course MDT should know at least this much how to read a memory data sheet am I right this is the one of the most fundamental things that someone has done this course should know so we have this table of contents which talks about symbol and pin description see you never talked about pins that also has pin description as to what kind of pins exist in the particular memory and then we already talked about timing characteristics power characteristics leakage characteristics so let's look at what it means one by one so let us say we want to look at cell characteristics so it says the number of words is 512 number of bits per word is 74. number of multiplexer inputs is 8. what is this Max we did not talk about it in the last class also but what is this Max what do you understand by marks anyone so you said for selection of column we use it for selection of column we use it but I have a 512 across 74 memory so where does column come in I have 74 bits I want to read all the 74 bits you simply accept it but I said you did not question me so you have one bit at a time right not the complete word why you're not talking about a Serial bus the processor would need all the 64 or 74 bits from any location now when you look at a processor you say load address 5. so does it load only one bit of address five no it loads all the 64 bits of address 5. so I have same Doubt last class you said we will get that uh I'm just trying to see if you have the answer already or not so to maintain the aspect ratios to maintain the aspect ratio what do you mean by aspect ratio nickel um number of like word Line This in column and rows we want to maintain number of word lines yeah why do I want to do that you're right so that the delay delay reduces like if column is very high so the bit lines will be large so we want to make it a squarish memory we want to make it a squaresh memory so why is it not a square memory so Birds orbits the other words um so what we are seeing is that the number of words is much more than the number of bits huh so okay the number of bits which is 74 is that is the number of bit cells we have in the array right 74 bit cells we have in the array hmm [Music] yeah 74 bits per word we have so let me let me switch over to the Whiteboard are you able to see my whiteboard yes sir Okay so let us say we have this let us forget this 512 across 74 for a moment let us say I just want to make a 64 cross 2 memory I can want it um I can want a 64 cross 2 memory yes so what will I have I will have a long a very tall memory where there are two bits per word and there are 64 such rows and this is 2. am I right so what is the ratio of this one is to 32. um have you seen pictographs of chips ICS somewhere do you realize they are usually shown to be or designed to be squarish yes now what I am saying is in this querish strip make a memory which is aspect ratio one is to 32. now what would happen overall this doesn't work now if the chip is squarish you would want something like a ratio which is manageable additionally let us look as a memory designer only over here my bit line has a capacitance of 64 rows my word line has a capacitance of two columns so the way the RC is distributed across word line and bitline is very skewed in fact my bit cell is very small for right driver I could actually have a big buffer I can actually design a big buffer but bitcell is bound to be very small because area is diamond and memories hmm so somewhere I could have a brick driver I do not have a capacitance to drive but where I had a very small driver the pixel was very small I have to drive this long long capacitance of bit line there so what would you want to do you would say somehow yeah I can I can drive them you say I can drive the word line faster but please reduce Bitcoin capacitance so what do you do you say okay let me fold the memory so how do you fold the memory you say I will put two words per row instead of just one word per row I will put two words per row so what happens now if there are two words per row how many rows do I have now and how many columns do I have for all how has my aspect ratio changed one is too interested and what do I now need to do at a different level what I now need to do is I just need to put a multiplexer here Hannah that there will be two bits that would come of these two bits depending on my address one of the bits should go out are you able to see this so that is why this is called as mux then let us say oh one by one s two eight is also a bad ratio and I do still better so what do I do some more folding I do let us say one more folding I go for an additional fold and I say okay fold it once more so now how many words do I have per per row four words per row how many columns 16. 8. eight and how many rows screen 16 my expert ratio has to come one is to 2. more manageable um bit line capacitance has reduced by one fourth void line capacitance has increased to four times and we call this as mux 4. because there are four words per row so what do you need to do you need to bring four inputs of which one would go out are you able to see this so I'm not able to understand the mux operation okay so now when you you not understood the Box operation very good thanks for asking so let us say now I selected this particular word line how many how many bits will be written into eight eight bits are there I have only one address with me I wanted to write only on one word so which word will I write into which word so I'm doing the right operation when I select the word line four words get selected yes sir but I wanted to write only on one word so that we that will have to tell them okay right in that where do we tell them how do we tell them through that mux yeah that is why you need the marks okay okay yes sir you got it yes yes here only uh like each word would have multiple bits right so for example if I want to write on the like four four word last word like the fourth word so each of these lines that you have said that it's much for you have four lines so each of these lines will be corresponding to all the eight bits of that particular word no no I mean all the bits of that so because in each word we have material in fact there will be two muxes here there will be another Max this will be for the second bit okay so so if we have say in a word we have eight bits so there will be eight Maxes here yes and the number of marks will be depending on how many words in a particular row and okay yes that is the max size 4 is represents that how many words for a particular row yes okay sir data sheet that that you have shown us that is 74 bits okay the number of marxists were eight and what's the what's the case in that like over here there are two bits but the marks is four two bits so I'm not getting it like Max 4 means how many inputs per marks yes sir yes sir yeah and how many muxes yes sir so here here we have eight bits that that's why we have okay here we have this this is a 64 cross 2 memory instance okay so we have 128 bits total yes yeah in a word line we have eight bits like after the folding it twice yes after folding we have eight bits because max four into two bits per word yes sir hmm okay so can you relate this with that 512 is 274. that's good let's do that I think that will make it much easier for all of you let us say there is this memory which has five and two words and 74 bits um so now in that particular memory they said we have Max 8. what that means is first you do one folding this becomes marks two then you do next folding this becomes Max 4 then you do one more folding and it would become Max 8. so how many rows would you have finally five and two by eight 64. yes yes how many columns would you have 74 into 8 what is that 597. 596. um so this memory would have 596 columns and 64 rows Max is it columns is equal to 596 rows is equal to 64. words was already given as 5 and 2 bits was 74. is this clear divided by eight words per row is eight okay aspect ratio is not equal to 100 yeah so that is why I asked you why do we only want to limit it to aspect ratio but we are using this much we are using more area for uh implementing the multiplexer also no no see you do not yet have the sense of area in this system yet I have not told you what is the X and Y of the memory cell I have not told you what is the area consumed in the row decoder I have not told you what is the area consumed in the IU region so you cannot judge by looking at my cartoon tell me that okay the area is more or less you can't array area will anyway remain constant because the number of bit cells is constant but overall memory area how it will change we can't say that just yet with the kind of information we have till now are you able to see this so so in this though they will be eight mucks and eight mucks will have 596 kind of lines coming to it no so here will be having 74 works and Each of which is eight each of flux because there are 74 bits I have 74 outputs to give so there will be 74 muxes each Max will accept eight inputs because each row has eight words is this clear see multiplexer is an important concept you need to understand it well because if this is clear I will go to the next step which is called as bit interleaving so there will be 74 muxes and each box will be it is 12. yes okay okay so uh here if we introduce Max then uh at the select lens for the max will be based uh based upon the address information that we give to them in memory and also the decode all the decoder size also might change based upon the folding which we do yeah obviously because earlier you had to decode 512 words so you needed nine bits now you only need to decode 64 so you need only how many bits six six bits but you need three bits to decode the column address yes so you still need all the nine bits because your memory is five and two words yes sir but six bits for row decoding three bits for column decoding yes sir anything else so can you repeat about the capacitances you were saying about the word line and the bit line how are they dependent it'd be like like hold the memory yeah you tell me when there was no marks or when the mux was born okay let us say per Row the bit nine is the bit line has a capacitance of CR so what was the bit line capacitance uh so number of bits into CR yeah to give me the capacitance number how many rows how many rows are there if there is much one uh so in this 5.12 so 74 Max one number of rows number of rows okay rows five and two five and two so then the capacitance was CR what happens in the max is eight uh 60 percent 64. okay okay when we like uh hold it yeah Hannah yeah it's only this long otherwise it was this long yeah yes now let us say per column the word line capacitance is c c what was the capacitance of the of the word line 70 courses 74 CC what is the word line capacitance later 596 59 596 CC so what have I done I have reduced Bitcoin capacitance and I have increased waterline capacity and capacitance right okay does this match with what I wanted to do earlier I said I could actually have a bigger driver for wordline Hannah you remember I had said that wordline driver could be much bigger than the because bitsell is small but World line I can have a bigger driver that is what I have achieved now yes so yes [Music] is this part clear now yes so I have one thing to ask like in the data sheet it was given 512 words and 74 bits so the memory is actually designed like five 512 rows and 74 bits in each row or with that eight marks uh information we can reduce that the memory is designed like this folded one so the Max and the data sheet also given to be eight now ESL so what would it mean s okay okay um 74 into eight yes sorry thank you phrasal question [Music] um 64 and 592. so data sheet measure directly as if you need it is 64 is the word line to keep the processor wanted to have 74 bits per word processor wanted 512 words to be addressed yes sir so I had to have nine address bits now yes I would say the memory is 64 cross 592 then the memory would become 64 words and 592 bits per word that was not what the processor needed um yes sir so hey the marks concept comes in because we want to improve the performance right we want to improve the aspect ratio we want to improve the performance we want to reduce change the power whatever so but like it come to me it seems that it is coming at a very big penalt uh area penalty because it does it I mean right in that because mux I I just told you that you do not know what is the area of the row decoder what is the area of the i o how can you estimate the area penalty here right away okay yeah right so okay can you area would remain same can all of you all of you agree on that so now whether it is an area penalty or an area again you cannot know unless you know the row decoder area and unless you know the i o area yes sir or can you imagine no sir not right now so cannot deduce that let us not jump into conclusions we do not have the required information yet I'm just making some cartoons for you yeah so an aspect ratio you want to be uh to be squarish because it like fits into that kind of like packages yes or squarish okay so even you know same number of rows and same number of columns does not means aspect ratio is querish by the way I have not told you about the aspect ratio of the memory cell in itself in the first place have I told you Nina so this logical aspect ratio that we were talking about that does not really mean the physical aspect ratio is also a square what if the bit cell is much taller than when it is wider right so again don't read too much into the cartoons that we are making here I would try to keep it as representative as possible but even then don't read too much into it Shivam sir uh sorry sir I must be I must not understand the point like you said uh because we need bigger driver for word lines sir uh we can't make a driver for World lines because they are not a part of the memory cell so they are external that's why we need we can make we can make bigger yes sir thank you,https://www.youtube.com/watch?v=bdapjpFeUX8,"Link: https://www.youtube.com/watch?v=bdapjpFeUX8
Transcript: hmm yeah what do you understand by the term data sheet have you seen data sheets of stuff of circuits earlier what does the data sheet typically have specifications of that device specification of the device what does what do you mean by the term specification animesh um so all all the data that a programmer or somebody who is working on it may need to make full use of that device hmm may not necessarily be specification but it is all the information it may not be complete specification that is but it still has all the information so that someone can use it yes so for a memory what kind of information would you need to be able to use a memory oh sir it could be the Opera operating voltage the temperature then the total number of alloble read or writes the capacity the right time so the right time the retain yeah the read and the right times the typical minimum okay and some also maybe like in the previous class I showed us that it could exist in different states so maybe like that also okay interesting clock frequency okay endurance endurance srams unlimited endurance okay but yes classically you will need it yes so capacitance values the Maybe very interesting we just talked about it that the input capacitance has to be within a particular limit yes right so size and PVD conditions size and pvt conditions very good and um okay very good so shall we look at one memory data sheet yeah someone was saying something speeds yeah frequency we talked about yeah speed we talked about reads read write CDs what do we talk about when we talk of circuits area someone said size yeah area area is very important yes and marriage what do you mean by figure of Merit so uh noise margin values and what will a user do with that but yeah okay let us assume that some for somewhere you will need SNR or a data sheet of a PLL for example or a ADC you will need SNR also yes definitely versions version okay that is also important because as the version changes timings and functionality may change yes capacity capacity yes okay the leakage leakage yes and the power consumption power consumption when it's an ideal state or in like operating differently yeah in all the various States what is the kind of power consumption yeah and leakage also the same so you should definitely talk about all the three at least EPA performance power and area all three should be clearly evident in the data sheet okay what else supply voltages for operating this might be some load how much load it can okay the load range and everything yes so timing conceals standing constraints timing constraints yes we talked about frequency and speed and everything yes a technology node which nanometer 65 or 90. yes which technology it is so you should be looking at the right data sheet when you are designing something into your circuit yes thank you very good so shall we look at one data sheet you've almost covered all of it but what we need to put there so is it okay if you move to a data sheet now yes sir okay so this is a data sheet uh this is from SD microelectronics they have very kindly allowed us to use it and for your purposes so look at it you talked about version which version it is it also talks about which data was it generated the version may be 3.2 and the date so that how old is this version and you see it also talks about something five and two words 774 bits uh it says synchronous single port SRAM with eight multiplexer inputs so Phi 1 2 cross 74 and 8. and then there is also a prefix CMOS m55 which could be the terms that they use for technology St that St is the one that developed St is the vendor for this particular memory spht single port high density uh LL typically could stand for low leakage and so on so there's a first page where you need to have at least this kind of information there then you see now okay so this is this is a memory data sheet in PDF format but uh typically memory data sheet you know when you will generate a memory instance memory data sheet may be available in either PDF or HTML or text or maybe all these kinds of formats it will be made available to you when you purchase a memory from a vendor it could be in any format but what we are interested to look at over here is what are the typical details that are that are given in a data sheet so that when we ourselves either become memory designers or want to become you know system Architects whatever and we want to use memories what are the important things that we need to look at someone having done this course MDT should know at least this much how to read a memory data sheet am I right this is the one of the most fundamental things that someone has done this course should know so we have this table of contents which talks about symbol and pin description see you never talked about pins that also has pin description as to what kind of pins exist in the particular memory and then we already talked about timing characteristics power characteristics leakage characteristics so let's look at what it means one by one so let us say we want to look at cell characteristics so it says the number of words is 512 number of bits per word is 74. number of multiplexer inputs is 8. what is this Max we did not talk about it in the last class also but what is this Max what do you understand by marks anyone so you said for selection of column we use it for selection of column we use it but I have a 512 across 74 memory so where does column come in I have 74 bits I want to read all the 74 bits you simply accept it but I said you did not question me so you have one bit at a time right not the complete word why you're not talking about a Serial bus the processor would need all the 64 or 74 bits from any location now when you look at a processor you say load address 5. so does it load only one bit of address five no it loads all the 64 bits of address 5. so I have same Doubt last class you said we will get that uh I'm just trying to see if you have the answer already or not so to maintain the aspect ratios to maintain the aspect ratio what do you mean by aspect ratio nickel um number of like word Line This in column and rows we want to maintain number of word lines yeah why do I want to do that you're right so that the delay delay reduces like if column is very high so the bit lines will be large so we want to make it a squarish memory we want to make it a squaresh memory so why is it not a square memory so Birds orbits the other words um so what we are seeing is that the number of words is much more than the number of bits huh so okay the number of bits which is 74 is that is the number of bit cells we have in the array right 74 bit cells we have in the array hmm [Music] yeah 74 bits per word we have so let me let me switch over to the Whiteboard are you able to see my whiteboard yes sir Okay so let us say we have this let us forget this 512 across 74 for a moment let us say I just want to make a 64 cross 2 memory I can want it um I can want a 64 cross 2 memory yes so what will I have I will have a long a very tall memory where there are two bits per word and there are 64 such rows and this is 2. am I right so what is the ratio of this one is to 32. um have you seen pictographs of chips ICS somewhere do you realize they are usually shown to be or designed to be squarish yes now what I am saying is in this querish strip make a memory which is aspect ratio one is to 32. now what would happen overall this doesn't work now if the chip is squarish you would want something like a ratio which is manageable additionally let us look as a memory designer only over here my bit line has a capacitance of 64 rows my word line has a capacitance of two columns so the way the RC is distributed across word line and bitline is very skewed in fact my bit cell is very small for right driver I could actually have a big buffer I can actually design a big buffer but bitcell is bound to be very small because area is diamond and memories hmm so somewhere I could have a brick driver I do not have a capacitance to drive but where I had a very small driver the pixel was very small I have to drive this long long capacitance of bit line there so what would you want to do you would say somehow yeah I can I can drive them you say I can drive the word line faster but please reduce Bitcoin capacitance so what do you do you say okay let me fold the memory so how do you fold the memory you say I will put two words per row instead of just one word per row I will put two words per row so what happens now if there are two words per row how many rows do I have now and how many columns do I have for all how has my aspect ratio changed one is too interested and what do I now need to do at a different level what I now need to do is I just need to put a multiplexer here Hannah that there will be two bits that would come of these two bits depending on my address one of the bits should go out are you able to see this so that is why this is called as mux then let us say oh one by one s two eight is also a bad ratio and I do still better so what do I do some more folding I do let us say one more folding I go for an additional fold and I say okay fold it once more so now how many words do I have per per row four words per row how many columns 16. 8. eight and how many rows screen 16 my expert ratio has to come one is to 2. more manageable um bit line capacitance has reduced by one fourth void line capacitance has increased to four times and we call this as mux 4. because there are four words per row so what do you need to do you need to bring four inputs of which one would go out are you able to see this so I'm not able to understand the mux operation okay so now when you you not understood the Box operation very good thanks for asking so let us say now I selected this particular word line how many how many bits will be written into eight eight bits are there I have only one address with me I wanted to write only on one word so which word will I write into which word so I'm doing the right operation when I select the word line four words get selected yes sir but I wanted to write only on one word so that we that will have to tell them okay right in that where do we tell them how do we tell them through that mux yeah that is why you need the marks okay okay yes sir you got it yes yes here only uh like each word would have multiple bits right so for example if I want to write on the like four four word last word like the fourth word so each of these lines that you have said that it's much for you have four lines so each of these lines will be corresponding to all the eight bits of that particular word no no I mean all the bits of that so because in each word we have material in fact there will be two muxes here there will be another Max this will be for the second bit okay so so if we have say in a word we have eight bits so there will be eight Maxes here yes and the number of marks will be depending on how many words in a particular row and okay yes that is the max size 4 is represents that how many words for a particular row yes okay sir data sheet that that you have shown us that is 74 bits okay the number of marxists were eight and what's the what's the case in that like over here there are two bits but the marks is four two bits so I'm not getting it like Max 4 means how many inputs per marks yes sir yes sir yeah and how many muxes yes sir so here here we have eight bits that that's why we have okay here we have this this is a 64 cross 2 memory instance okay so we have 128 bits total yes yeah in a word line we have eight bits like after the folding it twice yes after folding we have eight bits because max four into two bits per word yes sir hmm okay so can you relate this with that 512 is 274. that's good let's do that I think that will make it much easier for all of you let us say there is this memory which has five and two words and 74 bits um so now in that particular memory they said we have Max 8. what that means is first you do one folding this becomes marks two then you do next folding this becomes Max 4 then you do one more folding and it would become Max 8. so how many rows would you have finally five and two by eight 64. yes yes how many columns would you have 74 into 8 what is that 597. 596. um so this memory would have 596 columns and 64 rows Max is it columns is equal to 596 rows is equal to 64. words was already given as 5 and 2 bits was 74. is this clear divided by eight words per row is eight okay aspect ratio is not equal to 100 yeah so that is why I asked you why do we only want to limit it to aspect ratio but we are using this much we are using more area for uh implementing the multiplexer also no no see you do not yet have the sense of area in this system yet I have not told you what is the X and Y of the memory cell I have not told you what is the area consumed in the row decoder I have not told you what is the area consumed in the IU region so you cannot judge by looking at my cartoon tell me that okay the area is more or less you can't array area will anyway remain constant because the number of bit cells is constant but overall memory area how it will change we can't say that just yet with the kind of information we have till now are you able to see this so so in this though they will be eight mucks and eight mucks will have 596 kind of lines coming to it no so here will be having 74 works and Each of which is eight each of flux because there are 74 bits I have 74 outputs to give so there will be 74 muxes each Max will accept eight inputs because each row has eight words is this clear see multiplexer is an important concept you need to understand it well because if this is clear I will go to the next step which is called as bit interleaving so there will be 74 muxes and each box will be it is 12. yes okay okay so uh here if we introduce Max then uh at the select lens for the max will be based uh based upon the address information that we give to them in memory and also the decode all the decoder size also might change based upon the folding which we do yeah obviously because earlier you had to decode 512 words so you needed nine bits now you only need to decode 64 so you need only how many bits six six bits but you need three bits to decode the column address yes so you still need all the nine bits because your memory is five and two words yes sir but six bits for row decoding three bits for column decoding yes sir anything else so can you repeat about the capacitances you were saying about the word line and the bit line how are they dependent it'd be like like hold the memory yeah you tell me when there was no marks or when the mux was born okay let us say per Row the bit nine is the bit line has a capacitance of CR so what was the bit line capacitance uh so number of bits into CR yeah to give me the capacitance number how many rows how many rows are there if there is much one uh so in this 5.12 so 74 Max one number of rows number of rows okay rows five and two five and two so then the capacitance was CR what happens in the max is eight uh 60 percent 64. okay okay when we like uh hold it yeah Hannah yeah it's only this long otherwise it was this long yeah yes now let us say per column the word line capacitance is c c what was the capacitance of the of the word line 70 courses 74 CC what is the word line capacitance later 596 59 596 CC so what have I done I have reduced Bitcoin capacitance and I have increased waterline capacity and capacitance right okay does this match with what I wanted to do earlier I said I could actually have a bigger driver for wordline Hannah you remember I had said that wordline driver could be much bigger than the because bitsell is small but World line I can have a bigger driver that is what I have achieved now yes so yes [Music] is this part clear now yes so I have one thing to ask like in the data sheet it was given 512 words and 74 bits so the memory is actually designed like five 512 rows and 74 bits in each row or with that eight marks uh information we can reduce that the memory is designed like this folded one so the Max and the data sheet also given to be eight now ESL so what would it mean s okay okay um 74 into eight yes sorry thank you phrasal question [Music] um 64 and 592. so data sheet measure directly as if you 
need it is 64 is the word line to keep the processor wanted to have 74 bits per word processor wanted 512 words to be addressed yes sir so I had to have nine address bits now yes I would say the memory is 64 cross 592 then the memory would become 64 words and 592 bits per word that was not what the processor needed um yes sir so hey the marks concept comes in because we want to improve the performance right we want to improve the aspect ratio we want to improve the performance we want to reduce change the power whatever so but like it come to me it seems that it is coming at a very big penalt uh area penalty because it does it I mean right in that because mux I I just told you that you do not know what is the area of the row decoder what is the area of the i o how can you estimate the area penalty here right away okay yeah right so okay can you area would remain same can all of you all of you agree on that so now whether it is an area penalty or an area again you cannot know unless you know the row decoder area and unless you know the i o area yes sir or can you imagine no sir not right now so cannot deduce that let us not jump into conclusions we do not have the required information yet I'm just making some cartoons for you yeah so an aspect ratio you want to be uh to be squarish because it like fits into that kind of like packages yes or squarish okay so even you know same number of rows and same number of columns does not means aspect ratio is querish by the way I have not told you about the aspect ratio of the memory cell in itself in the first place have I told you Nina so this logical aspect ratio that we were talking about that does not really mean the physical aspect ratio is also a square what if the bit cell is much taller than when it is wider right so again don't read too much into the cartoons that we are making here I would try to keep it as representative as possible but even then don't read too much into it Shivam sir uh sorry sir I must be I must not understand the point like you said uh because we need bigger driver for word lines sir uh we can't make a driver for World lines because they are not a part of the memory cell so they are external that's why we need we can make we can make bigger yes sir thank you"
lqlTpTIbgp4,hmm okay so now let us consider this memory itself what are we saying that I want to make 74 muxes so there are there are 74 muxes that I want to make because there are 74 bits and each Max has eight inputs am I right so where are those inputs coming from there is one bit zero coming from here bit 0 coming no not here bit 0 coming from second word but zero coming from third word fourth word and then four bit zeros coming from here are you able to see this I just placed this one full word on the side so there are eight horizontal lines which are traveling to this particular Max are you able to see this yes sir similarly for the second bit it would be another eight lines coming from here so how many horizontal lines are we talking about then 592 horizontal lines are you able to see this yes so one for each pet one for each bit now what does this mean this means that every bit line is going to see such huge capacitance see horizontally it will run through the entire array and then it will receive go to a mux is this a good way to design lotion so what would you want to do if you have to make a Max 4 what would be the ideal thing that okay all the four inputs links to Max 4 are placed right here up there then for the next bit all the four inputs should be right up there that is what I want to do huh so what does this mean unless finally will give me a bit zero this will give me bit one this will give me bit 2 let us say so what does this mean s there are four words then this particular word would represent word zero Bit Zero word one bit zero word Two Bit Zero word three Bit Zero then word 0 bit 1 Word 0 bit 2 squared 0 bit sorry and word three bit one then word 0 bit 2 word one bit two words two bit two word three bit two are you able to see this so instead of actually placing words as word zero then word one then word two what am I doing I'm actually interleaving at every bit level there is word zero one two three then at second bit again 0 1 2 3 0 1 2 3. what has it done it has reduced this whole set of capacitances it has now I do not need as many wires just because we just pull it down and right there we have the max implementation done are you able to see this so This is called as bit interleaving any questions sir I couldn't understand sir what is the difference between the two the earlier that we were using there also we were using the those uh bits from the particular words yeah I wanted to use bit 0 from here but the bit 0 for the second word would come from here now far away for the third word the bit would come from here this region fourth word here fifth word sixth word seventh word eighth word so I would have wires running all around my memory just to get the connections to one marks yes sir I know so this would lead to lots of congestion lots of area wastes lots of additional capacitances power delay everything yes sir is okay so we did this from uh keeping it like a square and selecting the bit lines instead of keeping all the bits of a word together is he kept all the words of a bit together yes sir we changed it instead of all the bits of one word together we kept all the words related to Bit Zero together so how can we like do that I mean like we have different words and they are placed differently how can we just cut a simple part in it just a bit size part and just place them um who stops you what you need to do is wherever you write you read only from there okay Hannah so actually for a processor processor only needs to know where what is what was written on this particular address where and how that bit was placed the processor is not interested is it interested no so it just needs data faster so all that I need to do is I need to write into this particular place only when I want to write a zero bit that's it are you able to see this any questions so this I know this is not a simple transition um suggest for clarification this is foreign so word four Bit Zero would come here word five Bit Zero would come here word 6 bit 0 would come here what 7 bit 0 would come here then again word 4 bit 1. word four uh word five bit one then word six bit one then word seven bit one are you able to see this are you able to see the memory getting built different rows of a memory getting built and so on so this is row 0 this is row 1. sir what generates the select line for this Multiplex cursor addressing we gave nine bit address three bits will uh and in this particular Max 4K is two bits will come to the max sir uh those the addressing which address which we get should also be in the same pattern right it should follow this pattern of uh between the living yeah I will give address now I will give address 0 and address one over here um yes yes okay so select it will now yes sir yeah okay anything else let's put into leaving clear ly votes um let us say we had a eight word memory only how many address bits did I have three address bits yes sir so this this is the complete memory let us say it has it was an eight word three bit memory let us put it like that only okay so let me just complete the memory here word four bit two word five bit two word six bit two word seven bit two you are you want to see if this is really the case huh so I said max forehead so two addresses will go to decipher which marks which column to select is this clear till here it works yes sir yeah okay sir now which word to select I still need to identify the decipher the third address better this goes to the row decoder if A2 is 0 rho zero will be selected if a table is 1 1 will be selected do you see that finally one word will be selected yes sir but sorry I have cross section by selecting a cross section of word line and bit line I will be have I would have decoded the entire address bus is it clear so but word for example in the first Mark word 0 or word for me distinguished by selecting the appropriate word line okay TKS is got itself and I am using at a cross section of bit line and wordline selection whatever word is there that is what will be get collected yes yes I got it thank you sir Anna yes sir clear to everyone any questions you were folding the memory array so that and all the bits of a particular word were uh were put it all together so sir how can we arrange the structure to have this kind of design you just decided to arrange it like this so that our capacitance is to reduce it just did it it is we are the designers right see if if we would go by what we had initially logically thought um we saw there is a big problem there Hannah there's this big problem of all these capacitances that was coming into picture yes Hannah all these capacitances were coming into picture we didn't want to have all this trouble with us are you able to see this so we said okay let us arrange the things differently and we arranged it differently we interleave the bits can I not do it has anyone stopped me from doing this okay so is this clear can be done like this any questions because I still want to spend five minutes on the data sheet yes sir uh yeah we can do uh this kind of we can make memories like this but sort of what I wanted to ask like this or what structural uh Arrangements we can do to uh have this kind of so you don't need to do anything you just design a mux like this where the bits are come where the where the inputs are coming from vertically up there not from sides that's it okay so seamless yes sir so if you would do this course the creativity course that I'm teaching this semester you will see that this principle is called the principle of geometry or spirituality or stuff like that you you just rearrange the material in such a way that it becomes simpler to handle you may want to so regarding that principle and went to principle there is also this Mobius ribbon that you may want to see very interesting geometrical Transformations can happen which can really ease out your life in a very significant way just like it has done over here yes sir so that is the concept of marks and bit interleaving there okay now let us look at the data sheet again we can so what was there in the data sheet let us look at that so we said there would be 64 columns now 64 rows and 592 columns you see this part 64.92 columns yes aspect ratio they said something and now you see width is 837 height is something and it also has the diamond the the thing of area and perimeter given there and the cell parameters are able to see this okay so once you have that then you also have a symbol View so that whenever because see we said that the data should data sheet should have sufficient information for us to be able to design or understand the complexity of the design there so this symbol view tells me what all pins do I need to Route what kind of congestion should I expect around this particular memory huh and then you will see we also give pin description what does each pin do what is the functionality of each pen what is the capacitance of that particular pin in this particular memory instance you see the clock already has a capacitance of 30 pentofarads and compare it with capacitance of other pins all other pins have much lower capacitance you see address pins eight rental farads control chip select seven phentofarads right enable six window parrots and clock they're talking about 30 front periods are you able to see why we could not use external clock for all the other purposes the discussion that we had just before sharing the data sheet clock already has high capacitance we cannot load it any further and then there are these pens like sleep and then there are these extra additional pins which are scansane related so you see memory has a scan chain of its own there are so many inputs in this particular memory if you look at it how many inputs do we have one two three plus nine twelve plus seventy four 86 87 88 89 uh 89.90 over 90 Plus 74. 164 164 Pence for uh one for one memory instance compare it with a nand gate three input nand gate has four pins a flip flop seven or eight months memory has 190 you know 164 pins and this is not the biggest memory the biggest a bigger memory would have many more pins there so if you have so many pens there you would rather have a scan chain internal to the memory it's a big macro so we also have a scan chain dedicated to the memory there and then we have timing characteristics cycle time what is the highest frequency CK high pulse wet CK low pulse width excess time data valid after right after clock and so on so so all the pins there could be some timings CSN setup time CSN hold time address at the time address hold time and so on there are symbols links to all these timings and we also are putting some number as men or Max what do you mean what do you think this Min and Max would mean so setup hold kind of thing yeah Min would mean that at least this much timing should be maintained Max means this is the maximum it would take it's a pessimistic approaches yes and this is the safest or because if you would latch the outputs before this Max timing then we are not guaranteeing anything but after this timing if you latch we guarantee everything yes sir yes sir I have seen in three four positions here process is given as best sir okay itself what what do you mean by Best Selection over here even in the second slide yeah so we saw about best process workspace process everything we saw now also corresponding to memory which one is assessment fast and most fast pmos okay okay best case processment fast and most fast pmos and you'll see there are climbing diagrams also okay see we had these symbols over here timing symbols t a t s t a s and everything now they're also shown in form of timing diagram what does EAS mean what does TAA mean and so on okay so these timing diagrams are also there in the data sheet so that you can actually understand what different timings mean what various constraints linked to different timings mean okay and then you will see we also give the power numbers see Power active power so first is the peak current then our active Read 50 percent of stuff toggling so you can see the definitions of what each of these uh symbols mean right here in the notes section also hmm so we give the dynamic power numbers in the data sheet and finally we also give all the leakage numbers in the data sheet um we're also given the tolerances leakages are valid at plus minus 10 percent because they can vary on input and output States and so on so all the information that a user needs to decide whether I want to use this memory or not we want to given the data sheet so what I will do is I will upload this datasheet in the classroom I would want you to spend some time understanding it okay if you have any questions you can ask in the classroom it says the TA will help you respond there I'm sorry what is yeah can you just write that in the chat room I'm not able to understand what you're interesting what is can change yes content contains are test structures so you will read about study about them more in the vdf course also but you can find that online also important which are embedded in the in the design so that the design becomes testable okay so they are linked to testability of the design does that answer your question uh hello sir yes sir uh here uh in this data sheet we can see that the Sleep pin is having a very much higher capacitance what is because sleep okay so what happens clock you need to toggle every cycle um so for clock yes you have timing constraints which do not allow very large capacitance to be put on the clock pin okay sleep pin on the other hand would toggle after every 100 Cycles let us say because it shuts down the memory it it plays with the power power range of the memory so the Sleep pen you cannot toggle every cycle so you say okay for the Sleep pin because I am not toggling it in every cycle I can relax the capacitance constraint a bit don't waste area buffering the sleep then take the Sleep pen directly to wherever you want to it will be slow fine no problems it will still be okay with us is that okay okay sir yes sir so but for all other things you will see that the there is a limit on what kind of capacitance it has anything else yes questions so it is like foreign to reduce the congestion because there are so many pins there okay uh if I'm if complexity there's no other option if I have to get more density then I have to otherwise things will Define start to define the area that my memory has yes sir Focus office we are not discussed about the office hours let me talk to the ts1 and let me come back to you with all the office apps for all of us okay sure thank you we'll post that in the classroom itself thank you for reminding us okay thank you sir yeah anything else uh hello sir yes um and sometimes our data pins can can there be a default state or a preferred state for a data pin unless control so scan chain input for control bits so it's an input pin it is Data it is it will carry some information so that could be zero and that dependent does nothing about active high or active low on layer so control signals control pins would have a preferred state uh look at this control pins would have the preferred state if there is a preferred state for CSN the memory is active when CSN is low WN memory is in right mode when when it is low but at rest can there be a preferred state for address no addresses data addresses information I know it's not a control pin it's an input pin is that clear Rohit hi yes sir okay anything else total foreign no that simply says uh memory key external input here okay there could be a flip flop is so smaller circuit you may not have an internal clock though you have antenna clock in the flip flop also but uh you can say that CK is the clock input for the memory you can avoid the they could have avoided the use of term XML over here will be used lock resources will connect the memory input also okay okay we talked about it we in the in the in the cartoon that I showed you we I had used the term clock generation internal clock generator yes okay so that is a separate kind of block itself yeah logical circuitry here yeah okay so not a buffer it's a clock generator okay okay otherwise I have simply said you could have said clock buffer now it's not a buffer it's a cloud generator okay so we'll close the class now it's a cache memory copy data sheet yeah typically same memories would also be used for cash purposes [Music] that we will talk about later when we will talk about casualty,https://www.youtube.com/watch?v=lqlTpTIbgp4,"Link: https://www.youtube.com/watch?v=lqlTpTIbgp4
Transcript: hmm okay so now let us consider this memory itself what are we saying that I want to make 74 muxes so there are there are 74 muxes that I want to make because there are 74 bits and each Max has eight inputs am I right so where are those inputs coming from there is one bit zero coming from here bit 0 coming no not here bit 0 coming from second word but zero coming from third word fourth word and then four bit zeros coming from here are you able to see this I just placed this one full word on the side so there are eight horizontal lines which are traveling to this particular Max are you able to see this yes sir similarly for the second bit it would be another eight lines coming from here so how many horizontal lines are we talking about then 592 horizontal lines are you able to see this yes so one for each pet one for each bit now what does this mean this means that every bit line is going to see such huge capacitance see horizontally it will run through the entire array and then it will receive go to a mux is this a good way to design lotion so what would you want to do if you have to make a Max 4 what would be the ideal thing that okay all the four inputs links to Max 4 are placed right here up there then for the next bit all the four inputs should be right up there that is what I want to do huh so what does this mean unless finally will give me a bit zero this will give me bit one this will give me bit 2 let us say so what does this mean s there are four words then this particular word would represent word zero Bit Zero word one bit zero word Two Bit Zero word three Bit Zero then word 0 bit 1 Word 0 bit 2 squared 0 bit sorry and word three bit one then word 0 bit 2 word one bit two words two bit two word three bit two are you able to see this so instead of actually placing words as word zero then word one then word two what am I doing I'm actually interleaving at every bit level there is word zero one two three then at second bit again 0 1 2 3 0 1 2 3. what has it done it has reduced this whole set of capacitances it has now I do not need as many wires just because we just pull it down and right there we have the max implementation done are you able to see this so This is called as bit interleaving any questions sir I couldn't understand sir what is the difference between the two the earlier that we were using there also we were using the those uh bits from the particular words yeah I wanted to use bit 0 from here but the bit 0 for the second word would come from here now far away for the third word the bit would come from here this region fourth word here fifth word sixth word seventh word eighth word so I would have wires running all around my memory just to get the connections to one marks yes sir I know so this would lead to lots of congestion lots of area wastes lots of additional capacitances power delay everything yes sir is okay so we did this from uh keeping it like a square and selecting the bit lines instead of keeping all the bits of a word together is he kept all the words of a bit together yes sir we changed it instead of all the bits of one word together we kept all the words related to Bit Zero together so how can we like do that I mean like we have different words and they are placed differently how can we just cut a simple part in it just a bit size part and just place them um who stops you what you need to do is wherever you write you read only from there okay Hannah so actually for a processor processor only needs to know where what is what was written on this particular address where and how that bit was placed the processor is not interested is it interested no so it just needs data faster so all that I need to do is I need to write into this particular place only when I want to write a zero bit that's it are you able to see this any questions so this I know this is not a simple transition um suggest for clarification this is foreign so word four Bit Zero would come here word five Bit Zero would come here word 6 bit 0 would come here what 7 bit 0 would come here then again word 4 bit 1. word four uh word five bit one then word six bit one then word seven bit one are you able to see this are you able to see the memory getting built different rows of a memory getting built and so on so this is row 0 this is row 1. sir what generates the select line for this Multiplex cursor addressing we gave nine bit address three bits will uh and in this particular Max 4K is two bits will come to the max sir uh those the addressing which address which we get should also be in the same pattern right it should follow this pattern of uh between the living yeah I will give address now I will give address 0 and address one over here um yes yes okay so select it will now yes sir yeah okay anything else let's put into leaving clear ly votes um let us say we had a eight word memory only how many address bits did I have three address bits yes sir so this this is the complete memory let us say it has it was an eight word three bit memory let us put it like that only okay so let me just complete the memory here word four bit two word five bit two word six bit two word seven bit two you are you want to see if this is really the case huh so I said max forehead so two addresses will go to decipher which marks which column to select is this clear till here it works yes sir yeah okay sir now which word to select I still need to identify the decipher the third address better this goes to the row decoder if A2 is 0 rho zero will be selected if a table is 1 1 will be selected do you see that finally one word will be selected yes sir but sorry I have cross section by selecting a cross section of word line and bit line I will be have I would have decoded the entire address bus is it clear so but word for example in the first Mark word 0 or word for me distinguished by selecting the appropriate word line okay TKS is got itself and I am using at a cross section of bit line and wordline selection whatever word is there that is what will be get collected yes yes I got it thank you sir Anna yes sir clear to everyone any questions you were folding the memory array so that and all the bits of a particular word were uh were put it all together so sir how can we arrange the structure to have this kind of design you just decided to arrange it like this so that our capacitance is to reduce it just did it it is we are the designers right see if if we would go by what we had initially logically thought um we saw there is a big problem there Hannah there's this big problem of all these capacitances that was coming into picture yes Hannah all these capacitances were coming into picture we didn't want to have all this trouble with us are you able to see this so we said okay let us arrange the things differently and we arranged it differently we interleave the bits can I not do it has anyone stopped me from doing this okay so is this clear can be done like this any questions because I still want to spend five minutes on the data sheet yes sir uh yeah we can do uh this kind of we can make memories like this but sort of what I wanted to ask like this or what structural uh Arrangements we can do to uh have this kind of so you don't need to do anything you just design a mux like this where the bits are come where the where the inputs are coming from vertically up there not from sides that's it okay so seamless yes sir so if you would do this course the creativity course that I'm teaching this semester you will see that this principle is called the principle of geometry or spirituality or stuff like that you you just rearrange the material in such a way that it becomes simpler to handle you may want to so regarding that principle and went to principle there is also this Mobius ribbon that you may want to see very interesting geometrical Transformations can happen which can really ease out your life in a very significant way just like it has done over here yes sir so that is the concept of marks and bit interleaving there okay now let us look at the data sheet again we can so what was there in the data sheet let us look at that so we said there would be 64 columns now 64 rows and 592 columns you see this part 64.92 columns yes aspect ratio they said something and now you see width is 837 height is something and it also has the diamond the the thing of area and perimeter given there and the cell parameters are able to see this okay so once you have that then you also have a symbol View so that whenever because see we said that the data should data sheet should have sufficient information for us to be able to design or understand the complexity of the design there so this symbol view tells me what all pins do I need to Route what kind of congestion should I expect around this particular memory huh and then you will see we also give pin description what does each pin do what is the functionality of each pen what is the capacitance of that particular pin in this particular memory instance you see the clock already has a capacitance of 30 pentofarads and compare it with capacitance of other pins all other pins have much lower capacitance you see address pins eight rental farads control chip select seven phentofarads right enable six window parrots and clock they're talking about 30 front periods are you able to see why we could not use external clock for all the other purposes the discussion that we had just before sharing the data sheet clock already has high capacitance we cannot load it any further and then there are these pens like sleep and then there are these extra additional pins which are scansane related so you see memory has a scan chain of its own there are so many inputs in this particular memory if you look at it how many inputs do we have one two three plus nine twelve plus seventy four 86 87 88 89 uh 89.90 over 90 Plus 74. 164 164 Pence for uh one for one memory instance compare it with a nand gate three input nand gate has four pins a flip flop seven or eight months memory has 190 you know 164 pins and this is not the biggest memory the biggest a bigger memory would have many more pins there so if you have so many pens there you would rather have a scan chain internal to the memory it's a big macro so we also have a scan chain dedicated to the memory there and then we have timing characteristics cycle time what is the highest frequency CK high pulse wet CK low pulse width excess time data valid after right after clock and so on so so all the pins there could be some timings CSN setup time CSN hold time address at the time address hold time and so on there are symbols links to all these timings and we also are putting some number as men or Max what do you mean what do you think this Min and Max would mean so setup hold kind of thing yeah Min would mean that at least this much timing should be maintained Max means this is the maximum it would take it's a pessimistic approaches yes and this is the safest or because if you would latch the outputs before this Max timing then we are not guaranteeing anything but after this timing if you latch we guarantee everything yes sir yes sir I have seen in three four positions here process is given as best sir okay itself what what do you mean by Best Selection over here even in the second slide yeah so we saw about best process workspace process everything we saw now also corresponding to memory which one is assessment fast and most fast pmos okay okay best case processment fast and most fast pmos and you'll see there are climbing diagrams also okay see we had these symbols over here timing symbols t a t s t a s and everything now they're also shown in form of timing diagram what does EAS mean what does TAA mean and so on okay so these timing diagrams are also there in the data sheet so that you can actually understand what different timings mean what various constraints linked to different timings mean okay and then you will see we also give the power numbers see Power active power so first is the peak current then our active Read 50 percent of stuff toggling so you can see the definitions of what each of these uh symbols mean right here in the notes section also hmm so we give the dynamic power numbers in the data sheet and finally we also give all the leakage numbers in the data sheet um we're also given the tolerances leakages are valid at plus minus 10 percent because they can vary on input and output States and so on so all the information that a user needs to decide whether I want to use this memory or not we want to given the data sheet so what I will do is I will upload this datasheet in the classroom I would want you to spend some time understanding it okay if you have any questions you can ask in the classroom it says the TA will help you respond there I'm sorry what is yeah can you just write that in the chat room I'm not able to understand what you're interesting what is can change yes content contains are test structures so you will read about study about them more in the vdf course also but you can find that online also important which are embedded in the in the design so that the design becomes testable okay so they are linked to testability of the design does that answer your question uh hello sir yes sir uh here uh in this data sheet we can see that the Sleep pin is having a very much higher capacitance what is because sleep okay so what happens clock you need to toggle every cycle um so for clock yes you have timing constraints which do not allow very large capacitance to be put on the clock pin okay sleep pin on the other hand would toggle after every 100 Cycles let us say because it shuts down the memory it it plays with the power power range of the memory so the Sleep pen you cannot toggle every cycle so you say okay for the Sleep pin because I am not toggling it in every cycle I can relax the capacitance constraint a bit don't waste area buffering the sleep then take the Sleep pen directly to wherever you want to it will be slow fine no problems it will still be okay with us is that okay okay sir yes sir so but for all other things you will see that the there is a limit on what kind of capacitance it has anything else yes questions so it is like foreign to reduce the congestion because there are so many pins there okay uh if I'm if complexity there's no other option if I have to get more density then I have to otherwise things will Define start to define the area that my memory has yes sir Focus office we are not discussed about the office hours let me talk to the ts1 and let me come back to you with all the office apps for all of us okay sure thank you we'll post that in the classroom itself thank you for reminding us okay thank you sir yeah anything else uh hello sir yes um and sometimes our data pins can can there be a default state or a preferred state for a data pin unless control so scan chain input for control bits so it's an input pin it is Data it is it will carry some information so that could be zero and that dependent does nothing about active high or active low on layer so control signals control pins would have a preferred state uh look at this control pins would have the preferred state if there is a preferred state for CSN the memory is active when CSN is low WN memory is in right mode when when it is low but at rest can there be a preferred state for address no addresses data addresses information I know it's not a control pin it's an input pin is that clear Rohit hi yes sir okay anything else total foreign no that simply says uh memory key external input here okay there could be a flip flop is so smaller circuit you may not have an internal clock though you have antenna clock in the flip flop also but uh you can say that CK is the clock input for the memory you can avoid the they could have avoided the use of term XML over here will be used lock resources will connect the memory input also okay okay we talked about it we in the in the in the cartoon that I showed you we I had used the term clock generation internal clock generator yes okay so that is a separate kind of block itself yeah logical circuitry here yeah okay so not a buffer it's a clock generator okay okay otherwise I have simply said you could have said clock buffer now it's not a buffer it's a cloud generator okay so we'll 
close the class now it's a cache memory copy data sheet yeah typically same memories would also be used for cash purposes [Music] that we will talk about later when we will talk about casualty"
zV339UClbIM,yes sir okay so today we are going to look at 60 memory cell but before that I just want to close one at one additional point that we had with uh data sheets if you remember that particular memory we called it spht single port high density um in in a similar manner you could have high speed memories also where the architecture is such that the memory is fast and you could have low power memories also where again the overall architecture is designed such that you consume lesser Dynamic power so you could have splp you could have sphs you could have uh similar you know nomenclatures every company again would have something different but different kind of optimizations are available on this slide I have also listed what are the different levers that memory designers use to you know to make such memories there if you want a high density memory you will use a very dense memory cell which would have because it's very dense the devices are small so the memory cell current is going to be low so memory cell current is low means current is low means you are slower and because any feature any additional features means more area you may not have any any additional speakers there high speed memory means large memory cell so that you can have a large current big drivers big sense amplifiers hierarchical architecture so that you can reduce the password answers that are toggling and so on similarly for low power you could have special low power features like retention circuits or floating bit lines and so on,https://www.youtube.com/watch?v=zV339UClbIM,"Link: https://www.youtube.com/watch?v=zV339UClbIM
Transcript: yes sir okay so today we are going to look at 60 memory cell but before that I just want to close one at one additional point that we had with uh data sheets if you remember that particular memory we called it spht single port high density um in in a similar manner you could have high speed memories also where the architecture is such that the memory is fast and you could have low power memories also where again the overall architecture is designed such that you consume lesser Dynamic power so you could have splp you could have sphs you could have uh similar you know nomenclatures every company again would have something different but different kind of optimizations are available on this slide I have also listed what are the different levers that memory designers use to you know to make such memories there if you want a high density memory you will use a very dense memory cell which would have because it's very dense the devices are small so the memory cell current is going to be low so memory cell current is low means current is low means you are slower and because any feature any additional features means more area you may not have any any additional speakers there high speed memory means large memory cell so that you can have a large current big drivers big sense amplifiers hierarchical architecture so that you can reduce the password answers that are toggling and so on similarly for low power you could have special low power features like retention circuits or floating bit lines and so on"
__bYZeL-0Gc,so uh again this is just about uh closing what we were talking about last time and with that I want to come to memory cells so uh we discussed there are different kinds of memories uh single port dual Port I am now introducing you multi-port memories also and then ROMs also we talked about so single port Memories the most common single port memory that you would have heard about is a 60 60 memory am I right anyone who has not heard about the 60s so all of us have heard about 60 exam sets so 60 what does RW stand for can anyone tell me read write yes so this is a single port memory in which you can do both read and write now let's come to the two Port category over there are there are two cells both HP but one is to read write and one is one read one rewrite what does this mean yes and the second one both the channels can be used for both read and write operations both the channels are symmetrical uh what about the 20 cells 2R and one rewrite how many ports are we talking about in three ports three reports of which two ports are only read ports and one port is both read and write so if I want to do three reads in this birthday Port memory can I do yes yes I can do yes if I want to do two rights in this particular multiple memory can I do no sir no because only one channel has the right capability there okay again this is important so that you understand uh when you read some technical paper or something you just should know what this means so 60 70 40 50 80 all this means how many transistors in the memory set for adira and we would call one t one one t one C that is one transistor one capacitor for mram you may simply call one one t one r so R Ram you may call one t one R and stuff like that or if it's a crossbar memory there may be no transistor at all it's just a cross bar there you will need some transistor but yeah okay so uh this the number before the the alphabet T represents number of transistors in the memory cell so which which memory cell do you think is bigger 60 or 40 360. why number of devices so more area it depends on the size good just 40 doesn't mean small set it depends on what are the specifications if the 40 cell is designed such that it has a huge current and 60 cell is designed such that it is a high density cell 60 cell could be smaller than the 47. we just talked about it in the last slide depending on the optimization a 60 cell could be denser than a 40 cell or a 5D cell also the layout physically is how I am placing those four cells what are those forces are they all pmoses are they all land masses are the pmoses and nmoses that could also change the kind of area we are talking about yeah are you able to see this so when you are simply looking at how do I put it we are simply talking about or reading technical papers with stock of 40 cell or five T cell mentally we might be tuned to think that they have lesser area that they are denser what I'm telling you is don't jump to that conclusion just yet you need more information to arrive at that answer are you with me yes sir okay now what does this uh Nora and ROM mean any idea no idea yet might be uh it's kind of we use a stack which forms nor or an end and similar kind of yeah so how is the memory cell memory cell organized is it organized in a nor structure or a nand structure what this means we will look at it I think in the next class uh then what does this diffusion contact middle one and we are mean for a ram cell might be sir if we programmed uh in Rome at a fabrication level in diffusion itself or contact for metal one then it will be called as very good friends thank you so this diffusion contact metal one via these are layers on a on a layout Hannah hello yes sir yes yes sir do you have different layers another layout on the Silicon so which layer do you use to program this read-only memory so read only memory means what something is already written into the memory now you can only read it something is already written means it is already programmed so when you want to program the memory do you use the diffusion layer or the contact layer or metal one layer or via one layer that tells what kind of round cell it is so which round cell would be most preferable so metal one I think so metal or the VR1 right why uh such diffusion it's a diffusion uh foreign there is no current flowing I can have a zero so but I would have more flexibility connecting the with the metal one why I'm manufacturing something I put a device somewhere I know not put a device somewhere manufacturability sir could it be the reason for the masks of the Mask no anyway you're making a difference to write to program the ROM you need an extra mask we are not talking about that we're talking about regular um what do you say diffusion you don't even need to need a mask you need to make the layers mask make extra whole like and how does that change anything so but mask costs are significant right so anyway are making a mask you need a diffusion mask anyways this if you are programming the memory in metal one do you not need the diffusion mask you'll still need that mask yes I know yes sir there's something else diffusion name foreign [Music] [Music] we'll finish foreign we're not talking about Max over here now Okay so uh certainly could it be the reason that if you go for diffusion type around cell it will be Mass programmable whereas when we uh talk about something like metal based ROMs and it can be uh pram programmable job so it can be one time we're talking about only ROMs they're Mass from algorithms only okay so um how many of you like with us you can put a plus one in the chat window no one likes Pizza some people like pizza okay so uh what do you think you know Domino's or something they are delivering your pizza within 20 minutes [Music] so do they net the dough just before just when you order or something is done previously start to mix maida and water and everything as soon as you order the pizza something is done beforehand um the dough is net the dough is leaving it is even what you say uh before long before you they don't even know that you are going to place an order but they know some orders would come so because they have done some amount of work already as soon as you place an order all that he needs to do is okay it's a regular sized Pizza I need this kind of this amount of dough I will just flatten it put the toppings and go ahead now that is Domino's you also have get frozen pizzas and from the market um you also get Frozen pictures from the market or you get you get a pre-made pizza basis what do you do with those teammates with the basis if it's a pre-made pizza base all that you need to do is apply some sauces on it put the toppings put it in the oven you will get something without five minutes dominoes guys because he had to do some extra stuff what what extra stuff we had to actually flatten the dough then he had to put the sauces so there was at least one extra step so he would take a little longer hmm similarly if there is a suppose we are talking about a setup box suppose you're talking about a setup box and we say that there are four customers that a particular company say broadcom has to handle uh four customers could be Airtel jio and Dish TV and blah blah blah each one of them need some different programmation for their boot code because they have different validation codes with their satellites and something like that so you need to put a ROM in in those steps and you need to program it according to the vendor what would you want you would want to deliver the chips to the customer as early as possible or is it fine if you deliver it four days five days later ten days later there's a customer ready to pay you money he needs to go to the market would you want to deliver it to him ASAP that's a figure of Merit that's a thing that he would value enough hello yes sir so if I say that the programmation has to be done at diffusion level then I have to wait for the customer to give me his or her program and only then I will be able to do the diffusion layer in the first place whereas if the programmation is that we have one level then I know that the memory is exactly the same uphill metal one so I will already prepare those bases huh I will already have the Wafers processed up till metal one as soon as the user code comes I will generate the mask for VR1 and I will process the Wafers from VR1 onwards after the customer places a request what would be faster diffusion or VR1 what is faster so as higher up metal layer or as higher up layer that you use for programming around that is what is preferred clear hello please sir is it because it is then everyone will choose to go with the higher level okay no that if you if you use the diffusion layer you could be denser yeah or it could be that in total you have only three Metals in a given process Imaging process for example we talked about it in the DVD course also you have only three metal layers you do not want to use one metal layer for programming you would rather go for diffusion but when you have 10 metal layers on the chip you can ask values one metal layer or a real layer for programming and great works well there could be different reasons why you would use different layers rather uh sir is this approach called the gate array based design I mean is this the same approach no no okay now we're not talking about Gates here we're talking about memory cells only okay okay sir uh sir so read only in read only membership will be previously putting our standard data into our cell right sir another data how about you mean by standard data version I mean it's it's already decided I mean we can't change that read-only memory means whatever is inside the memory you can't change it right into the memory now so you have to know it yes sir so sir uh how do we program this data exactly sir I mean you are saying that we'll be programming it on diffusion contact metal one or VR so how will visit programming that because uh I what what uh I understood is that we need some transistors to store some kind of data over there so uh I think we can't have any kind of transfer on metal one there yeah there could be transistors down there which you could connect or not connect are there if you use metal one Proclamation you will either connect those transistors or not connect those transistors if they are not connected they are not as good as not they are not yes sir so we will see we will look into this uh when we talk about Ram self I mean I'm just introducing these types to you okay we are still in that zone of top level data sheet understanding that if someone tells you that I have I'm giving you a diffusion ROM what does it mean and if someone tells you I'm giving you a via one ROM what does it mean when you look at the data sheet you should be able to understand that that is what I need to say okay okay sir now how to do it we will look at it later okay so uh now we come to so any questions here yes sir I have one talking about the two Port uh how exactly internally they divide the addresses do do the two ports have exist Texas from starting to ending or towards the Divide and then we'll look at round sets okay multiport cells are extension of these uh two Port says only so this is a step timer slide for you guys as to what to expect in the next in today's and the next lecture or the next to next one yes Rohit foreign can you please repeat I was not able to hear you can you please repeat oh hello sir yeah no at times the kind of space you have on a chip could be rectangular and you want a rectangular memory mux only allows you to change the aspect ratio as you desire,https://www.youtube.com/watch?v=__bYZeL-0Gc,"Link: https://www.youtube.com/watch?v=__bYZeL-0Gc
Transcript: so uh again this is just about uh closing what we were talking about last time and with that I want to come to memory cells so uh we discussed there are different kinds of memories uh single port dual Port I am now introducing you multi-port memories also and then ROMs also we talked about so single port Memories the most common single port memory that you would have heard about is a 60 60 memory am I right anyone who has not heard about the 60s so all of us have heard about 60 exam sets so 60 what does RW stand for can anyone tell me read write yes so this is a single port memory in which you can do both read and write now let's come to the two Port category over there are there are two cells both HP but one is to read write and one is one read one rewrite what does this mean yes and the second one both the channels can be used for both read and write operations both the channels are symmetrical uh what about the 20 cells 2R and one rewrite how many ports are we talking about in three ports three reports of which two ports are only read ports and one port is both read and write so if I want to do three reads in this birthday Port memory can I do yes yes I can do yes if I want to do two rights in this particular multiple memory can I do no sir no because only one channel has the right capability there okay again this is important so that you understand uh when you read some technical paper or something you just should know what this means so 60 70 40 50 80 all this means how many transistors in the memory set for adira and we would call one t one one t one C that is one transistor one capacitor for mram you may simply call one one t one r so R Ram you may call one t one R and stuff like that or if it's a crossbar memory there may be no transistor at all it's just a cross bar there you will need some transistor but yeah okay so uh this the number before the the alphabet T represents number of transistors in the memory cell so which which memory cell do you think is bigger 60 or 40 360. why number of devices so more area it depends on the size good just 40 doesn't mean small set it depends on what are the specifications if the 40 cell is designed such that it has a huge current and 60 cell is designed such that it is a high density cell 60 cell could be smaller than the 47. we just talked about it in the last slide depending on the optimization a 60 cell could be denser than a 40 cell or a 5D cell also the layout physically is how I am placing those four cells what are those forces are they all pmoses are they all land masses are the pmoses and nmoses that could also change the kind of area we are talking about yeah are you able to see this so when you are simply looking at how do I put it we are simply talking about or reading technical papers with stock of 40 cell or five T cell mentally we might be tuned to think that they have lesser area that they are denser what I'm telling you is don't jump to that conclusion just yet you need more information to arrive at that answer are you with me yes sir okay now what does this uh Nora and ROM mean any idea no idea yet might be uh it's kind of we use a stack which forms nor or an end and similar kind of yeah so how is the memory cell memory cell organized is it organized in a nor structure or a nand structure what this means we will look at it I think in the next class uh then what does this diffusion contact middle one and we are mean for a ram cell might be sir if we programmed uh in Rome at a fabrication level in diffusion itself or contact for metal one then it will be called as very good friends thank you so this diffusion contact metal one via these are layers on a on a layout Hannah hello yes sir yes yes sir do you have different layers another layout on the Silicon so which layer do you use to program this read-only memory so read only memory means what something is already written into the memory now you can only read it something is already written means it is already programmed so when you want to program the memory do you use the diffusion layer or the contact layer or metal one layer or via one layer that tells what kind of round cell it is so which round cell would be most preferable so metal one I think so metal or the VR1 right why uh such diffusion it's a diffusion uh foreign there is no current flowing I can have a zero so but I would have more flexibility connecting the with the metal one why I'm manufacturing something I put a device somewhere I know not put a device somewhere manufacturability sir could it be the reason for the masks of the Mask no anyway you're making a difference to write to program the ROM you need an extra mask we are not talking about that we're talking about regular um what do you say diffusion you don't even need to need a mask you need to make the layers mask make extra whole like and how does that change anything so but mask costs are significant right so anyway are making a mask you need a diffusion mask anyways this if you are programming the memory in metal one do you not need the diffusion mask you'll still need that mask yes I know yes sir there's something else diffusion name foreign [Music] [Music] we'll finish foreign we're not talking about Max over here now Okay so uh certainly could it be the reason that if you go for diffusion type around cell it will be Mass programmable whereas when we uh talk about something like metal based ROMs and it can be uh pram programmable job so it can be one time we're talking about only ROMs they're Mass from algorithms only okay so um how many of you like with us you can put a plus one in the chat window no one likes Pizza some people like pizza okay so uh what do you think you know Domino's or something they are delivering your pizza within 20 minutes [Music] so do they net the dough just before just when you order or something is done previously start to mix maida and water and everything as soon as you order the pizza something is done beforehand um the dough is net the dough is leaving it is even what you say uh before long before you they don't even know that you are going to place an order but they know some orders would come so because they have done some amount of work already as soon as you place an order all that he needs to do is okay it's a regular sized Pizza I need this kind of this amount of dough I will just flatten it put the toppings and go ahead now that is Domino's you also have get frozen pizzas and from the market um you also get Frozen pictures from the market or you get you get a pre-made pizza basis what do you do with those teammates with the basis if it's a pre-made pizza base all that you need to do is apply some sauces on it put the toppings put it in the oven you will get something without five minutes dominoes guys because he had to do some extra stuff what what extra stuff we had to actually flatten the dough then he had to put the sauces so there was at least one extra step so he would take a little longer hmm similarly if there is a suppose we are talking about a setup box suppose you're talking about a setup box and we say that there are four customers that a particular company say broadcom has to handle uh four customers could be Airtel jio and Dish TV and blah blah blah each one of them need some different programmation for their boot code because they have different validation codes with their satellites and something like that so you need to put a ROM in in those steps and you need to program it according to the vendor what would you want you would want to deliver the chips to the customer as early as possible or is it fine if you deliver it four days five days later ten days later there's a customer ready to pay you money he needs to go to the market would you want to deliver it to him ASAP that's a figure of Merit that's a thing that he would value enough hello yes sir so if I say that the programmation has to be done at diffusion level then I have to wait for the customer to give me his or her program and only then I will be able to do the diffusion layer in the first place whereas if the programmation is that we have one level then I know that the memory is exactly the same uphill metal one so I will already prepare those bases huh I will already have the Wafers processed up till metal one as soon as the user code comes I will generate the mask for VR1 and I will process the Wafers from VR1 onwards after the customer places a request what would be faster diffusion or VR1 what is faster so as higher up metal layer or as higher up layer that you use for programming around that is what is preferred clear hello please sir is it because it is then everyone will choose to go with the higher level okay no that if you if you use the diffusion layer you could be denser yeah or it could be that in total you have only three Metals in a given process Imaging process for example we talked about it in the DVD course also you have only three metal layers you do not want to use one metal layer for programming you would rather go for diffusion but when you have 10 metal layers on the chip you can ask values one metal layer or a real layer for programming and great works well there could be different reasons why you would use different layers rather uh sir is this approach called the gate array based design I mean is this the same approach no no okay now we're not talking about Gates here we're talking about memory cells only okay okay sir uh sir so read only in read only membership will be previously putting our standard data into our cell right sir another data how about you mean by standard data version I mean it's it's already decided I mean we can't change that read-only memory means whatever is inside the memory you can't change it right into the memory now so you have to know it yes sir so sir uh how do we program this data exactly sir I mean you are saying that we'll be programming it on diffusion contact metal one or VR so how will visit programming that because uh I what what uh I understood is that we need some transistors to store some kind of data over there so uh I think we can't have any kind of transfer on metal one there yeah there could be transistors down there which you could connect or not connect are there if you use metal one Proclamation you will either connect those transistors or not connect those transistors if they are not connected they are not as good as not they are not yes sir so we will see we will look into this uh when we talk about Ram self I mean I'm just introducing these types to you okay we are still in that zone of top level data sheet understanding that if someone tells you that I have I'm giving you a diffusion ROM what does it mean and if someone tells you I'm giving you a via one ROM what does it mean when you look at the data sheet you should be able to understand that that is what I need to say okay okay sir now how to do it we will look at it later okay so uh now we come to so any questions here yes sir I have one talking about the two Port uh how exactly internally they divide the addresses do do the two ports have exist Texas from starting to ending or towards the Divide and then we'll look at round sets okay multiport cells are extension of these uh two Port says only so this is a step timer slide for you guys as to what to expect in the next in today's and the next lecture or the next to next one yes Rohit foreign can you please repeat I was not able to hear you can you please repeat oh hello sir yeah no at times the kind of space you have on a chip could be rectangular and you want a rectangular memory mux only allows you to change the aspect ratio as you desire"
CtBNzYGvi9s,correct so now we come to water 16 60 single port cell is but before we go to a 60 single port cell can you tell me what is the simplest and we discuss this in DVD also what is the simplest storage element that you know of course a latch and if you want to uh you know store a desired data into it we call it as an Sr latch hmm am I right this is how Sr latch looks like yes sir now if I say that I want to clock it also um then I will put a clock some extra transistors come into picture which were which are clocked um now I say see actually storing only one data the Q and Q Bar are complementary expected to be complementary to each other so um uh what do you say why have two pins two input pins R and S why can't we have just one so what is it called then D latch where you say okay there is D and there is D Bar and output and then and you're storing Q there and Q Bar is also available to you now this B latch if I ask you to implement it in CMOS logic can you do this for me the last can be implemented in CMOS Logic for me quickly and tell me how many number of transistors you need you can put the number of transistors in the chat window d-latch I want you to implement use complex Gates no problem there use complex Gates but implement it and full CMOS logic how many transistors do you need foreign okay so uh 18 . yes classy did you also make the inverter D2 data bar inverter so some of you are saying 18 some are saying 14 some are also saying 12. so in reality if you also need to make that inverter there you would need 14 devices something like this so 12 devices for the complex Gates and two devices for the inverter this is the CMOS implementation can you just quickly check if this meets the if it is equivalent to the Circuit that we saw earlier we'll use complex Gates here so it is 14 transistors but we wanted a six transistor memory cell this is the simplest clogged memory cell that uh this is the simplest clocked storage element we're talking about but somehow everyone said srams would have six transistor cells so how do you reach six transistors um so what we say is that look for a memory when I'm talking about a big memory there huh I need so there could be one zero two four words in a memory but I want to access only one word at a time so in one zero two three words the clock will not go so clock will be zero of the one zero two four words one word I access and the one zero two three words there was no there is going to be no clock this clock is going to be zero then do you realize that this this transistors are almost always on if I assume that the probability of selection of any memory cell is equal or any word is equal then the probability of this transistor being off in any given cycle is 1 by 1000 let us say that's a low probability is it not so if I say that I want to save area anyways for more than 1000 cycles and 1024 or in fact one zero two three Cycles out of one zero two four this transistor is going to be on so effectively what is happening vdd is getting transferred here in almost every cycle so only accept the selected cell except the selected cell uh vdd and in which whether vdd arrives here or not is dependent on these two transistors otherwise in all the other cells this node already has bdd are you able to see this yes so what I say is yeah this one cell the selected word we will look at it differently but to save area and if if I if I connect vdd there I save four transistors you see however when I remove those four to four pmoses on the top and put vdd here what happened see over here there were these transistors which carried D and D Bar now they are no longer there if these two transistors are no longer there then what happens I need to say that if D is equal to 1 over here initially when clock was 1 D was one what would have happened when clockwise 1 and D was one this node would not have gone to vdd because both these transistors would have been off D was one clock was one so both these would have been off but now this is vdd over here so what my what happens it means when I want to write 0 onto Q Bar it will be difficult now because there is this pmos which is connecting vdd here so now even though I saved area my ability to write in the latch has degraded and it is kind of become ratioed sizing so I have to take care of sizing of this pmos and the strength of these devices to say whether I am able to write 0 in the memory cell or not are you with me yes sir so please repeat the last part so what we are saying is that because this pmos is on now I want to write a 0 here it means initially there was one here if it was 1 here then the 0 was written on this side are you able to see this if zero was written on this side it means this pmos was conducting current yes sir now you want to write a 0 over here so what this means D is equal to 1 c k equal to 1 you want to sync the current yes sir I will be able to sync the sufficient current only when the strength of this pmos is smaller than the strength of this stack of nmoses yes sir yes sir so sizing of the devices now plays a role in the functionality of the memory cell yeah okay yes sir to save area I have to now take care of sizing but the area gains are humongous you see instead of 14 T you are you reduced four transistors from there humongous area again so you want to maintain that now let's look at now that we are here now that we are here let's look at what else can we do to save area so the first thing we do is we just simply re organize this cell now if you look at it this is an inverter now these two are inverters so I can actually reorganize the cell as something like this are you able to see this I simply uh kind of pick this Stack Up and rotated it so that it appears like this I've also put the clock terminal inside and the data terminal outside it doesn't change the functionality per se hmm so now I say that see memory cells are organized in an array so let me look at an array view now so this is what my array view would be a two cross so two set of storage elements now I say that uh see if I now when we looked at the memory array what did we say I will have one data pin here it will be able to write into all the memory cells and it will write into that particular memory cell where the word line is selected do you remember this yes sir Anna so I am saying that in reality there is only one data pin per column so this is D2 then this is also D2 and if this is D1 then this is also D1 what that means is I can pull these inverters out of this memory cell so my 14p memory cell is now appearing to be 8p Memory cell with no loss of functionality as of now except that I have some sizing constraints built in now all that I did is I shared the inverters across columns I can do that is it okay yes sir okay so then what we do is we say ah see there is this D1 over here there is this D1 over here D1 bar over here D1 bar over here D2 over here D2 over here so there is some additional element which has the same same vertical Behavior and I do something about it and I pull this D1 nmos and D1 bar nmos and D2 nmos and D2 bar nmos outside again into the common area and bingo I appear to have a 60 cell now hmm it is just that instead of calling this as a clock we call this as a word line and these vertical signals are called bit lines and this D1 D2 these nmoses these are now available not inside the memory cell but in the i o region and we will call them right drivers is that okay any questions clear sir can you repeat the part where the inverters were shared across the columns okay so if we look at that side what did we say we said that uh in reality because there is only one data pin per column so I have to access only one word and I know because we looked at memory organization earlier we know that in a memory we need one data pin per column or per multiple columns actually if there is a mux then only one data pin is needed so in reality this D2 is not going to be different from B1 okay so if if it is going to be D1 only then why put two inverters and put an inverter in every row put that inverter down there so we put this inverter down here then we looked at the set of nmoses we said oh these and Moses have the same signal so I shared them also and I came to this stage is this clear answer so when we were removing those clock transistor when you were saying only one will have a clock out of one zero two four transistors that is why we removed it for everyone okay constraint now ESL okay so yes so you have uh mentioned the clocks as different clock one and clock two so so it's generated and based upon my address bits will connect to again foreign lines but connecting to the same block like depending upon the address bit yeah so you gave clock only to the selected word now okay so but actually there's only one clock it is only connected negative different word lines depending upon that yeah yes okay now because word line Spectra are not clocks that is why we change the name from ck1 ck2 to wl1 wl2 yes sir these are decoded signals but they are clogged but only when the clock counts will you get the word line is it not yes sir so they can be considered as clocks also for this particular memory cell it is like a clock okay clear any further questions bit line bar so q and Q Bar bit line and bit line bar so so uh in this I have region the D1 and D1 Dash transistors will be called as right diverse or this whole structure this inverter D1 and D1 transistor yeah yeah so we'll come to that later doesn't matter it's a it's a point it's what it would be called is whatever see have you understood the concept that is what my question is whether we call all these four transistors as a right driver or there are 10 other transistors that also come into picture we are not even talking about that yet right driver design is a separate thing you'll look at it later but yeah this becomes a part of the right driver okay so there could be other stuff also there it's not memory design is not so simple as I've made it appear to you don't worry go into more details I am going into detail slowly so that you don't get overwhelmed by yeah again so with this now we say that my one memory cell has only six transistors where there is bit nine bit nine bar and word line they are the three interfaces some some things that go out and then they carry information in and out of the memory cell they control the memory cells and then inside the memory cell you have the Q pin and the Q Prime Q Bar pen you could also call it Q Bar whatever okay so now how do you read and write into the memory cell see until the time it was a d latch you knew you would get a one at the Q pin and uh zero at the Q Bar but now q and Q Bar are no longer accessible now I just somehow said that void line bit line and bit line bar all of the only ports that you have the user can no longer access q and Q Bar so how does he read how does he read search through WL in bit line yes,https://www.youtube.com/watch?v=CtBNzYGvi9s,"Link: https://www.youtube.com/watch?v=CtBNzYGvi9s
Transcript: correct so now we come to water 16 60 single port cell is but before we go to a 60 single port cell can you tell me what is the simplest and we discuss this in DVD also what is the simplest storage element that you know of course a latch and if you want to uh you know store a desired data into it we call it as an Sr latch hmm am I right this is how Sr latch looks like yes sir now if I say that I want to clock it also um then I will put a clock some extra transistors come into picture which were which are clocked um now I say see actually storing only one data the Q and Q Bar are complementary expected to be complementary to each other so um uh what do you say why have two pins two input pins R and S why can't we have just one so what is it called then D latch where you say okay there is D and there is D Bar and output and then and you're storing Q there and Q Bar is also available to you now this B latch if I ask you to implement it in CMOS logic can you do this for me the last can be implemented in CMOS Logic for me quickly and tell me how many number of transistors you need you can put the number of transistors in the chat window d-latch I want you to implement use complex Gates no problem there use complex Gates but implement it and full CMOS logic how many transistors do you need foreign okay so uh 18 . yes classy did you also make the inverter D2 data bar inverter so some of you are saying 18 some are saying 14 some are also saying 12. so in reality if you also need to make that inverter there you would need 14 devices something like this so 12 devices for the complex Gates and two devices for the inverter this is the CMOS implementation can you just quickly check if this meets the if it is equivalent to the Circuit that we saw earlier we'll use complex Gates here so it is 14 transistors but we wanted a six transistor memory cell this is the simplest clogged memory cell that uh this is the simplest clocked storage element we're talking about but somehow everyone said srams would have six transistor cells so how do you reach six transistors um so what we say is that look for a memory when I'm talking about a big memory there huh I need so there could be one zero two four words in a memory but I want to access only one word at a time so in one zero two three words the clock will not go so clock will be zero of the one zero two four words one word I access and the one zero two three words there was no there is going to be no clock this clock is going to be zero then do you realize that this this transistors are almost always on if I assume that the probability of selection of any memory cell is equal or any word is equal then the probability of this transistor being off in any given cycle is 1 by 1000 let us say that's a low probability is it not so if I say that I want to save area anyways for more than 1000 cycles and 1024 or in fact one zero two three Cycles out of one zero two four this transistor is going to be on so effectively what is happening vdd is getting transferred here in almost every cycle so only accept the selected cell except the selected cell uh vdd and in which whether vdd arrives here or not is dependent on these two transistors otherwise in all the other cells this node already has bdd are you able to see this yes so what I say is yeah this one cell the selected word we will look at it differently but to save area and if if I if I connect vdd there I save four transistors you see however when I remove those four to four pmoses on the top and put vdd here what happened see over here there were these transistors which carried D and D Bar now they are no longer there if these two transistors are no longer there then what happens I need to say that if D is equal to 1 over here initially when clock was 1 D was one what would have happened when clockwise 1 and D was one this node would not have gone to vdd because both these transistors would have been off D was one clock was one so both these would have been off but now this is vdd over here so what my what happens it means when I want to write 0 onto Q Bar it will be difficult now because there is this pmos which is connecting vdd here so now even though I saved area my ability to write in the latch has degraded and it is kind of become ratioed sizing so I have to take care of sizing of this pmos and the strength of these devices to say whether I am able to write 0 in the memory cell or not are you with me yes sir so please repeat the last part so what we are saying is that because this pmos is on now I want to write a 0 here it means initially there was one here if it was 1 here then the 0 was written on this side are you able to see this if zero was written on this side it means this pmos was conducting current yes sir now you want to write a 0 over here so what this means D is equal to 1 c k equal to 1 you want to sync the current yes sir I will be able to sync the sufficient current only when the strength of this pmos is smaller than the strength of this stack of nmoses yes sir yes sir so sizing of the devices now plays a role in the functionality of the memory cell yeah okay yes sir to save area I have to now take care of sizing but the area gains are humongous you see instead of 14 T you are you reduced four transistors from there humongous area again so you want to maintain that now let's look at now that we are here now that we are here let's look at what else can we do to save area so the first thing we do is we just simply re organize this cell now if you look at it this is an inverter now these two are inverters so I can actually reorganize the cell as something like this are you able to see this I simply uh kind of pick this Stack Up and rotated it so that it appears like this I've also put the clock terminal inside and the data terminal outside it doesn't change the functionality per se hmm so now I say that see memory cells are organized in an array so let me look at an array view now so this is what my array view would be a two cross so two set of storage elements now I say that uh see if I now when we looked at the memory array what did we say I will have one data pin here it will be able to write into all the memory cells and it will write into that particular memory cell where the word line is selected do you remember this yes sir Anna so I am saying that in reality there is only one data pin per column so this is D2 then this is also D2 and if this is D1 then this is also D1 what that means is I can pull these inverters out of this memory cell so my 14p memory cell is now appearing to be 8p Memory cell with no loss of functionality as of now except that I have some sizing constraints built in now all that I did is I shared the inverters across columns I can do that is it okay yes sir okay so then what we do is we say ah see there is this D1 over here there is this D1 over here D1 bar over here D1 bar over here D2 over here D2 over here so there is some additional element which has the same same vertical Behavior and I do something about it and I pull this D1 nmos and D1 bar nmos and D2 nmos and D2 bar nmos outside again into the common area and bingo I appear to have a 60 cell now hmm it is just that instead of calling this as a clock we call this as a word line and these vertical signals are called bit lines and this D1 D2 these nmoses these are now available not inside the memory cell but in the i o region and we will call them right drivers is that okay any questions clear sir can you repeat the part where the inverters were shared across the columns okay so if we look at that side what did we say we said that uh in reality because there is only one data pin per column so I have to access only one word and I know because we looked at memory organization earlier we know that in a memory we need one data pin per column or per multiple columns actually if there is a mux then only one data pin is needed so in reality this D2 is not going to be different from B1 okay so if if it is going to be D1 only then why put two inverters and put an inverter in every row put that inverter down there so we put this inverter down here then we looked at the set of nmoses we said oh these and Moses have the same signal so I shared them also and I came to this stage is this clear answer so when we were removing those clock transistor when you were saying only one will have a clock out of one zero two four transistors that is why we removed it for everyone okay constraint now ESL okay so yes so you have uh mentioned the clocks as different clock one and clock two so so it's generated and based upon my address bits will connect to again foreign lines but connecting to the same block like depending upon the address bit yeah so you gave clock only to the selected word now okay so but actually there's only one clock it is only connected negative different word lines depending upon that yeah yes okay now because word line Spectra are not clocks that is why we change the name from ck1 ck2 to wl1 wl2 yes sir these are decoded signals but they are clogged but only when the clock counts will you get the word line is it not yes sir so they can be considered as clocks also for this particular memory cell it is like a clock okay clear any further questions bit line bar so q and Q Bar bit line and bit line bar so so uh in this I have region the D1 and D1 Dash transistors will be called as right diverse or this whole structure this inverter D1 and D1 transistor yeah yeah so we'll come to that later doesn't matter it's a it's a point it's what it would be called is whatever see have you understood the concept that is what my question is whether we call all these four transistors as a right driver or there are 10 other transistors that also come into picture we are not even talking about that yet right driver design is a separate thing you'll look at it later but yeah this becomes a part of the right driver okay so there could be other stuff also there it's not memory design is not so simple as I've made it appear to you don't worry go into more details I am going into detail slowly so that you don't get overwhelmed by yeah again so with this now we say that my one memory cell has only six transistors where there is bit nine bit nine bar and word line they are the three interfaces some some things that go out and then they carry information in and out of the memory cell they control the memory cells and then inside the memory cell you have the Q pin and the Q Prime Q Bar pen you could also call it Q Bar whatever okay so now how do you read and write into the memory cell see until the time it was a d latch you knew you would get a one at the Q pin and uh zero at the Q Bar but now q and Q Bar are no longer accessible now I just somehow said that void line bit line and bit line bar all of the only ports that you have the user can no longer access q and Q Bar so how does he read how does he read search through WL in bit line yes"
LkOnj23Q3UE,so if we say this is the sixth transition memory cell now over here I have changed the nomenclature from q and Q Bar to uh BLT and blfi okay but it means the same thing don't worry about that okay so what we do is before anything happens we keep before the word line comes we actually keep the bit lines pre-charged pre-charge means that they are so these bit lines are essentially capacitances um so we say that these capacitances are held at or pre-charged to some voltage level let us say vdd itself let us say they are pre-charged at vdd level when wordline goes High what happens these these nmoses will turn on these and Mosses are called excess transistors so these are Moses will turn on they will allow access to the contents inside the memory and because there is a zero written here the charge would start to flow like this on this side over here also it is one over here it is vdd both side is vdd over here this was vdd and the other side was zero so some charges flow like this and this bit line will discharge what happens one bit line discharge the other bit line did not and that is what will now in the i o region trigger the sense amplifier to complete the read operation is this clear are you able to see this any questions to the read operation can you explain this what part did you not understand Abhishek sir bitline is discharging that part then this is the decline bar and B yes so when wordline gets selected do you see that okay this is so what I said was both the internal nodes are precharged to vdd both the bit lines are precharged to vdd yeah so yes sir okay now when we turn the word line on what happens these are nmoses they will turn on now what happens when they turn on there was a zero stored on this side so this nmos will now start to conduct some current yes sir will there be any current here no Hello both sides are we ready yes sir so some current will start to flow from here now this is a capacitor you remove some so when a current flows some charge is removed from this capacitor yes so when a charge is removed from a capacitor what happens to its voltage decreases it is reduces the voltage Falls so over here because bit line was connected to blti which had zero stored on it my BL voltage faults after some time there would be sufficient differential between bitline and bit line bar and I will be able to trigger the synth amplifier and complete the read operation yes sir is this clear now yes sir The BLT I will get charged to vtd minus VT right why see this if there was a zero stored here there was a if there was Zero stored on this side then there was one stored on the other side now yes okay I know in fact if if this this nmos is not strong enough what will happen you very rightly said this blti will start to rise up yes if this BLT starts to rise up what would happen the discharging of from BL will be slower than like yeah the stars from beer will become at a slower rate but still more worrisome thing is you stored a one here you stored a zero here now this is no longer zero this is almost one oh yes sir so what happens [Music] my data can get corrupted so during read cycle or when the word line is on that is when my stability things lowest because this blti is going up if there was no flow of current this blti would remain at zero are you able to see this because even if it had gone a little bit up the nmos is on it will discharge but when the word line is on then there is a current coming from here also and therefore my stability is slowest is is the least when the word line is on that is where we will finally measure the noise margin of the memory cell okay so read operation is clear any questions for the read operation say Excel I'm able to understand the operation but actually the bit line went to zero so the Suns amplifier would say that bit nine had stored as a bit line blti was storing a zero so the user may interpret it as red zero okay okay it is your prerogative as a designer as to what it means you may call it zero you may call it one it depends on what you what you wrote if when you had to write a zero you stored 0 on brti you would read it as zero listen when you wanted to write a zero you stored one on the ITI you will read it as one yes sir okay so so read and write are coupled you cannot look at them independently whether it is a zero or a one is that okay sir yes vaishna so sir previously we were seeing that our bit line and bitline bar were having an inverter and tensor so both how can they have the same value at the same time exactly I mean during start you are giving them that was a simplistic view for you as I said we are going to more and more Real views so these are two capacitors I can charge those two capacitors are varied in a okay so there is there is no inverter in reality in between them but we are just storing the value of this bit line and bitline bar with the help of a capacitor yeah so in reality if you notice there was never a inverter directly between the bit lines the inverter was on data pin and that went to the right driver bit lines um yes yes yeah that's it sir I didn't understand how did this animals if the animals uh is slower then how will the data corruption occur I didn't understand that we will come to that we'll look at stability in much more detail in a little while don't worry there will be some homework assignment for you also to understand this so it is it is not a graded assignment so you can you may or may not do it but there will be something that I will ask you to do okay we will come back anything else doesn't mean anything it's just a name BLT T could represent true node and I could represent internal so true and false I could have called it q and Q Bar I could have called it anything don't worry na members uh because that you're coming to these questions I want to arrive at these questions in just a little while we will jointly find the answers to these questions what do you think how how would you size this foreign uh so that current should be uh that pull down and was Jada partially I think yeah so what we essentially want is that even if there is a lot of current coming from bit line onto the blti node all that current should be immediately shifted away without significant rise in the level of biti so that there is least impact on stability so if I have to shrink lots of current without significant VDS the pull down should be strong much stronger than the pull pass gate there much stronger than the access transistor there so we will see we will come into this sizing Bala business in just a little while Ranjit okay Niraj yeah so actually I'm a little bit confused like what we are reading so like what I interpreted is that like we are just making depending on blog like on the wishes that we are reading is that correct so we're creating a differential between bitline and bitline wire and that is what we will amplify in the sense amplifier yes so sir like if the case we take like blti is one and blfi 0 and like then the BLB will go we'll fall down then we can see that we are reading one yes okay thank you okay sir we have fast enough sir so uh I don't know if I can ask this question right now or not but sir now my bit line is has got discharged and this difference which creates between the bit line and bitline bar that is sent to the sense amplifier right sir so sir for my since amplifier to work the sense amplifier signal should be enabled so I mean there should be some other wire going from between these positions to the same sample require enabled to enable that so saying that okay my uh so you can you can work on with my sentence sales amplifier operation when uh when my bit line is down and bitline bar is uh uh so we had that San horizontal wire in the io region so is that where coming from somewhere around here how can it come from every memory sir oh yes we talked about the reference bit cell and reference uh reference bit lines and reference World lines now yes sir that was exactly for this purpose so that we could generate the enable signal for the Suns amplifier look at that in more detail later also don't worry yes sir so now how does the right happen for the right to happen so you already know what you want to write now it is 0 over here and one over here if you want to write into the memory cell you would actually want it to go to one and it to go to zero so you already know what data you want to write into the memory cell based on that what you do is even before the word line comes you keep one bit line at one and you discharge the other bit line to zero then when the world line arrives what happens over here now this was at vdd this was at zero over here vdd 0. so on on the left side regular read operation will start to happen but on the right side what happens is this one starts to get discharged through the excess transistor when that discharges what happens as it starts to go to zero this pmos will turn on so initially when this was reading only this was the voltage we ensured that blti does not rise very much but after a lot of discharge had happened what happened this pmos turned on so this will take this node to 1. and we would say that and we would say that I have flipped the contents of the memory cell I have written 0 there and 1 here okay any questions on the right operation is disturbing yes mid lane is also Disturbed so we discharged the Bedtime through that right driver yeah the right way we wanted to write a zero we discharged it through the right driver is in the reads so this one we will keep recharge the bit line so because we know this is the right cycle what we could do is we could actually have a p Mass connected here which is on during the right cycle so this would remain at one this would not discharge that we can do we may do we may not do that as a designer I have to decide if it helps me or not oh sir sir how are you deciding where we need to write one left side or right side the user gave you some data based on that you decide whether biti needs to be one or a zero okay so suppose sir here if you want to write uh one at vlti side so what I should do if I want to write a one on blti I know that dlfi needs to be written to zero foreign means dlfi needs to be at zero so that is what we just did we took BLB to 0 and we wrote 0 on blfi then we wrote 0 on blfi plti automatically went to one so not clear yourself okay so if you want to write a one on blti it essentially means that you want to write a 0 on blfi yes yes sir so that is what we just did if I want to write a zero on blfi what did I do I took BLB to 0 I wrote a 0 there once I wrote a 0 there what happened the pmos turned on on the blti side and it wrote a one on that side okay but initially if the stored data was at vlti was Zero was if you look at it what was the case he said blti is zero um he said blti is zero we discharged the bit line bar to zero now therefore we discharged blfi to zero once blfi went to zero we said that blti will get charged to the people this thing I understood I am saying that's a palace but now uh user sends that the vla 5. now if you want to write one on blfi then you will put bit line to 0 and maintain BLB at one basically what I am saying is you cannot write a one inside a memory cell because you are using nmos pass Gates can you transfer a full one no you can only write a zero are you able to see this uh sir you will always write a zero first because you have n Mass baskets if you had T Mass yes you would write a one first okay yes um is it by using that D Bar uh data is one so that yeah the die drivers yes okay and so so if D is 0 and D Bar is one so what means by that data uh we say that we want to write one or zero here yes so that we decide as designers okay okay neeraj yeah I'm sorry uh as much I understand like if we have to write zero so can we say like we keep BL at 0 b l b at one and then we uh we raise up the right line yes if you want to write the other data like we just wrote one one zero in the memory cell now you want to write 0 1. so now in the next cycle you will take bit line to zero you will maintain bit line bar at one and you will write 0 on the blti side yeah yes yes Transit uh sorry I to add the same dot as what a Raga said so we start the right cycle uh from the discharging node and once this node discharges it drives the other inverter which which charges the uh the other node yes okay yeah and let's do so you said either of bit line or bit line but one should be tuned so how are you deciding which one should be sure uh see suppose the user wants to write a data one I as a designer can decide that when the user wants to write data one whether BL will go to zero or BLB would go to zero I can decide that okay and then all that I need to do is that during read I should know okay during write I said for one BL had to go to zero so when BL goes to 0 I have I'm reading a 1. so during read you will use that information that you used that that decision that you had made during right you will use during interpreting what is right okay read the interpretation because you write and then you read Sachi you have a question oh blessings so anything else any any another question on the right operation is the right operation clear okay so uh we are almost at the end of the class what I will do is I will just introduce so when we,https://www.youtube.com/watch?v=LkOnj23Q3UE,"Link: https://www.youtube.com/watch?v=LkOnj23Q3UE
Transcript: so if we say this is the sixth transition memory cell now over here I have changed the nomenclature from q and Q Bar to uh BLT and blfi okay but it means the same thing don't worry about that okay so what we do is before anything happens we keep before the word line comes we actually keep the bit lines pre-charged pre-charge means that they are so these bit lines are essentially capacitances um so we say that these capacitances are held at or pre-charged to some voltage level let us say vdd itself let us say they are pre-charged at vdd level when wordline goes High what happens these these nmoses will turn on these and Mosses are called excess transistors so these are Moses will turn on they will allow access to the contents inside the memory and because there is a zero written here the charge would start to flow like this on this side over here also it is one over here it is vdd both side is vdd over here this was vdd and the other side was zero so some charges flow like this and this bit line will discharge what happens one bit line discharge the other bit line did not and that is what will now in the i o region trigger the sense amplifier to complete the read operation is this clear are you able to see this any questions to the read operation can you explain this what part did you not understand Abhishek sir bitline is discharging that part then this is the decline bar and B yes so when wordline gets selected do you see that okay this is so what I said was both the internal nodes are precharged to vdd both the bit lines are precharged to vdd yeah so yes sir okay now when we turn the word line on what happens these are nmoses they will turn on now what happens when they turn on there was a zero stored on this side so this nmos will now start to conduct some current yes sir will there be any current here no Hello both sides are we ready yes sir so some current will start to flow from here now this is a capacitor you remove some so when a current flows some charge is removed from this capacitor yes so when a charge is removed from a capacitor what happens to its voltage decreases it is reduces the voltage Falls so over here because bit line was connected to blti which had zero stored on it my BL voltage faults after some time there would be sufficient differential between bitline and bit line bar and I will be able to trigger the synth amplifier and complete the read operation yes sir is this clear now yes sir The BLT I will get charged to vtd minus VT right why see this if there was a zero stored here there was a if there was Zero stored on this side then there was one stored on the other side now yes okay I know in fact if if this this nmos is not strong enough what will happen you very rightly said this blti will start to rise up yes if this BLT starts to rise up what would happen the discharging of from BL will be slower than like yeah the stars from beer will become at a slower rate but still more worrisome thing is you stored a one here you stored a zero here now this is no longer zero this is almost one oh yes sir so what happens [Music] my data can get corrupted so during read cycle or when the word line is on that is when my stability things lowest because this blti is going up if there was no flow of current this blti would remain at zero are you able to see this because even if it had gone a little bit up the nmos is on it will discharge but when the word line is on then there is a current coming from here also and therefore my stability is slowest is is the least when the word line is on that is where we will finally measure the noise margin of the memory cell okay so read operation is clear any questions for the read operation say Excel I'm able to understand the operation but actually the bit line went to zero so the Suns amplifier would say that bit nine had stored as a bit line blti was storing a zero so the user may interpret it as red zero okay okay it is your prerogative as a designer as to what it means you may call it zero you may call it one it depends on what you what you wrote if when you had to write a zero you stored 0 on brti you would read it as zero listen when you wanted to write a zero you stored one on the ITI you will read it as one yes sir okay so so read and write are coupled you cannot look at them independently whether it is a zero or a one is that okay sir yes vaishna so sir previously we were seeing that our bit line and bitline bar were having an inverter and tensor so both how can they have the same value at the same time exactly I mean during start you are giving them that was a simplistic view for you as I said we are going to more and more Real views so these are two capacitors I can charge those two capacitors are varied in a okay so there is there is no inverter in reality in between them but we are just storing the value of this bit line and bitline bar with the help of a capacitor yeah so in reality if you notice there was never a inverter directly between the bit lines the inverter was on data pin and that went to the right driver bit lines um yes yes yeah that's it sir I didn't understand how did this animals if the animals uh is slower then how will the data corruption occur I didn't understand that we will come to that we'll look at stability in much more detail in a little while don't worry there will be some homework assignment for you also to understand this so it is it is not a graded assignment so you can you may or may not do it but there will be something that I will ask you to do okay we will come back anything else doesn't mean anything it's just a name BLT T could represent true node and I could represent internal so true and false I could have called it q and Q Bar I could have called it anything don't worry na members uh because that you're coming to these questions I want to arrive at these questions in just a little while we will jointly find the answers to these questions what do you think how how would you size this foreign uh so that current should be uh that pull down and was Jada partially I think yeah so what we essentially want is that even if there is a lot of current coming from bit line onto the blti node all that current should be immediately shifted away without significant rise in the level of biti so that there is least impact on stability so if I have to shrink lots of current without significant VDS the pull down should be strong much stronger than the pull pass gate there much stronger than the access transistor there so we will see we will come into this sizing Bala business in just a little while Ranjit okay Niraj yeah so actually I'm a little bit confused like what we are reading so like what I interpreted is that like we are just making depending on blog like on the wishes that we are reading is that correct so we're creating a differential between bitline and bitline wire and that is what we will amplify in the sense amplifier yes so sir like if the case we take like blti is one and blfi 0 and like then the BLB will go we'll fall down then we can see that we are reading one yes okay thank you okay sir we have fast enough sir so uh I don't know if I can ask this question right now or not but sir now my bit line is has got discharged and this difference which creates between the bit line and bitline bar that is sent to the sense amplifier right sir so sir for my since amplifier to work the sense amplifier signal should be enabled so I mean there should be some other wire going from between these positions to the same sample require enabled to enable that so saying that okay my uh so you can you can work on with my sentence sales amplifier operation when uh when my bit line is down and bitline bar is uh uh so we had that San horizontal wire in the io region so is that where coming from somewhere around here how can it come from every memory sir oh yes we talked about the reference bit cell and reference uh reference bit lines and reference World lines now yes sir that was exactly for this purpose so that we could generate the enable signal for the Suns amplifier look at that in more detail later also don't worry yes sir so now how does the right happen for the right to happen so you already know what you want to write now it is 0 over here and one over here if you want to write into the memory cell you would actually want it to go to one and it to go to zero so you already know what data you want to write into the memory cell based on that what you do is even before the word line comes you keep one bit line at one and you discharge the other bit line to zero then when the world line arrives what happens over here now this was at vdd this was at zero over here vdd 0. so on on the left side regular read operation will start to happen but on the right side what happens is this one starts to get discharged through the excess transistor when that discharges what happens as it starts to go to zero this pmos will turn on so initially when this was reading only this was the voltage we ensured that blti does not rise very much but after a lot of discharge had happened what happened this pmos turned on so this will take this node to 1. and we would say that and we would say that I have flipped the contents of the memory cell I have written 0 there and 1 here okay any questions on the right operation is disturbing yes mid lane is also Disturbed so we discharged the Bedtime through that right driver yeah the right way we wanted to write a zero we discharged it through the right driver is in the reads so this one we will keep recharge the bit line so because we know this is the right cycle what we could do is we could actually have a p Mass connected here which is on during the right cycle so this would remain at one this would not discharge that we can do we may do we may not do that as a designer I have to decide if it helps me or not oh sir sir how are you deciding where we need to write one left side or right side the user gave you some data based on that you decide whether biti needs to be one or a zero okay so suppose sir here if you want to write uh one at vlti side so what I should do if I want to write a one on blti I know that dlfi needs to be written to zero foreign means dlfi needs to be at zero so that is what we just did we took BLB to 0 and we wrote 0 on blfi then we wrote 0 on blfi plti automatically went to one so not clear yourself okay so if you want to write a one on blti it essentially means that you want to write a 0 on blfi yes yes sir so that is what we just did if I want to write a zero on blfi what did I do I took BLB to 0 I wrote a 0 there once I wrote a 0 there what happened the pmos turned on on the blti side and it wrote a one on that side okay but initially if the stored data was at vlti was Zero was if you look at it what was the case he said blti is zero um he said blti is zero we discharged the bit line bar to zero now therefore we discharged blfi to zero once blfi went to zero we said that blti will get charged to the people this thing I understood I am saying that's a palace but now uh user sends that the vla 5. now if you want to write one on blfi then you will put bit line to 0 and maintain BLB at one basically what I am saying is you cannot write a one inside a memory cell because you are using nmos pass Gates can you transfer a full one no you can only write a zero are you able to see this uh sir you will always write a zero first because you have n Mass baskets if you had T Mass yes you would write a one first okay yes um is it by using that D Bar uh data is one so that yeah the die drivers yes okay and so so if D is 0 and D Bar is one so what means by that data uh we say that we want to write one or zero here yes so that we decide as designers okay okay neeraj yeah I'm sorry uh as much I understand like if we have to write zero so can we say like we keep BL at 0 b l b at one and then we uh we raise up the right line yes if you want to write the other data like we just wrote one one zero in the memory cell now you want to write 0 1. so now in the next cycle you will take bit line to zero you will maintain bit line bar at one and you will write 0 on the blti side yeah yes yes Transit uh sorry I to add the same dot as what a Raga said so we start the right cycle uh from the discharging node and once this node discharges it drives the other inverter which which charges the uh the other node yes okay yeah and let's do so you said either of bit line or bit line but one should be tuned so how are you deciding which one should be sure uh see suppose the user wants to write a data one I as a designer can decide that when the user wants to write data one whether BL will go to zero or BLB would go to zero I can decide that okay and then all that I need to do is that during read I should know okay during write I said for one BL had to go to zero so when BL goes to 0 I have I'm reading a 1. so during read you will use that information that you used that that decision that you had made during right you will use during interpreting what is right okay read the interpretation because you write and then you read Sachi you have a question oh blessings so anything else any any another question on the right operation is the right operation clear okay so uh we are almost at the end of the class what I will do is I will just introduce so when we"
FlmyugticOw,what we did see over here was that there is a in a 60 memory cell there are some ratio thing that is coming into picture there is the steamer that is sinking some current there is this nmos that is syncing some current that is driving some current and so on so there is a ratio thing that will come because we removed those four pmoses in the first step so because of which there are certain figures of Merit linked to a memory cell the first and the foremost the most important flavor of Merit of a memory cell is area it is so important to figure of Merit that I tell you that you call a memory cell you know if I want a memory cell to be included in my library I would call it by the area area defines the name of the membership I would say 149 LL so 14.149 Micron Square cell in the LL flavor or one two one HS so 0.121 microns curved cell in the HS flavor so area is such an important figure of Merit data memory cell is recognized by area okay Beyond area there are some electrical figures of Merit which are cell current so we'll look into these in more detail in the next class which is also called as read current then there is bit line leakage cell stability we looked at very fittingly today we will look at it in more detail tomorrow in the next class then there is something called retention voltage I'm just leaving these terms with you so that they they kind of stay in your mind and you can if you want to just read about them somewhere okay I'm not saying whatever you read from the internet would be right or not but if you want you can if you will discuss them in much more detail in the next class then there is something called as right margin so you see we we took the bit line to zero you remember when during when we were writing we took the bit line to zero in reality can you really take any note to full zero SNR it's a capacitance through you will decide it through some resistance so in reality it will follow that uh RC curve if the r is very less it will just start very fast but still arriving at 0 may not be possible so how high above zero can it be that I will be able to write into the memory cell that is what is called as right margin okay right time is intuitive the name the name itself suggests how long does it take to write into the memory cell and we just now saw that uh write one happens slower than right zero in a in a 60 memory cell with nmos pass Gates 0 is written first and then one is written so right time is typically measured when one is written completely hmm and then leakage leakage is a very important figure of Merit because as we just saw that out of 1024 words even when the memory is accessed only one word is on the remaining one zero two three words are off so when they are off it means they are simply leaking not doing anything else so leakage is a very important figure of Merit for a memory for a memory cell okay so these are the figures of Merit that we will look at in the next class we will go into more details we will look at how these figures of Merit impact the sizing the sizing constraints for the different devices and uh subsequently we will look at stability and other features also in more detail [Music] so we can close the class here any questions sir in the last slide uh right second first we are reading k um then we are deciding to BLB for writing purpose no we get the information from the user what is D what is the data that I need to write into the memory cell okay based on user input I decide whether I want to discharge bit line or bit line bar okay the same if the same data is already there then the user has also given the same data then there will be no change in the memory content yeah then the memory contents will remain same okay storage is not for not of our Focus I don't know I don't know what was stored earlier when I'm asked to write assembly write yes got it anything else,https://www.youtube.com/watch?v=FlmyugticOw,"Link: https://www.youtube.com/watch?v=FlmyugticOw
Transcript: what we did see over here was that there is a in a 60 memory cell there are some ratio thing that is coming into picture there is the steamer that is sinking some current there is this nmos that is syncing some current that is driving some current and so on so there is a ratio thing that will come because we removed those four pmoses in the first step so because of which there are certain figures of Merit linked to a memory cell the first and the foremost the most important flavor of Merit of a memory cell is area it is so important to figure of Merit that I tell you that you call a memory cell you know if I want a memory cell to be included in my library I would call it by the area area defines the name of the membership I would say 149 LL so 14.149 Micron Square cell in the LL flavor or one two one HS so 0.121 microns curved cell in the HS flavor so area is such an important figure of Merit data memory cell is recognized by area okay Beyond area there are some electrical figures of Merit which are cell current so we'll look into these in more detail in the next class which is also called as read current then there is bit line leakage cell stability we looked at very fittingly today we will look at it in more detail tomorrow in the next class then there is something called retention voltage I'm just leaving these terms with you so that they they kind of stay in your mind and you can if you want to just read about them somewhere okay I'm not saying whatever you read from the internet would be right or not but if you want you can if you will discuss them in much more detail in the next class then there is something called as right margin so you see we we took the bit line to zero you remember when during when we were writing we took the bit line to zero in reality can you really take any note to full zero SNR it's a capacitance through you will decide it through some resistance so in reality it will follow that uh RC curve if the r is very less it will just start very fast but still arriving at 0 may not be possible so how high above zero can it be that I will be able to write into the memory cell that is what is called as right margin okay right time is intuitive the name the name itself suggests how long does it take to write into the memory cell and we just now saw that uh write one happens slower than right zero in a in a 60 memory cell with nmos pass Gates 0 is written first and then one is written so right time is typically measured when one is written completely hmm and then leakage leakage is a very important figure of Merit because as we just saw that out of 1024 words even when the memory is accessed only one word is on the remaining one zero two three words are off so when they are off it means they are simply leaking not doing anything else so leakage is a very important figure of Merit for a memory for a memory cell okay so these are the figures of Merit that we will look at in the next class we will go into more details we will look at how these figures of Merit impact the sizing the sizing constraints for the different devices and uh subsequently we will look at stability and other features also in more detail [Music] so we can close the class here any questions sir in the last slide uh right second first we are reading k um then we are deciding to BLB for writing purpose no we get the information from the user what is D what is the data that I need to write into the memory cell okay based on user input I decide whether I want to discharge bit line or bit line bar okay the same if the same data is already there then the user has also given the same data then there will be no change in the memory content yeah then the memory contents will remain same okay storage is not for not of our Focus I don't know I don't know what was stored earlier when I'm asked to write assembly write yes got it anything else"
3xICE4rWAgw,we now look at what are the various triggers of Merit so what were the figures of Merit Lottery uh saw in the last class just the names stability um cell current stability then Solutions leakage right margin right margin so right ability right time okay retention voltage retention voltage wow almost good so let's quickly look at what the various figures of Merit are so the most important figure of Merit for a memory cell is area area so after area is taken care of then we go to the next figure of Merit which is let us say cell current or the read current so uh why is it important because it defines the speed of memory access and uh in a memory cell the side which is storing zero only that particular bit times discharges am I right the other bit line remains at the pre-charged voltage level only so and what does the read current then depend on the cell current then depends on only this stack of pass gate and pull down because this is what defines how much current will flow so if you want more read current what do you want to do uh the pass gate and the cooldown should be sized higher yeah size them as large as possible what happens when you size them bigger resistance will be less resistance should be less okay so why do we not always keep them very big right yes yeah that is the most important figure of Merit that was where we started from if you really increase the size of basket and pull down to huge area goes for a toss ramjit you have a question so why are we talking about the cell current only with the read operation why why can't we determine it with the right operations because in the right operation uh what is more important uh do you like you already are just writing data into the memory side are you interested in the read current all right so Richland will be there but are you interested in that not sure sir so uh not exactly not because you're reading you're writing into the memory cell whatever whatever was already written is probably getting to be overwritten now so do you really want to read what was there earlier no you're writing there now am I right yes sir so the read current doesn't doesn't come into picture when you are writing that is why when we talk of cell current I'm only talking of read Cycles there oh that was why exactly are we concentrate about why are we concentrating about the rate cycles and measuring the current in the device why shouldn't we consider a right cycle and read the currents in the device you will look at that also did we say we will not okay for talking of read currently only you can read cycle not the current that flows in the right cycle that is what I am saying okay okay when you are writing uh recurrented um we will do an exercise you will I will give you some assignment and you will see what why this why this read current is also important during write cycle you will see then you will I will give you an exercise don't worry sir regarding the sizing sir so previously we saw that our blti node uh if the if the if it's unable to sync the current if my inmost is unable to seeing the current then it might characterize it increased right so isn't that the shouldn't that be the main reason why uh we want our sizing to be high because the data might get corrupted so a VM you know okay let us look at it like this what we are trying to do over here is we are trying to look at all the various figures of Merit and trying to see which direction they are pulling the sizing of various devices which one wins we decide okay okay we are first looking at if this was the only figure of Merit what would we want so if this was the only figure of Merit I would want to increase PG and PD's devices as big as possible but then I know this is not the only figure of Merit clearly there is a more important figure of Merit which is area so we cannot really go overboard and increase PG and PD devices without any bounds we have to see what what is the area versus Cell current trade-off then we do this um okay sir yeah so now the read operation in a memory cell we just saw that on the last class also we saw that one of the bit lines is held at vdd the other bit line discharges you measure this discharge and you trigger the sense amplifier huh all of us remember yes sir so what happens now what we are saying is that uh this is this discharge is determined by what we call as well current am I right there is another figure of Merit which says that see when my when my void line is off so we said that our memory would be organized in an array like this there would be so many rows and one of the rows will be selected in this particular rows I will in this particular row I will read but the reality is this bit line is actually connected to the entire memory array are you with me yes sir so what is happening on the other cells the other cells their word lines are off but they also have the connection to their pull down uh to the pass gates in their memory cells am I right so if there is any leakage across the memories across the pass gate that leakage will discharge this other bit line also are you able to see this let us say in a particular column I had stored all zeros and only one one so what was written on the other side on the other side it was all ones and only one zero when I brought the word line on this side discharged so this this line came into picture however the bit line over here would also leak because so many cells have zero stored on this side are you able to see this hello yes sir so when when this happens what we see is instead of this thing being straight this actually falls so the non-discharging bit line also falls what this means is that when initially I could trigger my sense amplifier at this point of time now because there is leakage on the other bit line also I will probably trigger my sense amplifier later only I can trigger it only here are you able to see this yes sir so this therefore is also an important figure of Merit which is called as bitline leakage and it is dependent on the size of the pass gate over here so now if we know that bitline leakage so we said increase the size of pass gate and pull down so that we could have better cell current now just and wetter cell current meant better excess time I could trigger San faster now I am telling you that if the pass gate is going to be very large this leakage is also going to be large are you able to see this if this leaker is going to be large I have to anyway delay my sense amplifier trigger signal so essentially what we are saying is that there are two forces that are acting on the pass gate device sizing one force is about one force is about increasing the size so that I can have better cell current and the other force is about reducing it so that bit line leakage reduces so this says that basket should be small are you able to see this any questions oh sir sir like the scenario that you just showed key on one side we are having all zeros all ones and so suppose if the scenario is reversed then basically I would have a better kind of read operation there yeah but when you do the timing analysis uh when when can you earliest trigger the SAR do you know what is the data written inside a memory when you're doing timing analysis oh no sorry no and data is random this user can write whatever program he or she wishes to so you have to design your memory for the worst case okay so as a memory designer you always find worst cases and you qualify them okay in fact why the system memory designer as a designer you should always ensure that the worst case is also passing whether you're designing memories or PLS or whatever whatever is the worst case that should qualify that should pass nope so but for example uh for the very minuscule probability of that very uh good case to happen still I would be writing only after uh in a sense enabled will be enabled only after the worst case timing has been taken answer for the last part that you just uh like I mean the EG device has to kind of cell current and this so sir like how did we kind of come to that uh keynote I will be from me it seems that we are preferring the bit line leakage more as compared to sell current when we are saying it as it should be so this is the independent constraint rather okay and I say that we will keep it very small no I'm just saying if bitline detail was the only thing I would want to keep it very small okay so select uh between these two opposing forces how will we decide then basically we will decide don't worry okay then did they have a question uh pointed out uh the reverse of the previous case would be the best case but it can't be understood because if I uh the reverse case uh I will have the bit lines and the bit line bars flipped but still now the bit line bar has multiple zeros and just a single one so now the bit line bar can uh um uh correspond to this bit line leakage and once again still the sense amplifier has to wait for more time to sense the difference or different BL and B Alpha so still either ways it is the worst case itself process yes so see there is an important figure of Merit over here also which is that Rose how many cells are connected to the bit line that is also an important figure of Merit if you are designing a small memory you can actually not worry about bitline leakage but if your bit lines are going to be big large number of bit lines draws large number of rows are going to be there then you have to really need to take care of the straight line leakage yes either well can you please explain more about SAE and triggering uh Sam programming means that some we somehow will find out when to trigger the sense amplifier when the differential is sufficiently generated okay so that differential uh is fixed like we decided yes sir so Oppam has an offset requirement yes sir if you give any input Which is less than the offset will the op-amp work sign no sir same is true with the sense amplifiers okay there is an offset requirement for every sense amplifier they would characterize it and we would know it before we do this timing tuning okay okay so thank you yeah uh vaishnav sir when we say pass gate it should be small so the basket should be small with respect to what exactly I mean it should be because the current which it draws from the bit line should be however discharged from the nmos which is present right yeah so a way to size the pass gate a typical figure of Merit vaishnav is that the for the for the given number of rows if rows minus 1 are leaking then I read minus rows minus 1 and 2 bit line leakage that should be a reasonable number with which you can get the access time of your of your choice also very importantly what is a rule of thumb is that uh for all the rows that are leaking the total leakage current should be at least or should be at most one tenth of the read current that is another rule of thumb that people use okay okay sir okay so these are rules of thumb they are not written anywhere you could design something with uh with some ratio of five also but then when you keep it at five you don't gain anything because you kept the pass gate large you kept the cooldown large whatever you did uh but finally in terms of delay you do not gain anything you just wasted area yes I got it yeah okay so that is a rule of thumb that the total leakage for on the bit line bar should be one tenth of the read current on the bit line of vice versa take care so the next figure of Merit is cell stability so what is cell stability why is self stability important I have written this is the most important specification of a storage element by or it specifies to what extent uh this particular cell can hold the data yeah what kind of noise it can accept without spoiling the contents there hmm is it really important is because if the data gets distorted then what will the user memories yes then what did you store if you cannot even guarantee what you've stored independent of noise um then what storage element are we talking about if you read into the memory and the memory contents get corrupted what's the point so cell stability is is actually the most important figure of Merit or it it has to be taken care of if Cell stability is not there whether you can write into the memory cell doesn't matter well what is the rate current doesn't matter nothing else matters even area doesn't matter because you can't really use that memory do you realize this is because of noise whatever noise whatever could be the source of noise but because of noise your memory contents get corrupted is that memory even usable no sir that is our stability is a very important figure of Merit in fact after area this could be considered as the most important figure of Merit what is self-stability dependent on we are saying that noise immunity it is a metric of noise immunity so what is noise immunity dependent on CE Mercy yeah what is that noise margin dependent on sales amplifier since amplifier why is sense Amplified since amplifier is not even connected to the memory cell so password and pull down Network sizing of the transistors the beta ratio what is beta ratio you're taking us somewhere we are not even talked about it in the class yet what is Vita ratio so independent basket and pull down Network because we are writing in writing celebration we are writing or reading we then pull pull down network is where we write zero one read okay I think it depends on SNM sir yeah so what is SNM dependent on that's the question so stability is measured by this figure of Merit called SNF but what is s m dependent on so how would I say so yeah so the sizing of this pull down should be more [Music] okay so uh why did I write that challenge is highest during read operation why not write operation there is a uh I mean like there is a state where we can have a data corruption and read operation foreign [Music] right the current is Flowing to the bit line but in uh the right read the current is flowing into the bit cell so the noise injected into the width cylinder during the read but not that is happening yeah I suppose and see during the write I already know what needs to be written I have that data with me I will simply write like this I'll get corrupted whatever happens I'm not bothered I I write what I want to write that is what I am interested in are you able to see this I know what I need to write I'm not really bothered about the stability of what was there in fact I want that to be unstable so that I can write easily it is during read operation that I say that I will I'm most worried there is a word line which is on my memory cell is getting accessed this noise comes at this time then my data can get corrupted why will that happen because I say that there is some read current happening I'm sorry it was a question yes sir no sir I just I want to add an air uh if we do read operation suppose we are reading 0 on plti node right so uh word line bit line bar would discharge and during that the part the node between past gate and pull down would uh would about charging and uh it might be charge up to the voltage because of that the blfi side uh pull down uh nmos would start uh on uh and due to that the BL side blfi side whatever the stored data might be corrupted okay so thank you friends so I was actually about to say exactly this so what is what princess said is that when you do a read operation uh you want some current to flow from here am I right so for any current to flow from this particular pull down device what do you need you need a certain VDS unless there is some VDS can any current flow from the pull down device no so it means that the voltage at this particular node if we call it VX will not be zero if you really want to flow any current then this VX has to rise when this VX Rises what happens there is a possibility that this nmos can turn on we do not want that to happen so a very important Endeavor of any memory cell designer is to ensure that this VX is as low as possible what is this voltage VX dependent on potential in basket and pull down yes it is almost like a potential divider there is a resistance of the pass gate RPG and the resistance of the pull down RPD and we're talking about this voltage VX if I want to keep this VX low how should RPD and RPG compare RPG should be more resistive than rpdg so in this potential divider then RPD should be clearly higher than RPD or RPD or RPD is lower means that the size of the pull down has to be greater than the size of the pass gate so you will see that there is a ratio of cooldown size upon pass gate size and that is called as beta ratio this usually you will see people will keep greater than 1.25 greater than 1.3 so that uh the VX the value of VX is low enough any questions so until now what we looked at was that pass gear and pull down so first we saw PG and PDS make them as big as possible then the next slide we saw oh keep PD small I am not worried about PD now what we are saying is that uh PG and PD should have a ratio passgate should be smaller than the pull down now if pull down is very very big what happens if pull down is very very big this VX may not rise much very true but because it is very very big this nmos over here can start to sink some current which is no longer insignificant see till the time this pull down is small only even if there is some leakage current happening from this part pull down this pull up is is handling it it is able to supply that current on the other side now if pass pull Downs are very large then this current in itself can be big and this pull up may not be able to hold it so therefore uh you know data flip can happen so you cannot really keep the pull down to be very very large also are you able to see this you want to keep pull down larger than the path gate but you can't keep it very very large because even then there could be an error sir sir here you are talking of the flip in terms of the leakage to the pull down yeah this folder will only be leaking because this VX you ensured is low but there is some voltage on the gate yes some voltage on the gate means there will be some leakage current from this other pull down device which this pull-up may not be able to fulfill so but pull up devices like fully on so leakage current will be still significantly lower than this pull up that is what we want but do we do we yet have any indication of how to size the pull up there not exactly so so can we say that the on current of the pull up will be greater than the off current of the pull down and we say this so so I mean there could be such a such a significant difference in the sizes of the pull up and the pull down that it could really reverse like the leakage could be more it is not just about sizing yes sizing could be that but also you know there will be VT variations that will happen due to which the off current of the pull down will change yes hello so it is not just about sizing it is about so many other variations that can happen on a die so you have to take care of everything yes sir so uh what we derive out of this slide is that PD has to be greater than the pass gate okay and this figure of Merit as to how much noise can be injected is is actually dependent on what is the v action rated over here if this v x is very large I have lesser noise margin this v x is very small I know I can accept more noise before I turn this device on are you with me any questions uh sir one more question sir for example uh suppose the VX comes to that level that it is able to flip that one store on the other side to zero so then I have zero zero on both side but that cannot happen so what exactly would be then resulting into and so it means you have reached a situation where now depending on device variations this side could actually go to one and this this side could actually go to zero so what sort of device relation so this we said that this this nmos could be very low VT due to which the leakage the the off current is also very high what is VT of this tmos is also low so it will actually sink more current now than this one this so you can apply your analysis skills and say what should be the worst case mismatch on the cells to to flip it again but I cannot be uh sure exactly Which side will be showing now why if I say that the VT of this device is smaller is is lesser than the BT of this device and VT of this device is lesser than the VT of this device can we not say that this cell would probably want to store a 1 over here and a zero over here yes yes yes Hannah yes sir so as a designer you should be able to uh to do this basic uh estimation projection then you do a simulation to see that's a different thing but as a designer you should be able to anticipate what's going to happen so then the pvt variation should be determining exactly what happens inside yes for srams PPT variations parametric variations device variations have a very very significant role to play whether your device will even function fine or not sure thanks okay so the next figure of Merit that we are going to talk over here is a retention voltage so what is retention voltage what is the tension voltage just give me a minute yeah so uh what is retention voltage foreign thing like uh by reducing the VX value we are increasing the noise margin right yes you're improving the noise margin you can accept more noise now okay that's it yes thanks so what is retention voltage any idea on the top of so all of us know that when we reduce the voltage of operation uh the leakage reduces so when the memory is not in operation we say that okay we will reduce its voltage so that the leakage of the memory array reduces now how low can we reduce the voltage level if this is the full vdd how low can we go such that the latch is still operational the latch still has sufficient margin noise margin that my contents will be preserved okay that voltage at which all the latches in the memory array will still be able to preserve their content is called as retention voltage you want it to be as low as possible so that you can actually save as much leakage as possible are you able to see this and it is the stability of this latch primarily that defines what is retention voltage any questions so those stability uh in the previous slide was coming to picture during the when we were accessing the cell so sir when we are considering retention voltage do we consider that access operation also or do we consider independent of that so uh the first statement says when the memory is not accessed we said memory is not being used that is where we want to put it into standby into a low power mode yes sir so that is where the pass gates are no longer in the in the picture there it is only the last that is now in in consideration okay okay so sir like then how the stability with stability are we talking here of for example any latch there would be a noise margin yes sir that is what we're talking about so but noise is not coming noisy knows getting injected so why I just oh noise is not getting injected I'm not systematically injecting any noise but is there no noise in the environment okay there would be some straight noise there would be thermal noise there will be random telegraphic noise you talk you you you just Google and you will see hundreds of noises that that will be there there'll be flicker noise there will be short noise it's so many kinds of noises that these devices are encountering foreign level are such that the we are able to maintain to store the logic yeah these devices okay okay so noise will always be there we want our device to we want that kind of a vdd there so that in the presence of all that noise we still have the contents preserved okay,https://www.youtube.com/watch?v=3xICE4rWAgw,"Link: https://www.youtube.com/watch?v=3xICE4rWAgw
Transcript: we now look at what are the various triggers of Merit so what were the figures of Merit Lottery uh saw in the last class just the names stability um cell current stability then Solutions leakage right margin right margin so right ability right time okay retention voltage retention voltage wow almost good so let's quickly look at what the various figures of Merit are so the most important figure of Merit for a memory cell is area area so after area is taken care of then we go to the next figure of Merit which is let us say cell current or the read current so uh why is it important because it defines the speed of memory access and uh in a memory cell the side which is storing zero only that particular bit times discharges am I right the other bit line remains at the pre-charged voltage level only so and what does the read current then depend on the cell current then depends on only this stack of pass gate and pull down because this is what defines how much current will flow so if you want more read current what do you want to do uh the pass gate and the cooldown should be sized higher yeah size them as large as possible what happens when you size them bigger resistance will be less resistance should be less okay so why do we not always keep them very big right yes yeah that is the most important figure of Merit that was where we started from if you really increase the size of basket and pull down to huge area goes for a toss ramjit you have a question so why are we talking about the cell current only with the read operation why why can't we determine it with the right operations because in the right operation uh what is more important uh do you like you already are just writing data into the memory side are you interested in the read current all right so Richland will be there but are you interested in that not sure sir so uh not exactly not because you're reading you're writing into the memory cell whatever whatever was already written is probably getting to be overwritten now so do you really want to read what was there earlier no you're writing there now am I right yes sir so the read current doesn't doesn't come into picture when you are writing that is why when we talk of cell current I'm only talking of read Cycles there oh that was why exactly are we concentrate about why are we concentrating about the rate cycles and measuring the current in the device why shouldn't we consider a right cycle and read the currents in the device you will look at that also did we say we will not okay for talking of read currently only you can read cycle not the current that flows in the right cycle that is what I am saying okay okay when you are writing uh recurrented um we will do an exercise you will I will give you some assignment and you will see what why this why this read current is also important during write cycle you will see then you will I will give you an exercise don't worry sir regarding the sizing sir so previously we saw that our blti node uh if the if the if it's unable to sync the current if my inmost is unable to seeing the current then it might characterize it increased right so isn't that the shouldn't that be the main reason why uh we want our sizing to be high because the data might get corrupted so a VM you know okay let us look at it like this what we are trying to do over here is we are trying to look at all the various figures of Merit and trying to see which direction they are pulling the sizing of various devices which one wins we decide okay okay we are first looking at if this was the only figure of Merit what would we want so if this was the only figure of Merit I would want to increase PG and PD's devices as big as possible but then I know this is not the only figure of Merit clearly there is a more important figure of Merit which is area so we cannot really go overboard and increase PG and PD devices without any bounds we have to see what what is the area versus Cell current trade-off then we do this um okay sir yeah so now the read operation in a memory cell we just saw that on the last class also we saw that one of the bit lines is held at vdd the other bit line discharges you measure this discharge and you trigger the sense amplifier huh all of us remember yes sir so what happens now what we are saying is that uh this is this discharge is determined by what we call as well current am I right there is another figure of Merit which says that see when my when my void line is off so we said that our memory would be organized in an array like this there would be so many rows and one of the rows will be selected in this particular rows I will in this particular row I will read but the reality is this bit line is actually connected to the entire memory array are you with me yes sir so what is happening on the other cells the other cells their word lines are off but they also have the connection to their pull down uh to the pass gates in their memory cells am I right so if there is any leakage across the memories across the pass gate that leakage will discharge this other bit line also are you able to see this let us say in a particular column I had stored all zeros and only one one so what was written on the other side on the other side it was all ones and only one zero when I brought the word line on this side discharged so this this line came into picture however the bit line over here would also leak because so many cells have zero stored on this side are you able to see this hello yes sir so when when this happens what we see is instead of this thing being straight this actually falls so the non-discharging bit line also falls what this means is that when initially I could trigger my sense amplifier at this point of time now because there is leakage on the other bit line also I will probably trigger my sense amplifier later only I can trigger it only here are you able to see this yes sir so this therefore is also an important figure of Merit which is called as bitline leakage and it is dependent on the size of the pass gate over here so now if we know that bitline leakage so we said increase the size of pass gate and pull down so that we could have better cell current now just and wetter cell current meant better excess time I could trigger San faster now I am telling you that if the pass gate is going to be very large this leakage is also going to be large are you able to see this if this leaker is going to be large I have to anyway delay my sense amplifier trigger signal so essentially what we are saying is that there are two forces that are acting on the pass gate device sizing one force is about one force is about increasing the size so that I can have better cell current and the other force is about reducing it so that bit line leakage reduces so this says that basket should be small are you able to see this any questions oh sir sir like the scenario that you just showed key on one side we are having all zeros all ones and so suppose if the scenario is reversed then basically I would have a better kind of read operation there yeah but when you do the timing analysis uh when when can you earliest trigger the SAR do you know what is the data written inside a memory when you're doing timing analysis oh no sorry no and data is random this user can write whatever program he or she wishes to so you have to design your memory for the worst case okay so as a memory designer you always find worst cases and you qualify them okay in fact why the system memory designer as a designer you should always ensure that the worst case is also passing whether you're designing memories or PLS or whatever whatever is the worst case that should qualify that should pass nope so but for example uh for the very minuscule probability of that very uh good case to happen still I would be writing only after uh in a sense enabled will be enabled only after the worst case timing has been taken answer for the last part that you just uh like I mean the EG device has to kind of cell current and this so sir like how did we kind of come to that uh keynote I will be from me it seems that we are preferring the bit line leakage more as compared to sell current when we are saying it as it should be so this is the independent constraint rather okay and I say that we will keep it very small no I'm just saying if bitline detail was the only thing I would want to keep it very small okay so select uh between these two opposing forces how will we decide then basically we will decide don't worry okay then did they have a question uh pointed out uh the reverse of the previous case would be the best case but it can't be understood because if I uh the reverse case uh I will have the bit lines and the bit line bars flipped but still now the bit line bar has multiple zeros and just a single one so now the bit line bar can uh um uh correspond to this bit line leakage and once again still the sense amplifier has to wait for more time to sense the difference or different BL and B Alpha so still either ways it is the worst case itself process yes so see there is an important figure of Merit over here also which is that Rose how many cells are connected to the bit line that is also an important figure of Merit if you are designing a small memory you can actually not worry about bitline leakage but if your bit lines are going to be big large number of bit lines draws large number of rows are going to be there then you have to really need to take care of the straight line leakage yes either well can you please explain more about SAE and triggering uh Sam programming means that some we somehow will find out when to trigger the sense amplifier when the differential is sufficiently generated okay so that differential uh is fixed like we decided yes sir so Oppam has an offset requirement yes sir if you give any input Which is less than the offset will the op-amp work sign no sir same is true with the sense amplifiers okay there is an offset requirement for every sense amplifier they would characterize it and we would know it before we do this timing tuning okay okay so thank you yeah uh vaishnav sir when we say pass gate it should be small so the basket should be small with respect to what exactly I mean it should be because the current which it draws from the bit line should be however discharged from the nmos which is present right yeah so a way to size the pass gate a typical figure of Merit vaishnav is that the for the for the given number of rows if rows minus 1 are leaking then I read minus rows minus 1 and 2 bit line leakage that should be a reasonable number with which you can get the access time of your of your choice also very importantly what is a rule of thumb is that uh for all the rows that are leaking the total leakage current should be at least or should be at most one tenth of the read current that is another rule of thumb that people use okay okay sir okay so these are rules of thumb they are not written anywhere you could design something with uh with some ratio of five also but then when you keep it at five you don't gain anything because you kept the pass gate large you kept the cooldown large whatever you did uh but finally in terms of delay you do not gain anything you just wasted area yes I got it yeah okay so that is a rule of thumb that the total leakage for on the bit line bar should be one tenth of the read current on the bit line of vice versa take care so the next figure of Merit is cell stability so what is cell stability why is self stability important I have written this is the most important specification of a storage element by or it specifies to what extent uh this particular cell can hold the data yeah what kind of noise it can accept without spoiling the contents there hmm is it really important is because if the data gets distorted then what will the user memories yes then what did you store if you cannot even guarantee what you've stored independent of noise um then what storage element are we talking about if you read into the memory and the memory contents get corrupted what's the point so cell stability is is actually the most important figure of Merit or it it has to be taken care of if Cell stability is not there whether you can write into the memory cell doesn't matter well what is the rate current doesn't matter nothing else matters even area doesn't matter because you can't really use that memory do you realize this is because of noise whatever noise whatever could be the source of noise but because of noise your memory contents get corrupted is that memory even usable no sir that is our stability is a very important figure of Merit in fact after area this could be considered as the most important figure of Merit what is self-stability dependent on we are saying that noise immunity it is a metric of noise immunity so what is noise immunity dependent on CE Mercy yeah what is that noise margin dependent on sales amplifier since amplifier why is sense Amplified since amplifier is not even connected to the memory cell so password and pull down Network sizing of the transistors the beta ratio what is beta ratio you're taking us somewhere we are not even talked about it in the class yet what is Vita ratio so independent basket and pull down Network because we are writing in writing celebration we are writing or reading we then pull pull down network is where we write zero one read okay I think it depends on SNM sir yeah so what is SNM dependent on that's the question so stability is measured by this figure of Merit called SNF but what is s m dependent on so how would I say so yeah so the sizing of this pull down should be more [Music] okay so uh why did I write that challenge is highest during read operation why not write operation there is a uh I mean like there is a state where we can have a data corruption and read operation foreign [Music] right the current is Flowing to the bit line but in uh the right read the current is flowing into the bit cell so the noise injected into the width cylinder during the read but not that is happening yeah I suppose and see during the write I already know what needs to be written I have that data with me I will simply write like this I'll get corrupted whatever happens I'm not bothered I I write what I want to write that is what I am interested in are you able to see this I know what I need to write I'm not really bothered about the stability of what was there in fact I want that to be unstable so that I can write easily it is during read operation that I say that I will I'm most worried there is a word line which is on my memory cell is getting accessed this noise comes at this time then my data can get corrupted why will that happen because I say that there is some read current happening I'm sorry it was a question yes sir no sir I just I want to add an air uh if we do read operation suppose we are reading 0 on plti node right so uh word line bit line bar would discharge and during that the part the node between past gate and pull down would uh would about charging and uh it might be charge up to the voltage because of that the blfi side uh pull down uh nmos would start uh on uh and due to that the BL side blfi side whatever the stored data might be corrupted okay so thank you friends so I was actually about to say exactly this so what is what princess said is that when you do a read operation uh you want some current to flow from here am I right so for any current to flow from this particular pull down device what do you need you need a certain VDS unless there is some VDS can any current flow from the pull down device no so it means that the voltage at this particular node if we call it VX will not be zero if you really want to flow any current then this VX has to rise when this VX Rises what happens there is a possibility that this nmos can turn on we do not want that to happen so a very important Endeavor of any memory cell designer is to ensure that this VX is as low as possible what is this voltage VX dependent on potential in basket and pull down yes it is almost like a potential divider there is a resistance of the pass gate RPG and the resistance of the pull down RPD and we're talking about this voltage VX if I want to keep this VX low how should RPD and RPG compare RPG should be more 
resistive than rpdg so in this potential divider then RPD should be clearly higher than RPD or RPD or RPD is lower means that the size of the pull down has to be greater than the size of the pass gate so you will see that there is a ratio of cooldown size upon pass gate size and that is called as beta ratio this usually you will see people will keep greater than 1.25 greater than 1.3 so that uh the VX the value of VX is low enough any questions so until now what we looked at was that pass gear and pull down so first we saw PG and PDS make them as big as possible then the next slide we saw oh keep PD small I am not worried about PD now what we are saying is that uh PG and PD should have a ratio passgate should be smaller than the pull down now if pull down is very very big what happens if pull down is very very big this VX may not rise much very true but because it is very very big this nmos over here can start to sink some current which is no longer insignificant see till the time this pull down is small only even if there is some leakage current happening from this part pull down this pull up is is handling it it is able to supply that current on the other side now if pass pull Downs are very large then this current in itself can be big and this pull up may not be able to hold it so therefore uh you know data flip can happen so you cannot really keep the pull down to be very very large also are you able to see this you want to keep pull down larger than the path gate but you can't keep it very very large because even then there could be an error sir sir here you are talking of the flip in terms of the leakage to the pull down yeah this folder will only be leaking because this VX you ensured is low but there is some voltage on the gate yes some voltage on the gate means there will be some leakage current from this other pull down device which this pull-up may not be able to fulfill so but pull up devices like fully on so leakage current will be still significantly lower than this pull up that is what we want but do we do we yet have any indication of how to size the pull up there not exactly so so can we say that the on current of the pull up will be greater than the off current of the pull down and we say this so so I mean there could be such a such a significant difference in the sizes of the pull up and the pull down that it could really reverse like the leakage could be more it is not just about sizing yes sizing could be that but also you know there will be VT variations that will happen due to which the off current of the pull down will change yes hello so it is not just about sizing it is about so many other variations that can happen on a die so you have to take care of everything yes sir so uh what we derive out of this slide is that PD has to be greater than the pass gate okay and this figure of Merit as to how much noise can be injected is is actually dependent on what is the v action rated over here if this v x is very large I have lesser noise margin this v x is very small I know I can accept more noise before I turn this device on are you with me any questions uh sir one more question sir for example uh suppose the VX comes to that level that it is able to flip that one store on the other side to zero so then I have zero zero on both side but that cannot happen so what exactly would be then resulting into and so it means you have reached a situation where now depending on device variations this side could actually go to one and this this side could actually go to zero so what sort of device relation so this we said that this this nmos could be very low VT due to which the leakage the the off current is also very high what is VT of this tmos is also low so it will actually sink more current now than this one this so you can apply your analysis skills and say what should be the worst case mismatch on the cells to to flip it again but I cannot be uh sure exactly Which side will be showing now why if I say that the VT of this device is smaller is is lesser than the BT of this device and VT of this device is lesser than the VT of this device can we not say that this cell would probably want to store a 1 over here and a zero over here yes yes yes Hannah yes sir so as a designer you should be able to uh to do this basic uh estimation projection then you do a simulation to see that's a different thing but as a designer you should be able to anticipate what's going to happen so then the pvt variation should be determining exactly what happens inside yes for srams PPT variations parametric variations device variations have a very very significant role to play whether your device will even function fine or not sure thanks okay so the next figure of Merit that we are going to talk over here is a retention voltage so what is retention voltage what is the tension voltage just give me a minute yeah so uh what is retention voltage foreign thing like uh by reducing the VX value we are increasing the noise margin right yes you're improving the noise margin you can accept more noise now okay that's it yes thanks so what is retention voltage any idea on the top of so all of us know that when we reduce the voltage of operation uh the leakage reduces so when the memory is not in operation we say that okay we will reduce its voltage so that the leakage of the memory array reduces now how low can we reduce the voltage level if this is the full vdd how low can we go such that the latch is still operational the latch still has sufficient margin noise margin that my contents will be preserved okay that voltage at which all the latches in the memory array will still be able to preserve their content is called as retention voltage you want it to be as low as possible so that you can actually save as much leakage as possible are you able to see this and it is the stability of this latch primarily that defines what is retention voltage any questions so those stability uh in the previous slide was coming to picture during the when we were accessing the cell so sir when we are considering retention voltage do we consider that access operation also or do we consider independent of that so uh the first statement says when the memory is not accessed we said memory is not being used that is where we want to put it into standby into a low power mode yes sir so that is where the pass gates are no longer in the in the picture there it is only the last that is now in in consideration okay okay so sir like then how the stability with stability are we talking here of for example any latch there would be a noise margin yes sir that is what we're talking about so but noise is not coming noisy knows getting injected so why I just oh noise is not getting injected I'm not systematically injecting any noise but is there no noise in the environment okay there would be some straight noise there would be thermal noise there will be random telegraphic noise you talk you you you just Google and you will see hundreds of noises that that will be there there'll be flicker noise there will be short noise it's so many kinds of noises that these devices are encountering foreign level are such that the we are able to maintain to store the logic yeah these devices okay okay so noise will always be there we want our device to we want that kind of a vdd there so that in the presence of all that noise we still have the contents preserved okay"
tvPsWbnyBEA,then what is Right margin there are two definitions of flight margin one is that how high can the bit line be while I am still able to write into the memory cell so I I turn my word line fully on it is at vdd then my bit line I want to discharge but I do not discharge it to full zero like this would have been zero I I could discharge it only here up till only here can I still write into the memory cell what will prevent me from writing the on current from here hello so what is what am I trying to do I'm trying to discharge I am trying to discharge the internal node I'm trying to discharge the internal node like this but this pull up is providing current at what level can my bit line be that the current through the pass gate exceeds the current from the pull up that is one definition of right margin because if this current exceeds the pull-up current if the pass gate current exceeds the pull-up current I will be able to write a zero area yes sir so the voltage level at which I will be able to successfully write a zero the voltage on the bit line at which I will be able to successfully write a zero is the right margin now that is one definition another definition is that c my word line RC could be very very high so what if my word line is unable to rise to full vdd this is vdd what if my word line is not not able to rise to full video or Rises very very slowly at what level of word line will I be able to write into the memory cell if my bit line has been taken to 0 already so this then becomes the word line right margin this Gap why are we calling this margin because I now know that my word line need not rise to full vdd or in the other case my bit line need not fall to full zero and I will still be able to complete the right operation that is why the term margin over here so if this is what the definition is how would you want to size the different devices in the memory cell now what are the constraints that you would want to put so pull up should be science down and pass questions should be sized up so what we are saying is pull up should be sized down and pass gate should be sized up the pass gate and right driver stack has to be stronger than the pull up am I right sir sir uh I'm not able to understand this highest level of bitline operation this definition so okay so I have my word line at vdd my bit line was supposed to fall to zero but this right driver calmed off let us say so instead of taking it to full zero it went only up till here will I be able to complete my right operation or not I do not know if I am able to complete then this is my right margin since this voltage is zero I said what is the highest level of bitline at which I am able to still write see if this was still higher I know the the set the current through the pass gate will be smaller what is the current of the past is dependent on amongst other things VDS am I right yes sir the VDS reduces then the password will not be able to sync sync the charge to zero so what is the highest level of bitline at which the password will still operate we'll still have more current than the pull up there okay so I'm considering the right operation here yes that is why it's called right margin okay okay but when it is discharging the internal node from one to zero then my bit line is already zero right so that is what we wanted that is what right margin is about if it is not zero then how much margin do I have on the bit line okay if it is logically zero but we are now talking about the analog voltage there it is less than VD by 2 for sure yes but is it really zero or is it 20 millivolts or is it 50 millivolts or is it 100 millivolts now you're talking about the voltage level logically it is zero clear now we are going deeper into the memory cell now we are now treating it as an analog circuit okay so sir ideally I want my bit line to be zero so that I can write the 0 into the memory cell but uh it will not be zero exactly it will be some positive thing so that difference is called the right margin for me no that is not called right margin it will be positive as a fact yes sir now what is the positive level at which I will still be able to write into the membership that is what is called the right margin okay relative to zero yeah so sir is it like that uh yes because when the word line is not fully VD then the pass gate is resistive it will not conduct as much current so what how what kind of margin do I have on the pass on the word line level also that is word line right margin okay so if this is right margin then uh what we also see is that writability of the sellers inverse to its stability If the sellers very writable it will also be unstable but if sellers um a stable a little bit difficult to write into some eraser this is evident this is clear so can you please also be to touch upon this word line how do you defining the right margin with the word line level okay what did you understand if you just apply what we talked about for the bit line what do you understand for the word line uh so uh basically I am considering the operation when I have to write the 0 into the bit cell so my bit line is zero but it is not zero so it has some positive voltage so that differential voltage will be determining the current that can flow but also uh so the but also this uh because the current is flowing through this uh pass gate so the resistivity of the pass gate and the logic level of bit line comes to a picture so when I consider the logic level of bitline only the voltage level then I consider terms of the highest level of bit line but uh when it comes to this basket it comes but how exactly the resistive uh I'm not able to figure this out sir what is the record we can look at it separately also but very quickly how how much current will the pass gate carry what is that dependent on um so it's sizing number one in terms of voltages which voltages are dependent on the voltage the gate voltage is what is going on the gate the word line the third line now if the word line is not fully on then the current will be lesser yes sir yes sir okay that is what we are asking okay how much lesser can it be what kind of margin do we have that is right margin on the word line okay so so does uh in the bgs I consider so uh at the s i take to zero then I say key how low the VG could be yes okay okay got it so thank you so next is right time we already know that we write a zero yeah I am a little bit confused in sales stability while uh slides so why why it's uh if no VX means uh uh hike uh noise margin we can see we will just see a different perspective on stability don't worry what would be the dependency I didn't we will see we will look at we will have a deeper look at stability it's so important to figure of Merit we'll have a deeper look at stability and a little while friends so coming back to right time when we look at right time uh what is it what is it that is important that we should have written both 0 and 1 inside the cells and it should be written in such a way that the cell contents are preserved even Slater what does this mean see what we are saying is that uh I wrote a zero on this side and a one on this side so the internal nodes went like this something like this they are going up the this this pmos is charging the other node towards one so right time is that this has gone to zero and this has gone to vdd or as close to VD as possible such that when the next access is activated then this one remains one if I say that this is the way my cell could have would have gone but I triggered the next read operation let us say here it can happen that myself goes back to zero and this then goes to one I could actually corrupt my memory cell because the memory cell had one uh one node at zero but the other node had not really reached bdd so you really want the internal node to reach a reasonably good level to say that right operation has completed so why why is this Clause important one would say that as soon as this other node goes above vdd by 2 um my write has happened I've written a one because logically it is one but in reality in reality if it is just weekly by 2 I am almost confident that as soon as you trigger the next read this will go back to zero so right time is a very important figure of Merit because that also defines the fastest speed at which you can operate the memory foreign has to be fast so that a zero is written quickly and there is a less fight back from the pull-up but somehow this pull-up also needs to be fast so that I can quickly do a right one so you want this pull up to be V but this will have to be fast but we have a symmetrical memory cell what do you do we have a symmetrical memory cell what would you do would you keep the pull up small or would you keep the pull up large so I mean I cannot figure this out directly because but the area if I cancel the area then I should keep small but because it is symmetrical it could happen either ways yeah so see because there are two opposing constraints on the pull up you can't really say it should be small or large there's a bigger bigger bigger figure of Merit which is called area which says it keep it small so you actually keep the pull-up very small okay uh so so uh actually I was not able to get this next read access point clearly uh I mean if it is video by 2 you said that it will definitely go to zero in the next cycle that point was so uh if you're not able to store a full zero or a full one in the memory cell how what kind of noise margin would you have would it be equal higher or lower than the case in which you have a full zero full one what does your knowledge of devices knowledge of circuits tell you okay so if it is like at the bdd it is at the kind of the threshold kind of point if my PD is down the leakage becomes high like in the previous slide then maybe it could let us say there is this latch now if one side is zero the side is vdd by 2. versus it was vdd what is more stable BTD that is all that I am saying but take the other node as close to vdd as possible just don't look at logic so logic one is there though okay that is all that that this means okay so what here you are uh correlating with the read access I mean when the read is accessed the noise injection will be at zero site yeah so if I if I if I say right has completed at PDD by two yes sir initiate the next read so this is what will be the picture when you start the read now but the noise will get injected here will this sitting be more stable or when it was vdd here that would be more stable yes okay give me the answer sure uh if for example sir if I've designed the PD to be strong then this noise imagine the this how stable my cell is is dependent on this PD just pull it down PD if this is really by 2 will this Beam us also not start to turn on will it also not inject charge over here still it is not near threshold now uh of this the question is not near threshold or not near threshold the question is is VD by 2 more stable or VD more stable so vdd will ensure that the pmos device is totally off yes so we won't be ready there okay that is the point okay so to control this pmos device basically to ensure more stability for the latch okay pleasure uh so by sizing down the pull up VR as per our area constraint we are reducing the area but we are also reducing the speed yes okay yes okay so then another figure of Merit is overall leakage see till now we looked at bit line leakage only now this is we're talking about overall leakage and what we are saying is that all our devices have leakage and even on devices have Junction leakage so to reduce overall leakage what do you want you want all devices to be kept as small as possible and you want the length to be as large as possible so that you can reduce a threshold leakage of the off devices and you also want the gate decays to be reduced so you want to use thick blade oxides not all of it you can do but these are the set of constraints that are there on the sizing part if you keep the devices small the leakage would also be small so area will also be less so this is something that we will definitely want to do but we will not keep minimum length in our devices we will use long channels long tunnels means length is greater than minimum length of a technology so as a rule of thumb typically what is observed is that in 65 nanometer technology length of the all the different devices is 80 to 90 nanometer and 45 nanometer technology the length is 60 to 65 nanometers and 90 nanometer technology the length used to be 100 to 120 nanometers so never do you use minimum length of Any Given technology as the length of devices in your memory cell okay,https://www.youtube.com/watch?v=tvPsWbnyBEA,"Link: https://www.youtube.com/watch?v=tvPsWbnyBEA
Transcript: then what is Right margin there are two definitions of flight margin one is that how high can the bit line be while I am still able to write into the memory cell so I I turn my word line fully on it is at vdd then my bit line I want to discharge but I do not discharge it to full zero like this would have been zero I I could discharge it only here up till only here can I still write into the memory cell what will prevent me from writing the on current from here hello so what is what am I trying to do I'm trying to discharge I am trying to discharge the internal node I'm trying to discharge the internal node like this but this pull up is providing current at what level can my bit line be that the current through the pass gate exceeds the current from the pull up that is one definition of right margin because if this current exceeds the pull-up current if the pass gate current exceeds the pull-up current I will be able to write a zero area yes sir so the voltage level at which I will be able to successfully write a zero the voltage on the bit line at which I will be able to successfully write a zero is the right margin now that is one definition another definition is that c my word line RC could be very very high so what if my word line is unable to rise to full vdd this is vdd what if my word line is not not able to rise to full video or Rises very very slowly at what level of word line will I be able to write into the memory cell if my bit line has been taken to 0 already so this then becomes the word line right margin this Gap why are we calling this margin because I now know that my word line need not rise to full vdd or in the other case my bit line need not fall to full zero and I will still be able to complete the right operation that is why the term margin over here so if this is what the definition is how would you want to size the different devices in the memory cell now what are the constraints that you would want to put so pull up should be science down and pass questions should be sized up so what we are saying is pull up should be sized down and pass gate should be sized up the pass gate and right driver stack has to be stronger than the pull up am I right sir sir uh I'm not able to understand this highest level of bitline operation this definition so okay so I have my word line at vdd my bit line was supposed to fall to zero but this right driver calmed off let us say so instead of taking it to full zero it went only up till here will I be able to complete my right operation or not I do not know if I am able to complete then this is my right margin since this voltage is zero I said what is the highest level of bitline at which I am able to still write see if this was still higher I know the the set the current through the pass gate will be smaller what is the current of the past is dependent on amongst other things VDS am I right yes sir the VDS reduces then the password will not be able to sync sync the charge to zero so what is the highest level of bitline at which the password will still operate we'll still have more current than the pull up there okay so I'm considering the right operation here yes that is why it's called right margin okay okay but when it is discharging the internal node from one to zero then my bit line is already zero right so that is what we wanted that is what right margin is about if it is not zero then how much margin do I have on the bit line okay if it is logically zero but we are now talking about the analog voltage there it is less than VD by 2 for sure yes but is it really zero or is it 20 millivolts or is it 50 millivolts or is it 100 millivolts now you're talking about the voltage level logically it is zero clear now we are going deeper into the memory cell now we are now treating it as an analog circuit okay so sir ideally I want my bit line to be zero so that I can write the 0 into the memory cell but uh it will not be zero exactly it will be some positive thing so that difference is called the right margin for me no that is not called right margin it will be positive as a fact yes sir now what is the positive level at which I will still be able to write into the membership that is what is called the right margin okay relative to zero yeah so sir is it like that uh yes because when the word line is not fully VD then the pass gate is resistive it will not conduct as much current so what how what kind of margin do I have on the pass on the word line level also that is word line right margin okay so if this is right margin then uh what we also see is that writability of the sellers inverse to its stability If the sellers very writable it will also be unstable but if sellers um a stable a little bit difficult to write into some eraser this is evident this is clear so can you please also be to touch upon this word line how do you defining the right margin with the word line level okay what did you understand if you just apply what we talked about for the bit line what do you understand for the word line uh so uh basically I am considering the operation when I have to write the 0 into the bit cell so my bit line is zero but it is not zero so it has some positive voltage so that differential voltage will be determining the current that can flow but also uh so the but also this uh because the current is flowing through this uh pass gate so the resistivity of the pass gate and the logic level of bit line comes to a picture so when I consider the logic level of bitline only the voltage level then I consider terms of the highest level of bit line but uh when it comes to this basket it comes but how exactly the resistive uh I'm not able to figure this out sir what is the record we can look at it separately also but very quickly how how much current will the pass gate carry what is that dependent on um so it's sizing number one in terms of voltages which voltages are dependent on the voltage the gate voltage is what is going on the gate the word line the third line now if the word line is not fully on then the current will be lesser yes sir yes sir okay that is what we are asking okay how much lesser can it be what kind of margin do we have that is right margin on the word line okay so so does uh in the bgs I consider so uh at the s i take to zero then I say key how low the VG could be yes okay okay got it so thank you so next is right time we already know that we write a zero yeah I am a little bit confused in sales stability while uh slides so why why it's uh if no VX means uh uh hike uh noise margin we can see we will just see a different perspective on stability don't worry what would be the dependency I didn't we will see we will look at we will have a deeper look at stability it's so important to figure of Merit we'll have a deeper look at stability and a little while friends so coming back to right time when we look at right time uh what is it what is it that is important that we should have written both 0 and 1 inside the cells and it should be written in such a way that the cell contents are preserved even Slater what does this mean see what we are saying is that uh I wrote a zero on this side and a one on this side so the internal nodes went like this something like this they are going up the this this pmos is charging the other node towards one so right time is that this has gone to zero and this has gone to vdd or as close to VD as possible such that when the next access is activated then this one remains one if I say that this is the way my cell could have would have gone but I triggered the next read operation let us say here it can happen that myself goes back to zero and this then goes to one I could actually corrupt my memory cell because the memory cell had one uh one node at zero but the other node had not really reached bdd so you really want the internal node to reach a reasonably good level to say that right operation has completed so why why is this Clause important one would say that as soon as this other node goes above vdd by 2 um my write has happened I've written a one because logically it is one but in reality in reality if it is just weekly by 2 I am almost confident that as soon as you trigger the next read this will go back to zero so right time is a very important figure of Merit because that also defines the fastest speed at which you can operate the memory foreign has to be fast so that a zero is written quickly and there is a less fight back from the pull-up but somehow this pull-up also needs to be fast so that I can quickly do a right one so you want this pull up to be V but this will have to be fast but we have a symmetrical memory cell what do you do we have a symmetrical memory cell what would you do would you keep the pull up small or would you keep the pull up large so I mean I cannot figure this out directly because but the area if I cancel the area then I should keep small but because it is symmetrical it could happen either ways yeah so see because there are two opposing constraints on the pull up you can't really say it should be small or large there's a bigger bigger bigger figure of Merit which is called area which says it keep it small so you actually keep the pull-up very small okay uh so so uh actually I was not able to get this next read access point clearly uh I mean if it is video by 2 you said that it will definitely go to zero in the next cycle that point was so uh if you're not able to store a full zero or a full one in the memory cell how what kind of noise margin would you have would it be equal higher or lower than the case in which you have a full zero full one what does your knowledge of devices knowledge of circuits tell you okay so if it is like at the bdd it is at the kind of the threshold kind of point if my PD is down the leakage becomes high like in the previous slide then maybe it could let us say there is this latch now if one side is zero the side is vdd by 2. versus it was vdd what is more stable BTD that is all that I am saying but take the other node as close to vdd as possible just don't look at logic so logic one is there though okay that is all that that this means okay so what here you are uh correlating with the read access I mean when the read is accessed the noise injection will be at zero site yeah so if I if I if I say right has completed at PDD by two yes sir initiate the next read so this is what will be the picture when you start the read now but the noise will get injected here will this sitting be more stable or when it was vdd here that would be more stable yes okay give me the answer sure uh if for example sir if I've designed the PD to be strong then this noise imagine the this how stable my cell is is dependent on this PD just pull it down PD if this is really by 2 will this Beam us also not start to turn on will it also not inject charge over here still it is not near threshold now uh of this the question is not near threshold or not near threshold the question is is VD by 2 more stable or VD more stable so vdd will ensure that the pmos device is totally off yes so we won't be ready there okay that is the point okay so to control this pmos device basically to ensure more stability for the latch okay pleasure uh so by sizing down the pull up VR as per our area constraint we are reducing the area but we are also reducing the speed yes okay yes okay so then another figure of Merit is overall leakage see till now we looked at bit line leakage only now this is we're talking about overall leakage and what we are saying is that all our devices have leakage and even on devices have Junction leakage so to reduce overall leakage what do you want you want all devices to be kept as small as possible and you want the length to be as large as possible so that you can reduce a threshold leakage of the off devices and you also want the gate decays to be reduced so you want to use thick blade oxides not all of it you can do but these are the set of constraints that are there on the sizing part if you keep the devices small the leakage would also be small so area will also be less so this is something that we will definitely want to do but we will not keep minimum length in our devices we will use long channels long tunnels means length is greater than minimum length of a technology so as a rule of thumb typically what is observed is that in 65 nanometer technology length of the all the different devices is 80 to 90 nanometer and 45 nanometer technology the length is 60 to 65 nanometers and 90 nanometer technology the length used to be 100 to 120 nanometers so never do you use minimum length of Any Given technology as the length of devices in your memory cell okay"
oHO2qA8sebs,overall leakage see till now we looked at bit line leakage only so this is we're talking about overall leakage and what we are saying is that all our devices have leakage and even on devices have Junction leakage so to reduce overall leakage what do you want you want all devices to be kept as small as possible and you want the length to be as large as possible so that you can reduce sub threshold leakage of the off devices and you also want the gate decays to be reduced so you want to use thick gate oxides not all of it you can do but these are the set of constraints that are there on the sizing part if you keep the devices small the leakage would also be small so area will also be less so this is something that we will definitely want to do but we will not keep minimum length in our devices we will use long channels long channels means length is greater than minimum length of a technology so as a rule of thumb typically what is observed is that in 65 nanometer technology length of the all the different devices is 80 to 90 nanometers and 45 nanometer technology the length is 60 to 65 nanometers in 90 nanometer technology the length used to be 100 to 120 nanometers so never do you use minimum length of Any Given technology as the length of devices in your memory cell okay so these are some empirical numbers some numbers that I am giving you now what this means is that when we want to size the pass gate we say s m is better than when pass gate is smaller than pull down a large pass gate means High Drive current but a small pass gate means difficulty in right operation if the pass gate is large bit line leakage is also very high pass gate is large also means bit line load is high so excess time again degrades so if I say I would want to keep a large PG to have faster access that is really not going to happen so since cell stability is a very critical parameter we as of now just conclude that pass gate is to be kept weaker than the pull down is this clear so whatever we discussed in the figures of Merit now I'm just trying to summarize them for sizing the devices in a memory memory cell is this okay hello yes sir now if we come to the pull down then we say SNM is better than when pull down is strong cooldown has to be stronger than the path gate that is what we just saw but we also discussed that if the pull down is very very large then what happens the other side can turn on very easily so we don't want a very large pull down also pulled on large pull down also has a direct impact on area so while you want to put it down to be large you cannot keep it to be very very large so in fact in a memory cell pull down is the strongest device in a memory cell but it is still a small device it cannot be very big device okay so in 65 nanometer technology then you will work on your projects you have to ensure that you pull down is the largest or the strongest amongst all the other devices but still it is less than say 300 nanometers or less than 250 nanometers definitely not more than this size okay now pull up sizing everything said and done we saw that you know small pull up easier right operation SNM has not much role to play like just pull down and passgate had a role to play there if we manage their sizing SNM is largely taken care of so we want to keep pull up as weak as possible okay in fact pull up is the weakest device in the memory cell you can you will probably use a pull-up of size 0.120 you know microns so 120 nanometers if that is not allowed 135 whatever is the minimum size allowed that is the minimum width you will use for the pull up there when you will Design memory cell in your projects okay so yes so in the previous slide I have some questions here so the view sizing sir so uh so here you have written that small pu easier right operation so sir it is we are considering here when we are writing the zero right now yes so what like so but like if we have a uh when we are considering the small pu the zero will be written faster but when we are writing the one then I need a large view so this yeah so what is important you want to be able to write a zero or a one what is most important what do you write into the memory cells essentially write a zero then one you get so zero has to be written easily is it not so so I'm basically based upon that I'm saying small view should be yeah okay and being able to write is functionality the other aspect is only timing performance you know functionality you need functionality for sure performance comes next okay so this small po will ensure my functionality you tell me yes sir yeah okay the other is other po size basically ensures my the time performance the performance the functionality is more important than performance a person has to be functional then you think of performance yes sir and so this uh so at this first line so first point SNM is better than pure strong so this point isn't really awesome so in SNM what were you trying to do so we generally looked when you uh looked at that the VX bump was should be as small as possible so if v x bump increases what happens the rent of the pull down increases the on current of the Pull-Ups that was what we were discussing now the on current to the pull up is lesser than the sub threshold current of the pull down so the sub threshold current of the uh nmos yeah that if this v-x is even if this VX is small it would happen that the sub threshold current of this n mass is greater than the on current of the pull up yes sir if it is more yes so what we are saying is if this pull up is able to sink more current even if there is some larger VX over here I will not have a problem okay so sir basically my it will help my enhance my stability yes that is what is written yeah so but then uh in the list that you mentioned that stability is the critical parameter but I still am sizing the PG to be very smart the most small device yeah because what we say is influence of PG and PD is very high on SNM this is the primary factor this is the secondary Factor okay pu strong is secondary for this stability okay obviously not a second Arena okay you're able to see this VX why when does PU come into picture when v x goes high if I do not let v x go high will pu come into picture no no sir okay okay yes I've got it thanks so even though they appear to be six devices hmm do you realize that uh there is a whole lot of game happening there designing these six devices and a memory cell in these six devices is not a simple task are you,https://www.youtube.com/watch?v=oHO2qA8sebs,"Link: https://www.youtube.com/watch?v=oHO2qA8sebs
Transcript: overall leakage see till now we looked at bit line leakage only so this is we're talking about overall leakage and what we are saying is that all our devices have leakage and even on devices have Junction leakage so to reduce overall leakage what do you want you want all devices to be kept as small as possible and you want the length to be as large as possible so that you can reduce sub threshold leakage of the off devices and you also want the gate decays to be reduced so you want to use thick gate oxides not all of it you can do but these are the set of constraints that are there on the sizing part if you keep the devices small the leakage would also be small so area will also be less so this is something that we will definitely want to do but we will not keep minimum length in our devices we will use long channels long channels means length is greater than minimum length of a technology so as a rule of thumb typically what is observed is that in 65 nanometer technology length of the all the different devices is 80 to 90 nanometers and 45 nanometer technology the length is 60 to 65 nanometers in 90 nanometer technology the length used to be 100 to 120 nanometers so never do you use minimum length of Any Given technology as the length of devices in your memory cell okay so these are some empirical numbers some numbers that I am giving you now what this means is that when we want to size the pass gate we say s m is better than when pass gate is smaller than pull down a large pass gate means High Drive current but a small pass gate means difficulty in right operation if the pass gate is large bit line leakage is also very high pass gate is large also means bit line load is high so excess time again degrades so if I say I would want to keep a large PG to have faster access that is really not going to happen so since cell stability is a very critical parameter we as of now just conclude that pass gate is to be kept weaker than the pull down is this clear so whatever we discussed in the figures of Merit now I'm just trying to summarize them for sizing the devices in a memory memory cell is this okay hello yes sir now if we come to the pull down then we say SNM is better than when pull down is strong cooldown has to be stronger than the path gate that is what we just saw but we also discussed that if the pull down is very very large then what happens the other side can turn on very easily so we don't want a very large pull down also pulled on large pull down also has a direct impact on area so while you want to put it down to be large you cannot keep it to be very very large so in fact in a memory cell pull down is the strongest device in a memory cell but it is still a small device it cannot be very big device okay so in 65 nanometer technology then you will work on your projects you have to ensure that you pull down is the largest or the strongest amongst all the other devices but still it is less than say 300 nanometers or less than 250 nanometers definitely not more than this size okay now pull up sizing everything said and done we saw that you know small pull up easier right operation SNM has not much role to play like just pull down and passgate had a role to play there if we manage their sizing SNM is largely taken care of so we want to keep pull up as weak as possible okay in fact pull up is the weakest device in the memory cell you can you will probably use a pull-up of size 0.120 you know microns so 120 nanometers if that is not allowed 135 whatever is the minimum size allowed that is the minimum width you will use for the pull up there when you will Design memory cell in your projects okay so yes so in the previous slide I have some questions here so the view sizing sir so uh so here you have written that small pu easier right operation so sir it is we are considering here when we are writing the zero right now yes so what like so but like if we have a uh when we are considering the small pu the zero will be written faster but when we are writing the one then I need a large view so this yeah so what is important you want to be able to write a zero or a one what is most important what do you write into the memory cells essentially write a zero then one you get so zero has to be written easily is it not so so I'm basically based upon that I'm saying small view should be yeah okay and being able to write is functionality the other aspect is only timing performance you know functionality you need functionality for sure performance comes next okay so this small po will ensure my functionality you tell me yes sir yeah okay the other is other po size basically ensures my the time performance the performance the functionality is more important than performance a person has to be functional then you think of performance yes sir and so this uh so at this first line so first point SNM is better than pure strong so this point isn't really awesome so in SNM what were you trying to do so we generally looked when you uh looked at that the VX bump was should be as small as possible so if v x bump increases what happens the rent of the pull down increases the on current of the Pull-Ups that was what we were discussing now the on current to the pull up is lesser than the sub threshold current of the pull down so the sub threshold current of the uh nmos yeah that if this v-x is even if this VX is small it would happen that the sub threshold current of this n mass is greater than the on current of the pull up yes sir if it is more yes so what we are saying is if this pull up is able to sink more current even if there is some larger VX over here I will not have a problem okay so sir basically my it will help my enhance my stability yes that is what is written yeah so but then uh in the list that you mentioned that stability is the critical parameter but I still am sizing the PG to be very smart the most small device yeah because what we say is influence of PG and PD is very high on SNM this is the primary factor this is the secondary Factor okay pu strong is secondary for this stability okay obviously not a second Arena okay you're able to see this VX why when does PU come into picture when v x goes high if I do not let v x go high will pu come into picture no no sir okay okay yes I've got it thanks so even though they appear to be six devices hmm do you realize that uh there is a whole lot of game happening there designing these six devices and a memory cell in these six devices is not a simple task are you"
RU-Coji28dw,just so many contradictions so uh memory cell even if it appears to be a small latch is not just the latch okay now we will have a quick look another look at cell stability uh a more visual kind of a look and uh so let us say there are these two inverters you know a pair of inverters this node is called N1 N2 and out two what I do is so if I if I draw there transfer characteristics the transfer characteristics would appear something like this now if I close this switch what happens now my transfer characteristics are like this what is important to notice is that for the first inverter the input no longer is N1 the input is now out to so the first curve is between out 2 and N2 the second curve is between N2 and out 2 9. so both the curves are between N2 and out 2. I can actually overlap them but when I want to overlap them I will have to flip one of the curves as I flip one of the curves what happens I'll come up with what is called as a butterfly curve okay foreign like two wings of a butterfly so in this butterfly curve now we say that we want to do some noise analysis on this latch so let us say this blue dot was zero and the Green Dot was one on zero I will put a positive noise and on one I will put a negative noise I will inject noise which is trying to disturb the contents of this latch now if I look at this two inverters which are connected back to back and I say that okay let me just you know this is this means that there is going to be a positive feedback here am I right so there is going to be positive feedback over here can I simply say that it is almost like saying that there are these two inverters feeding into each other as an infinite chain where N1 is equal to N3 is equal to N5 and then 2 is equal to in 4 is equal to n6 um so I'm just instead of showing it as a positive feedback in a loop I just opened the loop and I've injected noise there all in twos have a negative noise all in all odd ends have a negative noise all evenings have a positive noise vice versa so yes so in so for example I get this point that uh once you form this Loop it could be considered as a long infinite chain of inverters so but for example uh if I consider the first inverter only I inject a positive noise at the z i i in one so but if that uh noise is below is in the range of the noise margin of the in my inverter so it will win it will not get transferred to this in2 right yeah who said it will not get it will not lead to a flipping of the contents of the memory cell some impact may come on in2 depending on the transfer characteristics how much gets transferred depends on the transfer characteristics so it even if it is within the rise versions The Noise will get transferred that is what the transfer curve is about now but uh like in vcna key if it is below the contents uh however my input it doesn't get transferred that it doesn't need to flip no it does not lead to a flip but it does get transferred how can an inverter not transfer its input onto the output can it ever happen can it happen that an inverter will not give an output based on the input so it will but it will maintain that output to be uh so the logic level May remain same raghav yes sir but the voltage level can change now okay let us look at it why worry so let us say we know what in this butterfly curve all in Rd and odd ends are on this side all even ends are on this side on the zero on the N1 I injected the noise so this is where my transfer curve came so my N2 you will notice if if this is my transfer characteristic and this is the noise injected my N2 was at full vddl here it will now come to a little below VDB okay I have just zoomed this small region into this okay so now N2 has gone a little low I also injected some noise on N2 so what happens the N1 where it was all earlier at full 0 as you noticed have you noticed it has gone a little above zero because that is what the transfer curve is about hmm then for N3 now N3 is somewhere here I inject a noise there okay so N4 is here and I see that since the amount of noise is very less my you know I add more noise across the other stages I simply play between this this axis my contents remain safe are you with me are you able to see this so why will why it is getting Bound in this region only that is not uh because you tell me in three came here so I added noise it means N4 came here I added noise on N4 it took me to the almost same level as where in three was so Iron 5 sees the same voltage as N3 um if infi is and in3 are going to be the same then what what are we saying that again all Iron 7 iron 9 Etc will also be the same that is what we are saying over here that when I injected noise onto N4 the way it impacted in five hours that N5 also came to the same level as in three because the noise was so less hmm now if the noise is more what happens now when you inject noise on in in on this curve now you will see that soon I actually enter into the other side so my cell contents are corrupted now I moved from this place the slope to the other lobe so in between these two places then there must be a boundary after which the cell fails but at that boundary the cell still passes and you will notice that that boundary comes when you are kind of talking about the largest Square so this is so this is your one axis of noise addition this is the other axis of noise addition the largest square that you can fit into the lobe of the memory cell that is in in the lobe of this butterfly curve is what is the maximum noise you can inject and this is then the noise margin of the latch we're not even talking about memory cell yet this is about a simple latch the slash could be in a flip flop this latch could be your delatch the splash could be anything any latch this is the noise margin this is the butterfly curve is the technique to measure its noise margin the largest Square you can fit into the smaller Loops would be called as the noise margin now another way to look at it is if I had injected one noise at N1 and 3 and N5 what that meant was that even when N1 was 0 the curve has moved to a little to the left so even at that zero value of N1 because of noise the the N2 has fallen from the top level to a little lower value now I inject the other side of other noise on the N2 and 4 Etc what that means is uh even when N2 is 0 my N1 is no longer zero okay so the point where these two curves kind of stop having an intersection this is no longer like a butterfly curve that point is your noise margin so the largest the longest you can go up and left is what your noise margin is in a way we are again reiterating that the biggest Square you can fit into the lobe is what the noise margin is okay any questions,https://www.youtube.com/watch?v=RU-Coji28dw,"Link: https://www.youtube.com/watch?v=RU-Coji28dw
Transcript: just so many contradictions so uh memory cell even if it appears to be a small latch is not just the latch okay now we will have a quick look another look at cell stability uh a more visual kind of a look and uh so let us say there are these two inverters you know a pair of inverters this node is called N1 N2 and out two what I do is so if I if I draw there transfer characteristics the transfer characteristics would appear something like this now if I close this switch what happens now my transfer characteristics are like this what is important to notice is that for the first inverter the input no longer is N1 the input is now out to so the first curve is between out 2 and N2 the second curve is between N2 and out 2 9. so both the curves are between N2 and out 2. I can actually overlap them but when I want to overlap them I will have to flip one of the curves as I flip one of the curves what happens I'll come up with what is called as a butterfly curve okay foreign like two wings of a butterfly so in this butterfly curve now we say that we want to do some noise analysis on this latch so let us say this blue dot was zero and the Green Dot was one on zero I will put a positive noise and on one I will put a negative noise I will inject noise which is trying to disturb the contents of this latch now if I look at this two inverters which are connected back to back and I say that okay let me just you know this is this means that there is going to be a positive feedback here am I right so there is going to be positive feedback over here can I simply say that it is almost like saying that there are these two inverters feeding into each other as an infinite chain where N1 is equal to N3 is equal to N5 and then 2 is equal to in 4 is equal to n6 um so I'm just instead of showing it as a positive feedback in a loop I just opened the loop and I've injected noise there all in twos have a negative noise all in all odd ends have a negative noise all evenings have a positive noise vice versa so yes so in so for example I get this point that uh once you form this Loop it could be considered as a long infinite chain of inverters so but for example uh if I consider the first inverter only I inject a positive noise at the z i i in one so but if that uh noise is below is in the range of the noise margin of the in my inverter so it will win it will not get transferred to this in2 right yeah who said it will not get it will not lead to a flipping of the contents of the memory cell some impact may come on in2 depending on the transfer characteristics how much gets transferred depends on the transfer characteristics so it even if it is within the rise versions The Noise will get transferred that is what the transfer curve is about now but uh like in vcna key if it is below the contents uh however my input it doesn't get transferred that it doesn't need to flip no it does not lead to a flip but it does get transferred how can an inverter not transfer its input onto the output can it ever happen can it happen that an inverter will not give an output based on the input so it will but it will maintain that output to be uh so the logic level May remain same raghav yes sir but the voltage level can change now okay let us look at it why worry so let us say we know what in this butterfly curve all in Rd and odd ends are on this side all even ends are on this side on the zero on the N1 I injected the noise so this is where my transfer curve came so my N2 you will notice if if this is my transfer characteristic and this is the noise injected my N2 was at full vddl here it will now come to a little below VDB okay I have just zoomed this small region into this okay so now N2 has gone a little low I also injected some noise on N2 so what happens the N1 where it was all earlier at full 0 as you noticed have you noticed it has gone a little above zero because that is what the transfer curve is about hmm then for N3 now N3 is somewhere here I inject a noise there okay so N4 is here and I see that since the amount of noise is very less my you know I add more noise across the other stages I simply play between this this axis my contents remain safe are you with me are you able to see this so why will why it is getting Bound in this region only that is not uh because you tell me in three came here so I added noise it means N4 came here I added noise on N4 it took me to the almost same level as where in three was so Iron 5 sees the same voltage as N3 um if infi is and in3 are going to be the same then what what are we saying that again all Iron 7 iron 9 Etc will also be the same that is what we are saying over here that when I injected noise onto N4 the way it impacted in five hours that N5 also came to the same level as in three because the noise was so less hmm now if the noise is more what happens now when you inject noise on in in on this curve now you will see that soon I actually enter into the other side so my cell contents are corrupted now I moved from this place the slope to the other lobe so in between these two places then there must be a boundary after which the cell fails but at that boundary the cell still passes and you will notice that that boundary comes when you are kind of talking about the largest Square so this is so this is your one axis of noise addition this is the other axis of noise addition the largest square that you can fit into the lobe of the memory cell that is in in the lobe of this butterfly curve is what is the maximum noise you can inject and this is then the noise margin of the latch we're not even talking about memory cell yet this is about a simple latch the slash could be in a flip flop this latch could be your delatch the splash could be anything any latch this is the noise margin this is the butterfly curve is the technique to measure its noise margin the largest Square you can fit into the smaller Loops would be called as the noise margin now another way to look at it is if I had injected one noise at N1 and 3 and N5 what that meant was that even when N1 was 0 the curve has moved to a little to the left so even at that zero value of N1 because of noise the the N2 has fallen from the top level to a little lower value now I inject the other side of other noise on the N2 and 4 Etc what that means is uh even when N2 is 0 my N1 is no longer zero okay so the point where these two curves kind of stop having an intersection this is no longer like a butterfly curve that point is your noise margin so the largest the longest you can go up and left is what your noise margin is in a way we are again reiterating that the biggest Square you can fit into the lobe is what the noise margin is okay any questions"
sj7Z-k2JWu8,so now we come to bit cell layout uh and some of you had seen this layout in the DVD course but we will go in much more detail over here so you can tell me which one of these devices is the so what is this devices this uh pass gate pull down Pull up which one is this it is pass gate okay what is this device so pull down pull down pull down okay and we see that pass gate is smaller than pull down so this is in line with what we had thought of what about this one and that is the pull down okay about this one asking what about this one so this is the envelope in which they are huh what about this one foreign poly so in this particular cell we will put some contacts so what what is this contact the set of contacts about a bit like the other bit lines the others they are the source node of the pass gate um okay what is this sorry vdd vdd great what about this one for ground ground great what about this one avoid lines okay so uh and let me also put bit9 over here okay what is this one so VX so what is the name of the node VX is the voltage we were talking about blti or blfi one of the two internal nodes now this is also the same node and do you see this is a long contact have you have you seen such a long contact anywhere else all of you have made layouts have you seen a long contact elsewhere no so so what is happening here so DRC rule follow me foreign on contact distance between two contacts there is a DRC of distance between two contacts so if I had not put this long contact over here what do I need to do I need to make a contact here and I need to make another contact here and then I need to connect them are you able to see this and there is a DRC spacing between these two contacts that I have to maintain that DRC spacing maintaining that DRC spacing would mean I have to increase the height of the memory cell this is what I don't want to do and to avoid that we use what are these long contacts these long contacts are used only inside the srams SRAM cells not even anywhere else in the restaurant only in the SRAM cells why do you think uh only in the Islam cells they allow this and nowhere else because of symmetry because we want to make my sense amplifiers also symmetrical many analog circuits I can make symmetrical symmetrically sorry to keep it compact yeah so I would want to make my analog circuits also compact why not allow it there so I think that because we have an array kind of structure so we know the placings already so we can uh maybe arrange them because we need to anyway design the whole to Custom Design so we can do that by keeping uh the whole structure the array structure came back so we know every spit cell so we can then uh any DRC we can buy a custom only we can take care of that hmm so what we are saying is what raghav over here is telling us is let's see in fact this memory cell would always appear would always be there in form of an array it is not just that I want to make this one contact somewhere or this one set of contacts in some region and then remaining area is is completely out of my control when we talk of an SRAM cell at that point of time I know that in this Pura 1000 microns per of area this kind of pattern would appear over and over again because this long contact helps us in Saving area very very significantly the process teams say that okay because you are using an array you are using a systematic formation of these long contacts we will tweak our resolution enhancement algorithms are Optical proximity correction algorithms so that such contacts can be formed fine in an array configuration so you cannot use long contacts in independently long contacts are all allowed only in Array configuration and therefore only in memory cells okay any questions so in case all standard cells we didn't know which other cell will be updated over the one we are designing that is why we were not using that and now in memory we know exactly okay thank you exactly hmm so there is some kind of continuity in the memory right uh I would not say continuity continuity you can have for standard cells also that is not the thing repetition repetitions would be the better word okay repetition number for a consistent pattern repetition leading to a pattern through which I could optimize stuff that is all that we are talking about okay so after we make these long contacts what do we do we add the metal steps so first we make them put the metal straps on the boundaries and then we make these connections of the brti blfi okay now again notice we have done a DRC violation here just so that I can maintain sufficients uh you know uh spacing between the two metals the contacts may not be fully covered this again is not allowed elsewhere nowhere else in the design can you do this only inside the memory cell you may have such things even these notches that you have the M1 notches that we have shown here even these notches could be violating DRC but all this all this is allowed simply because we want to gain density and it is technically possible because this is a very very repetitive structure extending over hundreds of thousands of microns okay so we can do something about the optimal Optical proximity correction over there if this was not that that Broad and that uh widely used symmetrical structure one would not want to do it so it's much risky okay so because we are doing all these DRC violations do you realize that typically memory cell yield will be worse than other logic parts they were letting drcs here are you able to see this so what exactly is it not just for here this Notch thing okay if you do not put this Notch what happens your contact is still less covered now ideally would want to cover the entire contact that is what your DRC says is it not yes we have not covered the entire contact okay we are saying instead of covering it fully just put a small notch extraordinary it's not Extra metal it was the metal that was expected to cover the contacts you remove the metal from there it is not Extra metal okay can I ask something we are doing with their solution mainly because we want the density to be here uh yes because area is diamond so sorry and we can do the DRC violations you cannot do technology team will do for you so you will not really be designing these DRC violations yourself whichever company you join unless you join a technical technology team there unless you join the technology team that designs the memory cells uh you will not be allowed to touch the layout of the memory cell at all as a design team you will be given this layout but I am preparing you for all kinds of job roles so mostly if you go into the design roles you will only get a layout so now you also there are so many violations there so you also told we can technically do because it's a reputative structure yes technologically this is enabled because only because it is a repetitive structure so we know what the neighborhood is the neighborhood is not random hmm foreign do you see there are there are so many structures that are shared across memory cells we started with the contacts here these contacts were shared now these vrs are shared across two memory cells across the cell boundary so this is these are shared across two memory cells and you see this via for example is shared across four memory sets do you see a paradigm shift when we were designing standard cells what did we say that whatever is the cell boundary leave half DRC from the boundary foreign yes sir over here we are saying do the sharing again simply because we know what the neighborhood is we know that it is repetitive it is the same cell that is going to come repeat there but do you see that I will not be able to when I am saying it is the same cell that will repeat next I am not I cannot really place this cell exactly translate it over here I will have to mirror it such that this is how my design will appear this will be metal one uh there will be a poly over here there will be this poly would extend like this you see we will we are now mirroring the cell this mirroring of the cell is called flipping is also called flipping mirroring to hey it's also called flipping so you do not translate the cell you slip the cell so the way it is referred to is like this cell the original cell let us say was in is called as X configuration when I mirror it I call that as MX configuration mirrored X when I when I look at over here huh the cell over here would be mirrored on the on the y-axis so it would be called as m y and then you mirror again and you will get y okay so you don't need to learn all this stuff or even remember all this what I am telling you is that we when we abut memory cells because we want to do sharing we mirror the cells we slip the cells so that we come into an array formation we will just look at one of the array formations so these are the bit lines the word line steps the word line and the ground connections okay now do you see that in this particular in this particular layout the word line that is running in the center has a lot of metal capacitance from the adjacent ground so my word line capacitance increases very significantly this is not what we like so what we do is we actually cut the ground rails and we say that we will overrun the memory cell with metas4 rails through which we will drop ground connections over here okay I am not able to get this so I mean so in this slide what do you see you are getting ground from row decoder region are you able to see this so see this metal C that I am going to run over it is connected to this node this node is connected to the source of the pull down this is ground we just discussed that Hannah so we are getting ground from the row decoder region but when I do that what happens there are two things first is the word line capacitance and creases this is something I don't like um if the word line the passions increases it will it will rise slowly it will also consume more power to select a word line and so on so this is not to my liking the Miller capacities metal capacitance incremental capacitance okay this is M3 this is also M3 okay yes there are three metal sea lines running next to each other there is going to be capacitance between them yes sir so I don't like this capacitance so what do we do the only way to reduce this capacitance is cut the metal rail but once you cut the material you still have to provide the ground connection you provide that ground connection through a vertical metaphor line instead of bringing grounds from the Rhode region you bring ground from say are you region vertically is that okay yes so similarly you may you may so over here the vdd supply is provided in metal two are you able to see this so you if you run Metal 2 through the entire array the vdd supply may see some resistance to avoid that you may also want to strap bdd Supply provide provide a metal three stub and a metal four connection somewhere somewhere at some interval not every cell but somewhere okay so when you design the memory array you have to take care of power routing of the memory array also very carefully okay so if I just as you're talking about putting cells in MX and Y and uh X by by location we get an array hmm do you see this ground this was the ground that is now shared with the adjacent cell this is the this is the word line that is shared across memory cells and so on so we can make an array through which this sharing enables still higher density so from this it seems that we have only done the kind of why mirroring we're mirroring vertically right no we have a mirrored we mirrored along this axis and a mirror along this axis also both the axis if I Will Not Mirror along the if I have not mirror along say this axis then there will be a disconnect I wanted to connect the bit line on the pass gate uh and I need the bit line if I just translate it up there there would be ground from here this side and bit line from this side yes not merge them therefore mirroring on this side is also required yes okay so any questions yeah so when we uh you were talking about the yield part uh so if fabrication team is allowing us to boil some drcs so they have prepared masks for that layout so why there will be a yield loss in such case so if they could always if the mask preparation and this Optical proximity correction was so simple as well they would have allowed everyone to use the degraded drcs yes sir they allowed only you because of the repetitiveness of the structure yes but it still meant that they are pushing the limits of the technology okay due to that pushing of Technology they may be the illness there will be a loss there will be the yeah okay okay so as a whenever a new process node is defined let us say I want to define the three nanometer process node now the yield is actually ramped up on srams is determined and measured dragged to see how the process has evolved because srams pushed the technology notes technology limits there yes sir yes sir okay yes understood yeah anything else Deepak you had a question just confirming if the metal 4 has not been shown here in this two cross two yeah okay just because if I would show metaphor you will not be able to see anything else already because of metal three I have put in some transparency on metal three but even then it's difficult to see what lies underneath so that's why anything else so in your projects you will have to make layouts so those of you who choose the SRAM cell project you have to make the layouts and you have to ensure this kind of sharing is happening okay in your in your course projects you will not be allowed to violate drcs but you have to use this this uh way of making layouts okay so we will be making this 2 cross 2 or a single cell you will be making uh I will probably ask you to make a 64 cross 64 array okay extract that I will want you to make a 64 cross 64 array extract it and then estimate the word line capacitance bit line capacitance Etc from that extraction okay okay so we will be using those long contacts no no you will be doing a DRC clean only Okay so you do not have the what do you say resourcefulness to design long contacts not allowed yes okay any further questions on this great so uh now let us look at some other layout topologies that were either used earlier or that you may see in some some books which are no longer used anywhere today okay so this kind of a topology uh they've already written where the pull-up is and can you tell me where the pull down is okay that is also written there is the pass gate these are the pass Gates hmm so this kind of layout was used I think more than 20 25 years back but many books carry only this layout for you that is why I had to make the whole layout Evolution for you otherwise I would not have needed to do it many books would show you only this kind of layout but please you have done this course do not ever make such layout in in your interviews or anywhere it is absolutely unacceptable today why do you think this layout is not acceptable today who can tell so lots of empty space and non-symmetrical elements they are using Vias on each contact with so much Wheels we also use lots of vrs and contacts that was needed maybe lots of turning lots of bands really look at this this poly is bending the the direction of pmos device and nmos devices is different there's a bend in the nmos device itself there there are pull-downs which are vertically which are like this and pass gate which is like this you know anyways you know in in Advanced Technologies you want to keep things as simple as possible not have any bends nothing so there's there are so many benzia metals there are so many notches and bends so this layout is now nowhere used today nowhere even if you now design a technology which was 25 years old you would want to use the new kind of layout that we discussed here not this one okay but yeah over here also you will notice lots of sharing is happening see there's so many sharing Happening Here along this because this is really rely on our ground line so a lot of sharing happens over here also in these layouts and you can actually make a array but also you will see that many books so this is taken from a book somewhere you will see that the books have not again given you the concept of mirroring because they are not given the concept of mirroring you see they are not able to do the sharing across the sets are you able to see this that was why in the beginning of the course I said no book will have to will be able to actually give you what we are going to discuss in the class okay so you will see all such all such stuff in the books I'm not saying it is wrong it is right but it was right 25 years back no one uses this today because this wastes enormous amount of area okay however in in Advanced Technologies for example Hitachi and denisas they say that see in what we and whatever we discussed in law what did we say we said that the beta ratio has to be greater than one so that my SNM is good but in Advanced Technologies because of because of uh Optical proximity errors and Corrections or whatever mismatch due to that we see that using a regular layout you know beta ratio equal to 1. actually meant a better yield look at this these are the results this is the this is the 614 the bigger cell which had beta ratio greater than one and this is the SNM the worst case SNM is this foreign naturally it's median and mean SNM is going to be lesser than the cell with beta ratio greater than 1. are you able to see this still here hello I would just give you these two cells you know that the top cell has a better SNM than the lower cell so yes you have a question okay so since beta ratio of the top cell is better we know that the median SNM is going to be better and that is what we see also but due to mismatches and Manufacturing do you realize that the worst case SNM of this ra over here is worse than the worst case SNM of the denser array the sigma is lesser yes sir and that makes a very very big difference that is why in Memories We very uh or this is the standard to call ADS this is a call as a figure of Merit so you never say median or mean value of SNM you never quote only SNM mean value or median value not just that you always also quote mu by Sigma what would mu by Sigma mean do you know what Sigma is standard deviation mu is mean when I talk of mu by Sigma what I am essentially saying is that if it was a gaussian distributed curve then I will go one Sigma away there is some probability that I am covering you know one set of cells I am coming you go to Sigma the way I will convert another set of cells three sigma away I will cover another set of cells so if my mu by Sigma is very large it means my uh my my variations are more controlled my median is very high I do not hit a zero far until far away until very many sigmas so if you if you have to quickly estimate the MU by Sigma of these two cells which one has a better mu by Sigma what is the MU by Sigma over here something like this 6.4 over something yeah what about the MU by Sigma over here 7.4 something point four something so okay so even though median value is lesser we realize the sigma value is better and that is why the worst case cell that you see in this region uh the the the large cell fails which is the small cell that is better not only did you save area you also had better yield finally so can you please uh focus on this uh new by signal significance I'm not able to get exactly we will look at it in much more detail later also then we'll talk about statistics links to srams but uh uh we can look at it as the higher the MU by Sigma the farther away my mean is from zero okay not exactly in absolute terms but in terms of Sigma so the small cell lattice seven Sigma steps seven point four Sigma steps away from zero and the big cell is only 6.4 Sigma steps away from zero okay and so that is more desirable the farther it is exactly because that means that uh see Zero May s m zero yeah okay and when when it comes to zero s m becomes zero so if I have more Sigma steps away from 0 it means more Sigma cell is covered without getting SNM to zero what that means is I can have more cells so suppose uh suppose uh mu by Sigma was 1. then do you realize only this kind of cells were functional other cells would have Sigma equal to zero yes yes but if mu by Sigma was 2 then I add these into functional cells if mu by Sigma was 3 even these cells become functional so greater than mu by Sigma higher the yield okay and so for example looking at their both these curves so we see that the worst case of uh lower is better so since we are always characterizing based on the worst case that's why we say that the lower end is better yeah because we look at what is Mu by Sigma because mu by Sigma of the lower is better we say lower is better okay is that okay so submit sales counterintuitive I think it's not a trivia yeah but it is important that you understand that not everything works according to your simplistic understanding yes sir are you able to see that simplistically yes see the Min the mean value of Sigma is 154 and 190. a simple person looking at it would say the blue cell is better is it not yes sir but a SRAM designer would ask the next question what is the sigma a sanicide designer would not ask the sigma designer would ask what is the sigma we were talking about it a little while back also that you cannot consider designing a memory cell without looking at mismatch you will see many papers published by many called many many students and different colleges just do one simulation no one take Carlo nothing and they say I have a very dense cell I have this kind of a cell people in Industry would never even consider reading such papers unless you talk about the concept of mu by Sigma unless you talk about the concept of eat or anything all the work that that is done in Academia is trash not usable okay so so if my Mumbai Sigma improves my yield is better so in effectively I'm beneficial okay so yes so with this we move to the next part which is other cells,https://www.youtube.com/watch?v=sj7Z-k2JWu8,"Link: https://www.youtube.com/watch?v=sj7Z-k2JWu8
Transcript: so now we come to bit cell layout uh and some of you had seen this layout in the DVD course but we will go in much more detail over here so you can tell me which one of these devices is the so what is this devices this uh pass gate pull down Pull up which one is this it is pass gate okay what is this device so pull down pull down pull down okay and we see that pass gate is smaller than pull down so this is in line with what we had thought of what about this one and that is the pull down okay about this one asking what about this one so this is the envelope in which they are huh what about this one foreign poly so in this particular cell we will put some contacts so what what is this contact the set of contacts about a bit like the other bit lines the others they are the source node of the pass gate um okay what is this sorry vdd vdd great what about this one for ground ground great what about this one avoid lines okay so uh and let me also put bit9 over here okay what is this one so VX so what is the name of the node VX is the voltage we were talking about blti or blfi one of the two internal nodes now this is also the same node and do you see this is a long contact have you have you seen such a long contact anywhere else all of you have made layouts have you seen a long contact elsewhere no so so what is happening here so DRC rule follow me foreign on contact distance between two contacts there is a DRC of distance between two contacts so if I had not put this long contact over here what do I need to do I need to make a contact here and I need to make another contact here and then I need to connect them are you able to see this and there is a DRC spacing between these two contacts that I have to maintain that DRC spacing maintaining that DRC spacing would mean I have to increase the height of the memory cell this is what I don't want to do and to avoid that we use what are these long contacts these long contacts are used only inside the srams SRAM cells not even anywhere else in the restaurant only in the SRAM cells why do you think uh only in the Islam cells they allow this and nowhere else because of symmetry because we want to make my sense amplifiers also symmetrical many analog circuits I can make symmetrical symmetrically sorry to keep it compact yeah so I would want to make my analog circuits also compact why not allow it there so I think that because we have an array kind of structure so we know the placings already so we can uh maybe arrange them because we need to anyway design the whole to Custom Design so we can do that by keeping uh the whole structure the array structure came back so we know every spit cell so we can then uh any DRC we can buy a custom only we can take care of that hmm so what we are saying is what raghav over here is telling us is let's see in fact this memory cell would always appear would always be there in form of an array it is not just that I want to make this one contact somewhere or this one set of contacts in some region and then remaining area is is completely out of my control when we talk of an SRAM cell at that point of time I know that in this Pura 1000 microns per of area this kind of pattern would appear over and over again because this long contact helps us in Saving area very very significantly the process teams say that okay because you are using an array you are using a systematic formation of these long contacts we will tweak our resolution enhancement algorithms are Optical proximity correction algorithms so that such contacts can be formed fine in an array configuration so you cannot use long contacts in independently long contacts are all allowed only in Array configuration and therefore only in memory cells okay any questions so in case all standard cells we didn't know which other cell will be updated over the one we are designing that is why we were not using that and now in memory we know exactly okay thank you exactly hmm so there is some kind of continuity in the memory right uh I would not say continuity continuity you can have for standard cells also that is not the thing repetition repetitions would be the better word okay repetition number for a consistent pattern repetition leading to a pattern through which I could optimize stuff that is all that we are talking about okay so after we make these long contacts what do we do we add the metal steps so first we make them put the metal straps on the boundaries and then we make these connections of the brti blfi okay now again notice we have done a DRC violation here just so that I can maintain sufficients uh you know uh spacing between the two metals the contacts may not be fully covered this again is not allowed elsewhere nowhere else in the design can you do this only inside the memory cell you may have such things even these notches that you have the M1 notches that we have shown here even these notches could be violating DRC but all this all this is allowed simply because we want to gain density and it is technically possible because this is a very very repetitive structure extending over hundreds of thousands of microns okay so we can do something about the optimal Optical proximity correction over there if this was not that that Broad and that uh widely used symmetrical structure one would not want to do it so it's much risky okay so because we are doing all these DRC violations do you realize that typically memory cell yield will be worse than other logic parts they were letting drcs here are you able to see this so what exactly is it not just for here this Notch thing okay if you do not put this Notch what happens your contact is still less covered now ideally would want to cover the entire contact that is what your DRC says is it not yes we have not covered the entire contact okay we are saying instead of covering it fully just put a small notch extraordinary it's not Extra metal it was the metal that was expected to cover the contacts you remove the metal from there it is not Extra metal okay can I ask something we are doing with their solution mainly because we want the density to be here uh yes because area is diamond so sorry and we can do the DRC violations you cannot do technology team will do for you so you will not really be designing these DRC violations yourself whichever company you join unless you join a technical technology team there unless you join the technology team that designs the memory cells uh you will not be allowed to touch the layout of the memory cell at all as a design team you will be given this layout but I am preparing you for all kinds of job roles so mostly if you go into the design roles you will only get a layout so now you also there are so many violations there so you also told we can technically do because it's a reputative structure yes technologically this is enabled because only because it is a repetitive structure so we know what the neighborhood is the neighborhood is not random hmm foreign do you see there are there are so many structures that are shared across memory cells we started with the contacts here these contacts were shared now these vrs are shared across two memory cells across the cell boundary so this is these are shared across two memory cells and you see this via for example is shared across four memory sets do you see a paradigm shift when we were designing standard cells what did we say that whatever is the cell boundary leave half DRC from the boundary foreign yes sir over here we are saying do the sharing again simply because we know what the neighborhood is we know that it is repetitive it is the same cell that is going to come repeat there but do you see that I will not be able to when I am saying it is the same cell that will repeat next I am not I cannot really place this cell exactly translate it over here I will have to mirror it such that this is how my design will appear this will be metal one uh there will be a poly over here there will be this poly would extend like this you see we will we are now mirroring the cell this mirroring of the cell is called flipping is also called flipping mirroring to hey it's also called flipping so you do not translate the cell you slip the cell so the way it is referred to is like this cell the original cell let us say was in is called as X configuration when I mirror it I call that as MX configuration mirrored X when I when I look at over here huh the cell over here would be mirrored on the on the y-axis so it would be called as m y and then you mirror again and you will get y okay so you don't need to learn all this stuff or even remember all this what I am telling you is that we when we abut memory cells because we want to do sharing we mirror the cells we slip the cells so that we come into an array formation we will just look at one of the array formations so these are the bit lines the word line steps the word line and the ground connections okay now do you see that in this particular in this particular layout the word line that is running in the center has a lot of metal capacitance from the adjacent ground so my word line capacitance increases very significantly this is not what we like so what we do is we actually cut the ground rails and we say that we will overrun the memory cell with metas4 rails through which we will drop ground connections over here okay I am not able to get this so I mean so in this slide what do you see you are getting ground from row decoder region are you able to see this so see this metal C that I am going to run over it is connected to this node this node is connected to the source of the pull down this is ground we just discussed that Hannah so we are getting ground from the row decoder region but when I do that what happens there are two things first is the word line capacitance and creases this is something I don't like um if the word line the passions increases it will it will rise slowly it will also consume more power to select a word line and so on so this is not to my liking the Miller capacities metal capacitance incremental capacitance okay this is M3 this is also M3 okay yes there are three metal sea lines running next to each other there is going to be capacitance between them yes sir so I don't like this capacitance so what do we do the only way to reduce this capacitance is cut the metal rail but once you cut the material you still have to provide the ground connection you provide that ground connection through a vertical metaphor line instead of bringing grounds from the Rhode region you bring ground from say are you region vertically is that okay yes so similarly you may you may so over here the vdd supply is provided in metal two are you able to see this so you if you run Metal 2 through the entire array the vdd supply may see some resistance to avoid that you may also want to strap bdd Supply provide provide a metal three stub and a metal four connection somewhere somewhere at some interval not every cell but somewhere okay so when you design the memory array you have to take care of power routing of the memory array also very carefully okay so if I just as you're talking about putting cells in MX and Y and uh X by by location we get an array hmm do you see this ground this was the ground that is now shared with the adjacent cell this is the this is the word line that is shared across memory cells and so on so we can make an array through which this sharing enables still higher density so from this it seems that we have only done the kind of why mirroring we're mirroring vertically right no we have a mirrored we mirrored along this axis and a mirror along this axis also both the axis if I Will Not Mirror along the if I have not mirror along say this axis then there will be a disconnect I wanted to connect the bit line on the pass gate uh and I need the bit line if I just translate it up there there would be ground from here this side and bit line from this side yes not merge them therefore mirroring on this side is also required yes okay so any questions yeah so when we uh you were talking about the yield part uh so if fabrication team is allowing us to boil some drcs so they have prepared masks for that layout so why there will be a yield loss in such case so if they could always if the mask preparation and this Optical proximity correction was so simple as well they would have allowed everyone to use the degraded drcs yes sir they allowed only you because of the repetitiveness of the structure yes but it still meant that they are pushing the limits of the technology okay due to that pushing of Technology they may be the illness there will be a loss there will be the yeah okay okay so as a whenever a new process node is defined let us say I want to define the three nanometer process node now the yield is actually ramped up on srams is determined and measured dragged to see how the process has evolved because srams pushed the technology notes technology limits there yes sir yes sir okay yes understood yeah anything else Deepak you had a question just confirming if the metal 4 has not been shown here in this two cross two yeah okay just because if I would show metaphor you will not be able to see anything else already because of metal three I have put in some transparency on metal three but even then it's difficult to see what lies underneath so that's why anything else so in your projects you will have to make layouts so those of you who choose the SRAM cell project you have to make the layouts and you have to ensure this kind of sharing is happening okay in your in your course projects you will not be allowed to violate drcs but you have to use this this uh way of making layouts okay so we will be making this 2 cross 2 or a single cell you will be making uh I will probably ask you to make a 64 cross 64 array okay extract that I will want you to make a 64 cross 64 array extract it and then estimate the word line capacitance bit line capacitance Etc from that extraction okay okay so we will be using those long contacts no no you will be doing a DRC clean only Okay so you do not have the what do you say resourcefulness to design long contacts not allowed yes okay any further questions on this great so uh now let us look at some other layout topologies that were either used earlier or that you may see in some some books which are no longer used anywhere today okay so this kind of a topology uh they've already written where the pull-up is and can you tell me where the pull down is okay that is also written there is the pass gate these are the pass Gates hmm so this kind of layout was used I think more than 20 25 years back but many books carry only this layout for you that is why I had to make the whole layout Evolution for you otherwise I would not have needed to do it many books would show you only this kind of layout but please you have done this course do not ever make such layout in in your interviews or anywhere it is absolutely unacceptable today why do you think this layout is not acceptable today who can tell so lots of empty space and non-symmetrical elements they are using Vias on each contact with so much Wheels we also use lots of vrs and contacts that was needed maybe lots of turning lots of bands really look at this this poly is bending the the direction of pmos device and nmos devices is different there's a bend in the nmos device itself there there are pull-downs which are vertically which are like this and pass gate which is like this you know anyways you know in in Advanced Technologies you want to keep things as simple as possible not have any bends nothing so there's there are so many benzia metals there are so many notches and bends so this layout is now nowhere used today nowhere even if you now design a technology which was 25 years old you would want to use the new kind of layout that we discussed here not this one okay but yeah over here also you will notice lots of sharing is happening see there's so many sharing Happening Here along this because this is really rely on our ground line so a lot of sharing happens over here also in these layouts and you can actually make a array but also you will see that many books so this is taken from a book somewhere you will see that the books have not again given you the concept of mirroring because 
they are not given the concept of mirroring you see they are not able to do the sharing across the sets are you able to see this that was why in the beginning of the course I said no book will have to will be able to actually give you what we are going to discuss in the class okay so you will see all such all such stuff in the books I'm not saying it is wrong it is right but it was right 25 years back no one uses this today because this wastes enormous amount of area okay however in in Advanced Technologies for example Hitachi and denisas they say that see in what we and whatever we discussed in law what did we say we said that the beta ratio has to be greater than one so that my SNM is good but in Advanced Technologies because of because of uh Optical proximity errors and Corrections or whatever mismatch due to that we see that using a regular layout you know beta ratio equal to 1. actually meant a better yield look at this these are the results this is the this is the 614 the bigger cell which had beta ratio greater than one and this is the SNM the worst case SNM is this foreign naturally it's median and mean SNM is going to be lesser than the cell with beta ratio greater than 1. are you able to see this still here hello I would just give you these two cells you know that the top cell has a better SNM than the lower cell so yes you have a question okay so since beta ratio of the top cell is better we know that the median SNM is going to be better and that is what we see also but due to mismatches and Manufacturing do you realize that the worst case SNM of this ra over here is worse than the worst case SNM of the denser array the sigma is lesser yes sir and that makes a very very big difference that is why in Memories We very uh or this is the standard to call ADS this is a call as a figure of Merit so you never say median or mean value of SNM you never quote only SNM mean value or median value not just that you always also quote mu by Sigma what would mu by Sigma mean do you know what Sigma is standard deviation mu is mean when I talk of mu by Sigma what I am essentially saying is that if it was a gaussian distributed curve then I will go one Sigma away there is some probability that I am covering you know one set of cells I am coming you go to Sigma the way I will convert another set of cells three sigma away I will cover another set of cells so if my mu by Sigma is very large it means my uh my my variations are more controlled my median is very high I do not hit a zero far until far away until very many sigmas so if you if you have to quickly estimate the MU by Sigma of these two cells which one has a better mu by Sigma what is the MU by Sigma over here something like this 6.4 over something yeah what about the MU by Sigma over here 7.4 something point four something so okay so even though median value is lesser we realize the sigma value is better and that is why the worst case cell that you see in this region uh the the the large cell fails which is the small cell that is better not only did you save area you also had better yield finally so can you please uh focus on this uh new by signal significance I'm not able to get exactly we will look at it in much more detail later also then we'll talk about statistics links to srams but uh uh we can look at it as the higher the MU by Sigma the farther away my mean is from zero okay not exactly in absolute terms but in terms of Sigma so the small cell lattice seven Sigma steps seven point four Sigma steps away from zero and the big cell is only 6.4 Sigma steps away from zero okay and so that is more desirable the farther it is exactly because that means that uh see Zero May s m zero yeah okay and when when it comes to zero s m becomes zero so if I have more Sigma steps away from 0 it means more Sigma cell is covered without getting SNM to zero what that means is I can have more cells so suppose uh suppose uh mu by Sigma was 1. then do you realize only this kind of cells were functional other cells would have Sigma equal to zero yes yes but if mu by Sigma was 2 then I add these into functional cells if mu by Sigma was 3 even these cells become functional so greater than mu by Sigma higher the yield okay and so for example looking at their both these curves so we see that the worst case of uh lower is better so since we are always characterizing based on the worst case that's why we say that the lower end is better yeah because we look at what is Mu by Sigma because mu by Sigma of the lower is better we say lower is better okay is that okay so submit sales counterintuitive I think it's not a trivia yeah but it is important that you understand that not everything works according to your simplistic understanding yes sir are you able to see that simplistically yes see the Min the mean value of Sigma is 154 and 190. a simple person looking at it would say the blue cell is better is it not yes sir but a SRAM designer would ask the next question what is the sigma a sanicide designer would not ask the sigma designer would ask what is the sigma we were talking about it a little while back also that you cannot consider designing a memory cell without looking at mismatch you will see many papers published by many called many many students and different colleges just do one simulation no one take Carlo nothing and they say I have a very dense cell I have this kind of a cell people in Industry would never even consider reading such papers unless you talk about the concept of mu by Sigma unless you talk about the concept of eat or anything all the work that that is done in Academia is trash not usable okay so so if my Mumbai Sigma improves my yield is better so in effectively I'm beneficial okay so yes so with this we move to the next part which is other cells"
sy9PrDbeJsg,67 till now this is other memory cell what is the benefit of this memory cell what is the benefit of this memory cell what is this rbl rwl let us say read word line so the right and the read operations are separated the right and the read operations are separated okay if I look at it as a single port says then you are absolutely right-handed I will write through wordline and I will read through read word line yes sir when I have separated these write and read operations what is the benefit I have driven drawn out of it uh it's self stability sir yes see now earlier what was happening when I was reading there was a bump that would appear on brti or blfi so my read operation myself was very susceptible to failure now what has happened I can read and there is no no impact on the cell stability uh additional thing I want to have a very high speed memory if I would use the regular 60 cell I would need to have a larger pass gate which means I will need to have a larger pull down also which means my area would anyways go up including load on the bit lines would go up everything we saw it's a law of diminishing returns remember that however now I can size my these two additional devices the read port independent of sizing of the pull down or independent of any other thing so my read and write operations are decoupled over here hmm when I read there is no noise that I inject onto the internal nodes so my stability is better additionally what do I do now since read operation is not even of consequence I simply size my right port according to the requirements of the right port according to the requirements of the right operation um so I can actually make a more optimal cell which is faster also and which is more stable also are you able to see this now what happens if I use mux greater than one and I'm in a right cycle foreign does my stability remain high or there is something that happens then which I do not want uh so when you you set that key in this cell while reading I would not be injecting any noise so v x not there so but by that I so while reading you will turn on the rwl yes sir when rwl goes on what happens to VX is it changing so there's no additional noise that is injected onto the system there when will we exchange when wordline is selected but that is during right Cycles only so now my next question is if mux is equal to 4 and I select my word line now then there are three other cells in which I am not writing in these three cells I am not writing but wordline has gotten selected what happens to the stability hello foreign but the other three cells which were also selected by the same word line but you're not writing into them because the max address is is to select this one these three cells are in the read mode only and they have the same read condition as a regular 60 cell what this means is that in a sense while you have decoupled read and write ports the stability requirement still is similar however your read current can now be completely independently adjusted so isil now becomes independent of SNM constraint if you were to use only mux1 then I would also say that stability problem is taken care of but if I am not using Max 1 I am using a higher marks then stability problem remains all that I have achieved through the safety cell then is I have improved the icel without impacting stability are you able to see this any questions Ranjit or sir when we are using uh mux greater than one then this is even a issue in the normal 60 years yeah yeah we have to take care of stability see I started this the discussion on this cell by saying oh rewrite are decoupled so stability is no longer a concern now I am saying no stability remains to be a concern if my marks is greater than 1. okay again numerous papers numerous papers in Academia you will see who who forget that there is a mux thing there they simply say oh 80 cell is the Panacea is it's the it solves all problems no it doesn't if you have Max greater than one it doesn't solve all the problems you need to do something else yes many academic papers simply ignore that aspect okay so I'm telling you this because I don't want you to fall into those traps so can you once again explain this uh ice and concept of people so okay in this particular cell what determines the cell current the the pull down in the read Network yeah the no not just the pull down the stack of the of the two nmos is connecting rbl to ground yes yes sir see when we were designing the similar stack on the regular 60 cell we had to ensure that PG was much lesser than PD yes sir so my PD being lesser even though I am giving area my current current was limited yes over here I can have both both the password and the pull down large enough yes yes sir so at in the same area I don't need to have any constraint sizing on the basket and therefore I can have more read current yes sir are you able to see this sir 0 and I want to read that zero so I put the read word line as one but then uh how exactly but I'm not changing the word line to be one then how I'm reading yeah so notice that will happen but if blfi was one then rbl would have discharged so you have red see if if blfi was one so you take rwl to one what happens to rbl oh it is charges it discharges if if blfi is equal to 0 what happens to rbl it doesn't discharge so so I have distinguished between 0 and 1 okay right what does reading mean I should be able to tell whether the inside the cell there is a zero or a one yes I am able to distinguish on the rbl yes um [Music] okay so is there any new figure of Merit that is introduced now so we already have cell current we already have stability we have right margin is there anything else that you would want to consider as a designer so the mugs part Max was already there but it is not a figure of Merit of a memory cell now okay yes character sticker area was the figure of Merit even for a 67 that is not a newspaper of Merit here yeah so for example so in this cell uh since my reading and writing be coupled so to improve my right I can now increase the pass gate size yeah yeah but as we just said nine if Max is greater than one then you can't do it because of stability constraints you will still need to maintain the beta ratio for the other three unselected columns no no so um the new figure of Merit is it the read speed uh read speech or read current you already had a figure of meritna cell currently already had a figure of Merit okay but yeah okay the new figure of Merit is also links to sell current though okay now consider a case that you are writing so you're using it as a dual Port set you're using it as a as a one read write and one read memory do you see this cell can be used like that also this is a read write port like a regular 60 cell and this is the read-only port you cannot write through the sport are you able to see this yes sir so if I am using this as one read write one read memory then I could actually be writing on this word line and also reading from this port can it happen I might be writing into this cell and reading this cell so arduable is also selected and WL is also selected yes so the lower and most of rbl is connected to VX which is dependent on the right so can we uh simultaneously read and write yeah we cannot there are two independent ports now but that is where the new figure of Merit comes into picture if if it so happens that my this boy line is selected and let us say this was Zero so in that case my bit rbl was not supposed to discharge are you with me if this if dlfi was 0 if vlfi was 0 and I selected both void line and a read word line rbl was not supposed to discharge I know hello yes sir yes sir now if my word line is also selected then this 0 goes to VX so this nmos turns partially on so there can be some current it can sync yeah are you able to see this so in this case I am trying to write uh one when there is zero right no I'm not trying to write a one I'm trying to write on some other self in the same row some other cell wanted I wanted to write there this select I'm not doing anything this cell only just turned on so why it turned on because the adjacent cell over here there were three other cells now I wanted to write on this particular cell okay sir let us say so the word line is common it will turn on yes sir so when the word line is on then the zero will go to the x so because bitline is uh blb's BDT that's to vdd yes okay so what happens as soon as it goes to VX this nmos turns partially on so there are some new current lattice now flowing so until now we were only looking at I on and I off and I said that if it is I off then this cell is storing a zero if it is Ion then this cell is storing a 1. that was what I had distinguished till now now what we are saying is that there is also another current which is I partially on which should also be considered as 0. are you able to see this but this uh discharging from RPL when it goes to that is partially on yes yes so for that this this lower and Moss do we have to make it high BT and mass or something else so if you make it a high vtn mass then what happens it will be sorry sorry not leakage if you make it high meaty then it will take more time to turn on then the read operation will be if you make it high VT then then since this is VX uh the I pawn may go down a bit yes but then you do you realize that ion will also reduce huh yes yes so you have to actually see what you were looking at was I want to distinguish initially between 0 and ion now they said no there is something which is IP on yes sir so much that modern is not there actually you have to have a sense amplifier which distinguishes between these two now you're telling me I will increase the VT of the device so what would happen this IP on could go here but this could come here okay yes sir so my margin could actually reduce yeah yes it may come only here also I do not know but it could come here also now potentially yes sir depends on what voltage I am operating at what is the sizing of these two devices depend on so many factors yes so there is no single formula that it has to be hvt making it activity may help it may not help additionally uh you cannot simply make just one device if I make this hvt this also needs to be made actually otherwise do you see there is a DRC between hvt and RBT devices I cannot abut them yes sir I know so in an SRAM cell you simply cannot say oh this device is low VT you will see many academic papers simply doing this oh I will just put one device at low VT no impact on leakage if you do that you cannot make the layout you're not even considering the impact on area then okay yeah just say yourself so we we designed the cells very carefully what is happening here what is this yeah to read write both the ports can do read write so there will be a different cell which would be two read and to write this is a two read write cell okay both ports can do read write operation then there are two ports so this this enables parallel parallel access to the memory from two different processors huh can you think of the new figures of Merit that will come into picture here hello how will you measure the stability over here what will be the worst case for stability yes both the ports on at the same time that is the worst case for stability is that also the worst case for read current foreign what would be the worst case for uh write operation both white line one and wordline two are on with different values of DX yes so we are saying that from one port I'm I'm simply keeping the pre-charge on okay the pre-charge is on but word line two is on and other Port I want to write so what happens over here there is a pre-charge that continuously supplies charge which has to be sunk through the right driver till now you are only designing right driver to discharge this node now your right driver has to sync this additional charge continuously are you able to see this foreign so this dual Port memory cell is is a little more complex to design than the single port memories have design and analyze primarily analyze designer but analyzing it is slightly more complex you have to look at what are the worst cases and then qualify those worst cases so what exactly was the worst case for the right worst case on the right was that see there is a right driver over here it was designed to sync this current only but my other Port also is on and the pre-charge of the bit line is on so there is a vdd that is being supplied to this bit line which goes from the first pass gate and now needs to be discharged through the right driver so both word line one and word line 2 are on and bl1 is equal to 0 through right driver and vl2 is vdd through pre-charge yes that would be the worst case for the right there could be another worst case which could be that oh my uh uh which you will realize when you will do that homework that I had given you last week which could be that let us say this word line one went on okay and then word line two went on and bl or bl1 discharged subsequently so when one of the word line goes on Suppose there was a zero stored here what will it do it will discharge this and it will discharge this also okay now you wanted to store a one here now the bit lines are discharged VX was initially something but it now Falls because the bit lines have the star so it is VX minus when you will do the solve those equations of write analysis and read analysis you will see that as the voltage of VX reduces what happens has the voltage of v x reduces the writability of the cell would degrade um so that could also be another worst case this is slightly more complex you need not bother about it but I just want you to remain open to other worst cases that could be there in this particular cell because of two ports two ports which are asynchronous one port could turn on before the other port okay so uh ideally when we when I have two ports I want to access different bit cells using the sports Arc yeah I am accessing different bitsers only ragas just the adjacent ones mission for one I am addressing it it has zero and with the other Port I'm addressing address one because it is Max 4 they are appearing in the same row,https://www.youtube.com/watch?v=sy9PrDbeJsg,"Link: https://www.youtube.com/watch?v=sy9PrDbeJsg
Transcript: 67 till now this is other memory cell what is the benefit of this memory cell what is the benefit of this memory cell what is this rbl rwl let us say read word line so the right and the read operations are separated the right and the read operations are separated okay if I look at it as a single port says then you are absolutely right-handed I will write through wordline and I will read through read word line yes sir when I have separated these write and read operations what is the benefit I have driven drawn out of it uh it's self stability sir yes see now earlier what was happening when I was reading there was a bump that would appear on brti or blfi so my read operation myself was very susceptible to failure now what has happened I can read and there is no no impact on the cell stability uh additional thing I want to have a very high speed memory if I would use the regular 60 cell I would need to have a larger pass gate which means I will need to have a larger pull down also which means my area would anyways go up including load on the bit lines would go up everything we saw it's a law of diminishing returns remember that however now I can size my these two additional devices the read port independent of sizing of the pull down or independent of any other thing so my read and write operations are decoupled over here hmm when I read there is no noise that I inject onto the internal nodes so my stability is better additionally what do I do now since read operation is not even of consequence I simply size my right port according to the requirements of the right port according to the requirements of the right operation um so I can actually make a more optimal cell which is faster also and which is more stable also are you able to see this now what happens if I use mux greater than one and I'm in a right cycle foreign does my stability remain high or there is something that happens then which I do not want uh so when you you set that key in this cell while reading I would not be injecting any noise so v x not there so but by that I so while reading you will turn on the rwl yes sir when rwl goes on what happens to VX is it changing so there's no additional noise that is injected onto the system there when will we exchange when wordline is selected but that is during right Cycles only so now my next question is if mux is equal to 4 and I select my word line now then there are three other cells in which I am not writing in these three cells I am not writing but wordline has gotten selected what happens to the stability hello foreign but the other three cells which were also selected by the same word line but you're not writing into them because the max address is is to select this one these three cells are in the read mode only and they have the same read condition as a regular 60 cell what this means is that in a sense while you have decoupled read and write ports the stability requirement still is similar however your read current can now be completely independently adjusted so isil now becomes independent of SNM constraint if you were to use only mux1 then I would also say that stability problem is taken care of but if I am not using Max 1 I am using a higher marks then stability problem remains all that I have achieved through the safety cell then is I have improved the icel without impacting stability are you able to see this any questions Ranjit or sir when we are using uh mux greater than one then this is even a issue in the normal 60 years yeah yeah we have to take care of stability see I started this the discussion on this cell by saying oh rewrite are decoupled so stability is no longer a concern now I am saying no stability remains to be a concern if my marks is greater than 1. okay again numerous papers numerous papers in Academia you will see who who forget that there is a mux thing there they simply say oh 80 cell is the Panacea is it's the it solves all problems no it doesn't if you have Max greater than one it doesn't solve all the problems you need to do something else yes many academic papers simply ignore that aspect okay so I'm telling you this because I don't want you to fall into those traps so can you once again explain this uh ice and concept of people so okay in this particular cell what determines the cell current the the pull down in the read Network yeah the no not just the pull down the stack of the of the two nmos is connecting rbl to ground yes yes sir see when we were designing the similar stack on the regular 60 cell we had to ensure that PG was much lesser than PD yes sir so my PD being lesser even though I am giving area my current current was limited yes over here I can have both both the password and the pull down large enough yes yes sir so at in the same area I don't need to have any constraint sizing on the basket and therefore I can have more read current yes sir are you able to see this sir 0 and I want to read that zero so I put the read word line as one but then uh how exactly but I'm not changing the word line to be one then how I'm reading yeah so notice that will happen but if blfi was one then rbl would have discharged so you have red see if if blfi was one so you take rwl to one what happens to rbl oh it is charges it discharges if if blfi is equal to 0 what happens to rbl it doesn't discharge so so I have distinguished between 0 and 1 okay right what does reading mean I should be able to tell whether the inside the cell there is a zero or a one yes I am able to distinguish on the rbl yes um [Music] okay so is there any new figure of Merit that is introduced now so we already have cell current we already have stability we have right margin is there anything else that you would want to consider as a designer so the mugs part Max was already there but it is not a figure of Merit of a memory cell now okay yes character sticker area was the figure of Merit even for a 67 that is not a newspaper of Merit here yeah so for example so in this cell uh since my reading and writing be coupled so to improve my right I can now increase the pass gate size yeah yeah but as we just said nine if Max is greater than one then you can't do it because of stability constraints you will still need to maintain the beta ratio for the other three unselected columns no no so um the new figure of Merit is it the read speed uh read speech or read current you already had a figure of meritna cell currently already had a figure of Merit okay but yeah okay the new figure of Merit is also links to sell current though okay now consider a case that you are writing so you're using it as a dual Port set you're using it as a as a one read write and one read memory do you see this cell can be used like that also this is a read write port like a regular 60 cell and this is the read-only port you cannot write through the sport are you able to see this yes sir so if I am using this as one read write one read memory then I could actually be writing on this word line and also reading from this port can it happen I might be writing into this cell and reading this cell so arduable is also selected and WL is also selected yes so the lower and most of rbl is connected to VX which is dependent on the right so can we uh simultaneously read and write yeah we cannot there are two independent ports now but that is where the new figure of Merit comes into picture if if it so happens that my this boy line is selected and let us say this was Zero so in that case my bit rbl was not supposed to discharge are you with me if this if dlfi was 0 if vlfi was 0 and I selected both void line and a read word line rbl was not supposed to discharge I know hello yes sir yes sir now if my word line is also selected then this 0 goes to VX so this nmos turns partially on so there can be some current it can sync yeah are you able to see this so in this case I am trying to write uh one when there is zero right no I'm not trying to write a one I'm trying to write on some other self in the same row some other cell wanted I wanted to write there this select I'm not doing anything this cell only just turned on so why it turned on because the adjacent cell over here there were three other cells now I wanted to write on this particular cell okay sir let us say so the word line is common it will turn on yes sir so when the word line is on then the zero will go to the x so because bitline is uh blb's BDT that's to vdd yes okay so what happens as soon as it goes to VX this nmos turns partially on so there are some new current lattice now flowing so until now we were only looking at I on and I off and I said that if it is I off then this cell is storing a zero if it is Ion then this cell is storing a 1. that was what I had distinguished till now now what we are saying is that there is also another current which is I partially on which should also be considered as 0. are you able to see this but this uh discharging from RPL when it goes to that is partially on yes yes so for that this this lower and Moss do we have to make it high BT and mass or something else so if you make it a high vtn mass then what happens it will be sorry sorry not leakage if you make it high meaty then it will take more time to turn on then the read operation will be if you make it high VT then then since this is VX uh the I pawn may go down a bit yes but then you do you realize that ion will also reduce huh yes yes so you have to actually see what you were looking at was I want to distinguish initially between 0 and ion now they said no there is something which is IP on yes sir so much that modern is not there actually you have to have a sense amplifier which distinguishes between these two now you're telling me I will increase the VT of the device so what would happen this IP on could go here but this could come here okay yes sir so my margin could actually reduce yeah yes it may come only here also I do not know but it could come here also now potentially yes sir depends on what voltage I am operating at what is the sizing of these two devices depend on so many factors yes so there is no single formula that it has to be hvt making it activity may help it may not help additionally uh you cannot simply make just one device if I make this hvt this also needs to be made actually otherwise do you see there is a DRC between hvt and RBT devices I cannot abut them yes sir I know so in an SRAM cell you simply cannot say oh this device is low VT you will see many academic papers simply doing this oh I will just put one device at low VT no impact on leakage if you do that you cannot make the layout you're not even considering the impact on area then okay yeah just say yourself so we we designed the cells very carefully what is happening here what is this yeah to read write both the ports can do read write so there will be a different cell which would be two read and to write this is a two read write cell okay both ports can do read write operation then there are two ports so this this enables parallel parallel access to the memory from two different processors huh can you think of the new figures of Merit that will come into picture here hello how will you measure the stability over here what will be the worst case for stability yes both the ports on at the same time that is the worst case for stability is that also the worst case for read current foreign what would be the worst case for uh write operation both white line one and wordline two are on with different values of DX yes so we are saying that from one port I'm I'm simply keeping the pre-charge on okay the pre-charge is on but word line two is on and other Port I want to write so what happens over here there is a pre-charge that continuously supplies charge which has to be sunk through the right driver till now you are only designing right driver to discharge this node now your right driver has to sync this additional charge continuously are you able to see this foreign so this dual Port memory cell is is a little more complex to design than the single port memories have design and analyze primarily analyze designer but analyzing it is slightly more complex you have to look at what are the worst cases and then qualify those worst cases so what exactly was the worst case for the right worst case on the right was that see there is a right driver over here it was designed to sync this current only but my other Port also is on and the pre-charge of the bit line is on so there is a vdd that is being supplied to this bit line which goes from the first pass gate and now needs to be discharged through the right driver so both word line one and word line 2 are on and bl1 is equal to 0 through right driver and vl2 is vdd through pre-charge yes that would be the worst case for the right there could be another worst case which could be that oh my uh uh which you will realize when you will do that homework that I had given you last week which could be that let us say this word line one went on okay and then word line two went on and bl or bl1 discharged subsequently so when one of the word line goes on Suppose there was a zero stored here what will it do it will discharge this and it will discharge this also okay now you wanted to store a one here now the bit lines are discharged VX was initially something but it now Falls because the bit lines have the star so it is VX minus when you will do the solve those equations of write analysis and read analysis you will see that as the voltage of VX reduces what happens has the voltage of v x reduces the writability of the cell would degrade um so that could also be another worst case this is slightly more complex you need not bother about it but I just want you to remain open to other worst cases that could be there in this particular cell because of two ports two ports which are asynchronous one port could turn on before the other port okay so uh ideally when we when I have two ports I want to access different bit cells using the sports Arc yeah I am accessing different bitsers only ragas just the adjacent ones mission for one I am addressing it it has zero and with the other Port I'm addressing address one because it is Max 4 they are appearing in the same row"
-cvp7gW8hTw,are now doing is we are looking at how to estimate this read bounce so we do first we just make this uh we just make the structure of the bit cell where we have M1 and M2 the pass gate and the pull down devices the basket and the pull down devices wait foreign devices and we say that the pass gate is in saturation region of operation so we say the equation for we just look at the first order equation over here in this particular analysis as of now and we say okay that is the equation one by one one by two mu and C C Ox W by L of M one into VDS so vgs over here would be vwl minus VX minus v t okay the whole Square so that is the current that you will get from the pass gate at the pass gate is sinking the current that the pull down is sinking is in the linear region so we use the equation as Mu C Ox W by L and we go to VRE the ra minus VSS which is vgs minus VT for the cooldown into VDS for the pull down minus VDS Square by 2. so this is the equation that we use for the current through M2 Now by Kershaw's law we understand that the current from IDs from M1 is equal to IDs from M2 by equating them we get this so what we have what I have done in between is I have simply uh uh uh put CR I have introduced a variable called cell ratio which is a w by L of the pull down divided by the WL of the pass gate over here so when I equate the current from the pull down to the current from the pass gate I get a quadratic equation now since I am not using these uh seconds or second order effects I am getting a quadratic equation as we just discussed you go to more more accurate modeling and you can go to cubic equations and you can also go to fourth order and fifth order equations and depending on which all effects you want to consider in your analysis so since we have a quadratic equation we simply look at what is the a of this quadratic equation what is the B what is the c and we estimate the solution as minus B plus minus b square minus 4 AC by 2A so given this we arrive at uh the solution for v x which is in this kind of a quadratic form are you able to see this this looks complex but you will see that when you just go and solve it it gets solved huh and uh looks cumbersome but not really a big problem there okay so uh I think those of you have already solved it I've already done that those who are those are not done yet you anyway need to do it and it's better that you do it and then we discuss more about if you have any questions then the office hours later uh let us look at what this means in terms of a memory cell huh so how many of you and I'm just curious to understand how many of you those who derived these equations went ahead and saw the impact of changing different voltages changing the front threshold voltages changing different uh variables uh to uh to see what is the impact on VX how many of you were able to do that or did you do that you can put a plus five in the chat window if any one of you did that um no one did it okay so let's let's look at uh yeah good rather so at least you didn't intuitively uh what what we can also do is we can just write this equation as mat in Matlab and and run experiments you can run as many experiments and you will get interesting results so let me take you through a small journey of of the impact of different things on uh on VX value there so let us look at the impact of cell ratio first uh what we are assuming over here is in this first order set of equations that vth of all the devices is 300 millivolts that v r a is equal to V word line is equal to V bit line which is one volts that VD sat is equal to 150 millivolts that's the standard you know 6 KT by Q is what is considered to be vdsat regularly and that we keep a cell ratio of 1.5 so when we do that we notice that VX or V bump comes to be 82 millivolts now if I change the cell ratio to 1. V bump Rises to 119 millivolts so if we bomb prices what happens what what form degrades right stabilities immediately SNM degrades because now you have lesser noise margin there okay now we say we went to a still bigger cell ratio and you see v-bump reduce so significantly so that is why but you know when you go to a cell ratio of three you also increase the area too much and uh not really desirable so we keep a cell ratio between uh one to 1.5 um and and and very high current cells or where we really want low voltage of operation we can go up to 1.75 typically 1.75 is other cell ratio is avoided and I'm everywhere it has a much much larger area impact no you would rather increase on every cell current and increase the pass gate a little more huh so what is the impact of mismatch so in the previous case we had assumed that VTS were all equal now we want to see what what how what happens if the VT or different devices changes we've kept the other things as constant we are using cell ratio is equal to 1.5 in the first case we know that when all the VT of all the devices was 300 millivolts V bump was 82 millivolts now let us say that the pass gate passgate is manufactured fast gate has lower VT and we also say that the sigma the variation of VT the sigma of that is 30 millivolts so three sigma passed a faster pass gate means the VT of the pass gate would be how many millivolts so then we kept the pass gate VT at 210 millivolts we saw that the bump increased to 95 millivolts so this is almost so not exactly the same it is the same Trend as you degrade the cell ratio we made the pass gate fast so the cell ratio in a way effectively reduced and bump increased if simultaneously the pull down was towards slope so what will be the VT of cooldown then again three sigma slope pull down 390. 390. in that case the V Bump went to 109 millivolts and if you say so if you have these two variables you know pass gate VT and pull down VT and you say that one is three sigma away the other is three sigma away then in in essence what we have done is you have created a memory cell which is something like uh four point something Sigma away 4.2 Sigma away three three so because uh in in probability if you realize these are independent variables so they will be orthogonal to each other when we represent them on a graph and the effective location of my point of my memory cell would be around 4.2 Sigma away uh 4.2 Sigma away means I am talking about 10 000 memory cells or something like that order but in reality in reality I would have memory cells which would or a memory array or on-sip memory capacity which would be of the order of megabits so when we have huge memory capacity I need to qualify larger Sigma Sigma extent I need to possibly go up till Six Sigma to go up to Six Sigma I will need to go up to around 4.5 Sigma on these axis okay if I do that if as gate is 4.5 Sigma fast and pull down is 4.5 Sigma slow then with a cell ratio of 1.5 I already have a v bump of 126. do you remember what was the v-bump and cell ratio was one so 119 million 119. so keeping a cell ratio of 1.5 variations have actually exceeded the impact of uh keeping a good sale ratio now if I had kept the cell ratio of 1. we looked at the layout and we saw that in that case the sigma value would reduce so what has happened over here the sigma of the pull down is the VT of the pull down is 450 millivolts 450 no uh 35 435 435 and and the VT of the pass gate is sir 165 165 millivolts because my Sigma was 30 millivolts pair if I use cell ratio to be 1 probably that Sigma would reduce to 20 millivolts and these are just hypothetical numbers as of now if it is reduced to 20 millivolts what happens to this this goes to 390 390. this goes to 210. foreign VT of 290 or 300 210 and 390 you may you may find that V bump is probably the same value or slightly lesser huh at least that on Silicon we observe that SNM was better for cell ratio of 1. simply because mismatch had reduced are you able to see why why uh mismatch and how mismatch impacts uh um stability of a cell any questions so this is for the worst case right if if you reverse like PD fast and PG so it will reduce the volume yeah but uh as a designer what do you want to design do you want to qualify the worst case or you want to be happy about the best case worst case yeah that is why we're talking about the worst case mine um yeah this is the worst case but the worst case has to be qualified now that is why because why I have need to qualify six digit master so uh if you look at the gaussian statistics we will look at the statistics part A little later in the course also but if you look at the gaussian statistics uh you will see that uh uh for getting good yield 99 yield in a in a 16 megabit array you need to qualify around Six Sigma variations foreign we talked about what is the coverage you know if we have uh uh if we if we have a gaussian then within one Sigma there are this cells are covered they are qualified two Sigma uh still larger extent is qualified three sigma still larger extent is qualified remember we discussed this sure so if I go to Six Sigma I qualify more cells and you will notice that Six Sigma means I'm able to get a 99 read on a 16 megabit array how much memory how much cache does your system have does your cell phone have application processor in the cell phone have do you know have you checked L1 cache or L2 cache on your on your application processor just go go on uh go on go and Google the application processor name of your phone and details will be available there thank you so you will see that typically onset memory capacity uh including L1 caches L2 caches and so on of all the cores and of of the remaining part of the chip for digital stocks it is it is actually very high it could be 64 megabits and the most Advanced Technologies today so sex Sigma is the bare minimum that you need to qualify for srams okay so I had a thing to ask them so for example when we have cell ratio of one then by a statistical analysis observation we can see that the web might slightly decrease so but like as a designer I only have this salvation my control the beauty mismatch is not in my control yeah as a designer I should be designing a cell ratio of 1.5 writes because yes so uh only when you are working closely with the technology team which can only happen when you are working with an IDM which and I what is an IDM for example you're working as a designer and uh in a company like St who has its own Fabs and who can't decide what the memory cell is or Samsung or Intel or tfmc then you can do that but if you're working at arm or if you're working at synopsis where you cannot really request an extra extra model for uh for a regular you know for a cell ratio of one kind of a memory cell you cannot really request the uh a specific spice card which has reduced variations models inside it you cannot do this design and even in idms uh this this is usually done by the process teams technology teams themselves a designer would not get to choose a cell ratio of one until the technology teams is convinced that yes they can manage it they will not open the possibility for the design team but you should know so so as we are getting the V bump similar to the celebration of 1.5 for the cell ratio of 1. after the considering the variations no with the cell ratio of 1.5 I am ending up with the same V bump or Worse bump than what I would have got with the cell ratio of 1 when variations are considered yes 1.5 and cell ratio 1. with mismatch and one without mismatch yet okay okay okay sir understood that the cell ratio of one if you put mismatch you will see there is uh there is a loss of bump there also okay okay so okay so what is the impact of Supply voltage again now we say okay we are going to that worst case and our setting that this mismatch is already built in that cell ratio is 1.5 we decide as this uh the array is equal to V bit line is equal to V by line is equal to one volt so we found that the bump was 126. if I increase the voltage the pump reduces a bit if I reduce the voltage the bump increases so as I go to lower Supply voltages my static noise margin degrades very significantly okay so in this slide we are basically looking at the impact of varr right because uh yeah as of now we have kept same voltage on the word line the bit line and the array so but like if we reduce the V error foreign we will see that the pump will increase but if we also reduce about independently as they suppose we reduce bit line then that has helped the stability so I mean like because let us look like that let us look at word line and then we will also look at bit line so what happens in wordline voltage is changed what happens then let us look at that point seven case now everything was at 0.7 my V bump was 162. I reduced wordline voltage my V Bump went to 118. um I reduced it further V bomb went further lower so what do we mean by this that word line under a drive is a read assist scheme will help us to improve stability of the cell but what is the impact what is the penalty of oil and Enterprise quickly yes the cell current goes for a toss now the basket does not have sufficient strength to sink any current my cell current actually goes for a toss my memory speed goes for a toss you're able to see this so one thing I need to answer that while reading we are looking at two kind of uh things one is the cell current and one is stability so when I say the reader system so I would be basically targeting the stability thing VX not necessarily raghav so you may use two assist schemes in parallel one ss schemes recovered stability the other recovers cell current but if you go on my Google Scholar page you will see one of my papers where we actually use multiple readers schemes in parallel to do exactly this okay okay if if if so for example I'm able to do something and improve any of the parameters that is the current causes stability I would call it as a leadership yeah it is assisting otherwise I would have to use larger devices now so anything that I am using to avoid increasing area by electrically modifying stuff that is assist scheme okay okay to me it seems to be contradictory because both can achieve but I will look into something now what is the impact of VSS so Avita we were always considering that it was ground now let us say VSS is negative so you will see bump goes lower if VSS positive the month would go still higher so negative VSS could also be an asset scheme that you could use in memory RF for improving stability what happens when you when you have a negative VSS what happens to the read current there increasing the Heat current would also increase see essentially all that you are saying is if V bump is reducing then the VDS across the pass gate has increased so read current would improve huh yes sir okay can you please repeat the statement so if I have reduced this uh V bump reduce the level of VX what happens to the rate current what happens to the voltage across the volts the brain and source of the pass gate the difference yeah I know it increases what happens to the VTS that also increases huh so we see an improvement in read current okay so sir I have a question in that yes uh so again we go back to the previously for VSS so when I was doing this I I coded the equations in Python and then I was entering the values so for for like minus zero point even zero one VSS I was getting a very negative value so sir if my value is essentially let's say for Viva V bump I'm getting in the order of 0.007 something and then for having a negative yes I get minus 0.5 so in magnitude something has gone wrong in your equation anymore yeah maybe because of certain constants or something but but I just want some sort of an intuition like having a negative value which is really high in magnitude does that really help us like do we say that we have actually managed to reduce vx to a better stable point if we are getting a negative value which has a higher magnitude than a positive value uh yeah see so it is look at it like this if it was minus 20 millivolts minus 50 millivolts minus 70 millivolts at the VX now to be able to cause a flip you will have to bring in more noise now right let's go that that helps the problem is something else here when we go to these negative voltage levels uh then while over here I am doing the analysis at 0.7 suppose I have I have to generate this negative voltage at 0.7 volts how would I generate that I would do some charge coupling I would put in some capacitors I would toggle those capacitors in a particular way so that so we'll look into this detail later also we will generate some negative voltage on the on the on the Fly take care uh as I go to higher voltage let us say 1.0 volts if at 0.7 volts I generated minus 0.2 volts at 1.0 volts what is the kind of voltage I would generate through those same couplings but 0.3 volts 50 higher point seven seven the negative voltage would also increase so now what is the voltage across the different devices the voltage is 1.0 which is on the gate let us say and minus 0.3 which is on the source or drain so across the gate oxide the voltage now is 1 1.3 volts as you increase the voltage across the gate oxide the reliability of the device starts to degrade that is what actually limits what kind of negative voltages we can use inside a memory so VSS is on the source of the pull down right yeah so so having um I mean what I meant to ask is that V bump is equal to 37 millivolts and V bump is equal to minus 55 millivolts which is the better case out of these two for stability so that I already answered minus 55 is better uh so even though it it in a sense that we are having a more noisy voltage at VX point because magnitude y still 55 millivolts is away from zero so are we just comparing which is big like what is the voltage drop across the why did you use the term noisy so much okay that is the wrong assumption it is just just for ease that we say that this particular voltage is 0 volts do you realize the entire chip for the entire chip I may keep VSS at 12 volts and uh we ready at 13.2 volts and my my circuit will work perfectly fine yes so all this is uh this is this is just about using something as a reference voltage okay no VSS is just about a reference voltage when you you just for your ease of calculations you want to keep that reference or you want to call that reference voltage as zero okay are you able to see this yes otherwise the entire clip is floating somewhere we don't even know we are doing all this analysis with the reference of BSS now what we said is I will take it lower than that reference I can do that Hannah yes sir yes that is what it is sir yes uh in this impact of virtual level I am a little confused and I'm seeing two different things happening one is that b bump is decreasing so I can say that it is kind of a stability kind of point of view it is good also but as we said that the video is also increasing from a cell current is also increasing yes okay now the question is uh what is the capacitance of VSS can you really take it to minus two volts what kind of power consumption will be what will be the power consumption just to take it to minus 0.2 volts the capacitance I can begin with the point you are not keeping it at minus 0.2 volts always now only during read Cycles you will take it to minus 0.2 volts the VA system yeah VSS so there is some charging or discharging that you need to do okay that is power consumption okay so you need to estimate what is the kind of power consumption or what is the kind of overhead that you are paying for any assist scheme okay so yes if you have a very controlled VSS a very small capacitance on the V assist very small in terms of not phentophilots but yeah not a huge capacitance on VSS then you can do this it may be power efficient if not then taking the entire memory array in every read cycle to minus 0.2 volts it's a huge power consumption so you may not be able to use the technique why can't we put it to minus point to all the time just let me finish just let me finish so you will notice that in in academic literature you will see many people are proposing such funny schemes without really talking about how to implement VSS in a manner not the voltage of uh or the capacitance of the SS is low enough okay so Faisal was asking why can't we keep VSS at minus 0.2 volts always so then that is almost as good as operating the memory at 0.9 volts then why generate a negative voltage in the first place just use 0.9 volts if VSS was always minus 0.2 then it is as good as operating at 0.9 volts no that is the kind of power consumption you are switching every capacitance between minus 0.2 and 0.7 so why then call this reference as minus 0.2 because the reference as 0 and call the vdd as Point time that is the power consumption you're talking about are you able to see this sizer uh actually I didn't understand sir so why do you want to go to lower Supply voltages let's start with this basic question lower Supply to reduce leakage sir actually um right here I am worried about leakage when I'm doing read and write no sir over here the bump voltage gets is getting reduced oh so you think I will reduce voltage of operation for reducing bump voltage in a memory cell so how to increase BTS why do we do voltage scaling remember we talked about Dynamic voltage and frequency scaling why do we do that so power power efficiency because I want to modulate my depending on frequency operation I want to say we saw that when the load is not very high let me not consume too much power let me operate slower and let me go to a lower voltage so the entire attempt of going to lower voltage was to reduce power consumption am I right then what's the point in going to lower voltage so now you are telling me now you're telling me that always keep VSS at minus 0.2 so what is the voltage swing that you are having on all the capacitors now instead of 0 to 1.9 they are swinging between minus 0.2 to 0.7 is the power consumption reducing no sir no sir then why this is not even a scheme then yes sir you only do this in the read cycle only in that limited part where you are doing read operation everywhere else everything is 0.7 only where you're doing read operation there you have done this uh voltage boost or negative VSS and you recover the performance you recover the functionality everywhere else it is lower power that is when you will gain some benefit that is where it is called as an assist scheme okay yes sir thank you yeah so now if we add mismatch or look at mismatch in the presence of uh you know High VT devices let us say a memory cell we want to use a high VT memory cell so that leakage is lower then you will see the bump would increase further hmm memory RS if you remember even the examples that we have done in the DVD course memory arrays are usually designed in with high VT devices so when we use a high VT device we see bump increases further okay in this I would be needing more hair streams with the VT kind of IBT prices yeah so high weighted devices you you see that the effect of mismatch increases still further the impact of mismatch is still higher okay so,https://www.youtube.com/watch?v=-cvp7gW8hTw,"Link: https://www.youtube.com/watch?v=-cvp7gW8hTw
Transcript: are now doing is we are looking at how to estimate this read bounce so we do first we just make this uh we just make the structure of the bit cell where we have M1 and M2 the pass gate and the pull down devices the basket and the pull down devices wait foreign devices and we say that the pass gate is in saturation region of operation so we say the equation for we just look at the first order equation over here in this particular analysis as of now and we say okay that is the equation one by one one by two mu and C C Ox W by L of M one into VDS so vgs over here would be vwl minus VX minus v t okay the whole Square so that is the current that you will get from the pass gate at the pass gate is sinking the current that the pull down is sinking is in the linear region so we use the equation as Mu C Ox W by L and we go to VRE the ra minus VSS which is vgs minus VT for the cooldown into VDS for the pull down minus VDS Square by 2. so this is the equation that we use for the current through M2 Now by Kershaw's law we understand that the current from IDs from M1 is equal to IDs from M2 by equating them we get this so what we have what I have done in between is I have simply uh uh uh put CR I have introduced a variable called cell ratio which is a w by L of the pull down divided by the WL of the pass gate over here so when I equate the current from the pull down to the current from the pass gate I get a quadratic equation now since I am not using these uh seconds or second order effects I am getting a quadratic equation as we just discussed you go to more more accurate modeling and you can go to cubic equations and you can also go to fourth order and fifth order equations and depending on which all effects you want to consider in your analysis so since we have a quadratic equation we simply look at what is the a of this quadratic equation what is the B what is the c and we estimate the solution as minus B plus minus b square minus 4 AC by 2A so given this we arrive at uh the solution for v x which is in this kind of a quadratic form are you able to see this this looks complex but you will see that when you just go and solve it it gets solved huh and uh looks cumbersome but not really a big problem there okay so uh I think those of you have already solved it I've already done that those who are those are not done yet you anyway need to do it and it's better that you do it and then we discuss more about if you have any questions then the office hours later uh let us look at what this means in terms of a memory cell huh so how many of you and I'm just curious to understand how many of you those who derived these equations went ahead and saw the impact of changing different voltages changing the front threshold voltages changing different uh variables uh to uh to see what is the impact on VX how many of you were able to do that or did you do that you can put a plus five in the chat window if any one of you did that um no one did it okay so let's let's look at uh yeah good rather so at least you didn't intuitively uh what what we can also do is we can just write this equation as mat in Matlab and and run experiments you can run as many experiments and you will get interesting results so let me take you through a small journey of of the impact of different things on uh on VX value there so let us look at the impact of cell ratio first uh what we are assuming over here is in this first order set of equations that vth of all the devices is 300 millivolts that v r a is equal to V word line is equal to V bit line which is one volts that VD sat is equal to 150 millivolts that's the standard you know 6 KT by Q is what is considered to be vdsat regularly and that we keep a cell ratio of 1.5 so when we do that we notice that VX or V bump comes to be 82 millivolts now if I change the cell ratio to 1. V bump Rises to 119 millivolts so if we bomb prices what happens what what form degrades right stabilities immediately SNM degrades because now you have lesser noise margin there okay now we say we went to a still bigger cell ratio and you see v-bump reduce so significantly so that is why but you know when you go to a cell ratio of three you also increase the area too much and uh not really desirable so we keep a cell ratio between uh one to 1.5 um and and and very high current cells or where we really want low voltage of operation we can go up to 1.75 typically 1.75 is other cell ratio is avoided and I'm everywhere it has a much much larger area impact no you would rather increase on every cell current and increase the pass gate a little more huh so what is the impact of mismatch so in the previous case we had assumed that VTS were all equal now we want to see what what how what happens if the VT or different devices changes we've kept the other things as constant we are using cell ratio is equal to 1.5 in the first case we know that when all the VT of all the devices was 300 millivolts V bump was 82 millivolts now let us say that the pass gate passgate is manufactured fast gate has lower VT and we also say that the sigma the variation of VT the sigma of that is 30 millivolts so three sigma passed a faster pass gate means the VT of the pass gate would be how many millivolts so then we kept the pass gate VT at 210 millivolts we saw that the bump increased to 95 millivolts so this is almost so not exactly the same it is the same Trend as you degrade the cell ratio we made the pass gate fast so the cell ratio in a way effectively reduced and bump increased if simultaneously the pull down was towards slope so what will be the VT of cooldown then again three sigma slope pull down 390. 390. in that case the V Bump went to 109 millivolts and if you say so if you have these two variables you know pass gate VT and pull down VT and you say that one is three sigma away the other is three sigma away then in in essence what we have done is you have created a memory cell which is something like uh four point something Sigma away 4.2 Sigma away three three so because uh in in probability if you realize these are independent variables so they will be orthogonal to each other when we represent them on a graph and the effective location of my point of my memory cell would be around 4.2 Sigma away uh 4.2 Sigma away means I am talking about 10 000 memory cells or something like that order but in reality in reality I would have memory cells which would or a memory array or on-sip memory capacity which would be of the order of megabits so when we have huge memory capacity I need to qualify larger Sigma Sigma extent I need to possibly go up till Six Sigma to go up to Six Sigma I will need to go up to around 4.5 Sigma on these axis okay if I do that if as gate is 4.5 Sigma fast and pull down is 4.5 Sigma slow then with a cell ratio of 1.5 I already have a v bump of 126. do you remember what was the v-bump and cell ratio was one so 119 million 119. so keeping a cell ratio of 1.5 variations have actually exceeded the impact of uh keeping a good sale ratio now if I had kept the cell ratio of 1. we looked at the layout and we saw that in that case the sigma value would reduce so what has happened over here the sigma of the pull down is the VT of the pull down is 450 millivolts 450 no uh 35 435 435 and and the VT of the pass gate is sir 165 165 millivolts because my Sigma was 30 millivolts pair if I use cell ratio to be 1 probably that Sigma would reduce to 20 millivolts and these are just hypothetical numbers as of now if it is reduced to 20 millivolts what happens to this this goes to 390 390. this goes to 210. foreign VT of 290 or 300 210 and 390 you may you may find that V bump is probably the same value or slightly lesser huh at least that on Silicon we observe that SNM was better for cell ratio of 1. simply because mismatch had reduced are you able to see why why uh mismatch and how mismatch impacts uh um stability of a cell any questions so this is for the worst case right if if you reverse like PD fast and PG so it will reduce the volume yeah but uh as a designer what do you want to design do you want to qualify the worst case or you want to be happy about the best case worst case yeah that is why we're talking about the worst case mine um yeah this is the worst case but the worst case has to be qualified now that is why because why I have need to qualify six digit master so uh if you look at the gaussian statistics we will look at the statistics part A little later in the course also but if you look at the gaussian statistics uh you will see that uh uh for getting good yield 99 yield in a in a 16 megabit array you need to qualify around Six Sigma variations foreign we talked about what is the coverage you know if we have uh uh if we if we have a gaussian then within one Sigma there are this cells are covered they are qualified two Sigma uh still larger extent is qualified three sigma still larger extent is qualified remember we discussed this sure so if I go to Six Sigma I qualify more cells and you will notice that Six Sigma means I'm able to get a 99 read on a 16 megabit array how much memory how much cache does your system have does your cell phone have application processor in the cell phone have do you know have you checked L1 cache or L2 cache on your on your application processor just go go on uh go on go and Google the application processor name of your phone and details will be available there thank you so you will see that typically onset memory capacity uh including L1 caches L2 caches and so on of all the cores and of of the remaining part of the chip for digital stocks it is it is actually very high it could be 64 megabits and the most Advanced Technologies today so sex Sigma is the bare minimum that you need to qualify for srams okay so I had a thing to ask them so for example when we have cell ratio of one then by a statistical analysis observation we can see that the web might slightly decrease so but like as a designer I only have this salvation my control the beauty mismatch is not in my control yeah as a designer I should be designing a cell ratio of 1.5 writes because yes so uh only when you are working closely with the technology team which can only happen when you are working with an IDM which and I what is an IDM for example you're working as a designer and uh in a company like St who has its own Fabs and who can't decide what the memory cell is or Samsung or Intel or tfmc then you can do that but if you're working at arm or if you're working at synopsis where you cannot really request an extra extra model for uh for a regular you know for a cell ratio of one kind of a memory cell you cannot really request the uh a specific spice card which has reduced variations models inside it you cannot do this design and even in idms uh this this is usually done by the process teams technology teams themselves a designer would not get to choose a cell ratio of one until the technology teams is convinced that yes they can manage it they will not open the possibility for the design team but you should know so so as we are getting the V bump similar to the celebration of 1.5 for the cell ratio of 1. after the considering the variations no with the cell ratio of 1.5 I am ending up with the same V bump or Worse bump than what I would have got with the cell ratio of 1 when variations are considered yes 1.5 and cell ratio 1. with mismatch and one without mismatch yet okay okay okay sir understood that the cell ratio of one if you put mismatch you will see there is uh there is a loss of bump there also okay okay so okay so what is the impact of Supply voltage again now we say okay we are going to that worst case and our setting that this mismatch is already built in that cell ratio is 1.5 we decide as this uh the array is equal to V bit line is equal to V by line is equal to one volt so we found that the bump was 126. if I increase the voltage the pump reduces a bit if I reduce the voltage the bump increases so as I go to lower Supply voltages my static noise margin degrades very significantly okay so in this slide we are basically looking at the impact of varr right because uh yeah as of now we have kept same voltage on the word line the bit line and the array so but like if we reduce the V error foreign we will see that the pump will increase but if we also reduce about independently as they suppose we reduce bit line then that has helped the stability so I mean like because let us look like that let us look at word line and then we will also look at bit line so what happens in wordline voltage is changed what happens then let us look at that point seven case now everything was at 0.7 my V bump was 162. I reduced wordline voltage my V Bump went to 118. um I reduced it further V bomb went further lower so what do we mean by this that word line under a drive is a read assist scheme will help us to improve stability of the cell but what is the impact what is the penalty of oil and Enterprise quickly yes the cell current goes for a toss now the basket does not have sufficient strength to sink any current my cell current actually goes for a toss my memory speed goes for a toss you're able to see this so one thing I need to answer that while reading we are looking at two kind of uh things one is the cell current and one is stability so when I say the reader system so I would be basically targeting the stability thing VX not necessarily raghav so you may use two assist schemes in parallel one ss schemes recovered stability the other recovers cell current but if you go on my Google Scholar page you will see one of my papers where we actually use multiple readers schemes in parallel to do exactly this okay okay if if if so for example I'm able to do something and improve any of the parameters that is the current causes stability I would call it as a leadership yeah it is assisting otherwise I would have to use larger devices now so anything that I am using to avoid increasing area by electrically modifying stuff that is assist scheme okay okay to me it seems to be contradictory because both can achieve but I will look into something now what is the impact of VSS so Avita we were always considering that it was ground now let us say VSS is negative so you will see bump goes lower if VSS positive the month would go still higher so negative VSS could also be an asset scheme that you could use in memory RF for improving stability what happens when you when you have a negative VSS what happens to the read current there increasing the Heat current would also increase see essentially all that you are saying is if V bump is reducing then the VDS across the pass gate has increased so read current would improve huh yes sir okay can you please repeat the statement so if I have reduced this uh V bump reduce the level of VX what happens to the rate current what happens to the voltage across the volts the brain and source of the pass gate the difference yeah I know it increases what happens to the VTS that also increases huh so we see an improvement in read current okay so sir I have a question in that yes uh so again we go back to the previously for VSS so when I was doing this I I coded the equations in Python and then I was entering the values so for for like minus zero point even zero one VSS I was getting a very negative value so sir if my value is essentially let's say for Viva V bump I'm getting in the order of 0.007 something and then for having a negative yes I get minus 0.5 so in magnitude something has gone wrong in your equation anymore yeah maybe because of certain constants or something but but I just want some sort of an intuition like having a negative value which is really high in magnitude does that really help us like do we say that we have actually managed to reduce vx to a better stable point if we are getting a negative value which has a higher magnitude than a positive value uh yeah see so it is look at it like this if it was minus 20 millivolts minus 50 millivolts minus 70 millivolts at the VX now to be able to cause a flip you will have to bring in more noise now right let's go that that helps the problem is something else here when we go to these negative voltage levels uh then while over here I am doing the analysis at 0.7 suppose I have I have to generate this negative 
voltage at 0.7 volts how would I generate that I would do some charge coupling I would put in some capacitors I would toggle those capacitors in a particular way so that so we'll look into this detail later also we will generate some negative voltage on the on the on the Fly take care uh as I go to higher voltage let us say 1.0 volts if at 0.7 volts I generated minus 0.2 volts at 1.0 volts what is the kind of voltage I would generate through those same couplings but 0.3 volts 50 higher point seven seven the negative voltage would also increase so now what is the voltage across the different devices the voltage is 1.0 which is on the gate let us say and minus 0.3 which is on the source or drain so across the gate oxide the voltage now is 1 1.3 volts as you increase the voltage across the gate oxide the reliability of the device starts to degrade that is what actually limits what kind of negative voltages we can use inside a memory so VSS is on the source of the pull down right yeah so so having um I mean what I meant to ask is that V bump is equal to 37 millivolts and V bump is equal to minus 55 millivolts which is the better case out of these two for stability so that I already answered minus 55 is better uh so even though it it in a sense that we are having a more noisy voltage at VX point because magnitude y still 55 millivolts is away from zero so are we just comparing which is big like what is the voltage drop across the why did you use the term noisy so much okay that is the wrong assumption it is just just for ease that we say that this particular voltage is 0 volts do you realize the entire chip for the entire chip I may keep VSS at 12 volts and uh we ready at 13.2 volts and my my circuit will work perfectly fine yes so all this is uh this is this is just about using something as a reference voltage okay no VSS is just about a reference voltage when you you just for your ease of calculations you want to keep that reference or you want to call that reference voltage as zero okay are you able to see this yes otherwise the entire clip is floating somewhere we don't even know we are doing all this analysis with the reference of BSS now what we said is I will take it lower than that reference I can do that Hannah yes sir yes that is what it is sir yes uh in this impact of virtual level I am a little confused and I'm seeing two different things happening one is that b bump is decreasing so I can say that it is kind of a stability kind of point of view it is good also but as we said that the video is also increasing from a cell current is also increasing yes okay now the question is uh what is the capacitance of VSS can you really take it to minus two volts what kind of power consumption will be what will be the power consumption just to take it to minus 0.2 volts the capacitance I can begin with the point you are not keeping it at minus 0.2 volts always now only during read Cycles you will take it to minus 0.2 volts the VA system yeah VSS so there is some charging or discharging that you need to do okay that is power consumption okay so you need to estimate what is the kind of power consumption or what is the kind of overhead that you are paying for any assist scheme okay so yes if you have a very controlled VSS a very small capacitance on the V assist very small in terms of not phentophilots but yeah not a huge capacitance on VSS then you can do this it may be power efficient if not then taking the entire memory array in every read cycle to minus 0.2 volts it's a huge power consumption so you may not be able to use the technique why can't we put it to minus point to all the time just let me finish just let me finish so you will notice that in in academic literature you will see many people are proposing such funny schemes without really talking about how to implement VSS in a manner not the voltage of uh or the capacitance of the SS is low enough okay so Faisal was asking why can't we keep VSS at minus 0.2 volts always so then that is almost as good as operating the memory at 0.9 volts then why generate a negative voltage in the first place just use 0.9 volts if VSS was always minus 0.2 then it is as good as operating at 0.9 volts no that is the kind of power consumption you are switching every capacitance between minus 0.2 and 0.7 so why then call this reference as minus 0.2 because the reference as 0 and call the vdd as Point time that is the power consumption you're talking about are you able to see this sizer uh actually I didn't understand sir so why do you want to go to lower Supply voltages let's start with this basic question lower Supply to reduce leakage sir actually um right here I am worried about leakage when I'm doing read and write no sir over here the bump voltage gets is getting reduced oh so you think I will reduce voltage of operation for reducing bump voltage in a memory cell so how to increase BTS why do we do voltage scaling remember we talked about Dynamic voltage and frequency scaling why do we do that so power power efficiency because I want to modulate my depending on frequency operation I want to say we saw that when the load is not very high let me not consume too much power let me operate slower and let me go to a lower voltage so the entire attempt of going to lower voltage was to reduce power consumption am I right then what's the point in going to lower voltage so now you are telling me now you're telling me that always keep VSS at minus 0.2 so what is the voltage swing that you are having on all the capacitors now instead of 0 to 1.9 they are swinging between minus 0.2 to 0.7 is the power consumption reducing no sir no sir then why this is not even a scheme then yes sir you only do this in the read cycle only in that limited part where you are doing read operation everywhere else everything is 0.7 only where you're doing read operation there you have done this uh voltage boost or negative VSS and you recover the performance you recover the functionality everywhere else it is lower power that is when you will gain some benefit that is where it is called as an assist scheme okay yes sir thank you yeah so now if we add mismatch or look at mismatch in the presence of uh you know High VT devices let us say a memory cell we want to use a high VT memory cell so that leakage is lower then you will see the bump would increase further hmm memory RS if you remember even the examples that we have done in the DVD course memory arrays are usually designed in with high VT devices so when we use a high VT device we see bump increases further okay in this I would be needing more hair streams with the VT kind of IBT prices yeah so high weighted devices you you see that the effect of mismatch increases still further the impact of mismatch is still higher okay so"
Rywz01X1QE4,early look at the right estimation what happens in the right operation so we looked at the read operation first now we look at the right operation over here we we make these four transistors there M1 M2 are already there where we say VX has appeared and we also now add the other side where where 0 is to be written you know we it needs to be discharged now you say a good write operation has happened when V int has gone as close to 0 as possible are you with me this operation has happened when we comes to as close to 0 as possible okay so now again we simply do the kirchhoff's law so we simply apply kirchhoff's law we say the current coming from M4 has to be sunk by the right driver and the the current going from M3 has to kind of also discharge the end hmm so IDs M4 and IDs M3 equations are written we Define just like we had defined cell ratio there we Define pull-up ratio there huh the size of the uh the size of the M4 is the pull up upon the size of the pass gate and we again arrive at this quadratic equation when we solve the quadratic equation this is what we get okay so again those of you have not done this analysis I would strongly recommend that you please do this I'm I'm not solving this for you I'm just showing it to you so that you can do this at leisure and get a better understanding of what happens during the right operation so now with that equation we again do the same kind of variations what is the impact of pull up ratio and you will see that when pull up ratio is very high or when pull up ratio goes High then vient Rises it means I'm not really able to write into the memory cell when I keep a still weaker pull-up ratio my V end goes till lower we keep a polar pressure of 0.5 for further analysis and now introduce mismatch you will see that with mismatch as expected so what we have done we have said that pass gate is slower see what did we want we wanted we wanted past gate to be faster Hannah password is faster means pull up ratio is small so for the worst case analysis in the presence of mismatch we put pass gate at three sigma slope we see V in rises from 30 to 40. you increase the VT of the pass gate and you also put uh increase the VT of the change the VT of the uh pull up and you see this goes still further so the system is degrading okay in terms of Supply voltage what do you expect as I reduce the supply voltage with writability improve or degrade so it should improve so it should improve why so uh if I'm lowering the supply then the pull-up is becoming weak sir and if my puller becomes big then my writability of zero then bro so if I reduce the supply voltage you will see it degrades because my basket now also seems lesser current saturation region pull-up is still in saturation region basket is in linear region as you reduce the supply voltage pass gate goes into still more resistive mode pull up is still operating in saturation so my V end actually increases you see V inters lowest when vdd was one volts even at 1.1 volt we integrated so the trend that you're talking about that trend is right when you're talking of going to a higher voltage but as you go to lower voltage the second parameter which is the current being sunk from the pass gate that comes into picture and that degrades the sex study okay so I mean I'm not able to get it that but with increase also I am integrating so yes that's the that's the challenge of uh non-cmas ratioed kind of a design you could experience that stuff so when I'm seeing the supply voltage I mean to supply this all the World Language you are reading everything here so sir here though my pull up will become weaker but my interview uh the reduction in the past gate is more otherwise dominating here it is because see the pass gate was never operating at its full strength now it was a linear region yes sir yes sir okay so that is what you need to see what is a linear region what is an saturation region so the impact is like this yeah so what happens when I simply lower array is applied do not lower the bit line and word line so you see that was 63 I lowered just the array I saw an improvement now this is where pass gate has not degraded now yes sir this is where only the pmos has degraded are you able to see this since we are not wearing the word line yeah okay so vdd lower end vdd lowering but not lowering word line and bit line is a right assists technique what goes for a task when we do this quickly right time Hannah because your pull up has become so weak now right time goes for a tough you're able to write but it takes much longer um okay uh now let us look at the impact of word line so again as the word line is raised so I have kept array and bit9 both at 0.7 I simply raise the word line um and you will see I see an improvement so wordline lowering was a read assist scheme Wireline raising is a right assist scheme so if you are in Max 4 can you use wordline raising as a right assist scheme so it will it will have some issues yes because wordline raising would degrade the stability of the adjacent memory cells you cannot really use void line raising or void line boost as a write asses came for higher mux configurations yeah you can use it in Max bundo so the paper that I was mentioning to you about where we use multiple read and write this schemes in parallel to go to very low voltages in that paper you will see that we are doing something of this sort we are using wordline boost we have a physical Max 4 but we have an electrical Max file so just go and check out that paper how it's a very interesting paper okay now let's look at an impact of VSS so you will see that when VSS is raised what happens when VSS is raised VX Rises as DX Rises my writability improves the relativity so some of my activities between me writability improved now because this voltage lowered from 63 to 53 oh yes yes writability improved but when I raise the VSS what degrades the the stability of the cell degrades so again if I am able to change VSS see the layout that we just saw how was the VSS there the layout that we just saw we said VSS is going you know is is connected on these uh uh two adjacent memory cells have the same VSS and there is a metal four which would connect to this VSS so if I change the supply of of a particular metal rail huh the adjacent cell Supply also degrades I need to take care of what happens to the stability of this particular cell now are you able to see this property even the stability of that shall also will be great right because see you are writing into this memory cell so either case stability degrading is what you want yeah it is adjacent cell which we are worried about it which was in read mode now what happens when we use hvt devices and stuff like that we see as we go to hvt devices uh the V end actually increases this is a typo I will correct this later okay so writability degrades so high weighted High VT memory errors are used on a regular basis but when you use ivt memory RS both readability and writability degrade okay actually this was a v-bump this was slide to copy it from the read part so that is where it has gone I will correct this thanks for pointing out okay so please do this analysis if you have written the equations I found the equations already for yourself just go ahead and extend it further if you have not done that yet please make those equations and make this short program you know you could use my python or you could you do it in Matlab do whatever just do this and see for yourself how different variables as they change how they impact the uh writability and readability of a memory cell when you do this play you know when you play like this you will have a much better understanding of Designing the memory cell so when you will enter into your project you will be able to work on the project much better if you don't do this you will struggle at the time of doing your project so better you do it okay so now we come to,https://www.youtube.com/watch?v=Rywz01X1QE4,"Link: https://www.youtube.com/watch?v=Rywz01X1QE4
Transcript: early look at the right estimation what happens in the right operation so we looked at the read operation first now we look at the right operation over here we we make these four transistors there M1 M2 are already there where we say VX has appeared and we also now add the other side where where 0 is to be written you know we it needs to be discharged now you say a good write operation has happened when V int has gone as close to 0 as possible are you with me this operation has happened when we comes to as close to 0 as possible okay so now again we simply do the kirchhoff's law so we simply apply kirchhoff's law we say the current coming from M4 has to be sunk by the right driver and the the current going from M3 has to kind of also discharge the end hmm so IDs M4 and IDs M3 equations are written we Define just like we had defined cell ratio there we Define pull-up ratio there huh the size of the uh the size of the M4 is the pull up upon the size of the pass gate and we again arrive at this quadratic equation when we solve the quadratic equation this is what we get okay so again those of you have not done this analysis I would strongly recommend that you please do this I'm I'm not solving this for you I'm just showing it to you so that you can do this at leisure and get a better understanding of what happens during the right operation so now with that equation we again do the same kind of variations what is the impact of pull up ratio and you will see that when pull up ratio is very high or when pull up ratio goes High then vient Rises it means I'm not really able to write into the memory cell when I keep a still weaker pull-up ratio my V end goes till lower we keep a polar pressure of 0.5 for further analysis and now introduce mismatch you will see that with mismatch as expected so what we have done we have said that pass gate is slower see what did we want we wanted we wanted past gate to be faster Hannah password is faster means pull up ratio is small so for the worst case analysis in the presence of mismatch we put pass gate at three sigma slope we see V in rises from 30 to 40. you increase the VT of the pass gate and you also put uh increase the VT of the change the VT of the uh pull up and you see this goes still further so the system is degrading okay in terms of Supply voltage what do you expect as I reduce the supply voltage with writability improve or degrade so it should improve so it should improve why so uh if I'm lowering the supply then the pull-up is becoming weak sir and if my puller becomes big then my writability of zero then bro so if I reduce the supply voltage you will see it degrades because my basket now also seems lesser current saturation region pull-up is still in saturation region basket is in linear region as you reduce the supply voltage pass gate goes into still more resistive mode pull up is still operating in saturation so my V end actually increases you see V inters lowest when vdd was one volts even at 1.1 volt we integrated so the trend that you're talking about that trend is right when you're talking of going to a higher voltage but as you go to lower voltage the second parameter which is the current being sunk from the pass gate that comes into picture and that degrades the sex study okay so I mean I'm not able to get it that but with increase also I am integrating so yes that's the that's the challenge of uh non-cmas ratioed kind of a design you could experience that stuff so when I'm seeing the supply voltage I mean to supply this all the World Language you are reading everything here so sir here though my pull up will become weaker but my interview uh the reduction in the past gate is more otherwise dominating here it is because see the pass gate was never operating at its full strength now it was a linear region yes sir yes sir okay so that is what you need to see what is a linear region what is an saturation region so the impact is like this yeah so what happens when I simply lower array is applied do not lower the bit line and word line so you see that was 63 I lowered just the array I saw an improvement now this is where pass gate has not degraded now yes sir this is where only the pmos has degraded are you able to see this since we are not wearing the word line yeah okay so vdd lower end vdd lowering but not lowering word line and bit line is a right assists technique what goes for a task when we do this quickly right time Hannah because your pull up has become so weak now right time goes for a tough you're able to write but it takes much longer um okay uh now let us look at the impact of word line so again as the word line is raised so I have kept array and bit9 both at 0.7 I simply raise the word line um and you will see I see an improvement so wordline lowering was a read assist scheme Wireline raising is a right assist scheme so if you are in Max 4 can you use wordline raising as a right assist scheme so it will it will have some issues yes because wordline raising would degrade the stability of the adjacent memory cells you cannot really use void line raising or void line boost as a write asses came for higher mux configurations yeah you can use it in Max bundo so the paper that I was mentioning to you about where we use multiple read and write this schemes in parallel to go to very low voltages in that paper you will see that we are doing something of this sort we are using wordline boost we have a physical Max 4 but we have an electrical Max file so just go and check out that paper how it's a very interesting paper okay now let's look at an impact of VSS so you will see that when VSS is raised what happens when VSS is raised VX Rises as DX Rises my writability improves the relativity so some of my activities between me writability improved now because this voltage lowered from 63 to 53 oh yes yes writability improved but when I raise the VSS what degrades the the stability of the cell degrades so again if I am able to change VSS see the layout that we just saw how was the VSS there the layout that we just saw we said VSS is going you know is is connected on these uh uh two adjacent memory cells have the same VSS and there is a metal four which would connect to this VSS so if I change the supply of of a particular metal rail huh the adjacent cell Supply also degrades I need to take care of what happens to the stability of this particular cell now are you able to see this property even the stability of that shall also will be great right because see you are writing into this memory cell so either case stability degrading is what you want yeah it is adjacent cell which we are worried about it which was in read mode now what happens when we use hvt devices and stuff like that we see as we go to hvt devices uh the V end actually increases this is a typo I will correct this later okay so writability degrades so high weighted High VT memory errors are used on a regular basis but when you use ivt memory RS both readability and writability degrade okay actually this was a v-bump this was slide to copy it from the read part so that is where it has gone I will correct this thanks for pointing out okay so please do this analysis if you have written the equations I found the equations already for yourself just go ahead and extend it further if you have not done that yet please make those equations and make this short program you know you could use my python or you could you do it in Matlab do whatever just do this and see for yourself how different variables as they change how they impact the uh writability and readability of a memory cell when you do this play you know when you play like this you will have a much better understanding of Designing the memory cell so when you will enter into your project you will be able to work on the project much better if you don't do this you will struggle at the time of doing your project so better you do it okay so now we come to"
ZGqW4n7ULLw,part of this today's session which is ROM sales so we talked about Ram cells earlier what was one thing that we established for the wrong cells when we were when we were discussing Ram sales earlier so we were using different kind of layers like the diffusion or the metal or the area to program them and what did we establish so that hired the metal layer better easier better the time to Market the higher the layer at which I do the programming faster is the time to Market and therefore I prefer to do all my programmation at higher levels at that point of time there was a question about how do we program and that is what we are looking at now okay so let us say this is a memory uh this is an array of devices where this is one row this is another row another word line and there are all these uh nmoses that are kept the vertical purple lines are bit lines okay but do you notice the bit lines are the the memory cells are not connected to the bit lines yet are you able to see that yes sir so what we do is we say that wherever I want to write a zero that is wherever I want to discharge the bit line at that place I will connect the transistor to the memory to the bit line at other places I will not so what happens this one would discharge this one would not now challenges that there are some memory some bit lines where there is say X number of connections there are some bit lines where there are no connections and there are some bit lines where where every every nmos cell is connected to the bit line are you able to see this yes sir so do you want this kind of a situation for your bit lines or do you prefer something else first have we understood what is the programmation being done here how is the programmation being done here any questions about the programation part so I am not able to understand that means writing zero yeah if I connect it to the bit line I am saying that I am writing 0 there the bit line would discharge if I'm not connecting then when the word line goes on the bit line would not discharge so I've kind of programmed that cell to one right right yes okay so we are doing that programmation and over here what we are doing is some bit line we have either connecting the bit9 to the transistor or not connecting it to the transistor I had a doubt in the first in the First Column and the second column in the First Column only the upper transistor is connected to the bit line in the second column both the transistor but discharging would be taking place in both the bit lines so like how will I distinguish this um okay tell me one thing uh when I select word line 0 let us say the bottom one is by line zero and top one is word line one what will I read 0.90 yeah one zero one zero one zero one zero a third line one was selected what would I read the above zero zero zero zero so that is how we have programmed the memory there okay now the problem is that over here every bit line has different capacitance every bit line has different capacitance so how will you size your pre-chart circuit however you size your right driver circuit here's some columns uh right driver so there is no right driver in a ROM but pre-charge is there so some columns will will get pre-charged very fast others will not get Peta as far some columns will discharge very fast others will not discharge fast uh let us say uh these two uh let us consider these two columns okay in these two columns this has very high load on the bit Line This bit line is not not that high suppose uh let us know let us consider two columns uh in one column say 90 cells are connected to the to the bit line 10 are not in the other one let us say 10 cells are connected to the bit line now I want to read a particular row where this cell is connected but this is not so what happens this bit line will discharge to zero very very fast because the bit line capacitance is low this bit line will remain at vdd however because its load is very large and there is so much leakage on it it will it will fall a little okay but there is this very fast moving another signal right next to it it will cause it to fall further due to coupling okay so we do not really want such kind of you can hyper you can actually analyze your design and you can arrive at what is the worst case for which you need to design but the reality is on Silicon then there will still be many variations many race conditions that will be there we want to avoid that if we want to avoid that the same nor cell we program it differently now what we say is all the nmoses are now connected to the bit line what do I program I program the connection to the ground so I am connecting some things to the ground others there is no current path so it is 0 0 1 0 1 1 0 0 on the top row and uh one zero one one zero one one zero on the bottom row but over here the benefit is that the capacitance of all the bit lines is same are you able to see this any questions sir for example in the earlier case uh when they were not we were contacting with the like the train region so in that case also like with the worst case kind of that we can uh basically design a circuitry circuits like that only after that time only machine we can do that I agree raghav but it's still you know well I can design the worst case on Silicon I want as much Symmetry and as much control as is possible yeah with so many bit lines varying at different rates it will be very difficult to debug if there is a failure on Silicon there are so many additional variables now what is the capacitance what was the code that was written because every chip will have a different code you see every chip will have a different code so the number of variables that you have to handle in in Silicon debug they increase overwhelmingly you want to keep much more control with yourself so you say bitline capacitance you may tend to be the same only the source side we now do the programmation yes yeah okay sir yes sir previously we were programming it towards the drain position right so sir I didn't understand how the load is changing so regularly on a bit line okay on a bit line you have 10 10 Source All Drain regions connected or you have five Source ordering regions connected will the load change in sources I mean okay so sir uh what I what I understood about load is that there would be a capacitance corresponding to the drain position of the transistor is there a capacitance that is related to the drain on source region of a memory is offered offered nmos yes sir in DVD we have started about that yes what is that capacitance uh value is uh KC I mean K into C no no we we did something more also we looked at the sidewall capacitance and the and the bottom capacitance huh yes sir yeah yeah so there is a junction capacitance that comes into picture whenever you connect any Source or drain region to any particular signal that signal gets loaded because of the junction capacitance yes sir so the more the connections to the source and the more the capacitance the lesser the number of connections lesser the capacitance okay so sir how did we overcome this that issue in this Source connections look at any bit line how many Source regions are connected to it how many drain but how many thermostats are connected to it is it changing across bit lines yes yes it's about it okay thank you yeah so this is the Northfield and North cell what we are doing is we are selecting all the cells and uh uh we are selecting uh the cells and wherever there is a select wherever there is a what do you say uh zero written or a one written depending on that the bit line discharges nor cells are very fast North cell based arounds are very fast because there is just one nmos there but the problem is that they do not they're not as dense so we go to denser class of ROM memories which are nine memories now over here we connect word lines so we make an ion kind of a structure the topmost nmos gets a clock and the lower end losses get word lines okay now suppose I want to read word line zero I will keep Bird Line 0 at low level and I will or wait if I have to read word line 0 I will take word Line 1 as 1 and I will maintain word line 0 at low levels okay so when the clock comes what happens when the clock comes what happens will the bit lines discharge Bird Line zero okay yeah so the waitlines will not discharge hello the bit lines will not discharge simply because Y Line 0 is off now if I do the programation over here and the programmation is something like this so when I read when I key word line 0 at 0 which columns would discharge what would I read are you able to see this hello so it is basically an almost completed yes we have bypassed the nmos through the programation we've connected the source of drain of the nmosis where I wanted to write a zero foreign disconnection should be dynamic right dynamic means I mean it should be changing uh depending on the depending on the values which we want or the select lenses so this this programmation has to be done by the user he says I want to store this particular code in the ROM I would know where it is a zero where it is one and I will then appropriately put the connections there okay sir what so if I say that I am reading word line one so I will keep Y Line one at zero I will take word line 0 high and then I will bring the clock in so what do I read over here are you able to see this so can you repeat this again so when I wanted to read word line one I will keep outline one at zero word line 0 goes High and yes clock goes higher yeah what do I read there is still a current path in this yes yes I read 0 there now because word line was Zero there is no current path here so even though there is a current path here and there is a current path here I read a one there is that fine reading a one there there is a current path in the third column right is there a path in the third column my void line one is zero yeah yeah there's no one yeah okay so I read zero zero one one so that is how ROM sales are designed it is not that you just connect our program on source side or drain side and nothing would happen you have to be very aware of the impact that your programmation can have on the overall robustness of the ROM okay Ram cells are very dense see instead of six transistors of a memory cell you have just one other step or memory cell I know so wrong cells are very very dense which means that there is there are huge coupling capacitances that will come between this these bit lines there are many other additional variables uh that can appear when there is a particle strike or anything and that can really bother you so you want to keep as many things in control and fixed even if that means larger power consumption fine even if that means a little higher delay you would say fine but at least it is deterministic it is in my control because there are so many other variables which will come into picture on Silicon which are not in my control so you want to keep as many things in your control so you prefer to do Source programming on the nor Rams or nor ROMs than the drain programming okay so for example capacitance would obviously the internet the interest because it is denser but so for example if I'm for example storing a 0 here and it's are going to zero and on other side I'm going to score one but since I don't have a connection there so why would that be very simple for me because there is coupling happening between the two bit lines huh these two bit lines will couple so you had assumed that this bit line will not fall yes it is only to remain at vdd but due to coupling it falls so but where is the path to fall I mean till they they missed a bit what happens in coupling okay what happens in coupling so I mean the other the capacitance kind of other departments will try to two wires were running close to each other you take one one one uh wire to vdd what happens you see the other wire also starts to rise a bit that is what is coupling over here you are discharging one of the bit lines to zero so the other bit line which was not expected to discharge is the floating capacity to also discharge a little it was supposed to be like this okay okay so with ram you have to be extremely careful ROM designs are not simple it may appear that oh there is no right circuitry so I have to design lesser circuits but the circuits that you have to design are so dense that you have to be extremely careful that they remain functional even in the presence of these uh crosstalk and other capacitances,https://www.youtube.com/watch?v=ZGqW4n7ULLw,"Link: https://www.youtube.com/watch?v=ZGqW4n7ULLw
Transcript: part of this today's session which is ROM sales so we talked about Ram cells earlier what was one thing that we established for the wrong cells when we were when we were discussing Ram sales earlier so we were using different kind of layers like the diffusion or the metal or the area to program them and what did we establish so that hired the metal layer better easier better the time to Market the higher the layer at which I do the programming faster is the time to Market and therefore I prefer to do all my programmation at higher levels at that point of time there was a question about how do we program and that is what we are looking at now okay so let us say this is a memory uh this is an array of devices where this is one row this is another row another word line and there are all these uh nmoses that are kept the vertical purple lines are bit lines okay but do you notice the bit lines are the the memory cells are not connected to the bit lines yet are you able to see that yes sir so what we do is we say that wherever I want to write a zero that is wherever I want to discharge the bit line at that place I will connect the transistor to the memory to the bit line at other places I will not so what happens this one would discharge this one would not now challenges that there are some memory some bit lines where there is say X number of connections there are some bit lines where there are no connections and there are some bit lines where where every every nmos cell is connected to the bit line are you able to see this yes sir so do you want this kind of a situation for your bit lines or do you prefer something else first have we understood what is the programmation being done here how is the programmation being done here any questions about the programation part so I am not able to understand that means writing zero yeah if I connect it to the bit line I am saying that I am writing 0 there the bit line would discharge if I'm not connecting then when the word line goes on the bit line would not discharge so I've kind of programmed that cell to one right right yes okay so we are doing that programmation and over here what we are doing is some bit line we have either connecting the bit9 to the transistor or not connecting it to the transistor I had a doubt in the first in the First Column and the second column in the First Column only the upper transistor is connected to the bit line in the second column both the transistor but discharging would be taking place in both the bit lines so like how will I distinguish this um okay tell me one thing uh when I select word line 0 let us say the bottom one is by line zero and top one is word line one what will I read 0.90 yeah one zero one zero one zero one zero a third line one was selected what would I read the above zero zero zero zero so that is how we have programmed the memory there okay now the problem is that over here every bit line has different capacitance every bit line has different capacitance so how will you size your pre-chart circuit however you size your right driver circuit here's some columns uh right driver so there is no right driver in a ROM but pre-charge is there so some columns will will get pre-charged very fast others will not get Peta as far some columns will discharge very fast others will not discharge fast uh let us say uh these two uh let us consider these two columns okay in these two columns this has very high load on the bit Line This bit line is not not that high suppose uh let us know let us consider two columns uh in one column say 90 cells are connected to the to the bit line 10 are not in the other one let us say 10 cells are connected to the bit line now I want to read a particular row where this cell is connected but this is not so what happens this bit line will discharge to zero very very fast because the bit line capacitance is low this bit line will remain at vdd however because its load is very large and there is so much leakage on it it will it will fall a little okay but there is this very fast moving another signal right next to it it will cause it to fall further due to coupling okay so we do not really want such kind of you can hyper you can actually analyze your design and you can arrive at what is the worst case for which you need to design but the reality is on Silicon then there will still be many variations many race conditions that will be there we want to avoid that if we want to avoid that the same nor cell we program it differently now what we say is all the nmoses are now connected to the bit line what do I program I program the connection to the ground so I am connecting some things to the ground others there is no current path so it is 0 0 1 0 1 1 0 0 on the top row and uh one zero one one zero one one zero on the bottom row but over here the benefit is that the capacitance of all the bit lines is same are you able to see this any questions sir for example in the earlier case uh when they were not we were contacting with the like the train region so in that case also like with the worst case kind of that we can uh basically design a circuitry circuits like that only after that time only machine we can do that I agree raghav but it's still you know well I can design the worst case on Silicon I want as much Symmetry and as much control as is possible yeah with so many bit lines varying at different rates it will be very difficult to debug if there is a failure on Silicon there are so many additional variables now what is the capacitance what was the code that was written because every chip will have a different code you see every chip will have a different code so the number of variables that you have to handle in in Silicon debug they increase overwhelmingly you want to keep much more control with yourself so you say bitline capacitance you may tend to be the same only the source side we now do the programmation yes yeah okay sir yes sir previously we were programming it towards the drain position right so sir I didn't understand how the load is changing so regularly on a bit line okay on a bit line you have 10 10 Source All Drain regions connected or you have five Source ordering regions connected will the load change in sources I mean okay so sir uh what I what I understood about load is that there would be a capacitance corresponding to the drain position of the transistor is there a capacitance that is related to the drain on source region of a memory is offered offered nmos yes sir in DVD we have started about that yes what is that capacitance uh value is uh KC I mean K into C no no we we did something more also we looked at the sidewall capacitance and the and the bottom capacitance huh yes sir yeah yeah so there is a junction capacitance that comes into picture whenever you connect any Source or drain region to any particular signal that signal gets loaded because of the junction capacitance yes sir so the more the connections to the source and the more the capacitance the lesser the number of connections lesser the capacitance okay so sir how did we overcome this that issue in this Source connections look at any bit line how many Source regions are connected to it how many drain but how many thermostats are connected to it is it changing across bit lines yes yes it's about it okay thank you yeah so this is the Northfield and North cell what we are doing is we are selecting all the cells and uh uh we are selecting uh the cells and wherever there is a select wherever there is a what do you say uh zero written or a one written depending on that the bit line discharges nor cells are very fast North cell based arounds are very fast because there is just one nmos there but the problem is that they do not they're not as dense so we go to denser class of ROM memories which are nine memories now over here we connect word lines so we make an ion kind of a structure the topmost nmos gets a clock and the lower end losses get word lines okay now suppose I want to read word line zero I will keep Bird Line 0 at low level and I will or wait if I have to read word line 0 I will take word Line 1 as 1 and I will maintain word line 0 at low levels okay so when the clock comes what happens when the clock comes what happens will the bit lines discharge Bird Line zero okay yeah so the waitlines will not discharge hello the bit lines will not discharge simply because Y Line 0 is off now if I do the programation over here and the programmation is something like this so when I read when I key word line 0 at 0 which columns would discharge what would I read are you able to see this hello so it is basically an almost completed yes we have bypassed the nmos through the programation we've connected the source of drain of the nmosis where I wanted to write a zero foreign disconnection should be dynamic right dynamic means I mean it should be changing uh depending on the depending on the values which we want or the select lenses so this this programmation has to be done by the user he says I want to store this particular code in the ROM I would know where it is a zero where it is one and I will then appropriately put the connections there okay sir what so if I say that I am reading word line one so I will keep Y Line one at zero I will take word line 0 high and then I will bring the clock in so what do I read over here are you able to see this so can you repeat this again so when I wanted to read word line one I will keep outline one at zero word line 0 goes High and yes clock goes higher yeah what do I read there is still a current path in this yes yes I read 0 there now because word line was Zero there is no current path here so even though there is a current path here and there is a current path here I read a one there is that fine reading a one there there is a current path in the third column right is there a path in the third column my void line one is zero yeah yeah there's no one yeah okay so I read zero zero one one so that is how ROM sales are designed it is not that you just connect our program on source side or drain side and nothing would happen you have to be very aware of the impact that your programmation can have on the overall robustness of the ROM okay Ram cells are very dense see instead of six transistors of a memory cell you have just one other step or memory cell I know so wrong cells are very very dense which means that there is there are huge coupling capacitances that will come between this these bit lines there are many other additional variables uh that can appear when there is a particle strike or anything and that can really bother you so you want to keep as many things in control and fixed even if that means larger power consumption fine even if that means a little higher delay you would say fine but at least it is deterministic it is in my control because there are so many other variables which will come into picture on Silicon which are not in my control so you want to keep as many things in your control so you prefer to do Source programming on the nor Rams or nor ROMs than the drain programming okay so for example capacitance would obviously the internet the interest because it is denser but so for example if I'm for example storing a 0 here and it's are going to zero and on other side I'm going to score one but since I don't have a connection there so why would that be very simple for me because there is coupling happening between the two bit lines huh these two bit lines will couple so you had assumed that this bit line will not fall yes it is only to remain at vdd but due to coupling it falls so but where is the path to fall I mean till they they missed a bit what happens in coupling okay what happens in coupling so I mean the other the capacitance kind of other departments will try to two wires were running close to each other you take one one one uh wire to vdd what happens you see the other wire also starts to rise a bit that is what is coupling over here you are discharging one of the bit lines to zero so the other bit line which was not expected to discharge is the floating capacity to also discharge a little it was supposed to be like this okay okay so with ram you have to be extremely careful ROM designs are not simple it may appear that oh there is no right circuitry so I have to design lesser circuits but the circuits that you have to design are so dense that you have to be extremely careful that they remain functional even in the presence of these uh crosstalk and other capacitances"
u-Y_cCf7rkk,and then I would want to okay so now today we will start to look at circuits in the i o so what are the circuits in the i o region that you know of what does um sense amplifier right driver okay multiplexers okay and number one row decoder the pre-charge I'm sorry input output buffer input buffers output buffers very good and social Switcher so there are lots of wiring sir and lots of Miles okay good and charging and charging and discharging of hobby things charging and discharging of bit line ah free chat circuits hmm so now so that kind of rounds it up we have in when we talk of a memory i o we have a wide range of circuits there and those circuits essentially involve uh uh how do we put it uh sense amplifiers latches at the outputs of the sense amplifiers input buffers for the right driver the right driver itself then we also have mux which would connect the relevant bitline to either the sensor amplifier or the right driver or both of them and then we also have the pre-charge circuits hmm so let us have a quick look at is on just a minute it's invisible now yes so yeah okay so uh and I would typically have this range of circuits in it and as a designer even when you are placing these circuits into your memory uh you have a choice you have a decision to make for example where would you want to place the mugs would you want to place the marks above the right driver or below the right driver so what is the difference what happens differently when you place the marks above the right driver or below the right driver or what you when you place a sense amplifier above the multiplexer or below the multiplexer what happens what difference does it bring according to you so I think the nodes will be different load scene loads will be different for what what will see different code foreign driver if it is placed like between the sense amplifier and marks then it will see uh sense amplifier as the load now but if right driver is placed like this right now it will see mugs absolute so so uh for the right driver where is the data coming from thank you sorry external input actually providing that is coming from the input buffer now so the data is going up for the right driver the data is coming from the bottom from the input buffer um and the path is like this going up where would the load of a right driver be would it be down there or up there okay up there what is the load of the right driver then okay so it is for example it is free charging is it fixed yeah pre-charge as the load now let's just detach the load what happens to the bit line there are bit lines running here yeah like okay now okay okay okay sir this iOS Place below the arena yes so the array is always the load so what what else changes Ranjit uh sorry if this ensemplifier is placed after the multiplexer then it can be a case where the performance can be hit because uh if the sense amplifier is placed before the multiplexer the performance improves but will have Lot number of sense amplifiers for each bit line wow very good so what ranjith is saying is that if you would place the sense amplifier or the right driver below the multiplexer you have only one right driver and one sense amplifier for all the bit lines that are coming on the dot marks so if it is Max 4 then yeah one sense amplifier for four pairs of bit lines connected to four bit cells however uh if you would place the sense amplifier or the right driver above the multiplexer then since multiplexing has not happened yet the each bit line will be connected to a sense amplifier each bit line will connect it to a right driver so the area so instead of one sense amplifier or one right driver you will have four sense amplifiers or four right drivers and Max 4. so the area goes for a toss we may improve the performance a bit but area definitely goes for a toss so this how and where you place your circuits in a i o has a very strong bearing on area and performance trade-off are you able to see this any questions uh sir in the sense amplifier we are basically sensing the differential voltage that is appearing so how my performance will increase because I can set the differential to uh even after the marks I can sense a differential with that I mean yeah but a multiplexer means additional resistance coming into picture so additional RC delays will come into picture hello okay yeah that line is a small swing signal bit nine is a small swing signal so uh the multiplexer that you will need to make cannot be a digital multiplexer per se yes sir so that is why it can so because it's a it's a non-digital multiplexer and when you place the Suns amplifier or ride driver below the multiplexer resistance comes into picture and that is what we are talking about so anything else any other questions so the right driver should be below multiplexer right in this image no did I say that no I did not say that I simplified you can put the right driver above the multiplexer but then you will have to put four right drivers instead of one when it is Max 4. so what's preferred that depends on your project goals if your project goal is speed you would put it above the multiplexer if your project goal is area you would put it below the multiplexer talk to sir okay yes sir leakage power will increase in this case so why will we prefer this circuit so as soon as you increase the area the leakage power would also increase yes you're right but uh because the performance would improve that is why you may want to use the circuit ability activity would improve right time would improve for the sense amplifier if we put it up there then the then the what do you say the time in that you can trigger the sense amplifier will improve the delay would improve it would reduce anything else sir in this sense my I even I can use four or five seven samples sorry four or many numbers and seven papers as my most requirement and I can keep them above for the read operation if I want it to be fast or something you know yeah if you want to do it like that you can do that but realize sense amplifier is a big circuit so we'll talk about them today WebEx circuits if you use four of them or five of them in every i o four or eight of them in every i o it can be a huge area penalty sir and moreover we take a long time to write that is that the reason why I mean we are using separate right driver so that we can increase the speed and feed doesn't take that much time the right driver with anime will be separate now the functionality and the requirements from a right driver are different from that professional amplifier yes okay yes right whatever is expected to be different huh yes yeah uh sir so with the right driver uh when I'm writing I'm taking the for example the bit line to zero I'm discharging the bit line to zero so so if I am basically placing it uh below the multiplexer so the additional RC delay that is coming that will lead to my uh basically it will take time to more time to cause that to zero so but like uh before I write uh even before I start the word line on before then only I have pre-charged or discharged that bit line right so writability how it is improving how it is improving so because even before I start the right I have ensured that my Bitcoin is the memory right time will not change okay let us same every right time will not change what will change the time it takes to discharge but line to zero has changed that you agree yes sir yes that that needs to happen before the word line arrives yes sir so World line if we say is a clock then what would this be called what would this phrase condition be called typically if you have a flip flop yes it has a clock as an input yes sir and you say that data should arrive this much before the clock arrives for setup condition setup like so if the time to the start bit line to 0 has increased what has increased at the setup time has increased so data setup has increased so performance has gotten yes performance is not just cycle time for a memory you saw the data sheet had so many timings definitions yes so that is a common set hmm you're able to see though yes sir okay,https://www.youtube.com/watch?v=u-Y_cCf7rkk,"Link: https://www.youtube.com/watch?v=u-Y_cCf7rkk
Transcript: and then I would want to okay so now today we will start to look at circuits in the i o so what are the circuits in the i o region that you know of what does um sense amplifier right driver okay multiplexers okay and number one row decoder the pre-charge I'm sorry input output buffer input buffers output buffers very good and social Switcher so there are lots of wiring sir and lots of Miles okay good and charging and charging and discharging of hobby things charging and discharging of bit line ah free chat circuits hmm so now so that kind of rounds it up we have in when we talk of a memory i o we have a wide range of circuits there and those circuits essentially involve uh uh how do we put it uh sense amplifiers latches at the outputs of the sense amplifiers input buffers for the right driver the right driver itself then we also have mux which would connect the relevant bitline to either the sensor amplifier or the right driver or both of them and then we also have the pre-charge circuits hmm so let us have a quick look at is on just a minute it's invisible now yes so yeah okay so uh and I would typically have this range of circuits in it and as a designer even when you are placing these circuits into your memory uh you have a choice you have a decision to make for example where would you want to place the mugs would you want to place the marks above the right driver or below the right driver so what is the difference what happens differently when you place the marks above the right driver or below the right driver or what you when you place a sense amplifier above the multiplexer or below the multiplexer what happens what difference does it bring according to you so I think the nodes will be different load scene loads will be different for what what will see different code foreign driver if it is placed like between the sense amplifier and marks then it will see uh sense amplifier as the load now but if right driver is placed like this right now it will see mugs absolute so so uh for the right driver where is the data coming from thank you sorry external input actually providing that is coming from the input buffer now so the data is going up for the right driver the data is coming from the bottom from the input buffer um and the path is like this going up where would the load of a right driver be would it be down there or up there okay up there what is the load of the right driver then okay so it is for example it is free charging is it fixed yeah pre-charge as the load now let's just detach the load what happens to the bit line there are bit lines running here yeah like okay now okay okay okay sir this iOS Place below the arena yes so the array is always the load so what what else changes Ranjit uh sorry if this ensemplifier is placed after the multiplexer then it can be a case where the performance can be hit because uh if the sense amplifier is placed before the multiplexer the performance improves but will have Lot number of sense amplifiers for each bit line wow very good so what ranjith is saying is that if you would place the sense amplifier or the right driver below the multiplexer you have only one right driver and one sense amplifier for all the bit lines that are coming on the dot marks so if it is Max 4 then yeah one sense amplifier for four pairs of bit lines connected to four bit cells however uh if you would place the sense amplifier or the right driver above the multiplexer then since multiplexing has not happened yet the each bit line will be connected to a sense amplifier each bit line will connect it to a right driver so the area so instead of one sense amplifier or one right driver you will have four sense amplifiers or four right drivers and Max 4. so the area goes for a toss we may improve the performance a bit but area definitely goes for a toss so this how and where you place your circuits in a i o has a very strong bearing on area and performance trade-off are you able to see this any questions uh sir in the sense amplifier we are basically sensing the differential voltage that is appearing so how my performance will increase because I can set the differential to uh even after the marks I can sense a differential with that I mean yeah but a multiplexer means additional resistance coming into picture so additional RC delays will come into picture hello okay yeah that line is a small swing signal bit nine is a small swing signal so uh the multiplexer that you will need to make cannot be a digital multiplexer per se yes sir so that is why it can so because it's a it's a non-digital multiplexer and when you place the Suns amplifier or ride driver below the multiplexer resistance comes into picture and that is what we are talking about so anything else any other questions so the right driver should be below multiplexer right in this image no did I say that no I did not say that I simplified you can put the right driver above the multiplexer but then you will have to put four right drivers instead of one when it is Max 4. so what's preferred that depends on your project goals if your project goal is speed you would put it above the multiplexer if your project goal is area you would put it below the multiplexer talk to sir okay yes sir leakage power will increase in this case so why will we prefer this circuit so as soon as you increase the area the leakage power would also increase yes you're right but uh because the performance would improve that is why you may want to use the circuit ability activity would improve right time would improve for the sense amplifier if we put it up there then the then the what do you say the time in that you can trigger the sense amplifier will improve the delay would improve it would reduce anything else sir in this sense my I even I can use four or five seven samples sorry four or many numbers and seven papers as my most requirement and I can keep them above for the read operation if I want it to be fast or something you know yeah if you want to do it like that you can do that but realize sense amplifier is a big circuit so we'll talk about them today WebEx circuits if you use four of them or five of them in every i o four or eight of them in every i o it can be a huge area penalty sir and moreover we take a long time to write that is that the reason why I mean we are using separate right driver so that we can increase the speed and feed doesn't take that much time the right driver with anime will be separate now the functionality and the requirements from a right driver are different from that professional amplifier yes okay yes right whatever is expected to be different huh yes yeah uh sir so with the right driver uh when I'm writing I'm taking the for example the bit line to zero I'm discharging the bit line to zero so so if I am basically placing it uh below the multiplexer so the additional RC delay that is coming that will lead to my uh basically it will take time to more time to cause that to zero so but like uh before I write uh even before I start the word line on before then only I have pre-charged or discharged that bit line right so writability how it is improving how it is improving so because even before I start the right I have ensured that my Bitcoin is the memory right time will not change okay let us same every right time will not change what will change the time it takes to discharge but line to zero has changed that you agree yes sir yes that that needs to happen before the word line arrives yes sir so World line if we say is a clock then what would this be called what would this phrase condition be called typically if you have a flip flop yes it has a clock as an input yes sir and you say that data should arrive this much before the clock arrives for setup condition setup like so if the time to the start bit line to 0 has increased what has increased at the setup time has increased so data setup has increased so performance has gotten yes performance is not just cycle time for a memory you saw the data sheet had so many timings definitions yes so that is a common set hmm you're able to see though yes sir okay"
bnQ-dd1fiCY,so as I just was mentioning that even when you have just these six or seven blocks there how you arrange them can have a bearing on the PPA of the memory that you are designing so now let's start with the circuit designs each of these circuits we will look at one by one okay so bitline pre-charge one very simple way to recharge the bit lines is put a pmos which is always on what's the problem with this static power is there is always yeah if you look at it like this uh memory is typically off throughout Hannah that was the reason why we were also able to remove the pmoses from that 14 TD latch most of the cells are always most of the bit lines you don't need to nothing will turn on memory is usually off most of the time access rate is very low so one could say oh this extra power consumption is only for a very short duration of time I will still go with it so power is not really the driving criteria the fact is that if the pmos is always on then the bit line so now then the discharge so this is the charging path and there's a discharge path on the same capacitance which is a read path so the memory cell would now be able to would now have to sync current not only of the original bit line but also the current that is being injected by these pmoses which are always on so you will not really be able to discharge the bit line to a low level and you may not be able to read your memory at all in some cases so the alternators Cloud free charge even the when the read operation has to happen or when the right operation has to happen only then the free charge would turn off so now there is no no race condition or there is no ratio logic that is happening between the pmoses of the recharge and the bit cell which is trying to sync currently are you able to see how close this is IO region where I originally have word lines oh no sir but we can consider clock as a word line right so so this has to be a little so this clock should arrive a little earlier than word line actually so that when the word line comes the pizza is already off there's no short circuit path okay and this is an internet generated signature yeah this is an internal generator clock typically you will call it a call it as pre-charge clock so this clock will typically go to pre-asset whenever the active read or write cycle is happening the pre-charge would turn off so do you notice there is this extra transistor over here what do you think is the role of this transistor so can it be that it gives both Decline and bitline power at the same level it gives both the planet bit nine bar the same level what do you mean by same level it equalizes them [Music] so after every clock cycle it will set them at the same voltage level okay so this this additional pmos is called an equalizer so that is really the primary function of the equalizer it ensures that both in the bit line and bit line bar are precharged at the same level so that if you were had read a zero earlier and now you want to read a one so the other bit line has to discharge if they were already equalized just the decide has to happen if they were not equalized let us say bitline was at uh 995 millivolts and bl bar was at ten thousand five millivolts or 1005 millivolts then if I now want to discharge this I have to decide an additional 10 millivolts in my design are you able to see this so if I do not have an equalizer if I do not put this transistor there can it happen that bit line would go to 995 millivolts and bit nine bar to 1005 millivolts can it happen so because it may have happened that it may have happened that I read uh one on this side for the past 100 Cycles and in the past 100 Cycles I read a 0 on this side so even after whatever time I gave up recharge my bit line is unable to go beyond uh 995 millivolts can it happen so I mean if my uh Supply voltage is vtd then both of them can rise to will rise to be done ultimately I mean why is that case happening ultimately ultimately could be five nanoseconds later also now yes so so but like white is not uh I'm not able to understand that why 995 it is getting limiting by that no so uh let us say any RC network huh you connected a supply over here uh can you tell me when it will go to full vdd output sir ideally it is infinite it will never go to vdd yes Hannah so we know that okay 63 percent it will go in Tau an additional uh twenty percent will go in the two Tau and so on that much we know but full vdd can you can you tell also no sir so for bit9 that is what I am saying 100 Cycles have elapsed and therefore bit line bar was precharged to 1005 already pre-chach okay right and one cycle you read a zero on this side now uh you write a zero on that side and one on this side let us say something like that happened okay right so what is the status for so this one the bit line would not be able to really because its pre-charge is coming and going coming and going coming and going it is not able to really recharge to full hundred one thousand millivolts or 1010 millivolts Joby right if you have The Equalizer in every cycle it ensures that the two sides the same voltage there could still be an error of one or two millivolts that is fine but an equalizer the role is to equalize the voltages of the beta and bit line bar during pre-charge sir when is this clock exactly user is it used only before read cycle because in right we are supposed to make our bit line too high and bit line bar to low rate so in that case this if if you give this clock then both the bit lines will be high both the bit lines will be higher yeah I mean okay so in that case if you give this clock then both the bit lines will be having the same value but in right cycle we should be having uh one should be at the at the positivity and other should be at ground right for the right side this clock should go one even your right cycle ah yes sir that that was made out actually yeah I mean the stock would go one in all the Cycles all active Cycles this pre-charge would be turned off all uh this is recharge clock now let us say this is recharge clock so this pre-charge clock has to come in every active cycle whether it is a read or a right that has to come yes okay so after that we'll be uh we'll be lowering our uh I'm like equating our bit line and bit line bar according to the right or read operation so the reader if it is the read operation the bit lines are already equalized when the pre-charge talk was Zero yeah if it is a right operation or if it is a read operation once you have turned the pre-charge clock off now the connection to vdd is gone now it's simply the now bit line is simply a floating capacitor there yes sir depending on which side you had a zero stored that bit language discharge or whatever bit line you want to write a zero uh you will you do it through the right driver okay okay got it yeah so sir uh so early when you were talking that key one bit line is at a lower level it is a case that that bitline is having basically we are to the right driver in subsequent cycle we're discharging it also I'm recharging it also but other is sort of maintained at vdd so that is kind of coming that is able to reach up to BTD but other is not because your subsequent discharging to the right time at the right yeah because because for the past 100 Cycles it was continuously in pre-charge mode it never got this out so it's like kind of it got hundred Cycles for charging of the capacitor it would charge it closer to vd9 okay yeah there are the other other one was charge within just one one second or less than one nanosecond right okay so it got much lesser time and therefore this free charge will not be useful vdd there will be some residual difference between one button and the other the VDS would appear and then it will equalize kind of photo yeah so The Equalizer the VDS would be there and that would kind of ensure that the charge flows from one bit line to the other yes sir so and one more doubt regarding the variousness question only so when the for example my pre-charge is off my bit line has been pre-charged now for example I am thinking of the right cycle so one of my deadline has to be discharged to zero and one then is that so once my pre-chart cycle is off now even before my word line comes on I need to ensure that one of the bit line is off so during this pre-charge and that one line turning on during that cycle difference between the word line the word driver is like coming to picture and discharging the bit lines yes the right travel will turn on after the pre-charge goes off okay before the middle and before the word line comes on yeah so you will only after bitline has research you will say my word line will start to rise okay okay so okay so yes so I'm still not able to understand during the right operation how we are keeping a bit line to zero and the other one too high so you do not do it with the pre-cast on the store file you do it from the uh you you do not do it from this place you do it from the uh right driver you have not even looked at the right driver yet uh okay okay this is only the pre-charge circuit okay sir okay so now the next circuit that we look at is column decoder,https://www.youtube.com/watch?v=bnQ-dd1fiCY,"Link: https://www.youtube.com/watch?v=bnQ-dd1fiCY
Transcript: so as I just was mentioning that even when you have just these six or seven blocks there how you arrange them can have a bearing on the PPA of the memory that you are designing so now let's start with the circuit designs each of these circuits we will look at one by one okay so bitline pre-charge one very simple way to recharge the bit lines is put a pmos which is always on what's the problem with this static power is there is always yeah if you look at it like this uh memory is typically off throughout Hannah that was the reason why we were also able to remove the pmoses from that 14 TD latch most of the cells are always most of the bit lines you don't need to nothing will turn on memory is usually off most of the time access rate is very low so one could say oh this extra power consumption is only for a very short duration of time I will still go with it so power is not really the driving criteria the fact is that if the pmos is always on then the bit line so now then the discharge so this is the charging path and there's a discharge path on the same capacitance which is a read path so the memory cell would now be able to would now have to sync current not only of the original bit line but also the current that is being injected by these pmoses which are always on so you will not really be able to discharge the bit line to a low level and you may not be able to read your memory at all in some cases so the alternators Cloud free charge even the when the read operation has to happen or when the right operation has to happen only then the free charge would turn off so now there is no no race condition or there is no ratio logic that is happening between the pmoses of the recharge and the bit cell which is trying to sync currently are you able to see how close this is IO region where I originally have word lines oh no sir but we can consider clock as a word line right so so this has to be a little so this clock should arrive a little earlier than word line actually so that when the word line comes the pizza is already off there's no short circuit path okay and this is an internet generated signature yeah this is an internal generator clock typically you will call it a call it as pre-charge clock so this clock will typically go to pre-asset whenever the active read or write cycle is happening the pre-charge would turn off so do you notice there is this extra transistor over here what do you think is the role of this transistor so can it be that it gives both Decline and bitline power at the same level it gives both the planet bit nine bar the same level what do you mean by same level it equalizes them [Music] so after every clock cycle it will set them at the same voltage level okay so this this additional pmos is called an equalizer so that is really the primary function of the equalizer it ensures that both in the bit line and bit line bar are precharged at the same level so that if you were had read a zero earlier and now you want to read a one so the other bit line has to discharge if they were already equalized just the decide has to happen if they were not equalized let us say bitline was at uh 995 millivolts and bl bar was at ten thousand five millivolts or 1005 millivolts then if I now want to discharge this I have to decide an additional 10 millivolts in my design are you able to see this so if I do not have an equalizer if I do not put this transistor there can it happen that bit line would go to 995 millivolts and bit nine bar to 1005 millivolts can it happen so because it may have happened that it may have happened that I read uh one on this side for the past 100 Cycles and in the past 100 Cycles I read a 0 on this side so even after whatever time I gave up recharge my bit line is unable to go beyond uh 995 millivolts can it happen so I mean if my uh Supply voltage is vtd then both of them can rise to will rise to be done ultimately I mean why is that case happening ultimately ultimately could be five nanoseconds later also now yes so so but like white is not uh I'm not able to understand that why 995 it is getting limiting by that no so uh let us say any RC network huh you connected a supply over here uh can you tell me when it will go to full vdd output sir ideally it is infinite it will never go to vdd yes Hannah so we know that okay 63 percent it will go in Tau an additional uh twenty percent will go in the two Tau and so on that much we know but full vdd can you can you tell also no sir so for bit9 that is what I am saying 100 Cycles have elapsed and therefore bit line bar was precharged to 1005 already pre-chach okay right and one cycle you read a zero on this side now uh you write a zero on that side and one on this side let us say something like that happened okay right so what is the status for so this one the bit line would not be able to really because its pre-charge is coming and going coming and going coming and going it is not able to really recharge to full hundred one thousand millivolts or 1010 millivolts Joby right if you have The Equalizer in every cycle it ensures that the two sides the same voltage there could still be an error of one or two millivolts that is fine but an equalizer the role is to equalize the voltages of the beta and bit line bar during pre-charge sir when is this clock exactly user is it used only before read cycle because in right we are supposed to make our bit line too high and bit line bar to low rate so in that case this if if you give this clock then both the bit lines will be high both the bit lines will be higher yeah I mean okay so in that case if you give this clock then both the bit lines will be having the same value but in right cycle we should be having uh one should be at the at the positivity and other should be at ground right for the right side this clock should go one even your right cycle ah yes sir that that was made out actually yeah I mean the stock would go one in all the Cycles all active Cycles this pre-charge would be turned off all uh this is recharge clock now let us say this is recharge clock so this pre-charge clock has to come in every active cycle whether it is a read or a right that has to come yes okay so after that we'll be uh we'll be lowering our uh I'm like equating our bit line and bit line bar according to the right or read operation so the reader if it is the read operation the bit lines are already equalized when the pre-charge talk was Zero yeah if it is a right operation or if it is a read operation once you have turned the pre-charge clock off now the connection to vdd is gone now it's simply the now bit line is simply a floating capacitor there yes sir depending on which side you had a zero stored that bit language discharge or whatever bit line you want to write a zero uh you will you do it through the right driver okay okay got it yeah so sir uh so early when you were talking that key one bit line is at a lower level it is a case that that bitline is having basically we are to the right driver in subsequent cycle we're discharging it also I'm recharging it also but other is sort of maintained at vdd so that is kind of coming that is able to reach up to BTD but other is not because your subsequent discharging to the right time at the right yeah because because for the past 100 Cycles it was continuously in pre-charge mode it never got this out so it's like kind of it got hundred Cycles for charging of the capacitor it would charge it closer to vd9 okay yeah there are the other other one was charge within just one one second or less than one nanosecond right okay so it got much lesser time and therefore this free charge will not be useful vdd there will be some residual difference between one button and the other the VDS would appear and then it will equalize kind of photo yeah so The Equalizer the VDS would be there and that would kind of ensure that the charge flows from one bit line to the other yes sir so and one more doubt regarding the variousness question only so when the for example my pre-charge is off my bit line has been pre-charged now for example I am thinking of the right cycle so one of my deadline has to be discharged to zero and one then is that so once my pre-chart cycle is off now even before my word line comes on I need to ensure that one of the bit line is off so during this pre-charge and that one line turning on during that cycle difference between the word line the word driver is like coming to picture and discharging the bit lines yes the right travel will turn on after the pre-charge goes off okay before the middle and before the word line comes on yeah so you will only after bitline has research you will say my word line will start to rise okay okay so okay so yes so I'm still not able to understand during the right operation how we are keeping a bit line to zero and the other one too high so you do not do it with the pre-cast on the store file you do it from the uh you you do not do it from this place you do it from the uh right driver you have not even looked at the right driver yet uh okay okay this is only the pre-charge circuit okay sir okay so now the next circuit that we look at is column decoder"
C3Yh0xpJI58,okay so this is the two input node this is a column decoder of one type where you have a two input nor decoder in the let us say control region it generates four select outputs depending on what a0 and A1 are either of those four outputs would get selected and you would be able to uh transfer data to and from the bit lines what is the challenge here would be up here okay okay going over here something like this there would be one circuit everywhere now what what is the limitation here if I say I will use this kind of a column decoder what is the problem very simple problem so I mean as we it to me it seems that as we are moving away across the columns the more RC is coming into picture and maybe that will always come now sir uh it consists of pmos only so area will be a large area zero uh look right yes when I want to write a zero I want to take one of the bit lines to full zero that you will not be able to do through the pmosis um so what is the limitation of this one so yeah there is one stage is huh nor type of a decoding there is this another kind of a decoding which is called tree decoding huh and over here what is happening is that you implemented Max 8 so if if this was the case how many how many uh like if I have to implement mux 8 by using this kind of a decoder how many select lines do I need so three select lines address neighborhood or select line script into here it's eight eight select lines actually you need 16 because S 0 and S 0 bar otherwise we would have needed eight output lines eight select lines there a select lines mean in terms of area at least you need to have the the pre-charge height to be let us say my pitch is 0.1 to 0.8 microns is the height minimum just because of this metal region if I go to Mach 16 how many lines would be there 6 16 it's 1.6 so 1.6 Micron is the height of the column decoder then so as I go to a higher marks the column decoder area increases very very significantly now let us say I had Max 8 I do not want to use as many lines I have area constraints so I now want to use only six lines so I save area but what is the limitation here the voltage levels but we cannot we cannot take uh the output y to complete one sir stack effect because hmm yeah if your sense amplifier has to be put here do you realize the bitter bit line bar voltage has to come from a stack of three n buses huh hello are you able to see the stack effect there yes sir so this is an additional analysis this device will be slow um and uh what other thing what what do I mean by this um foreign are connected to two different transistors so there might be some capacitance I think that that's what it's mentioned over there see look at it like this now this y will have two Traverse across all the eight columns this one signal has to travel through all the eight columns over here it has to Traverse through four columns and so on so there are all these additional parasitic capacitances that are coming into picture all over the place in the previous decoder there was no such thing see the data data bar one capacitance no intermediate in a tree decoder this capacitances are definitely there but there is also this intermediate capacitances that comes into picture and that will come down uh sir sir actually I have some difficulty understanding that can you go to the previous slide sir uh so I mean so these two pmoses that I'm connecting why I'm needing these three Moses for I mean so how will you how will you Multiplex the bit lines so that instead of four pairs of bit lines only one pair of bit lines goes to the center amplifier so I mean how uh so the after the decoder it should feed into my word line and that word line should go to the bit cell so that structure is not clear getting clear to me from this picture what about column marks this is column decoder multiplexer okay yeah we're not in the road decoder region we are in the i o region only okay yes okay so do you realize there is much extra capacitance in this structure this is actually going to be much slower so what is typically done is uh sir uh in previous to previous slide in previous slides sir you said earlier that that pmos is not going to put a strong zero right so why are we not using nmos ERA with pmos also yeah you have to use I just said then this implementation it is not there so you have to use the inverse also so you have to use transmission rates so that I do not understand why we are not using this kind of column decoder who said we are not using did I say we do not use so say I think so what which one would be better in first First Column decoder or second column decoder because in seconds yes then that becomes the preferred column decoder if the project goal is uh speed then this could be a decoder of choice okay got it I know I am giving you examples okay this is one this is another this is another I'm just giving you examples to open you up there is no one design of decoder as a designer you have flexibility do you want to exercise that flexibility do you want to do design work where there is everything is already Frozen for you I do want to have the freedom to design the way you want it I would like Freedom please yeah that's what I am giving you there is no one answer every situation is different hmm so you would use transmission Gates over here in the sky in both the kind of circuits you would want to use transmission git so that you can transmit both 0 and 1. well okay yes so uh what we could also do is that Implement one state of marks at the sense amplifier or right driver so you remember what we were saying uh over here that if the right driver is above the multiplexer or the sense amplifiers let us say over here below the multiplexer then multiplexer could be a two is to uh four marks two is to four decoder there okay there are four lines you wanted to implement a Max one so one is to two marks could be implemented over a sense amplifier so what happens I have to design a Max 8 there are eight pairs of bit lines coming from the top the first four I will take them to a Max put a sense amplifier over them the next four I put another Max and then put a sense amplifier over that and the second set of this one is to 2 this control signals goes here to select which and switch sense amplifier is being addressed the outputs are buffered after a latch so what you have essentially done is you have instead of a three input marks you've used two input marks and the remaining multiplexing is being done at the sense amplifier or right driver level and this then is a area speed trade-off are you able to see that what have I done I have split Max 8 into 2 sorry I have split Max 8 into a hierarchical multiplexing Max 4 first and then sense amplifiers and the sun simplifier in itself the enable is already Multiplex with some with mixed with address foreign any questions so here we are increasing the area to yes but we are improving the performance yeah yes okay by using a smaller marks I have lesser run of the horizontal signal so I'm improving the performance yes set by using smaller method you improve performance Circle could you please repeat on that so if it was a higher marks in the previous slide we saw that if it is Max 8 there is a huge capacitance of eight columns over here okay okay got it good yeah good so by using this kind of a composite or hybrid marks you could achieve better performance okay so but how I'm paying the area penalty is it performance you have to add now one additional sense amplifier so that area is extra okay right I know if you had implemented a Max 8 directly one sense amplifier would have worked but now you have two sense amplifiers hmm okay so sir like uh in the earlier classes that you set that key for example we were doing key uh if you have Mark said then all the bits of word 0 would be coming two mugs one Marks here would be separating that bit 0 is the two kind of muxes separately and yeah finally one output only one output only okay yeah yeah so yeah Okay so take care so another way could be that implement we could also have it at the latches output latch is now multiplexed okay what does that mean there we will call off something as Pages there are multiple Pages the page which is being accessed the latch of that particular stage would be selected and connected to a global bus so what do you mean by Pizza page is an arrangement of so when we will look at row decoding so what what did we say we said that there is a big memory and in this big memory there is an array memory array now suppose I need to make a very very big memory so what would happen I need to increase the array size very significantly so virline RC is very high even Bitcoin RC is very high I say that I will split the word line I will split this particular memory into smaller arrays this big array I will split into smaller arrays so what I do is I convert it into pages so these there are three pages over here and these three pages go and come here let us say okay so how are we moving the pages I mean if we split into six pages right the whole array yeah we just organize them separately now just like we organized as two mux Force you simply say there are instead of there are there being 1000 rows in one array you said okay I have distributed 128 rows each I can do that now okay I'm sorry what's the Gap in between sir oh that is uh that is just a representational this is a cartoon I hope you understand this this is not the layout this is a cartoon where I'm saying that as you transition from one page to another I've just shown that there is space between Pairs there will be some strapping that will be done between pages but yeah I've just shown it as a cartoon over here which tells you that there are eight pages so so somewhat the it seems that the intuition seems to be similar to kind of mux I mean trying to lower that uh yeah in this case the output latch of each page is where the multiplexing is happening okay which Pages output to be selected so output latch after the sense amplifier is what has been multiplexed are you able to see this so the addressing here would become a little bit complex because I am not selecting now the uh coveralls on top of that I'm also setting the pages I mean which page and then I will select the column and then I would select that kind of thing yeah that is when you're writing if you are reading then you select the word line then select which uh which sense amplifier then you select uh which output to be taken out on the output bus and so on so one is going up the other is going down so this is about the column decoder and we said that we can in the i o region we can organize uh different parts of the i o uh differently so that we could arrive at a different PPA as circuit designers we have that choice we also looked at various types of column decoders and we could choose which we want to use according to the customer requirement according to the specifications of the memory that you are designing,https://www.youtube.com/watch?v=C3Yh0xpJI58,"Link: https://www.youtube.com/watch?v=C3Yh0xpJI58
Transcript: okay so this is the two input node this is a column decoder of one type where you have a two input nor decoder in the let us say control region it generates four select outputs depending on what a0 and A1 are either of those four outputs would get selected and you would be able to uh transfer data to and from the bit lines what is the challenge here would be up here okay okay going over here something like this there would be one circuit everywhere now what what is the limitation here if I say I will use this kind of a column decoder what is the problem very simple problem so I mean as we it to me it seems that as we are moving away across the columns the more RC is coming into picture and maybe that will always come now sir uh it consists of pmos only so area will be a large area zero uh look right yes when I want to write a zero I want to take one of the bit lines to full zero that you will not be able to do through the pmosis um so what is the limitation of this one so yeah there is one stage is huh nor type of a decoding there is this another kind of a decoding which is called tree decoding huh and over here what is happening is that you implemented Max 8 so if if this was the case how many how many uh like if I have to implement mux 8 by using this kind of a decoder how many select lines do I need so three select lines address neighborhood or select line script into here it's eight eight select lines actually you need 16 because S 0 and S 0 bar otherwise we would have needed eight output lines eight select lines there a select lines mean in terms of area at least you need to have the the pre-charge height to be let us say my pitch is 0.1 to 0.8 microns is the height minimum just because of this metal region if I go to Mach 16 how many lines would be there 6 16 it's 1.6 so 1.6 Micron is the height of the column decoder then so as I go to a higher marks the column decoder area increases very very significantly now let us say I had Max 8 I do not want to use as many lines I have area constraints so I now want to use only six lines so I save area but what is the limitation here the voltage levels but we cannot we cannot take uh the output y to complete one sir stack effect because hmm yeah if your sense amplifier has to be put here do you realize the bitter bit line bar voltage has to come from a stack of three n buses huh hello are you able to see the stack effect there yes sir so this is an additional analysis this device will be slow um and uh what other thing what what do I mean by this um foreign are connected to two different transistors so there might be some capacitance I think that that's what it's mentioned over there see look at it like this now this y will have two Traverse across all the eight columns this one signal has to travel through all the eight columns over here it has to Traverse through four columns and so on so there are all these additional parasitic capacitances that are coming into picture all over the place in the previous decoder there was no such thing see the data data bar one capacitance no intermediate in a tree decoder this capacitances are definitely there but there is also this intermediate capacitances that comes into picture and that will come down uh sir sir actually I have some difficulty understanding that can you go to the previous slide sir uh so I mean so these two pmoses that I'm connecting why I'm needing these three Moses for I mean so how will you how will you Multiplex the bit lines so that instead of four pairs of bit lines only one pair of bit lines goes to the center amplifier so I mean how uh so the after the decoder it should feed into my word line and that word line should go to the bit cell so that structure is not clear getting clear to me from this picture what about column marks this is column decoder multiplexer okay yeah we're not in the road decoder region we are in the i o region only okay yes okay so do you realize there is much extra capacitance in this structure this is actually going to be much slower so what is typically done is uh sir uh in previous to previous slide in previous slides sir you said earlier that that pmos is not going to put a strong zero right so why are we not using nmos ERA with pmos also yeah you have to use I just said then this implementation it is not there so you have to use the inverse also so you have to use transmission rates so that I do not understand why we are not using this kind of column decoder who said we are not using did I say we do not use so say I think so what which one would be better in first First Column decoder or second column decoder because in seconds yes then that becomes the preferred column decoder if the project goal is uh speed then this could be a decoder of choice okay got it I know I am giving you examples okay this is one this is another this is another I'm just giving you examples to open you up there is no one design of decoder as a designer you have flexibility do you want to exercise that flexibility do you want to do design work where there is everything is already Frozen for you I do want to have the freedom to design the way you want it I would like Freedom please yeah that's what I am giving you there is no one answer every situation is different hmm so you would use transmission Gates over here in the sky in both the kind of circuits you would want to use transmission git so that you can transmit both 0 and 1. well okay yes so uh what we could also do is that Implement one state of marks at the sense amplifier or right driver so you remember what we were saying uh over here that if the right driver is above the multiplexer or the sense amplifiers let us say over here below the multiplexer then multiplexer could be a two is to uh four marks two is to four decoder there okay there are four lines you wanted to implement a Max one so one is to two marks could be implemented over a sense amplifier so what happens I have to design a Max 8 there are eight pairs of bit lines coming from the top the first four I will take them to a Max put a sense amplifier over them the next four I put another Max and then put a sense amplifier over that and the second set of this one is to 2 this control signals goes here to select which and switch sense amplifier is being addressed the outputs are buffered after a latch so what you have essentially done is you have instead of a three input marks you've used two input marks and the remaining multiplexing is being done at the sense amplifier or right driver level and this then is a area speed trade-off are you able to see that what have I done I have split Max 8 into 2 sorry I have split Max 8 into a hierarchical multiplexing Max 4 first and then sense amplifiers and the sun simplifier in itself the enable is already Multiplex with some with mixed with address foreign any questions so here we are increasing the area to yes but we are improving the performance yeah yes okay by using a smaller marks I have lesser run of the horizontal signal so I'm improving the performance yes set by using smaller method you improve performance Circle could you please repeat on that so if it was a higher marks in the previous slide we saw that if it is Max 8 there is a huge capacitance of eight columns over here okay okay got it good yeah good so by using this kind of a composite or hybrid marks you could achieve better performance okay so but how I'm paying the area penalty is it performance you have to add now one additional sense amplifier so that area is extra okay right I know if you had implemented a Max 8 directly one sense amplifier would have worked but now you have two sense amplifiers hmm okay so sir like uh in the earlier classes that you set that key for example we were doing key uh if you have Mark said then all the bits of word 0 would be coming two mugs one Marks here would be separating that bit 0 is the two kind of muxes separately and yeah finally one output only one output only okay yeah yeah so yeah Okay so take care so another way could be that implement we could also have it at the latches output latch is now multiplexed okay what does that mean there we will call off something as Pages there are multiple Pages the page which is being accessed the latch of that particular stage would be selected and connected to a global bus so what do you mean by Pizza page is an arrangement of so when we will look at row decoding so what what did we say we said that there is a big memory and in this big memory there is an array memory array now suppose I need to make a very very big memory so what would happen I need to increase the array size very significantly so virline RC is very high even Bitcoin RC is very high I say that I will split the word line I will split this particular memory into smaller arrays this big array I will split into smaller arrays so what I do is I convert it into pages so these there are three pages over here and these three pages go and come here let us say okay so how are we moving the pages I mean if we split into six pages right the whole array yeah we just organize them separately now just like we organized as two mux Force you simply say there are instead of there are there being 1000 rows in one array you said okay I have distributed 128 rows each I can do that now okay I'm sorry what's the Gap in between sir oh that is uh that is just a representational this is a cartoon I hope you understand this this is not the layout this is a cartoon where I'm saying that as you transition from one page to another I've just shown that there is space between Pairs there will be some strapping that will be done between pages but yeah I've just shown it as a cartoon over here which tells you that there are eight pages so so somewhat the it seems that the intuition seems to be similar to kind of mux I mean trying to lower that uh yeah in this case the output latch of each page is where the multiplexing is happening okay which Pages output to be selected so output latch after the sense amplifier is what has been multiplexed are you able to see this so the addressing here would become a little bit complex because I am not selecting now the uh coveralls on top of that I'm also setting the pages I mean which page and then I will select the column and then I would select that kind of thing yeah that is when you're writing if you are reading then you select the word line then select which uh which sense amplifier then you select uh which output to be taken out on the output bus and so on so one is going up the other is going down so this is about the column decoder and we said that we can in the i o region we can organize uh different parts of the i o uh differently so that we could arrive at a different PPA as circuit designers we have that choice we also looked at various types of column decoders and we could choose which we want to use according to the customer requirement according to the specifications of the memory that you are designing"
XwkWvIgOQc0,if I all of us know there's a sense amplifier in the memory but why is there a sense amplifier so to improve my read time basically because otherwise yeah if there was no sense amplifier then I will have to discharge the bit lines to full zero or at least VD by two to read a zero huh but a sense amplifier with a sense amplifier I can pre-charge the bit line discharge the bit line only by 100 millivolts and still be able to read correctly because the hundred variable is Amplified by the sense amplifier to a full vdd string are you able to see this any questions are you able to understand this example that I've given here that when you discharge less the delay is less if you discharge more the delay would be more and by using a sense amplifier you're making a circuit faster when you discharge less because in the sense amplifier you need to discharge less only what else would reduce so we said performance would the we said the delay would reduce what else would reduce it's a power consumption the power power consumption of the bit lines would also reduce hmm I guess so so sensor amplifier is a high speed and a low power solution to uh to speed on power trade-off what goes for a toss is the what goes for the toss is which figure of Merit the area in terms of PPA performance and power are both improving at the cost of area why because there are so many terms of Innocence amplifier so let's have a quick look at how a sense amplifier operates so this over here is the bit cell on the top okay the word line would come so this is the word line it would come when it needs to come but before that the bit lines would be pre-charged to vdd or whatever level you want to pre-charge them to okay there is this sense amplifier for which s a n is equal to 0. if San is equal to 0 there are two pmoses which are on and these two PM offers essentially connect the bit line to the sense amplifier internal nodes foreign s are connected to the expense amplifier internal nodes whatever differential appears on the bit lines also appears on the internal nodes or the sense amplifier when that differential is sufficient I would take san2 one as soon as the CN goes to 1 these pmoses also get disconnected and now this system operates as a latch quickly latches the output small decision on the bitline bitline bar is therefore Amplified into a full vdd string so can you just repeat after just switched from sense amplifier signal from 0 to like one what exactly you tell me what happens as soon as I switch to some the essay into one so let's look at this San so my internal nodes at a particular rate I took essay and since unable to 1. so what would happen now till now this voltage could be vdd vdd minus v t as soon as this goes to 1 so this latch was not operational this latch was only operating between VD and VV minus v t as soon as this goes to 1 this becomes a full latch all the charge over here will get discharged and this what do you say this uh sensor amplifier will be able to read a correct 0 or 1 on the sap and sat nodes so sap would also come down a little but it will go back up finally the difference between sat and sap would be something like this full vdd swing is that okay any questions so how do we know when to make this sense enable one like is it a particular time or something yeah you remember we talked about replica paths reference paths hi yes sir that is how okay okay sir okay sir um written over here that you have to carefully tune the reaction time and switch off the essence amplifier to enable startup new cycle yeah there was a question sorry sir here we have saf and sat21 previously that we got uh because we made a read operation a previously and those are the values that we got from the read operation right sense amplifier operation is a part of read operation of okay hello yes sir yes yeah sir but uh okay so uh my doubt is that when should the sensor amplifier be triggered it should be according to me it should be triggered after the read operation right um what do you mean by after the read operation so uh I mean uh when does the read operation end so after uh I mean like bltn node uh sorry after after I run my cell current through the blti node so that I can I can I have a current so that I can discharge my bit line or bit line bar whatever where my zero battery have done that you have done bitline and bitline bar over here have discharged two one is at the uh vdd other is a 3D minus 100 millivolts now so yes sir after that I mean like that was made outside if I enable my sensor sense amplifier enabled so I do understand there is a bmos and I'll I'll be able to uh run my values into this Central node I mean like B out and V out bar in this case so uh I mean after that does that happen in parallel or I mean like I I see like it's coming from bitland and bitland bar and it's directly dumb getting dumped into the ground so look at it over here when sand is equal to 0 is there a ground path no sir no sir so it is not the directly cutting termed into ground now we say s a n goes to 1. SN goes to one means these pass Gates have gone off bit lines are no longer connected to the sense amplifier now okay that is where it is written important to decouple bit lines from the sensor amplifier yes sir got it yeah you're able to see the functionality of the sensor amplifier here any questions so so for example during the read uh when my this sense enable signal is off the pmos are on so the differential for example this BLB underscore mux is sort of discharging and uh other one is head LBD so so the saf point will and the SAT point the SAT point will be basically charged to one and this is point will be little less not as vdd so after we turn off this both the pmoses because the SAT is higher point so it will quickly uh make that nmo strong at the SF point and it will discharge the zero that is what is happening yeah you you you're reading it wrongly in fact sat is discharging more if you look at it sat is the starting mode saf is discharging like this as it is just starting like this so when the when this nmos goes to one and the pmoses get disconnected what happens all of a sudden both sides start to sing current huh because this side had a higher level on the saf node the Gate of this pull down is at a higher level than the Gate of this pull down are you able to see this so originally my basically so my BL underscore MAX Line was basically discharging the sort of that at that point it was Zero was stored so that was discharging so that's why sat is discharging more yes okay this is just I'm just taking one example you could take an example where the other side the side is more what's the difference there okay what's the difference there's no difference it doesn't problem to realize is whichever side was discharging more that will continue to discharge faster because of the gate voltage also now yes as soon as Government pmos on the the way there was more discharge that will discharge more and uh other side would kind some kind of restore to one kind of okay yeah yeah okay so as he said this one discharges to full zero the otherwise other side goes to one because the latching operation yes sir yes sir I have a question yeah so does this mean that the internal loads sjf and sat should be pre-charged as well yes okay and uh you remember circuit over here oh yes okay okay so hmm okay and also should we make uh when it comes to sizing of uh distance amplifier should we have uh the size of this sense enabled signal and Moss very high so that it facilitates uh faster discharge well okay so let us say this is one micron so what do you mean by very high for this it should be at least greater than one micron it should be let us say 1.2 microns yes sir okay or faster discharge so Earth is and current API the cell current would be high so the first of all uh when this sense amplifier goes on we are not connected to the memory cell at all yes sir they have gone off we are only talking about the sense amplifier yes I meant this in the cell current builds the discharge current which I meant in the sense amplifier so the search current is being generated as a sense amplifier what do you mean by that I meant the discharge the discharge path from uh sat to ground so the current will be the latching operation yes no longer discharge it is latching operation now what is that an answer yeah latching means that one side will go to zero the other side will go to one yes so if you keep this transistor to be bigger you are saying that more current will flow yes so okay keep it a little bigger no problems but there's no point to take it so big that it goes to two microns because at any point of time only one of the saf or sat will go to zero both cannot go to zero simultaneously yes sir will not I know it's a latch finally so you keep it a little bigger than the uh then the pass Gates over here or the mashed devices over here that is fine okay and also when it comes to the sizing of the transistors in this enzyme paper so will we follow the same aspect ratio as we maintain in the memory cell or it'll be good sorry the size of the size of pull down the pass key why what is happening here are we reading are we syncing some like are we reading through the sense amplifier is there some data stored inside the sense amplifier that we are trying to read what is happening we know that we are not storing any data is there a stability condition around the sense amplifier no sir then okay see the structure looks very similar to a 60s Ram cell but don't get confused it's still a sense amplifier it has a completely different functionality to design it you need to consider the functionality that is required of it in in your analysis not how it is appearing to look or how it is appearing yes okay so set yes sir just I just wanted to confirm my understanding that could you please go back to the previous lecture tell me so sir the preacher circuit which you are using sir were you using it to maintain the saf and sat at zero oh you tell me sir it should be zero sir according to me why sir because if bitland bit line bar I just want I'm like they'll be at some voltage and I want them to write on this uh internal nodes then if that's one then I can't I can't write them directly in fact if I on my sends amplifier enable my uh the intermediate notes which I have that would be reverse driving into my BL and bitline bar right and bit line bar is at vdd minus 100 millivolts yes sir you are saying you want to pre-charge these to zero yes so what is happening the this pmos which is permanently on yes San has not arrived yet so this pmos is on can there be a connection between vdd and 0 like this no said uh okay uh understood sir so even if there is a vdd over there sir what I understood is that okay so since amplifier will be uh I I think it should be working on a higher voltage than uh and then the normal memory voltage which you are working no no it's the same voltage okay so sir just explain this condition with vdd also servants because if I if I take vdd uh then even then I'm like I'll be writing back into my vdd minus 100 millivolt right and like even I am not supposed to connect those both nodes directly because there are there are different potentials actually there's a pmos here one side there is very other side there is VD minus 100 millivolts the pmos is on so what would happen will also get discharged that is what you wanted me you want to translate the differential on the bit lines onto the internal nodes is it that is it not yes yes yes so you want to discharge the internal node now what's the problem there that is your desired functionality okay so um I mean where is the connection getting completed sir actually I mean okay and vdd and vdd minus 100 millivolts okay that's fine but uh there should be a closed circuit when I when I operate right to Forever word line is on the memory cell is thinking that current okay okay sir so basically I'm translating the discharge on the bit line to this kind of internal load it is yes sir can you also please what was in the slide there was Reaction Time mentioned so what was that reaction time is when I turn the essay and on after that after how long well the outputs the Saturns have the last as 0 and 1. foreign okay so now one of the two have discharged fat has the star side bath has discharged you want to now reset the sense amplifier the read operation has completed you want to reset the sense amplifier for that you will typically see that there would be this kind of a latch put there there is an output latch which latches whatever you wanted to write and then what happens now you can pre-charge your sense amplifier to make it ready for the next read is that okay uh so I didn't get it so I mean so there is the sense amplifier it has these two outputs the bit lines go in and these two outputs go out come out to to start the next cycle bit lines and also sat and sap node have to be pre-charged to vdd yes sir hello yes sir now there is an output latch down there output buffer down there yes yes yes sir if my Saturns have both are pretty charged to be ready what will the output buffer do how will it give an output there it cannot now I cannot connect hat or SAS because what happens is suppose sat went down I cannot really connect fat directly to my output buffer why because to start the next cycle I have to take it up it means my output will only get a glitch nothing else okay yes are you able to see this there is this analog circuit where the output went to zero now to start the new cycle you want to take it up you want to pre-charge it again that is when the next cycle can start but my output bus has to be driven to a desired Q value for much longer time so what do you need to do you need to put a latch in between somewhere and this is the kind of latch that is put where even if beta and bit bar both go to one the latch will regenerate its contents it's like an Sr latch so in the sense amplifier the saf and the SAT notes that were basically I were taking to this uh I was taking this output sir because it was not evident to me so from that example what was the output then okay what got Amplified from the from vdd and vdd to zero and vdd so the saf and the SAT nodes so that is the output now and so these two nodes are you taking to the latch yes okay so that was one set of sense amplifiers there are other sense amplifiers also and you can actually spend some time to understand their functionality over here what we have done is we have instead of the pmoses you remember there were pmoses there instead of the pmoses we have put capacitors what do you think is the benefit of capacitors instead of the pmos is there so uh I feel uh there is a emulate more than benefit there is a loss actually because there is BLB towards the internal role there is a delay in writing the BLB or BL B plan or bitlan bar towards the internal node actually okay what is the benefit why would one consider putting a capacitor instead of the pass gate select capacitor generally resist change in voltage right this voltage change so but I want to translate that so wouldn't it be like kind of a counterintuitive not bad because I want to translate that change to the internet is this a coupling capacitor or is there some loading capacitor coupling I think sir what does the coupling capacitor do couple the voltage from one side if you couple the voltage on the bit lines into the internal nodes okay yes sir I think DC stabilization May might be the case because Matlab we are isolating the DC voltage between the top and the bottom thing so might be the case to see the memory array you may want to operate at 1 volts because below 1 volts the memory cell will not function hmm but sense amplifier you may you can operate at 0.6 volts also because it's a circuit which can function at 0.6 volts also the last scan function in the previous design that we looked at bit line and SAS sat and sap nodes were connected with each other during the reset mode huh what that also meant was that they had to be at the same voltage you could not operate the sense amplifier at a voltage different than the memory array are you able to see this yes sir by decoupling them now you say oh even if your memory array needs to go to 1.0 volts my sense amplifier can operate at 0.6 volts also so let us do dvfs only this VD will go low that other vdd will not go low if you save power another way to achieve a similar independence of voltage of sensor amplifier and bit lines is this one where the bit lines go to the gate of a device they are never connected to the output nodes over here thank you okay and you will see both the sense amplifiers are used any questions till here so how I'm decoupling them so I mean immediately the essay answer uh we were close the discharge kind of the decoupling the and this one so yes yeah so in the reset mode what is the status of BLB and faf so both are like pre-charged what's up yes recharge and connected because sensionable is zero so they are connected oh yes yes so now by putting a capacitor instead can they ever be connected electrically no show they can be at different voltages then yes so hmm thanks anything else oh and it is awesome why is this output lines or pre-charged in the second case in the second case yes we have P4 and P3 mosfets because you want the flats to be operational no so it's just like uh you're saying that this latch will start from VD at all times the latch will need to be pre-charged but that vdd this this vddp can be different from the vdd array over here so this could be vdtp again the voltage of the sense amplifier can be different from the voltage of the array of the bit lines okay okay so again for this also you can see a paper in my Google Scholar page you will see there's a paper on gauge couplets and simplifier there's a patent also around it so you can study that in and get a better View okay another thing that you should notice is that there is because now because now I am not worried about what the voltage of this V out and V out bar is I can actually equalize it to a cue point to its cue point so you see there are no two pmoses over here I just have an equalizer a cue Point equalized uh SRAM was found to be faster than the pre-charged rasra foreign okay so uh the last slide on sense amplifiers uh in a sense in a SRAM we have discussed that there could be say one sense amplifier per mux 4 or Max 8 huh in a dram it is not possible in a dram you have to put a sense amplifier for every column so if you have to put a mux it has to be below the center amplifier okay why can't we use a why can't we use uh a multiplexer before the sensor amplifier energy Ram so in the case we'll have uh for four columns field around single legs in that case we use that in that case you would have will have a single uh sense amplifier for four columns which violates this statement hmm so so you're talking about the dram sir so sir like dram only uh we have like a pastor so I mean uh because uh earlier when I was putting like send simplifier after the uh multiplexer I was so there was a performance degradation so sir but because uh now we have the charge thing so I think that because they're discharging I'm sort of it becomes more kind of in The Logical to place above that because that loss of charge and creating more RC maybe so think about it think about it let me give you a hint in dram when you read it is always a destructive read so we will discuss diagrams in a little you know after a few lectures don't worry we will I will never give you the answer to it and just picking your cross curiosity as of now okay okay but in a drama we have to put a sense amplifier on every column for an SRAM you can save area by putting it up to the multiplexer okay yes okay sir yes sir uh we generally say dram is uh much dense right sir it is then simplifiers we are using so how does that become dense actually is the density of a memory because of the periphery or of course the memory cell if we buy a dram will get it with a sense amplifier right memory accelerator how much areas of the periphery and how much areas of the memory array yes so let us look at it like this let us say for an for an SRAM the area of the array is 9 area of the periphery is one total area is 10. for a dram that 9 would shrink to let us say 3. two okay periphery you made from one to three also let us say three times what happened total area is now five okay yes I'm just giving you some random gross cartoon in cartoon types numbers that is not the reality even in a DRM array is much much more area than the periphery but just I am exaggerating the situation for you okay okay there are two different components for area periphery area is larger okay understood but what about the air area is so dense that overall dram is denser okay so we'll close here and we will do right driver and uh closer of the i o circuits in the next class,https://www.youtube.com/watch?v=XwkWvIgOQc0,"Link: https://www.youtube.com/watch?v=XwkWvIgOQc0
Transcript: if I all of us know there's a sense amplifier in the memory but why is there a sense amplifier so to improve my read time basically because otherwise yeah if there was no sense amplifier then I will have to discharge the bit lines to full zero or at least VD by two to read a zero huh but a sense amplifier with a sense amplifier I can pre-charge the bit line discharge the bit line only by 100 millivolts and still be able to read correctly because the hundred variable is Amplified by the sense amplifier to a full vdd string are you able to see this any questions are you able to understand this example that I've given here that when you discharge less the delay is less if you discharge more the delay would be more and by using a sense amplifier you're making a circuit faster when you discharge less because in the sense amplifier you need to discharge less only what else would reduce so we said performance would the we said the delay would reduce what else would reduce it's a power consumption the power power consumption of the bit lines would also reduce hmm I guess so so sensor amplifier is a high speed and a low power solution to uh to speed on power trade-off what goes for a toss is the what goes for the toss is which figure of Merit the area in terms of PPA performance and power are both improving at the cost of area why because there are so many terms of Innocence amplifier so let's have a quick look at how a sense amplifier operates so this over here is the bit cell on the top okay the word line would come so this is the word line it would come when it needs to come but before that the bit lines would be pre-charged to vdd or whatever level you want to pre-charge them to okay there is this sense amplifier for which s a n is equal to 0. if San is equal to 0 there are two pmoses which are on and these two PM offers essentially connect the bit line to the sense amplifier internal nodes foreign s are connected to the expense amplifier internal nodes whatever differential appears on the bit lines also appears on the internal nodes or the sense amplifier when that differential is sufficient I would take san2 one as soon as the CN goes to 1 these pmoses also get disconnected and now this system operates as a latch quickly latches the output small decision on the bitline bitline bar is therefore Amplified into a full vdd string so can you just repeat after just switched from sense amplifier signal from 0 to like one what exactly you tell me what happens as soon as I switch to some the essay into one so let's look at this San so my internal nodes at a particular rate I took essay and since unable to 1. so what would happen now till now this voltage could be vdd vdd minus v t as soon as this goes to 1 so this latch was not operational this latch was only operating between VD and VV minus v t as soon as this goes to 1 this becomes a full latch all the charge over here will get discharged and this what do you say this uh sensor amplifier will be able to read a correct 0 or 1 on the sap and sat nodes so sap would also come down a little but it will go back up finally the difference between sat and sap would be something like this full vdd swing is that okay any questions so how do we know when to make this sense enable one like is it a particular time or something yeah you remember we talked about replica paths reference paths hi yes sir that is how okay okay sir okay sir um written over here that you have to carefully tune the reaction time and switch off the essence amplifier to enable startup new cycle yeah there was a question sorry sir here we have saf and sat21 previously that we got uh because we made a read operation a previously and those are the values that we got from the read operation right sense amplifier operation is a part of read operation of okay hello yes sir yes yeah sir but uh okay so uh my doubt is that when should the sensor amplifier be triggered it should be according to me it should be triggered after the read operation right um what do you mean by after the read operation so uh I mean uh when does the read operation end so after uh I mean like bltn node uh sorry after after I run my cell current through the blti node so that I can I can I have a current so that I can discharge my bit line or bit line bar whatever where my zero battery have done that you have done bitline and bitline bar over here have discharged two one is at the uh vdd other is a 3D minus 100 millivolts now so yes sir after that I mean like that was made outside if I enable my sensor sense amplifier enabled so I do understand there is a bmos and I'll I'll be able to uh run my values into this Central node I mean like B out and V out bar in this case so uh I mean after that does that happen in parallel or I mean like I I see like it's coming from bitland and bitland bar and it's directly dumb getting dumped into the ground so look at it over here when sand is equal to 0 is there a ground path no sir no sir so it is not the directly cutting termed into ground now we say s a n goes to 1. SN goes to one means these pass Gates have gone off bit lines are no longer connected to the sense amplifier now okay that is where it is written important to decouple bit lines from the sensor amplifier yes sir got it yeah you're able to see the functionality of the sensor amplifier here any questions so so for example during the read uh when my this sense enable signal is off the pmos are on so the differential for example this BLB underscore mux is sort of discharging and uh other one is head LBD so so the saf point will and the SAT point the SAT point will be basically charged to one and this is point will be little less not as vdd so after we turn off this both the pmoses because the SAT is higher point so it will quickly uh make that nmo strong at the SF point and it will discharge the zero that is what is happening yeah you you you're reading it wrongly in fact sat is discharging more if you look at it sat is the starting mode saf is discharging like this as it is just starting like this so when the when this nmos goes to one and the pmoses get disconnected what happens all of a sudden both sides start to sing current huh because this side had a higher level on the saf node the Gate of this pull down is at a higher level than the Gate of this pull down are you able to see this so originally my basically so my BL underscore MAX Line was basically discharging the sort of that at that point it was Zero was stored so that was discharging so that's why sat is discharging more yes okay this is just I'm just taking one example you could take an example where the other side the side is more what's the difference there okay what's the difference there's no difference it doesn't problem to realize is whichever side was discharging more that will continue to discharge faster because of the gate voltage also now yes as soon as Government pmos on the the way there was more discharge that will discharge more and uh other side would kind some kind of restore to one kind of okay yeah yeah okay so as he said this one discharges to full zero the otherwise other side goes to one because the latching operation yes sir yes sir I have a question yeah so does this mean that the internal loads sjf and sat should be pre-charged as well yes okay and uh you remember circuit over here oh yes okay okay so hmm okay and also should we make uh when it comes to sizing of uh distance amplifier should we have uh the size of this sense enabled signal and Moss very high so that it facilitates uh faster discharge well okay so let us say this is one micron so what do you mean by very high for this it should be at least greater than one micron it should be let us say 1.2 microns yes sir okay or faster discharge so Earth is and current API the cell current would be high so the first of all uh when this sense amplifier goes on we are not connected to the memory cell at all yes sir they have gone off we are only talking about the sense amplifier yes I meant this in the cell current builds the discharge current which I meant in the sense amplifier so the search current is being generated as a sense amplifier what do you mean by that I meant the discharge the discharge path from uh sat to ground so the current will be the latching operation yes no longer discharge it is latching operation now what is that an answer yeah latching means that one side will go to zero the other side will go to one yes so if you keep this transistor to be bigger you are saying that more current will flow yes so okay keep it a little bigger no problems but there's no point to take it so big that it goes to two microns because at any point of time only one of the saf or sat will go to zero both cannot go to zero simultaneously yes sir will not I know it's a latch finally so you keep it a little bigger than the uh then the pass Gates over here or the mashed devices over here that is fine okay and also when it comes to the sizing of the transistors in this enzyme paper so will we follow the same aspect ratio as we maintain in the memory cell or it'll be good sorry the size of the size of pull down the pass key why what is happening here are we reading are we syncing some like are we reading through the sense amplifier is there some data stored inside the sense amplifier that we are trying to read what is happening we know that we are not storing any data is there a stability condition around the sense amplifier no sir then okay see the structure looks very similar to a 60s Ram cell but don't get confused it's still a sense amplifier it has a completely different functionality to design it you need to consider the functionality that is required of it in in your analysis not how it is appearing to look or how it is appearing yes okay so set yes sir just I just wanted to confirm my understanding that could you please go back to the previous lecture tell me so sir the preacher circuit which you are using sir were you using it to maintain the saf and sat at zero oh you tell me sir it should be zero sir according to me why sir because if bitland bit line bar I just want I'm like they'll be at some voltage and I want them to write on this uh internal nodes then if that's one then I can't I can't write them directly in fact if I on my sends amplifier enable my uh the intermediate notes which I have that would be reverse driving into my BL and bitline bar right and bit line bar is at vdd minus 100 millivolts yes sir you are saying you want to pre-charge these to zero yes so what is happening the this pmos which is permanently on yes San has not arrived yet so this pmos is on can there be a connection between vdd and 0 like this no said uh okay uh understood sir so even if there is a vdd over there sir what I understood is that okay so since amplifier will be uh I I think it should be working on a higher voltage than uh and then the normal memory voltage which you are working no no it's the same voltage okay so sir just explain this condition with vdd also servants because if I if I take vdd uh then even then I'm like I'll be writing back into my vdd minus 100 millivolt right and like even I am not supposed to connect those both nodes directly because there are there are different potentials actually there's a pmos here one side there is very other side there is VD minus 100 millivolts the pmos is on so what would happen will also get discharged that is what you wanted me you want to translate the differential on the bit lines onto the internal nodes is it that is it not yes yes yes so you want to discharge the internal node now what's the problem there that is your desired functionality okay so um I mean where is the connection getting completed sir actually I mean okay and vdd and vdd minus 100 millivolts okay that's fine but uh there should be a closed circuit when I when I operate right to Forever word line is on the memory cell is thinking that current okay okay sir so basically I'm translating the discharge on the bit line to this kind of internal load it is yes sir can you also please what was in the slide there was Reaction Time mentioned so what was that reaction time is when I turn the essay and on after that after how long well the outputs the Saturns have the last as 0 and 1. foreign okay so now one of the two have discharged fat has the star side bath has discharged you want to now reset the sense amplifier the read operation has completed you want to reset the sense amplifier for that you will typically see that there would be this kind of a latch put there there is an output latch which latches whatever you wanted to write and then what happens now you can pre-charge your sense amplifier to make it ready for the next read is that okay uh so I didn't get it so I mean so there is the sense amplifier it has these two outputs the bit lines go in and these two outputs go out come out to to start the next cycle bit lines and also sat and sap node have to be pre-charged to vdd yes sir hello yes sir now there is an output latch down there output buffer down there yes yes yes sir if my Saturns have both are pretty charged to be ready what will the output buffer do how will it give an output there it cannot now I cannot connect hat or SAS because what happens is suppose sat went down I cannot really connect fat directly to my output buffer why because to start the next cycle I have to take it up it means my output will only get a glitch nothing else okay yes are you able to see this there is this analog circuit where the output went to zero now to start the new cycle you want to take it up you want to pre-charge it again that is when the next cycle can start but my output bus has to be driven to a desired Q value for much longer time so what do you need to do you need to put a latch in between somewhere and this is the kind of latch that is put where even if beta and bit bar both go to one the latch will regenerate its contents it's like an Sr latch so in the sense amplifier the saf and the SAT notes that were basically I were taking to this uh I was taking this output sir because it was not evident to me so from that example what was the output then okay what got Amplified from the from vdd and vdd to zero and vdd so the saf and the SAT nodes so that is the output now and so these two nodes are you taking to the latch yes okay so that was one set of sense amplifiers there are other sense amplifiers also and you can actually spend some time to understand their functionality over here what we have done is we have instead of the pmoses you remember there were pmoses there instead of the pmoses we have put capacitors what do you think is the benefit of capacitors instead of the pmos is there so uh I feel uh there is a emulate more than benefit there is a loss actually because there is BLB towards the internal role there is a delay in writing the BLB or BL B plan or bitlan bar towards the internal node actually okay what is the benefit why would one consider putting a capacitor instead of the pass gate select capacitor generally resist change in voltage right this voltage change so but I want to translate that so wouldn't it be like kind of a counterintuitive not bad because I want to translate that change to the internet is this a coupling capacitor or is there some loading capacitor coupling I think sir what does the coupling capacitor do couple the voltage from one side if you couple the voltage on the bit lines into the internal nodes okay yes sir I think DC stabilization May might be the case because Matlab we are isolating the DC voltage between the top and the bottom thing so might be the case to see the memory array you may want to operate at 1 volts because below 1 volts the memory cell will not function hmm but sense amplifier you may you can operate at 0.6 volts also because it's a circuit which can function at 0.6 volts also the last scan function in the previous design that we looked at bit line and SAS sat and sap nodes were connected with each other during the reset mode huh what that also meant was that they had to be at the same voltage you could not operate the sense amplifier at a voltage different than the memory array are you able to see this yes sir by decoupling them now you say oh even if your memory array needs to go to 
1.0 volts my sense amplifier can operate at 0.6 volts also so let us do dvfs only this VD will go low that other vdd will not go low if you save power another way to achieve a similar independence of voltage of sensor amplifier and bit lines is this one where the bit lines go to the gate of a device they are never connected to the output nodes over here thank you okay and you will see both the sense amplifiers are used any questions till here so how I'm decoupling them so I mean immediately the essay answer uh we were close the discharge kind of the decoupling the and this one so yes yeah so in the reset mode what is the status of BLB and faf so both are like pre-charged what's up yes recharge and connected because sensionable is zero so they are connected oh yes yes so now by putting a capacitor instead can they ever be connected electrically no show they can be at different voltages then yes so hmm thanks anything else oh and it is awesome why is this output lines or pre-charged in the second case in the second case yes we have P4 and P3 mosfets because you want the flats to be operational no so it's just like uh you're saying that this latch will start from VD at all times the latch will need to be pre-charged but that vdd this this vddp can be different from the vdd array over here so this could be vdtp again the voltage of the sense amplifier can be different from the voltage of the array of the bit lines okay okay so again for this also you can see a paper in my Google Scholar page you will see there's a paper on gauge couplets and simplifier there's a patent also around it so you can study that in and get a better View okay another thing that you should notice is that there is because now because now I am not worried about what the voltage of this V out and V out bar is I can actually equalize it to a cue point to its cue point so you see there are no two pmoses over here I just have an equalizer a cue Point equalized uh SRAM was found to be faster than the pre-charged rasra foreign okay so uh the last slide on sense amplifiers uh in a sense in a SRAM we have discussed that there could be say one sense amplifier per mux 4 or Max 8 huh in a dram it is not possible in a dram you have to put a sense amplifier for every column so if you have to put a mux it has to be below the center amplifier okay why can't we use a why can't we use uh a multiplexer before the sensor amplifier energy Ram so in the case we'll have uh for four columns field around single legs in that case we use that in that case you would have will have a single uh sense amplifier for four columns which violates this statement hmm so so you're talking about the dram sir so sir like dram only uh we have like a pastor so I mean uh because uh earlier when I was putting like send simplifier after the uh multiplexer I was so there was a performance degradation so sir but because uh now we have the charge thing so I think that because they're discharging I'm sort of it becomes more kind of in The Logical to place above that because that loss of charge and creating more RC maybe so think about it think about it let me give you a hint in dram when you read it is always a destructive read so we will discuss diagrams in a little you know after a few lectures don't worry we will I will never give you the answer to it and just picking your cross curiosity as of now okay okay but in a drama we have to put a sense amplifier on every column for an SRAM you can save area by putting it up to the multiplexer okay yes okay sir yes sir uh we generally say dram is uh much dense right sir it is then simplifiers we are using so how does that become dense actually is the density of a memory because of the periphery or of course the memory cell if we buy a dram will get it with a sense amplifier right memory accelerator how much areas of the periphery and how much areas of the memory array yes so let us look at it like this let us say for an for an SRAM the area of the array is 9 area of the periphery is one total area is 10. for a dram that 9 would shrink to let us say 3. two okay periphery you made from one to three also let us say three times what happened total area is now five okay yes I'm just giving you some random gross cartoon in cartoon types numbers that is not the reality even in a DRM array is much much more area than the periphery but just I am exaggerating the situation for you okay okay there are two different components for area periphery area is larger okay understood but what about the air area is so dense that overall dram is denser okay so we'll close here and we will do right driver and uh closer of the i o circuits in the next class"
AcJLjOxv44w,if I put the right driver above the marks how would it change my mux let us say we use the transmission gate marks earlier so if I put the right driver above the marks and sense amplifier is below the max how would the max change okay how would the transmission gate marks change so Transmissions there are two types of Marks One is tree type another a simple transmission gate marks where the decoding is done separately and you get the decoder address yes um yeah okay okay so as a designer how will it change anyone hello 30 of us sir uh right driver if you put it above the column decoder marks so if I if I if I want to discharge my bit line so it uh so there should be a closed loop right and like a Max even I am supposed to have this signals on at the column decoder as my uh actually I mean uh I don't know I am unable to in telling that I'm like keeping the right driver Above This column decoder imagine yeah I know see it's not obvious to you that is why I'm asking you um the course is not just about me telling you things the course is about me making you think also is it not unless you think like a designer how will you become one unless you think like a designer how will you connect the dots that I have given you so I'm insisting connect the dots um [Music] it will always do that okay it is a two-way process anyways Hannah that is not a challenge runs it uh so basically there should be no change in the column decoder as such okay sir uh write the right driver or or uh so maybe the chance foreign yes subject okay huh sorry sir anyone else don't even want to try um just you may just say yes I I think is right or that is also fine speak up [Music] okay now tell me one thing why do we need a transmission kit in the column multiplexer what if I had used only the nmos or the pmos only sir I will not be able to transfer a full zero if I have a pmos only Max and I will not be able to transfer the bit line discharge for the sense amplifier if I have a n mouse or lever that is how we put a transmission gate now if I put the right driver above the marks it is directly on the bit line do I need to transfer a full zero at all does not need to have the nmos then hmm similarly if my sense amplifier is above the max do I need to transfer vdd do I need to transfer vdd of sense amplifier do I need to transfer a analog vdd that is my question below the max from the bit line to below the max do I need to transfer something like that sir these are connected in series right they are connected in series then I mean they'll be connected in series right so you are speaking about first suppose pmos pmos machine gate is used to connect the bit line and the same amplifier now if you call it series we call it series that is your nomenclature I never use the word series anywhere you call it whatever you want to call it I have no problems but I never use the word Series so I don't know what it is in between the transmission gate and the data output which we take that's what you were seeing or above the above the transmission unit I am saying bit line transmission rate and Suns amplifier do we need a transmission gate there or can I do with only the pmos we need a transmission gate over there obviously because sir I mean uh we need a perfect Euro and perfect one right so I mean where where where do you need at the sense amplifier you need a perfect zero and a perfect one as an input hello sir I think that is why we we were using cells to sense the like minimum value so why do we need to full zero or full VPD so should do I need a full transmission get there will be transmitted to the max processor so at the max we need the transmission that will be a digital Max anyways my question is the bit line is otherwise connected to a transmission gate through which you transfer all levels of bit9 that toss down to the you know you you Multiplex any level analog level of the bit line that is the purpose of a transmission gate marks is it not yes sir once you convert it into digital then the marks can be simply uh digital marks yes it will be and gate and and gate mix that is logic so as a designer I am not worried about that as much but I'm just seeing okay can I reduce the reduce area somewhere can I do something that is where my question is coming from so do you think on the bit line I can reduce its load and keep Only One Max one one transistor not two so I mean again sorry right in right Circle we wanted in a read cycle we want to sorry I mean yeah index basically wanted animals and recycling want the pmos over there right uh I think I need an animal because since amplifiers I can I can get a full vdd and with the duel case so what did we say we want to say that there is a sense amplifier up there then we put a marks and then there is this let us say right driver here and the bit lines went to the sense amplifier and they also went to the mux so what should be there in this Max on the bit lines do I need a full transmission gate or can just an nmos do or can just a p master so which of these three should I choose that is my question sense amplifier secondary Channel yes foreign foreign um Serbia okay if this was right driver and this was essay sir then see maybe e let's see sir see okay so do you realize those decisions will also have an impact on how you would design your column decoder yes are you able to see that so tell me one thing that uh let us say let us say another case where there was this marks and both right driver and S server here do you now want to design a transmission gate like this or you would want to keep the transmission gate like this so it's not really a transmission gate here so there are again two configurations possible which one would you prefer second one sir why sir I mean in this in this uh we are getting the both possibilities right [Music] I don't see any kind of difference or actually I mean okay output from the first difference the difference is that over here this the output of the multiplexer is also shorted over here the outputs one side goes to let us say sense amplifier the other side goes to right driver okay so we can we can keep the right driver circuit and sense amplifier circuit but differently they I mean in first thing they might uh foreign because this ensemplifier is after the match then even the small differential voltages can be sensed so we can use a single inverse for the since amplifier and if the right margin is really good then we can use this for the word line as the right driver as well so what is the benefit of second configuration over the first configuration lesser areas there's exactly same two devices there were two devices in the first case there are two in the second case also so what's the diff what's the benefit of second if you say you have to go for a second what's the benefit of seconds can we say that in second read and write can be done at same time oh sorry sir we can give them both different actually I mean uh there won't be any kind of interaction you can keep them both different so what is the benefit of that so it's in second writability improves bye sir writing zero will be easy in second the first one may be writing zero so easy yeah because there is a signal will get transmitted to the bit line look there is it due to the parasitic capacitance because the junction capacitance is being parallel in the first case and the effective capacitance increases whereas in the second case it's not that yes so it's not as Junction capacitancy you need to realize that this wire will need to be routed and then it will be routed inside the sense amplifier also somewhere and this wire will go to the right driver and will be routed inside the right driver also from there by if if they were shorted then all this capacitance would be visible to both right driver and the fence amplifier when I did not shot them then right driver sees only its part of the capacitance when it wants to discharge the bit line only this thing discharges this thing can be turned off do you see that it's a first message the parasitic capacitance that's that that gets added due to the other other circuit also getting connected is much higher shared diffusion diffusion diffusion what I am saying is there is a bigger thing not just this one transistorical Junction capacitance getting added there's a lot more thing that is coming into picture sir I think rather meant if you use diffusion capacity diffusion then the capacitance reduces at that note if I'm not wrong can you use a shared diffusion between an envos and pmos no sir okay okay thank you foreign cycle so if this particular transistor is not even on if this particular transistor is not even on then what happens then only the bit line would see only this part of the capacitance yes only this part of the capacitance if it is if it is if this part is off this part is off the bit nine will see only this part of the capacitance so in both cases there will be lesser capacitance that you will have to handle you can be faster your power will be reduced a little not much but faster you will be are you able to see this so second casement imaginal area select certain those separates ultimately see anyways there was a wire going towards right driver there was a wire going towards okay sense amplifier now there are two wires okay there could be some additional metal routing required but only locally in that Max region otherwise there was any anyway two independent wires yes sir so you do not yet have that kind of a layout experience that's why these questions are coming but you will see that overall you will save on capacitance without any penalty on area actually yes so uh like I got confused I just want to clarify one thing when we are talking about the sense amplifier the signals are coming from upwards and when we are talking about right driver the signal is going up going upwards okay okay so that's so this is about trains I mean we are still reinforcing what we discussed in the last lecture okay okay we have not yet come to today's new Concepts so after that what did we discuss in the last class,https://www.youtube.com/watch?v=AcJLjOxv44w,"Link: https://www.youtube.com/watch?v=AcJLjOxv44w
Transcript: if I put the right driver above the marks how would it change my mux let us say we use the transmission gate marks earlier so if I put the right driver above the marks and sense amplifier is below the max how would the max change okay how would the transmission gate marks change so Transmissions there are two types of Marks One is tree type another a simple transmission gate marks where the decoding is done separately and you get the decoder address yes um yeah okay okay so as a designer how will it change anyone hello 30 of us sir uh right driver if you put it above the column decoder marks so if I if I if I want to discharge my bit line so it uh so there should be a closed loop right and like a Max even I am supposed to have this signals on at the column decoder as my uh actually I mean uh I don't know I am unable to in telling that I'm like keeping the right driver Above This column decoder imagine yeah I know see it's not obvious to you that is why I'm asking you um the course is not just about me telling you things the course is about me making you think also is it not unless you think like a designer how will you become one unless you think like a designer how will you connect the dots that I have given you so I'm insisting connect the dots um [Music] it will always do that okay it is a two-way process anyways Hannah that is not a challenge runs it uh so basically there should be no change in the column decoder as such okay sir uh write the right driver or or uh so maybe the chance foreign yes subject okay huh sorry sir anyone else don't even want to try um just you may just say yes I I think is right or that is also fine speak up [Music] okay now tell me one thing why do we need a transmission kit in the column multiplexer what if I had used only the nmos or the pmos only sir I will not be able to transfer a full zero if I have a pmos only Max and I will not be able to transfer the bit line discharge for the sense amplifier if I have a n mouse or lever that is how we put a transmission gate now if I put the right driver above the marks it is directly on the bit line do I need to transfer a full zero at all does not need to have the nmos then hmm similarly if my sense amplifier is above the max do I need to transfer vdd do I need to transfer vdd of sense amplifier do I need to transfer a analog vdd that is my question below the max from the bit line to below the max do I need to transfer something like that sir these are connected in series right they are connected in series then I mean they'll be connected in series right so you are speaking about first suppose pmos pmos machine gate is used to connect the bit line and the same amplifier now if you call it series we call it series that is your nomenclature I never use the word series anywhere you call it whatever you want to call it I have no problems but I never use the word Series so I don't know what it is in between the transmission gate and the data output which we take that's what you were seeing or above the above the transmission unit I am saying bit line transmission rate and Suns amplifier do we need a transmission gate there or can I do with only the pmos we need a transmission gate over there obviously because sir I mean uh we need a perfect Euro and perfect one right so I mean where where where do you need at the sense amplifier you need a perfect zero and a perfect one as an input hello sir I think that is why we we were using cells to sense the like minimum value so why do we need to full zero or full VPD so should do I need a full transmission get there will be transmitted to the max processor so at the max we need the transmission that will be a digital Max anyways my question is the bit line is otherwise connected to a transmission gate through which you transfer all levels of bit9 that toss down to the you know you you Multiplex any level analog level of the bit line that is the purpose of a transmission gate marks is it not yes sir once you convert it into digital then the marks can be simply uh digital marks yes it will be and gate and and gate mix that is logic so as a designer I am not worried about that as much but I'm just seeing okay can I reduce the reduce area somewhere can I do something that is where my question is coming from so do you think on the bit line I can reduce its load and keep Only One Max one one transistor not two so I mean again sorry right in right Circle we wanted in a read cycle we want to sorry I mean yeah index basically wanted animals and recycling want the pmos over there right uh I think I need an animal because since amplifiers I can I can get a full vdd and with the duel case so what did we say we want to say that there is a sense amplifier up there then we put a marks and then there is this let us say right driver here and the bit lines went to the sense amplifier and they also went to the mux so what should be there in this Max on the bit lines do I need a full transmission gate or can just an nmos do or can just a p master so which of these three should I choose that is my question sense amplifier secondary Channel yes foreign foreign um Serbia okay if this was right driver and this was essay sir then see maybe e let's see sir see okay so do you realize those decisions will also have an impact on how you would design your column decoder yes are you able to see that so tell me one thing that uh let us say let us say another case where there was this marks and both right driver and S server here do you now want to design a transmission gate like this or you would want to keep the transmission gate like this so it's not really a transmission gate here so there are again two configurations possible which one would you prefer second one sir why sir I mean in this in this uh we are getting the both possibilities right [Music] I don't see any kind of difference or actually I mean okay output from the first difference the difference is that over here this the output of the multiplexer is also shorted over here the outputs one side goes to let us say sense amplifier the other side goes to right driver okay so we can we can keep the right driver circuit and sense amplifier circuit but differently they I mean in first thing they might uh foreign because this ensemplifier is after the match then even the small differential voltages can be sensed so we can use a single inverse for the since amplifier and if the right margin is really good then we can use this for the word line as the right driver as well so what is the benefit of second configuration over the first configuration lesser areas there's exactly same two devices there were two devices in the first case there are two in the second case also so what's the diff what's the benefit of second if you say you have to go for a second what's the benefit of seconds can we say that in second read and write can be done at same time oh sorry sir we can give them both different actually I mean uh there won't be any kind of interaction you can keep them both different so what is the benefit of that so it's in second writability improves bye sir writing zero will be easy in second the first one may be writing zero so easy yeah because there is a signal will get transmitted to the bit line look there is it due to the parasitic capacitance because the junction capacitance is being parallel in the first case and the effective capacitance increases whereas in the second case it's not that yes so it's not as Junction capacitancy you need to realize that this wire will need to be routed and then it will be routed inside the sense amplifier also somewhere and this wire will go to the right driver and will be routed inside the right driver also from there by if if they were shorted then all this capacitance would be visible to both right driver and the fence amplifier when I did not shot them then right driver sees only its part of the capacitance when it wants to discharge the bit line only this thing discharges this thing can be turned off do you see that it's a first message the parasitic capacitance that's that that gets added due to the other other circuit also getting connected is much higher shared diffusion diffusion diffusion what I am saying is there is a bigger thing not just this one transistorical Junction capacitance getting added there's a lot more thing that is coming into picture sir I think rather meant if you use diffusion capacity diffusion then the capacitance reduces at that note if I'm not wrong can you use a shared diffusion between an envos and pmos no sir okay okay thank you foreign cycle so if this particular transistor is not even on if this particular transistor is not even on then what happens then only the bit line would see only this part of the capacitance yes only this part of the capacitance if it is if it is if this part is off this part is off the bit nine will see only this part of the capacitance so in both cases there will be lesser capacitance that you will have to handle you can be faster your power will be reduced a little not much but faster you will be are you able to see this so second casement imaginal area select certain those separates ultimately see anyways there was a wire going towards right driver there was a wire going towards okay sense amplifier now there are two wires okay there could be some additional metal routing required but only locally in that Max region otherwise there was any anyway two independent wires yes sir so you do not yet have that kind of a layout experience that's why these questions are coming but you will see that overall you will save on capacitance without any penalty on area actually yes so uh like I got confused I just want to clarify one thing when we are talking about the sense amplifier the signals are coming from upwards and when we are talking about right driver the signal is going up going upwards okay okay so that's so this is about trains I mean we are still reinforcing what we discussed in the last lecture okay okay we have not yet come to today's new Concepts so after that what did we discuss in the last class"
vxbpfM7PaDQ,up to today's session and we will close with right driver so there was this question as to what does a right driver include a right driver can be very simple my right driver can simply have just a pair of nmoses which connect the output of this driver it's on to your bid so are you able to see this in fact this is the max this can be the max signal only Max gate only right this can be called column multiplexer but right driver can be as simple as this can set a simple right driver work s um will put data and that should work is it fine inverter key okay can we have a bit nine pair now which is I can work with only one inverter now because I am kind of buffering the right data then to connecting to the other bit line why I'm doing that okay so suppose uh let us say again so that can be directly connected with the right data right so uh can we allow the memory inputs to directly go inside them and see the bit line capacitance we discussed that already do we want to do that no so bitline capacitances foreign is this right driver sufficient or do you want to do something else to it so during right operation we need BLT and MLS Bitcoin and Bitcoin bar two zero and one so as you can see there is only one latch which is uh operating and it's maintaining the same voltage towards both so sorry what did you see there and minus bit okay bit and minus bit over here will actually be driven to opposite values oh sorry yeah yes sir yes sir sorry yeah uh so should we uh include a transmission kit to write a complete one and zero on both bitline and put like um but we may want to run this we may not want to so if if I do not keep a a full transmission gate then what do I need to do I need to put a another pmos over here which is controlled by the other bit line do you think that would work yes so there are multiple ways to handle this so that this this circuit was incomplete in itself you are absolutely right we needed something some semblance of a transmission gate or we needed a pmos foreign like this okay in addition to this we already talked about right assist schemes hmm so when you design the right driver you also need to take care of Designing circuits so that your bit line can be taken to a negative uh bitline level so that you can have negative but try and write as a scheme so there are some capacitors in an advanced right drivers you will see that there are some some capacitors that are also put there there are some tracking circuitry that you may want to put there so that whichever side you want to write a zero on that side after 0 has been written and the capacitance is triggered to generate a negative bit line okay so this is a very simplistic view of a right driver and and for just for top level understanding that is fine but when you will enter into your projects and you will be making your right drivers and stuff like that then you have to take care of being able to generate negative bet9 also okay additionally there is another feature called mask or let us say bit right what this means is that in a in a full memory there could be say 72 bits suppose this memory is being used as L1 cache and there is a 73rd bit which is called Dirty Bit if my cash currency requires that some other processor has written data into the same location in another cache then I would say my caches are no longer coherent and I would put dirty bit I would want to make dirty bit equal to 1 over here I only want to write on one bit and not on the other bits this kind of a feature is called as bitrite why do I not why what is the benefit of this kind of a feature what do I save or what do I gain power and in the example that we just considered probably one cycle of this of the CPU also because now you'd say I do not need to get the required data from the other core which I had made the coherent cache made the change in the coherent cache I do not need that data I will simply put the Dirty Bit equal to 1. I will I will transfer that data only when this particular processor also requires the same information otherwise I will just put a dirty bit so you also probably save a few cycles of the processor maybe not always but at many times is that okay are we able to see this sorry actually dirty bits sorry bit right sorry you've not done something from computer architecture how many of you have done the course on computer architecture you can put a plus one in the chat window so quite a few have not done so uh in a multiprocessor architecture there could be a memory or a memory system which are so two memories three memories which are shared across uh two cores okay two processors wanting to access same data in two different memories uh let me go to whiteboard and try to explain it there foreign I have processor one I have processor 2. and they are supposed to operate and sync with each other okay they have different instructions they have different stuff coming into it but they are supposed to be in sync with each other what that also means is that the content of the memory may also require to be same now it so happens that this processor updated a particular address location over here now if when because they are to be in sync you can actually just tell this processor that by there is a dirty bit here put that Dirty Bit one and you do not need to write this new information over here at the same time why because most probably this this particular address is required only in this code there is this uh there is a set of instructions that are operating only on this part of the data this particular uh core could be working on let us say another part of the address of the contents there not the ones that the score was working on so because this score will never access or will not usually need to access this part of the data let me just write a dirty bit transmitting a Dirty Bit is much lower power for the bus is also faster for the bus and also over here I save Dynamic power because I'm just writing one bit not all the bits of the word so I save overall power and I also save transmission of all this data and therefore probably one cycle also memories basically yeah because they are supposed to be synchronized course which is definitely shared across two cores okay now this particular core updated one particular address this particular core also had the same address called over there but it was long back long long back okay so what happens is as soon as L2 cache is updated you know that this was same as L2 cache location was put in L1 cache also so you only update the Dirty Bit here you do not bring the new data from early to cache and then write it all together into this course okay are you is this is this clearest so the Dirty Bit of um yes I'll just add in the complete view there for you foreign okay so for this kind of operation you need what is called as bit right okay so this operation Whole is called as bitrate no being able to write only into one bit and not the entire word that is called bitrite or selective bits and not the entire word that is that that is called bitrite we also call it mask that the remaining 64 bits are masked only one bit I am writing into or remaining 72 bits I must only one bit I am writing into so one bit of L1 cache only I'm writing into yeah so it says Dynamic power and it also saves lots of processor Cycles many times okay so right driver is not really as simple as it appears to be here those of you venules pick up the projects you should you should Implement mask and also negative bit line in your right drivers okay sir again then it will use this uh Dirty Bit information to then fetch the data methods okay yes okay thank you sir so now let's have a quick refresh of how different memory operations happen so you remember this this graphic from earlier we said there is a word line selection that is going to happen like this and there is data that will come like this and there will be some signals that will be flowing like this you remember all this yes so now tell me before the word line gets selected which signal over here should have reached the particular i o suppose we're talking about the last IO over here bit signals should have arrived in the i o uh before the word line arrives in the array are there any sub signals foreign arrives because what we said was that before the burden arise my bedtime and bedtime bar should have been taken to zero and one levels wherever whatever was the appropriate requirement that is what we want huh yes sir friends why is it that only one or two people are speaking I am talking to the entire class um please I want I would I would be happy to have more participation so what we are essentially saying is that when we talk of all these operations read and write operational in the memory there are signals that are racing against each other over here there is a race between word line and let us say uh bit line reaching uh zero and one level before the burden arrives or let us say in the read cycle there would be a raise between before World arrives the pita should turn off yeah that kind of arrays would be there hello yes sir so now that we are looking at circuits on the periphery side we also need to be aware of the fact that there will be race conditions like preacher should go off before wordline is selected or that right driver should switch on much before Wireline has selected why much before because it has to discharge the bit line also or that sense amplifier should be enabled only after the burst pixel also has discharged sufficiently well so there are these race conditions that exist inside the memory if these race conditions are violated there could be loss of yield there could be loss of power there could be loss of performance all three things okay so as a memory designer you would need to necessarily do what is called as race analysis or marginality analysis why marginality what is the margin how how early does free charge go off before wordline arrives that's the kind of margin so we want to see what kind of margins exist inside the memory so that memory doesn't fail okay and all these margins whenever we talk about verification see whenever you talk about characterization you would do at SSA SS 1.08 volt 125 C but whenever you talk about uh these margins then you also need to check at SS 1.32 and 125. okay you also need to check at SS and Fs Lots also so when you talk of checking these margins you do not want your memory to fail in any case so all the all the different cross Corners are also tested and and verified to be fine when you do marginality analysis oh okay so large you know so margin of timing differences say does that race go uh that is why it's called marginal analysis marginality analysis but someone may also call it race analysis which which single came faster but with signal came faster with insufficient information I actually need to see what are the margins there that is why I prefer to call it marginality analysis okay so one thing to ask like for for any analysis equals condition s foreign name of course so you will notice that there are more than 20 30 conditions okay yes you can actually see uh you can actually write 30 different test vectors 30 different this and then run only on one one activity each you can do that yes sir no tolerance okay I prefer to say okay there's no harm in measuring what is the margin even on a pvt where it is not critical I would rather measure everything but reduce my work yeah yes sir sir hello yeah yeah so functionality may affect it may get affected because I may not be able to ensure keep a correct read is happening but yield to serum okay foreign you reduce the memory clock do you think you will be able to recover this cell now it's a clock see no when when you would call it a functionality issue and not an yield issue some basic operations so there is a there's an and gate something somewhere which works fine but when it is in the system because of some timing failure it doesn't work fine something like that is what you are referring to you know what you mean yeah operations that's okay you wanted to apply brakes and it accelerated the car fine with you you will sit in that car no sir no no so it's a failure yes sir now for the nand gate you could probably slow the clock and say instead of latching nand gate after 20 picoseconds I will latch it after 30 picoseconds and you could recover yield yes in the memory you can't do that in the memory the sense amplifier enable is not controlled by you it is controlled by the memory itself you slow down the clock as much the enable will still come at the same time so this is a permanent deal loss okay sir actually uh is somehow related to kind of worse bit BL um you're talking about the worst cell only okay okay faster than it should be so it's a failure um,https://www.youtube.com/watch?v=vxbpfM7PaDQ,"Link: https://www.youtube.com/watch?v=vxbpfM7PaDQ
Transcript: up to today's session and we will close with right driver so there was this question as to what does a right driver include a right driver can be very simple my right driver can simply have just a pair of nmoses which connect the output of this driver it's on to your bid so are you able to see this in fact this is the max this can be the max signal only Max gate only right this can be called column multiplexer but right driver can be as simple as this can set a simple right driver work s um will put data and that should work is it fine inverter key okay can we have a bit nine pair now which is I can work with only one inverter now because I am kind of buffering the right data then to connecting to the other bit line why I'm doing that okay so suppose uh let us say again so that can be directly connected with the right data right so uh can we allow the memory inputs to directly go inside them and see the bit line capacitance we discussed that already do we want to do that no so bitline capacitances foreign is this right driver sufficient or do you want to do something else to it so during right operation we need BLT and MLS Bitcoin and Bitcoin bar two zero and one so as you can see there is only one latch which is uh operating and it's maintaining the same voltage towards both so sorry what did you see there and minus bit okay bit and minus bit over here will actually be driven to opposite values oh sorry yeah yes sir yes sir sorry yeah uh so should we uh include a transmission kit to write a complete one and zero on both bitline and put like um but we may want to run this we may not want to so if if I do not keep a a full transmission gate then what do I need to do I need to put a another pmos over here which is controlled by the other bit line do you think that would work yes so there are multiple ways to handle this so that this this circuit was incomplete in itself you are absolutely right we needed something some semblance of a transmission gate or we needed a pmos foreign like this okay in addition to this we already talked about right assist schemes hmm so when you design the right driver you also need to take care of Designing circuits so that your bit line can be taken to a negative uh bitline level so that you can have negative but try and write as a scheme so there are some capacitors in an advanced right drivers you will see that there are some some capacitors that are also put there there are some tracking circuitry that you may want to put there so that whichever side you want to write a zero on that side after 0 has been written and the capacitance is triggered to generate a negative bit line okay so this is a very simplistic view of a right driver and and for just for top level understanding that is fine but when you will enter into your projects and you will be making your right drivers and stuff like that then you have to take care of being able to generate negative bet9 also okay additionally there is another feature called mask or let us say bit right what this means is that in a in a full memory there could be say 72 bits suppose this memory is being used as L1 cache and there is a 73rd bit which is called Dirty Bit if my cash currency requires that some other processor has written data into the same location in another cache then I would say my caches are no longer coherent and I would put dirty bit I would want to make dirty bit equal to 1 over here I only want to write on one bit and not on the other bits this kind of a feature is called as bitrite why do I not why what is the benefit of this kind of a feature what do I save or what do I gain power and in the example that we just considered probably one cycle of this of the CPU also because now you'd say I do not need to get the required data from the other core which I had made the coherent cache made the change in the coherent cache I do not need that data I will simply put the Dirty Bit equal to 1. I will I will transfer that data only when this particular processor also requires the same information otherwise I will just put a dirty bit so you also probably save a few cycles of the processor maybe not always but at many times is that okay are we able to see this sorry actually dirty bits sorry bit right sorry you've not done something from computer architecture how many of you have done the course on computer architecture you can put a plus one in the chat window so quite a few have not done so uh in a multiprocessor architecture there could be a memory or a memory system which are so two memories three memories which are shared across uh two cores okay two processors wanting to access same data in two different memories uh let me go to whiteboard and try to explain it there foreign I have processor one I have processor 2. and they are supposed to operate and sync with each other okay they have different instructions they have different stuff coming into it but they are supposed to be in sync with each other what that also means is that the content of the memory may also require to be same now it so happens that this processor updated a particular address location over here now if when because they are to be in sync you can actually just tell this processor that by there is a dirty bit here put that Dirty Bit one and you do not need to write this new information over here at the same time why because most probably this this particular address is required only in this code there is this uh there is a set of instructions that are operating only on this part of the data this particular uh core could be working on let us say another part of the address of the contents there not the ones that the score was working on so because this score will never access or will not usually need to access this part of the data let me just write a dirty bit transmitting a Dirty Bit is much lower power for the bus is also faster for the bus and also over here I save Dynamic power because I'm just writing one bit not all the bits of the word so I save overall power and I also save transmission of all this data and therefore probably one cycle also memories basically yeah because they are supposed to be synchronized course which is definitely shared across two cores okay now this particular core updated one particular address this particular core also had the same address called over there but it was long back long long back okay so what happens is as soon as L2 cache is updated you know that this was same as L2 cache location was put in L1 cache also so you only update the Dirty Bit here you do not bring the new data from early to cache and then write it all together into this course okay are you is this is this clearest so the Dirty Bit of um yes I'll just add in the complete view there for you foreign okay so for this kind of operation you need what is called as bit right okay so this operation Whole is called as bitrate no being able to write only into one bit and not the entire word that is called bitrite or selective bits and not the entire word that is that that is called bitrite we also call it mask that the remaining 64 bits are masked only one bit I am writing into or remaining 72 bits I must only one bit I am writing into so one bit of L1 cache only I'm writing into yeah so it says Dynamic power and it also saves lots of processor Cycles many times okay so right driver is not really as simple as it appears to be here those of you venules pick up the projects you should you should Implement mask and also negative bit line in your right drivers okay sir again then it will use this uh Dirty Bit information to then fetch the data methods okay yes okay thank you sir so now let's have a quick refresh of how different memory operations happen so you remember this this graphic from earlier we said there is a word line selection that is going to happen like this and there is data that will come like this and there will be some signals that will be flowing like this you remember all this yes so now tell me before the word line gets selected which signal over here should have reached the particular i o suppose we're talking about the last IO over here bit signals should have arrived in the i o uh before the word line arrives in the array are there any sub signals foreign arrives because what we said was that before the burden arise my bedtime and bedtime bar should have been taken to zero and one levels wherever whatever was the appropriate requirement that is what we want huh yes sir friends why is it that only one or two people are speaking I am talking to the entire class um please I want I would I would be happy to have more participation so what we are essentially saying is that when we talk of all these operations read and write operational in the memory there are signals that are racing against each other over here there is a race between word line and let us say uh bit line reaching uh zero and one level before the burden arrives or let us say in the read cycle there would be a raise between before World arrives the pita should turn off yeah that kind of arrays would be there hello yes sir so now that we are looking at circuits on the periphery side we also need to be aware of the fact that there will be race conditions like preacher should go off before wordline is selected or that right driver should switch on much before Wireline has selected why much before because it has to discharge the bit line also or that sense amplifier should be enabled only after the burst pixel also has discharged sufficiently well so there are these race conditions that exist inside the memory if these race conditions are violated there could be loss of yield there could be loss of power there could be loss of performance all three things okay so as a memory designer you would need to necessarily do what is called as race analysis or marginality analysis why marginality what is the margin how how early does free charge go off before wordline arrives that's the kind of margin so we want to see what kind of margins exist inside the memory so that memory doesn't fail okay and all these margins whenever we talk about verification see whenever you talk about characterization you would do at SSA SS 1.08 volt 125 C but whenever you talk about uh these margins then you also need to check at SS 1.32 and 125. okay you also need to check at SS and Fs Lots also so when you talk of checking these margins you do not want your memory to fail in any case so all the all the different cross Corners are also tested and and verified to be fine when you do marginality analysis oh okay so large you know so margin of timing differences say does that race go uh that is why it's called marginal analysis marginality analysis but someone may also call it race analysis which which single came faster but with signal came faster with insufficient information I actually need to see what are the margins there that is why I prefer to call it marginality analysis okay so one thing to ask like for for any analysis equals condition s foreign name of course so you will notice that there are more than 20 30 conditions okay yes you can actually see uh you can actually write 30 different test vectors 30 different this and then run only on one one activity each you can do that yes sir no tolerance okay I prefer to say okay there's no harm in measuring what is the margin even on a pvt where it is not critical I would rather measure everything but reduce my work yeah yes sir sir hello yeah yeah so functionality may affect it may get affected because I may not be able to ensure keep a correct read is happening but yield to serum okay foreign you reduce the memory clock do you think you will be able to recover this cell now it's a clock see no when when you would call it a functionality issue and not an yield issue some basic operations so there is a there's an and gate something somewhere which works fine but when it is in the system because of some timing failure it doesn't work fine something like that is what you are referring to you know what you mean yeah operations that's okay you wanted to apply brakes and it accelerated the car fine with you you will sit in that car no sir no no so it's a failure yes sir now for the nand gate you could probably slow the clock and say instead of latching nand gate after 20 picoseconds I will latch it after 30 picoseconds and you could recover yield yes in the memory you can't do that in the memory the sense amplifier enable is not controlled by you it is controlled by the memory itself you slow down the clock as much the enable will still come at the same time so this is a permanent deal loss okay sir actually uh is somehow related to kind of worse bit BL um you're talking about the worst cell only okay okay faster than it should be so it's a failure um"
CLWpYGaW0lA,data need loss Okay so now let's come to decoder design now it might appear to be simple or oh you just need to make a 9 to 512 output decoder um but it is not as simple actually how you design a row decoder how you design the decoding circuits has a very strong impact on how the memory is organized so for example it would Define how the words are scrambled inside the memory so what is kambling did we discuss that already huh between the living yeah better leaving so that is one aspect of it let us say there is this memory I could start to write word 0 here or I could write to start word 0 from here is that right I could have row 0 selecting the topmost row or it could be selecting the bottom most row that is a choice as a as a designer I have no yes sir or I could actually write row 0 somewhere here and then go this way and then go that way I can do whatever I wish to do as a designer are you able to see this yes sir so this is what we call as scrambling memory bit scrambling where are different words and bits corresponding to different addresses so when a particular address is asked for which row gets selected does this row get selected or this row gets selected or which column gets selected this one or this one why do you think this information is important correct read and write operation I mean um so why is this information important so apparently it seems um that is fine but why is it important why do as a designer you need to know it why would a stock designer also need to know it if at all server testing to see if it's working fine or not I mean the testing method you can simply read and write into one location and see if it was uh what you had written is what you read that is good enough sir when we select uh doubts are over here so when we select how do we see if one particular memory cell is being is being selected or not with the help of M like this select lines only right I'm like I'm sorry the row selector right row selector in the column select look at it like this I said that okay I said that this should be row 0. I said that okay however I ended up designing this to be row 0. will it change for the user anything no user sent an address for row 0 in one case this would have this row would have been written into and read or in another case this row would have been written in 200 whatever I wrote that is what I am reading for the user it is not changing anything how will the user make out whether the fault the bottommost row has been selected to the topmost row has been collected can the user Make Out no sir uh I was I was speaking from the designer perspective actually so this is another designer the designer you put something on Silicon you wrote and you read can you make out where the row was no so for any for all practical purposes do you need to know the scrambling in the practical purposes that you are telling about do you need to know that family no nature actually but then I'm still talking about scrambling and I'm saying that this is important to understand why so maybe when we program our defining memory map for peripheral sword and SOC we need this information to optimize the top system level program Maybe okay other ideas or maybe if this memory well mapping is present with us then we can uh we can choose the rows where the data has to be written uh apart which are of frequently which are frequently used so that the crosstalk can reduce something of these kind yeah so thank you Ranjit uh let me say that I was uh I I I I read the entire memory and two particular addresses failed now if I do not know the scrambling I would not know that these two addresses that are failing are actually right next to each other those rows are placed right next to each other and they are failing because there was crosstalk between them so I need scrambling information to debug that is one aspect then some of you also mentioned if I know the scrambling information I can somehow design better in the sense that I can say that there is this my entire memory there okay and that memory is split into let us say Banks so I would say that I would want to distribute my reads across Banks so that none of the banks is overly stressed so I would deter and I would write my data into different different banks even though they are consecutive data so this is word zero in One Bank word one and the other were two in third and what four in the topmost Bank or what three in the topmost rack so I know that okay I may write consecutive words but in the memory let them be spread far apart why simply because uh when I will read them again I will be reading them up and after the other then not let me not stress any One Bank too much none of the banks should be stressed too much I need four consecutive words I will I will actually access all the four Banks and uh it should be fine I would not degrade any bank I would not cause aging too much aging on any bank I would not cost too much stress on any Bank so I'm not saying you should do this what I am saying is if you know the scrambling you can start to think on these lines sir yes sir scramblings along the road right sir yeah let us say let us simply say abhi if I want to say word 0 word 1 Word to word three right next to each other in a given row huh which address bits will you send to the column marks which address which we'll send the column marks for decoding this zero one two three I want to do LSB so LSP LSB address 0 and address one huh now let me say that instead of word so this is word 0 this is word 16 this is word uh 32 this is word 48. okay now which bits are am I sending here sorry A1 3 so to select this row we we need to see I'm asking what happens in the column marks which addresses should go to the column marks for MSB MSB sir MSB why do you say MSB would be regulated to my like I have a 1K word it's stuff so I have 10 address bits MSB download how will I do how will I select among these sir it made it word 0 word 16 game is the word zero word 16 over 32.48 configuration yes sir I want to choose one of these words now what should go into this multiplexer which address bit is changing in between them amongst them is anything changing amongst the bottom four no sir what where is the change happening so in between this is 16. so this was initial was Zero Anna this is 16 this is 32 this is 48 are you able to see this so which bits would go there I mean again this was a 10-bit address oh yeah can you use MSB no no so what bits are we talking about intermediate sir okay yeah so which bits you send it to the column multiplexer will decide which words sit next to each other in a row do you see this so but why will I want to do that making so complex it I mean I can correct one what is complex on this so I mean I'm my question is why would I prefer this over say word zero words why would I prefer this I am saying how you manage the address bus can impact memory scrambling are you able to see this okay so how I'm placing the different words in the array that is kind of the scrambling and that will be impacted by how I choose to which bits I choose to select in the row and the column so the same memory rather in the same memory if I just change which pins come to the column marks decoder the words and that will the the memory scrambling would change nothing else has changed just which inputs I am connecting to the address decoder on the column side that will change the memory are you able to see this just so the memory organization will change depending on which bits I'm sending sir this example seems to be too suitable sir so if you take word number 47 over there then it will be different right where number 47 is in some other place yes it is in some other room scrambling I'm like we do the scrambling based on this uh two selections and we we first maintain any two select lines constant and we'll vary those conditions of four and according to that we make scrambling is that what you meant or uh what I mean is how you connect your address bus to different parts of your circuit will change the memory scrambling entirely that's it now depending on what your purpose is what your processor needs what your system needs you can use your address bus appropriately services already clear to you so I'm just elaborating on it yes now let's come to the back back yeah please yes so sir maybe scrambling this will be done based upon the my processor needs what exactly you can okay but you may not that's okay okay if you want to optimize something if you are a memory if you have done this course to now tomorrow when you go to wherever you go to as an architect you know okay this is possible and that is not possible someone has not done the memory design course would not be able to handle it like this are you able to see this now let us say these are my Banks suppose I want to want want to put word 0 here word one here word two here word three here which addresses 2 and which address bits do I need to use for Bank selection a0 A1 now if I say that okay word 0 word 16 word why 32 word 48 now which addresses A5 A4 so again which address bits you use for Bank selection will again Define how your words are distributed inside the memory huh are you able to see this subative bank is here I mean bank is if okay Bank means let us say you put extra i o somewhere this is hierarchical bit line architecture we will come to that a little later but take it so let me take it now because it is a part of address decoding only so let us say I had a memory which had this bigger bit line this longer bit line due to which its speed was 2 nanoseconds okay I want to operate at one nanosecond so what I do is I say oh this bit line capacitance is huge let me separate or split these bit lines into smaller bit lines each of these smaller bit lines will be associated with a sense amplifier and there will be a global line through which I will be able to give an output what happens now because the bitline capacitance that every bit cell sees is smaller this access time would come down to one nanoseconds because you have reduced the overall capacitance so this is called hierarchical bit line sir is the same as the page that we disc which that we discussed yesterday yeah that is another way of saying that okay then could be multiple such arrays which I could place next to each other and again one of the address bits would select one of the pages one of the address which would select one of the banks is this okay so uh I mean if general questions are so is so previously during television you explain that okay wiring issue here so we have scrambled that is the first place hmm that was my question sir worst issue that we are scrambling actually I mean why do you suppose we were not using mux let us say we're not using mugs 1K words 8 Bits what would be the direct pressure of your memory why did we talk about scrambling in the first place do you remember oh yes sir I mean different opposition positioning different organ we were seeing scrambling but okay before that why do we want to actually scramble that so okay okay how has how are the words placed that's it you have to place the word somewhere now if you do not want to give any scrambling information you have to place them linearly the moment you say I will fold the memory and use marks you need to tell various which word are you able to see this yes as soon as you start to use marks you have to tell enough where is which word which row which column that's it that is what we are calling about that is where the scrambling thing comes into picture in the first place now you do not only use marks you also use hierarchical bit line so now you need to know which bank is which word which is not simple so as you add as you add more complexity the array for whatever reasons you need to tell the user where is what because depending on where what is let us say a set of 20 words are failing 24 words are failing they are not consecutive words unless you know the scrambling you will not be able to make out that oh this particular sense amplifier is actually what is failing you will say oh 28 random 24 random failures are happening I do not know why but as soon as you know the scrambling you will realize oh they're all linked to one same Samsung amplifier so it is not that the wet cells are failing it is that the sense amplifier is failing yes sir yeah unable to see this that is why as a designer you should know how the words are distributed so that if there is any failure you can quickly tell oh this is the common circuit oh that is the common circuit okay sir is [Music] multiple bit lines okay smaller okay so so like each but basically kind of bank will corresponding to correspond to a certain set of uh bits of a certain set of words basically yeah okay so I would say think about these questions whatever values are used for page selection how would the scrambling change whatever msvs are used for page selection how would the scrambling change similarly we just did that I would say just stay with this thought and and do more of this uh before the next class a little bit of it before the next class okay then we'll look into it as decoding in much more detail in the next class foreign yes you will be able to localize faults and errors very quickly okay okay good guys thank you all the best and uh,https://www.youtube.com/watch?v=CLWpYGaW0lA,"Link: https://www.youtube.com/watch?v=CLWpYGaW0lA
Transcript: data need loss Okay so now let's come to decoder design now it might appear to be simple or oh you just need to make a 9 to 512 output decoder um but it is not as simple actually how you design a row decoder how you design the decoding circuits has a very strong impact on how the memory is organized so for example it would Define how the words are scrambled inside the memory so what is kambling did we discuss that already huh between the living yeah better leaving so that is one aspect of it let us say there is this memory I could start to write word 0 here or I could write to start word 0 from here is that right I could have row 0 selecting the topmost row or it could be selecting the bottom most row that is a choice as a as a designer I have no yes sir or I could actually write row 0 somewhere here and then go this way and then go that way I can do whatever I wish to do as a designer are you able to see this yes sir so this is what we call as scrambling memory bit scrambling where are different words and bits corresponding to different addresses so when a particular address is asked for which row gets selected does this row get selected or this row gets selected or which column gets selected this one or this one why do you think this information is important correct read and write operation I mean um so why is this information important so apparently it seems um that is fine but why is it important why do as a designer you need to know it why would a stock designer also need to know it if at all server testing to see if it's working fine or not I mean the testing method you can simply read and write into one location and see if it was uh what you had written is what you read that is good enough sir when we select uh doubts are over here so when we select how do we see if one particular memory cell is being is being selected or not with the help of M like this select lines only right I'm like I'm sorry the row selector right row selector in the column select look at it like this I said that okay I said that this should be row 0. I said that okay however I ended up designing this to be row 0. will it change for the user anything no user sent an address for row 0 in one case this would have this row would have been written into and read or in another case this row would have been written in 200 whatever I wrote that is what I am reading for the user it is not changing anything how will the user make out whether the fault the bottommost row has been selected to the topmost row has been collected can the user Make Out no sir uh I was I was speaking from the designer perspective actually so this is another designer the designer you put something on Silicon you wrote and you read can you make out where the row was no so for any for all practical purposes do you need to know the scrambling in the practical purposes that you are telling about do you need to know that family no nature actually but then I'm still talking about scrambling and I'm saying that this is important to understand why so maybe when we program our defining memory map for peripheral sword and SOC we need this information to optimize the top system level program Maybe okay other ideas or maybe if this memory well mapping is present with us then we can uh we can choose the rows where the data has to be written uh apart which are of frequently which are frequently used so that the crosstalk can reduce something of these kind yeah so thank you Ranjit uh let me say that I was uh I I I I read the entire memory and two particular addresses failed now if I do not know the scrambling I would not know that these two addresses that are failing are actually right next to each other those rows are placed right next to each other and they are failing because there was crosstalk between them so I need scrambling information to debug that is one aspect then some of you also mentioned if I know the scrambling information I can somehow design better in the sense that I can say that there is this my entire memory there okay and that memory is split into let us say Banks so I would say that I would want to distribute my reads across Banks so that none of the banks is overly stressed so I would deter and I would write my data into different different banks even though they are consecutive data so this is word zero in One Bank word one and the other were two in third and what four in the topmost Bank or what three in the topmost rack so I know that okay I may write consecutive words but in the memory let them be spread far apart why simply because uh when I will read them again I will be reading them up and after the other then not let me not stress any One Bank too much none of the banks should be stressed too much I need four consecutive words I will I will actually access all the four Banks and uh it should be fine I would not degrade any bank I would not cause aging too much aging on any bank I would not cost too much stress on any Bank so I'm not saying you should do this what I am saying is if you know the scrambling you can start to think on these lines sir yes sir scramblings along the road right sir yeah let us say let us simply say abhi if I want to say word 0 word 1 Word to word three right next to each other in a given row huh which address bits will you send to the column marks which address which we'll send the column marks for decoding this zero one two three I want to do LSB so LSP LSB address 0 and address one huh now let me say that instead of word so this is word 0 this is word 16 this is word uh 32 this is word 48. okay now which bits are am I sending here sorry A1 3 so to select this row we we need to see I'm asking what happens in the column marks which addresses should go to the column marks for MSB MSB sir MSB why do you say MSB would be regulated to my like I have a 1K word it's stuff so I have 10 address bits MSB download how will I do how will I select among these sir it made it word 0 word 16 game is the word zero word 16 over 32.48 configuration yes sir I want to choose one of these words now what should go into this multiplexer which address bit is changing in between them amongst them is anything changing amongst the bottom four no sir what where is the change happening so in between this is 16. so this was initial was Zero Anna this is 16 this is 32 this is 48 are you able to see this so which bits would go there I mean again this was a 10-bit address oh yeah can you use MSB no no so what bits are we talking about intermediate sir okay yeah so which bits you send it to the column multiplexer will decide which words sit next to each other in a row do you see this so but why will I want to do that making so complex it I mean I can correct one what is complex on this so I mean I'm my question is why would I prefer this over say word zero words why would I prefer this I am saying how you manage the address bus can impact memory scrambling are you able to see this okay so how I'm placing the different words in the array that is kind of the scrambling and that will be impacted by how I choose to which bits I choose to select in the row and the column so the same memory rather in the same memory if I just change which pins come to the column marks decoder the words and that will the the memory scrambling would change nothing else has changed just which inputs I am connecting to the address decoder on the column side that will change the memory are you able to see this just so the memory organization will change depending on which bits I'm sending sir this example seems to be too suitable sir so if you take word number 47 over there then it will be different right where number 47 is in some other place yes it is in some other room scrambling I'm like we do the scrambling based on this uh two selections and we we first maintain any two select lines constant and we'll vary those conditions of four and according to that we make scrambling is that what you meant or uh what I mean is how you connect your address bus to different parts of your circuit will change the memory scrambling entirely that's it now depending on what your purpose is what your processor needs what your system needs you can use your address bus appropriately services already clear to you so I'm just elaborating on it yes now let's come to the back back yeah please yes so sir maybe scrambling this will be done based upon the my processor needs what exactly you can okay but you may not that's okay okay if you want to optimize something if you are a memory if you have done this course to now tomorrow when you go to wherever you go to as an architect you know okay this is possible and that is not possible someone has not done the memory design course would not be able to handle it like this are you able to see this now let us say these are my Banks suppose I want to want want to put word 0 here word one here word two here word three here which addresses 2 and which address bits do I need to use for Bank selection a0 A1 now if I say that okay word 0 word 16 word why 32 word 48 now which addresses A5 A4 so again which address bits you use for Bank selection will again Define how your words are distributed inside the memory huh are you able to see this subative bank is here I mean bank is if okay Bank means let us say you put extra i o somewhere this is hierarchical bit line architecture we will come to that a little later but take it so let me take it now because it is a part of address decoding only so let us say I had a memory which had this bigger bit line this longer bit line due to which its speed was 2 nanoseconds okay I want to operate at one nanosecond so what I do is I say oh this bit line capacitance is huge let me separate or split these bit lines into smaller bit lines each of these smaller bit lines will be associated with a sense amplifier and there will be a global line through which I will be able to give an output what happens now because the bitline capacitance that every bit cell sees is smaller this access time would come down to one nanoseconds because you have reduced the overall capacitance so this is called hierarchical bit line sir is the same as the page that we disc which that we discussed yesterday yeah that is another way of saying that okay then could be multiple such arrays which I could place next to each other and again one of the address bits would select one of the pages one of the address which would select one of the banks is this okay so uh I mean if general questions are so is so previously during television you explain that okay wiring issue here so we have scrambled that is the first place hmm that was my question sir worst issue that we are scrambling actually I mean why do you suppose we were not using mux let us say we're not using mugs 1K words 8 Bits what would be the direct pressure of your memory why did we talk about scrambling in the first place do you remember oh yes sir I mean different opposition positioning different organ we were seeing scrambling but okay before that why do we want to actually scramble that so okay okay how has how are the words placed that's it you have to place the word somewhere now if you do not want to give any scrambling information you have to place them linearly the moment you say I will fold the memory and use marks you need to tell various which word are you able to see this yes as soon as you start to use marks you have to tell enough where is which word which row which column that's it that is what we are calling about that is where the scrambling thing comes into picture in the first place now you do not only use marks you also use hierarchical bit line so now you need to know which bank is which word which is not simple so as you add as you add more complexity the array for whatever reasons you need to tell the user where is what because depending on where what is let us say a set of 20 words are failing 24 words are failing they are not consecutive words unless you know the scrambling you will not be able to make out that oh this particular sense amplifier is actually what is failing you will say oh 28 random 24 random failures are happening I do not know why but as soon as you know the scrambling you will realize oh they're all linked to one same Samsung amplifier so it is not that the wet cells are failing it is that the sense amplifier is failing yes sir yeah unable to see this that is why as a designer you should know how the words are distributed so that if there is any failure you can quickly tell oh this is the common circuit oh that is the common circuit okay sir is [Music] multiple bit lines okay smaller okay so so like each but basically kind of bank will corresponding to correspond to a certain set of uh bits of a certain set of words basically yeah okay so I would say think about these questions whatever values are used for page selection how would the scrambling change whatever msvs are used for page selection how would the scrambling change similarly we just did that I would say just stay with this thought and and do more of this uh before the next class a little bit of it before the next class okay then we'll look into it as decoding in much more detail in the next class foreign yes you will be able to localize faults and errors very quickly okay okay good guys thank you all the best and uh"
nHTlZclihSs,foreign let us say 128 rows or in this case for example I am saying 5 and 2 rows decoding as you as you can easily understand essentially means that I am putting a nand gate you know for example that okay all these addresses for selecting Y Line 0 a 0 has to be 0 a 1 has to be 0 and so on or for selecting word line 511 all the nine address bits have to be one hmm so I have to either use a nand gate or an or gate or something like that so that I can make my decoder how to make large width decoders we already saw in DVD also but we can actually say that okay we make large large decoders by uh by splitting it into two stages okay what could those two stages be those status quo the first state is called pre-decoding the second state is called post decoding now at any point of time when we start to decode we would for example uh in this decoded a0 to a a 0 bar and a0 so this is a 0 bar and a0 buffered but what do you realize that I have not put any I have not connected a0 input directly to my nand Gates why did I not do that because of load yeah because I cannot really show a big load onto my external wins yes sir so I preferred them so even if I needed a0 I buffered it and then used inside my design so we essentially need to design a n is 2 2 raised to power n decoder if n was 2 then each of my nand Gates is to input but I need 2 raised to power nand gates are you able to see this hello yes sir yes sir now if this n was 9 as in you know 9 is to 5 and 2 decoder this would mean we're talking about five and two decoders and each each nine gate is nine stack long hmm that is not something that you want and that is what we are saying that we pre-decode the pre-d code says that if there are more address bits for example if we have four address bits we do first level of decoding through first set of dates and the second level of decoding through the second set of gates who will explain this slide to me what is happening here so like I'm more I can uh what I'm able to see is that uh they and they're kind of like two two four D pre-decoding happening uh good but after that is not evident I mean then it is going to the uh maybe kind of this uh below structure is kind of a like pre-decoding and above is the nand gates is kind of like post recording maybe yes good and and since uh there are eight kind of after pre-decoding we have kind of eight lines yes okay but there are four bits so it cannot be yes it is like kind of two to uh maybe two pre-decoding we have like two to four and maybe two such kind of pre-decodings but uh okay so we have two buses of pre-decoded addresses now okay and in the post decoder we simply merge these two buses so to select row zero what did you need you needed that a0 should be 0 a 1 should be 0 a 2 should be 0 and A3 should be 0. so if I connect this as one of the inputs I am ensuring that a 0 and a one are both zero are you able to see this and for the other input of this nand gate I have connected this line I haven't showed A2 and A3 are also 0. so I've used only two input gates at both the places now and I have a 4-bit address decoding available only so can you please adjust uh explain this again this A1 E2 is tapping at this above stage the black tab what is this one what is what does this line represent when will the sign be selected when a is equal to 0 and a 1 is also equal to 0. is it not if either of them is one this line will go to zero so this first one will be selected when a equals to zero N1 equals to say yes sir yes look at the connection of this nor gate now how is this Market connected if you look at the first nor gate it is connected to a0 where a0 is one input A1 is the other input on leaving both of them are zero will the output of nor gate be one yes sir yes similarly look at this one now only when both A2 and A3 are 0 will the output of this nor gate be one that is where this line represents yes A2 bar A3 bar the sign represents a 0 bar a 1 bar yes now you have merged or for this nand gate you took these as the inputs so what happens when I have chosen a 0 a 0 bar a 1 bar and A2 bar A3 bar as the inputs for a particular nand gate I will it this nand gate will give an output word line bar a row 0 bar when uh both of these set of inputs are all the four inputs are zero I will simply buffer it subsequently and I will have my word line yes so I mean seven a zero A1 A2 A3 will be zero then I will have this r0 yes yes this is called pre-decoding and this is called post decoding what I have essentially done is by splitting My overall decoding operation across two two levels I have reduced the stack size of my Gates there my designs will be faster and uh I will be more area efficient also probably are you able to see this sir I have a downside yes please please ask uh sir here uh why are we using active low word line selector active lower line select where no because uh if you are selecting r0 the row 0 then the row 0 is uh going to zero instead of one yeah so word line will be after like this nand gate output will be buffered and I will get the word liner okay so you buffer it through a inverter and then you are a designer see you have to see how these rates can be minimized are you able to see the inputs of these Gates as load to these nor Gates yes yes remember the discussion on logical effort and DVD yes sir so those of us who are attending MDT and did not attend the DVD course I would recommend that you watch the lecture of logical effort uh in the DVD course it's also available on the YouTube channel and uh it can it can bring you up to that we will discuss exactly this thing as to how to size uh different stages uh so that you have the best delay so now we are all that we're talking about is size these two stages such that you get the best delays are you able to see this Ranjit oh yes sir I understood that so one more thing is that are these uh connections programmable yes we'll come to that they are programmed we will come to how they are programmed okay but you can all obviously already see a trend here is it not yes sir that for some rows and this is getting selected these are the Dots here and so on so we will look at it in a little more detail later uh so so if you if you would have not used this kind of log scheme for the decoding then I would have like four stack nand Gates and total 16 and Gates Right okay so so not on not only able to able to reduce the stack and also able to read number of gates also maybe yes yes in this example you may not see that that reduction as much but overall you will see that the overall gate size and everything is reduced so when you do The Logical effort analysis you will see there's a significant gain of going through splitting this gate through two stages in fact we did that one example of Designing a eight input and gate uh in one stage and two stages and three status in in DVD so just that's exactly the same thing we are that that example was a precursor to this discussion that we wanted to have here okay so the only difference that we are uh kind of dividing different stages using different kind of gates like maybe not this you could have made that and gate also like this it doesn't matter you know how to do bubble pushing that was taught to you early much earlier just so right yeah yeah okay so now this how to do this pre-decoding should we also only use two to four pre-decoders or should we use three to eight pre-decoders and all that see these are important design decisions that you will have to make as a designer let us say you have a 10 input address bus so if you have a 10 input address bus what happens you obviously cannot make 10 input nand Gates can you no at most you may want to go to let us say four input nand Gates if you want to go to Atmos 4 and put nine Gates then how many pre-decoders do you need to put in your system if maximum nand gate stack has to be 4. how many maximum pre-decoders can you have if you want to do single stage post recording so originally I have 10 Pizza how many however number of bits you have originally that doesn't matter how many pre-decoding groups can you have if you have four input nand gates at the post decoding if my final line gate can accept four inputs how many pre-decoding groups can I have how many pre-decoders can I have I think four sir yeah see in the previous case we had we had two groups of pre-decoders uh one one was pre-decoding a0a1 and the other pre-decoder was decoding A3 and A2 so we had a two input post decoder if we can have a four input post decoder it means that we cannot have more than four pre-decoders there now you have 10 letters bits you have to distribute them amongst these uh four pre-decoders how would you distribute them would you make three pre-decoders of three to eight and one pre-decoder of one to two or you will make two pre-decoders of two to four and two pre-decorders of three to eight what would you do yes Father Yes actually I'm not getting the concept like in the previous example can you please show the previous example so here we are decoding 2 to the power 4 rows am I right or yes and to to reduce the stack we are we are doing pre-decoding and then post reporting yes okay okay so so what was your question so I was not able to get this part only then we have seen the slide and that's why okay so now how would you how would you distribute these standard aspects in the previous example we distributed into two blocks a 0 a 1 and another block of A2 A3 now you have 10 address bits how would you Club them you could do three three to eight decoders and one one two two decoder that would take care of 10 address bits or you could do 2 3 2 8 and 2 2 to 4. which one would you prefer so we can also do the five second ones right I have two to four acid is not allowed because your nine has only four inputs your nine will not function then I've already put in a constraint of four input nand gate oh yeah yes if I had not put that constraint your answer is right but over here I've already put that constraint yeah someone was saying something sir can we put uh two to four pre-decoder uh five times I think the overall output lines would be uh five into four uh to a twenty and uh if we see the second case sir uh three to eight uh uh pre-decoder it would be 16 and 8 it will be 24. so sir overall the uh uh area would be lost here I think if we if our input decoder the number of lines uh increases then I think area would be wasted good so you are saying there are 24 lines over here there are 26 lines over here and if we had two two uh four decoders five of them we would have been able to work with 20 lines absolutely right however I have already put a constraint that you can have only four input nand Gates so what to do the answer second case would be I think better because it is denser or is there any other reason uh sir I have a doubt I mean if we choose any of these two uh implementations my post decoding is basically fixed then I'm choosing the pre-decoding that is the question right yeah over here I have exit for you that you cannot go for an angle with a stack more than four so I'll fix the post decoding that it would be four input nine Gates yeah okay so do you you already see that if I use different kinds of the Coatings there is a different area that you're talking about given by number of lines but there is also a different kind of power that you're talking about if there are more lines it means every line has lesser load since every line has lesser load then what happens the power consumption reduces load reduces mean speed can also improve so the speed again the speed is a mix of two things the speed is a mix of how fast the pre-decoding is and then secondly the load on the pre-decoded outputs because that would define how fast the post decoding can be only pre-decoding impacts or can impact probably set up time post recording would typically be a part of excess time because that is where you will mix clock to address are you able to see all the three trade-offs happening in the address decoding domain now this looked at the number of address lines that is area uh Power if there are uh if you use big pre-decoders then lesser number of lines would toggle and therefore power would reduce and uh smaller pre-decoders can mean uh faster X faster set of times but because there are more number of lines and under and a long stack post decoder overall post recording may be slower hmm uh so uh what is this point so one one by eighth of flow decoder so this point can sign T28 pre-decoding yeah so if I have done three to eight pre-decoding how many row decoders how many post decoders will I connect to any one output so you see over here each output each output of this post decoders like if I consider this bus this bus of the first pre-decoder only one of the outputs of my pre-decoder connects to any one row decoder anyone post decoder are you able to see this yeah both a0 A1 bar and a0 a0 bar A1 Bar connected to this nand gate only one of them will connect attack any any in any row only one of them will connect are you able to see this so if I have a pre-decoder which has eight outputs each row will connect to one of those outputs so the total number of outputs uh total number of connections that any output would see would be rows by eight are you able to see this now so you're talking with the output r0 right these outputs oh okay okay outputs of the pre-decoder okay so that's what is meant by this anything else sir actually if I'm say a more number of rows are there so but cell load becomes more right there are more rows now we just said that there are 1K 110 address but so there are 1K rows whether I use three to eight PD code or two to four P decoder that is all that is the comparison I'm doing now this is for any instance the number of rows is already established we know how many rows we are talking about um hello sir yes so uh is there some constraint that we are supposed to do this decoding only in the two stages the pre decode on the post request can we increase and not we can we can for example when it comes to Pages then we would anyways have another stage which would decode the page exactly yeah so we can so if you really want to use uh five two to four three decoders then you can use two stages and two stage decoding at the post decoder also it will only increase delays so but if you increase the number of stages uh the delay should decrease no sir uh depends again logical effort results I know so there is an optimal number of stages that you would want to keep yeah true we arrive at that no problem that is what we will use so in the course project some of the teams would be involved in designing these uh decoding address decoding so you will have to do this logical effort analysis and and arrive at a appropriate architecture there okay okay sir in last slide sir mm-hmm let's get us I think I in uh there are four of three kind of connection here in uh in the fifth uh vertical line fifth uh nor gate output so would it create any kind of uh I think uh would it create any problem in this architecture so I didn't get it sorry I'm not even shown any connection to the fifth in or gate because I've only shown three rows r0 R1 and R3 for them we know that uh the okay sorry uh the Vanessa was the fifth one the fifth output has connections for four of them yes so what's the problem there so there are three connection to the rules uh for uh three and Gates so at same time uh three and gate would take the input from that uh flip nor so uh would it create any kind of race condition or or it could increase increase the capacitance load on the nor five five fifth North outputs so see how many how many outputs or how many row decoders will that gate 5B connected in total or sir is it for yeah so total it is four only yes whether they are connected first like as soon as you have the row 0 row and row to row three whether they are connected there itself or they are or for example for the last nor gate they will be connected for uh row 12 13 14 15. okay wherever it is connected the capacitance is going to be the same now friends yes sir in this example because I was showing the first few rows A2 bar A3 bar connection was connected everywhere but otherwise all all will be connected only four number of times the load will be same across all the four yes yes,https://www.youtube.com/watch?v=nHTlZclihSs,"Link: https://www.youtube.com/watch?v=nHTlZclihSs
Transcript: foreign let us say 128 rows or in this case for example I am saying 5 and 2 rows decoding as you as you can easily understand essentially means that I am putting a nand gate you know for example that okay all these addresses for selecting Y Line 0 a 0 has to be 0 a 1 has to be 0 and so on or for selecting word line 511 all the nine address bits have to be one hmm so I have to either use a nand gate or an or gate or something like that so that I can make my decoder how to make large width decoders we already saw in DVD also but we can actually say that okay we make large large decoders by uh by splitting it into two stages okay what could those two stages be those status quo the first state is called pre-decoding the second state is called post decoding now at any point of time when we start to decode we would for example uh in this decoded a0 to a a 0 bar and a0 so this is a 0 bar and a0 buffered but what do you realize that I have not put any I have not connected a0 input directly to my nand Gates why did I not do that because of load yeah because I cannot really show a big load onto my external wins yes sir so I preferred them so even if I needed a0 I buffered it and then used inside my design so we essentially need to design a n is 2 2 raised to power n decoder if n was 2 then each of my nand Gates is to input but I need 2 raised to power nand gates are you able to see this hello yes sir yes sir now if this n was 9 as in you know 9 is to 5 and 2 decoder this would mean we're talking about five and two decoders and each each nine gate is nine stack long hmm that is not something that you want and that is what we are saying that we pre-decode the pre-d code says that if there are more address bits for example if we have four address bits we do first level of decoding through first set of dates and the second level of decoding through the second set of gates who will explain this slide to me what is happening here so like I'm more I can uh what I'm able to see is that uh they and they're kind of like two two four D pre-decoding happening uh good but after that is not evident I mean then it is going to the uh maybe kind of this uh below structure is kind of a like pre-decoding and above is the nand gates is kind of like post recording maybe yes good and and since uh there are eight kind of after pre-decoding we have kind of eight lines yes okay but there are four bits so it cannot be yes it is like kind of two to uh maybe two pre-decoding we have like two to four and maybe two such kind of pre-decodings but uh okay so we have two buses of pre-decoded addresses now okay and in the post decoder we simply merge these two buses so to select row zero what did you need you needed that a0 should be 0 a 1 should be 0 a 2 should be 0 and A3 should be 0. so if I connect this as one of the inputs I am ensuring that a 0 and a one are both zero are you able to see this and for the other input of this nand gate I have connected this line I haven't showed A2 and A3 are also 0. so I've used only two input gates at both the places now and I have a 4-bit address decoding available only so can you please adjust uh explain this again this A1 E2 is tapping at this above stage the black tab what is this one what is what does this line represent when will the sign be selected when a is equal to 0 and a 1 is also equal to 0. is it not if either of them is one this line will go to zero so this first one will be selected when a equals to zero N1 equals to say yes sir yes look at the connection of this nor gate now how is this Market connected if you look at the first nor gate it is connected to a0 where a0 is one input A1 is the other input on leaving both of them are zero will the output of nor gate be one yes sir yes similarly look at this one now only when both A2 and A3 are 0 will the output of this nor gate be one that is where this line represents yes A2 bar A3 bar the sign represents a 0 bar a 1 bar yes now you have merged or for this nand gate you took these as the inputs so what happens when I have chosen a 0 a 0 bar a 1 bar and A2 bar A3 bar as the inputs for a particular nand gate I will it this nand gate will give an output word line bar a row 0 bar when uh both of these set of inputs are all the four inputs are zero I will simply buffer it subsequently and I will have my word line yes so I mean seven a zero A1 A2 A3 will be zero then I will have this r0 yes yes this is called pre-decoding and this is called post decoding what I have essentially done is by splitting My overall decoding operation across two two levels I have reduced the stack size of my Gates there my designs will be faster and uh I will be more area efficient also probably are you able to see this sir I have a downside yes please please ask uh sir here uh why are we using active low word line selector active lower line select where no because uh if you are selecting r0 the row 0 then the row 0 is uh going to zero instead of one yeah so word line will be after like this nand gate output will be buffered and I will get the word liner okay so you buffer it through a inverter and then you are a designer see you have to see how these rates can be minimized are you able to see the inputs of these Gates as load to these nor Gates yes yes remember the discussion on logical effort and DVD yes sir so those of us who are attending MDT and did not attend the DVD course I would recommend that you watch the lecture of logical effort uh in the DVD course it's also available on the YouTube channel and uh it can it can bring you up to that we will discuss exactly this thing as to how to size uh different stages uh so that you have the best delay so now we are all that we're talking about is size these two stages such that you get the best delays are you able to see this Ranjit oh yes sir I understood that so one more thing is that are these uh connections programmable yes we'll come to that they are programmed we will come to how they are programmed okay but you can all obviously already see a trend here is it not yes sir that for some rows and this is getting selected these are the Dots here and so on so we will look at it in a little more detail later uh so so if you if you would have not used this kind of log scheme for the decoding then I would have like four stack nand Gates and total 16 and Gates Right okay so so not on not only able to able to reduce the stack and also able to read number of gates also maybe yes yes in this example you may not see that that reduction as much but overall you will see that the overall gate size and everything is reduced so when you do The Logical effort analysis you will see there's a significant gain of going through splitting this gate through two stages in fact we did that one example of Designing a eight input and gate uh in one stage and two stages and three status in in DVD so just that's exactly the same thing we are that that example was a precursor to this discussion that we wanted to have here okay so the only difference that we are uh kind of dividing different stages using different kind of gates like maybe not this you could have made that and gate also like this it doesn't matter you know how to do bubble pushing that was taught to you early much earlier just so right yeah yeah okay so now this how to do this pre-decoding should we also only use two to four pre-decoders or should we use three to eight pre-decoders and all that see these are important design decisions that you will have to make as a designer let us say you have a 10 input address bus so if you have a 10 input address bus what happens you obviously cannot make 10 input nand Gates can you no at most you may want to go to let us say four input nand Gates if you want to go to Atmos 4 and put nine Gates then how many pre-decoders do you need to put in your system if maximum nand gate stack has to be 4. how many maximum pre-decoders can you have if you want to do single stage post recording so originally I have 10 Pizza how many however number of bits you have originally that doesn't matter how many pre-decoding groups can you have if you have four input nand gates at the post decoding if my final line gate can accept four inputs how many pre-decoding groups can I have how many pre-decoders can I have I think four sir yeah see in the previous case we had we had two groups of pre-decoders uh one one was pre-decoding a0a1 and the other pre-decoder was decoding A3 and A2 so we had a two input post decoder if we can have a four input post decoder it means that we cannot have more than four pre-decoders there now you have 10 letters bits you have to distribute them amongst these uh four pre-decoders how would you distribute them would you make three pre-decoders of three to eight and one pre-decoder of one to two or you will make two pre-decoders of two to four and two pre-decorders of three to eight what would you do yes Father Yes actually I'm not getting the concept like in the previous example can you please show the previous example so here we are decoding 2 to the power 4 rows am I right or yes and to to reduce the stack we are we are doing pre-decoding and then post reporting yes okay okay so so what was your question so I was not able to get this part only then we have seen the slide and that's why okay so now how would you how would you distribute these standard aspects in the previous example we distributed into two blocks a 0 a 1 and another block of A2 A3 now you have 10 address bits how would you Club them you could do three three to eight decoders and one one two two decoder that would take care of 10 address bits or you could do 2 3 2 8 and 2 2 to 4. which one would you prefer so we can also do the five second ones right I have two to four acid is not allowed because your nine has only four inputs your nine will not function then I've already put in a constraint of four input nand gate oh yeah yes if I had not put that constraint your answer is right but over here I've already put that constraint yeah someone was saying something sir can we put uh two to four pre-decoder uh five times I think the overall output lines would be uh five into four uh to a twenty and uh if we see the second case sir uh three to eight uh uh pre-decoder it would be 16 and 8 it will be 24. so sir overall the uh uh area would be lost here I think if we if our input decoder the number of lines uh increases then I think area would be wasted good so you are saying there are 24 lines over here there are 26 lines over here and if we had two two uh four decoders five of them we would have been able to work with 20 lines absolutely right however I have already put a constraint that you can have only four input nand Gates so what to do the answer second case would be I think better because it is denser or is there any other reason uh sir I have a doubt I mean if we choose any of these two uh implementations my post decoding is basically fixed then I'm choosing the pre-decoding that is the question right yeah over here I have exit for you that you cannot go for an angle with a stack more than four so I'll fix the post decoding that it would be four input nine Gates yeah okay so do you you already see that if I use different kinds of the Coatings there is a different area that you're talking about given by number of lines but there is also a different kind of power that you're talking about if there are more lines it means every line has lesser load since every line has lesser load then what happens the power consumption reduces load reduces mean speed can also improve so the speed again the speed is a mix of two things the speed is a mix of how fast the pre-decoding is and then secondly the load on the pre-decoded outputs because that would define how fast the post decoding can be only pre-decoding impacts or can impact probably set up time post recording would typically be a part of excess time because that is where you will mix clock to address are you able to see all the three trade-offs happening in the address decoding domain now this looked at the number of address lines that is area uh Power if there are uh if you use big pre-decoders then lesser number of lines would toggle and therefore power would reduce and uh smaller pre-decoders can mean uh faster X faster set of times but because there are more number of lines and under and a long stack post decoder overall post recording may be slower hmm uh so uh what is this point so one one by eighth of flow decoder so this point can sign T28 pre-decoding yeah so if I have done three to eight pre-decoding how many row decoders how many post decoders will I connect to any one output so you see over here each output each output of this post decoders like if I consider this bus this bus of the first pre-decoder only one of the outputs of my pre-decoder connects to any one row decoder anyone post decoder are you able to see this yeah both a0 A1 bar and a0 a0 bar A1 Bar connected to this nand gate only one of them will connect attack any any in any row only one of them will connect are you able to see this so if I have a pre-decoder which has eight outputs each row will connect to one of those outputs so the total number of outputs uh total number of connections that any output would see would be rows by eight are you able to see this now so you're talking with the output r0 right these outputs oh okay okay outputs of the pre-decoder okay so that's what is meant by this anything else sir actually if I'm say a more number of rows are there so but cell load becomes more right there are more rows now we just said that there are 1K 110 address but so there are 1K rows whether I use three to eight PD code or two to four P decoder that is all that is the comparison I'm doing now this is for any instance the number of rows is already established we know how many rows we are talking about um hello sir yes so uh is there some constraint that we are supposed to do this decoding only in the two stages the pre decode on the post request can we increase and not we can we can for example when it comes to Pages then we would anyways have another stage which would decode the page exactly yeah so we can so if you really want to use uh five two to four three decoders then you can use two stages and two stage decoding at the post decoder also it will only increase delays so but if you increase the number of stages uh the delay should decrease no sir uh depends again logical effort results I know so there is an optimal number of stages that you would want to keep yeah true we arrive at that no problem that is what we will use so in the course project some of the teams would be involved in designing these uh decoding address decoding so you will have to do this logical effort analysis and and arrive at a appropriate architecture there okay okay sir in last slide sir mm-hmm let's get us I think I in uh there are four of three kind of connection here in uh in the fifth uh vertical line fifth uh nor gate output so would it create any kind of uh I think uh would it create any problem in this architecture so I didn't get it sorry I'm not even shown any connection to the fifth in or gate because I've only shown three rows r0 R1 and R3 for them we know that uh the okay sorry uh the Vanessa was the fifth one the fifth output has connections for four of them yes so what's the problem there so there are three connection to the rules uh for uh three and Gates so at same time uh three and gate would take the input from that uh flip nor so uh would it create any kind of race condition or or it could increase increase the capacitance load on the nor five five fifth North outputs so see how many how many outputs or how many row decoders will that gate 5B connected in total or sir is it for yeah so total it is four only yes whether they are connected first like as soon as you have the row 0 row and row to row three whether they are connected there itself or they are or for example for the last nor gate they will be connected for uh row 12 13 14 15. okay wherever it is connected the capacitance is going to be the same now friends yes sir in this example because I was showing the first few rows A2 bar A3 bar connection was connected everywhere but otherwise all all will be connected only four number of times 
the load will be same across all the four yes yes"
0inc_Yr_OQU,questions so now once you have chosen chosen that I could I would want to go for uh two to four free decoder or c2a pre-decoder or every assessing huh you can't decide on whether you want to use static decoding or dynamic decoding static decoding is simple and it is robust to to reduce setup time you know you will end up using slightly bigger sizes probably at times and stuff like that and overall system would be because static static Gates have larger area than Dynamic Gates so static would be larger possibly a little more power than the dynamic decoding and the dynamic decoding as we discussed earlier also the total number of connections that any output would see so this is I'm just showing Dynamic post decoding over here so I have routed the clock but you see now the addresses are no longer required to go to the pmoses so I save capacitance and I save power and I save area as I reduce capacitance I also improve performance so typically you will see that in memories there will be a mix of static decoding and dynamic decoding in applications such as Automotive applications where safety is a very big concern you probably would not want to go to Dynamic decoding at all because of these challenges that we have with Dynamic Gates otherwise if the if the reliability reliability if the if the error sensitivity is not that high you can actually go for dynamic decoding but then tell me one thing do you want nor based decoding or non-based decoding what is preferred so nor based decoding more based recording is preferred by sir maybe the inmost stack whichever it is said uh all the and Moses will be parallel so the signal there is no need for the signal to travel along the entire stack as in case of net certainly faster for sure yes what is the loss then run it so area loss is there so area loss why area will be same yourself for both nor based and Land Based uh not necessarily I'm making this Dynamic nand then because in a nor case the stack size would be less a three input nor would have let us say three units of area but if I have a c input stack uh so it's a0 A1 and A2 a stack of four there then the area would be say a little more because I need to make all my devices larger for same delay or similar delay okay oh yes sir so we can't say that normal area that is not an obvious outcome in nor if there is any glitch on the input side then our output might get uh and like it might get discharged when my clock is high okay so it is it is more sensitive to noise yes even this one is the glitch need not come on a 0 A1 the noise would come directly on the output and it would be sensitive but nor would be more sensitive what else what are the what are the shortcomings of nor see uh being Dynamic Gates they're always three charged to one the output is always pre-charged to one am I right yes sir in a nor case you you would want to discharge all the all those address bits where there is even a single one in the addresses uh and only one of the rows the output would not discharge are you able to see this so if there are 1K decoders 1023 decoders out of them will have this this node X let us say we call this node as the internal node as X for one zero two three out of one zero two four cases this x naught would discharge in the nor setting whereas in the nand setting only one of them will discharge so so this is not clear sir I mean so why it will discharge for that how does nor function nor says any one of them is one this charge the output and give the output to be zero is that not yes yes sir so when you make the address bus you'd you would want so what happens is someone would be one anyways for one zero two three out of one zero two four rows finally you want to select only one Rona so accept that one row one zero two three rows some some of the at least a few of these n masses would be one it means all those one three one zero two three would discharge how does an and operate on the other hand says only when both are one only in that case I have a discharge this would be the case only for one row so only one row will consume Dynamic power in nor every row except the selected one will consume Dynamic power so but the tail and Moss will stop that discharge right if because only evaluated so once the clock comes all the 1K cells will discharge okay as soon as the clock comes one zero two three out of one zero two four voltage charge are you able to see this yes there's a probability so the power penalty is so prohibitive so prohibitive that unless you're really dying for that kind of speed and and you will notice that the speed is not very different you can simply size this up a bit and you can recover and get the similar speed you can do pre-decoding and post recording in such a way that the final and gate stack is not very tall and everything there are ways to design these nand gates in such a way that the overall stacking is reduced but the power consumption in the nor is so high that you do not want to use it unless you are dying for Speed okay so what we have just looked looked at in this section is uh how to split the decoding in hierarchical architectures as we said you could split them across rows and you would call them hierarchical bit lines or you could split them across word lines and you would call them as pages so banks are pages then how is the area timing power performance PPA you know different across these various hierarchical decisions then what about pre-decoders two to four pre decoders or three to eight pre-decoders each has a different impact on area different impact on Power and also performance then what makes a static and dynamic Gates Used what kind of final decoder do you want the final decoder to be static Dynamic what is the application or what is the product in which Your Design is going to be used if it is Automotive for example their safety is a very big concern you do not want to accept any failure you want to have a extremely extremely high noise immunity you would want to go for static decoding completely no no Dynamic decoding anywhere so any questions around this this is what we have already discussed oh sir actually when you were discussing the two to 40 core pre-decoder and the three two decoder then the area power kind of trade-off was evident but so the access time how that was not evident because how I am reducing is it at the pre-decoding level or at the because of the post decoding effect it has that is to discuss now if we have smaller pre-decoders and the setup time would be less but because of more number of lines the nand gate and the post recording will be longer so the access time would get impacted we talked about this uh so I mean pre when I'm using uh say two to four pre-decoder then my pre decoding is faster but post recording is kind of slow can be slower because you increase the stack size in your post decoder okay so like uh then finally how would be evaluating basically the PPA you tell me how would you do which tools you have what tools you do you have what have I taught you to to be able to do this we already done a tool have we just talked about it also in the class so logical effort yeah logical effort tells you exactly the same thing now how is the delay and how is the area changing ah yes yes sir area deleted office yeah it gives you the area performance rate of you use that okay so but one thing was also there key depending upon say I say use a smaller pre-decoding then I was maybe thinking that when you are tapping you know for the Post recording or tapping at certain lines right so that will also change so yeah when we accounted for so but will that load also impact the kind of post recording yes okay if that is what I am showing on this slide how do you size so you have to estimate all the loads including metal load and device load you have to size the final driver in such a way that uh see if my word line capacitance IS 250 ventofarads um you may think that okay for 100 front of Harris I had a row decoder final driver size of 10 microns by 5 microns for 250 I will go to 25 and 12.5 that's 2.5 times so I will just increase the size 2.5 times but you will see it won't work why because due to self loading some performance again would be limited then there is a huge RC component when I'm talking about 250 fento farads of capacitive load the void line is a very thin wire there is also a huge resistance if it comes to 250 front of herods of capacitive load then the resistance would also be significantly High so this RC will limit any gains that you may want to have because of larger post decoder so the final driving size has to be done carefully and leakage is one of the very very big criteria to Define how to size this driver so the entire remaining part of the road decoder could be lvt low VT huh but the final driver will be high VT because how many final drivers are there if it is a 1K row memory instance then they have 1K void line drivers and and if you make them very very big they are going to leak terribly bad so even as you make them big you make them lvt or you make them high VT also so that at least their leakage comes under control you get you get a good performance but the leakage comes under control okay then in logical effort we also saw that tapering would help and uh buffering would help so uh we also discussed that uh the stage ratio that you may want to keep for such loaded RC lines need not be two or three it can be as good as five or six also so that you don't waste leakage you don't waste area and there is minimal power minimal performance impact we looked at that aspect also so again I understand that how many of you have not done the course on DVD the DVD course can you just put a plus one in the chat window okay so at least everyone in the class who's present in the class today has done that course but those of you are not in the class but would want to study from the lectures I would say you will have to watch one more extra video now which is The Logical effort video okay so just one thing so are you calling the word line signal as the global signals here no I'm also calling the pre-decoding outputs AS Global signals okay now wordline is all definitely a global signal but even pre-recorded outputs are Global signals okay so see typically what is done is we saw you know in the previous example I just showed that there are these four lines and then there is a tapping done like this and then there is a nand gate where this is connected and so on um so in reality in reality what is done is uh the stepping like this nand gate is designed like this so there is this pmos which would get the clock and then the nmoses are placed something like this so that they connect to a0 A1 so what is happening over here a 0 bar a 1 bar a two bar A3 bar so this is word line zero this one is word line one word line two word line three and so on are you able to see this so This precharge Bar can also be considered as clock clock for the dynamic Gates there so the the dot that was shown there could actually simply mean that there is a there is a mosfet placed beneath that line so what am I doing I am doing I am doing uh programation by placing a device under a line wherever it is needed are you able to see this any questions this is one kind of programmation so here uh so here uh as we are connecting the presets to the pivots the Pima should be weaker than the inmost stack right uh so Ranjit this is dynamic gate so when the clock comes the pmos will anyway turn off okay correct yes sir I know yes the clock comes we must automatically so we're not talking talking about ratio design over here so but in you usually in the dynamic uh Dynamic Gates we uh placed a a restorer right weak restarts a week restart they would be a restaurant also but that is not a so that I'm only showing programmation over here and it so there will be many other things there would be buffers also there would be so many things [Music] will be there there will be an inverter also at the output of our line something all those things will be there okay just to show the programmation path,https://www.youtube.com/watch?v=0inc_Yr_OQU,"Link: https://www.youtube.com/watch?v=0inc_Yr_OQU
Transcript: questions so now once you have chosen chosen that I could I would want to go for uh two to four free decoder or c2a pre-decoder or every assessing huh you can't decide on whether you want to use static decoding or dynamic decoding static decoding is simple and it is robust to to reduce setup time you know you will end up using slightly bigger sizes probably at times and stuff like that and overall system would be because static static Gates have larger area than Dynamic Gates so static would be larger possibly a little more power than the dynamic decoding and the dynamic decoding as we discussed earlier also the total number of connections that any output would see so this is I'm just showing Dynamic post decoding over here so I have routed the clock but you see now the addresses are no longer required to go to the pmoses so I save capacitance and I save power and I save area as I reduce capacitance I also improve performance so typically you will see that in memories there will be a mix of static decoding and dynamic decoding in applications such as Automotive applications where safety is a very big concern you probably would not want to go to Dynamic decoding at all because of these challenges that we have with Dynamic Gates otherwise if the if the reliability reliability if the if the error sensitivity is not that high you can actually go for dynamic decoding but then tell me one thing do you want nor based decoding or non-based decoding what is preferred so nor based decoding more based recording is preferred by sir maybe the inmost stack whichever it is said uh all the and Moses will be parallel so the signal there is no need for the signal to travel along the entire stack as in case of net certainly faster for sure yes what is the loss then run it so area loss is there so area loss why area will be same yourself for both nor based and Land Based uh not necessarily I'm making this Dynamic nand then because in a nor case the stack size would be less a three input nor would have let us say three units of area but if I have a c input stack uh so it's a0 A1 and A2 a stack of four there then the area would be say a little more because I need to make all my devices larger for same delay or similar delay okay oh yes sir so we can't say that normal area that is not an obvious outcome in nor if there is any glitch on the input side then our output might get uh and like it might get discharged when my clock is high okay so it is it is more sensitive to noise yes even this one is the glitch need not come on a 0 A1 the noise would come directly on the output and it would be sensitive but nor would be more sensitive what else what are the what are the shortcomings of nor see uh being Dynamic Gates they're always three charged to one the output is always pre-charged to one am I right yes sir in a nor case you you would want to discharge all the all those address bits where there is even a single one in the addresses uh and only one of the rows the output would not discharge are you able to see this so if there are 1K decoders 1023 decoders out of them will have this this node X let us say we call this node as the internal node as X for one zero two three out of one zero two four cases this x naught would discharge in the nor setting whereas in the nand setting only one of them will discharge so so this is not clear sir I mean so why it will discharge for that how does nor function nor says any one of them is one this charge the output and give the output to be zero is that not yes yes sir so when you make the address bus you'd you would want so what happens is someone would be one anyways for one zero two three out of one zero two four rows finally you want to select only one Rona so accept that one row one zero two three rows some some of the at least a few of these n masses would be one it means all those one three one zero two three would discharge how does an and operate on the other hand says only when both are one only in that case I have a discharge this would be the case only for one row so only one row will consume Dynamic power in nor every row except the selected one will consume Dynamic power so but the tail and Moss will stop that discharge right if because only evaluated so once the clock comes all the 1K cells will discharge okay as soon as the clock comes one zero two three out of one zero two four voltage charge are you able to see this yes there's a probability so the power penalty is so prohibitive so prohibitive that unless you're really dying for that kind of speed and and you will notice that the speed is not very different you can simply size this up a bit and you can recover and get the similar speed you can do pre-decoding and post recording in such a way that the final and gate stack is not very tall and everything there are ways to design these nand gates in such a way that the overall stacking is reduced but the power consumption in the nor is so high that you do not want to use it unless you are dying for Speed okay so what we have just looked looked at in this section is uh how to split the decoding in hierarchical architectures as we said you could split them across rows and you would call them hierarchical bit lines or you could split them across word lines and you would call them as pages so banks are pages then how is the area timing power performance PPA you know different across these various hierarchical decisions then what about pre-decoders two to four pre decoders or three to eight pre-decoders each has a different impact on area different impact on Power and also performance then what makes a static and dynamic Gates Used what kind of final decoder do you want the final decoder to be static Dynamic what is the application or what is the product in which Your Design is going to be used if it is Automotive for example their safety is a very big concern you do not want to accept any failure you want to have a extremely extremely high noise immunity you would want to go for static decoding completely no no Dynamic decoding anywhere so any questions around this this is what we have already discussed oh sir actually when you were discussing the two to 40 core pre-decoder and the three two decoder then the area power kind of trade-off was evident but so the access time how that was not evident because how I am reducing is it at the pre-decoding level or at the because of the post decoding effect it has that is to discuss now if we have smaller pre-decoders and the setup time would be less but because of more number of lines the nand gate and the post recording will be longer so the access time would get impacted we talked about this uh so I mean pre when I'm using uh say two to four pre-decoder then my pre decoding is faster but post recording is kind of slow can be slower because you increase the stack size in your post decoder okay so like uh then finally how would be evaluating basically the PPA you tell me how would you do which tools you have what tools you do you have what have I taught you to to be able to do this we already done a tool have we just talked about it also in the class so logical effort yeah logical effort tells you exactly the same thing now how is the delay and how is the area changing ah yes yes sir area deleted office yeah it gives you the area performance rate of you use that okay so but one thing was also there key depending upon say I say use a smaller pre-decoding then I was maybe thinking that when you are tapping you know for the Post recording or tapping at certain lines right so that will also change so yeah when we accounted for so but will that load also impact the kind of post recording yes okay if that is what I am showing on this slide how do you size so you have to estimate all the loads including metal load and device load you have to size the final driver in such a way that uh see if my word line capacitance IS 250 ventofarads um you may think that okay for 100 front of Harris I had a row decoder final driver size of 10 microns by 5 microns for 250 I will go to 25 and 12.5 that's 2.5 times so I will just increase the size 2.5 times but you will see it won't work why because due to self loading some performance again would be limited then there is a huge RC component when I'm talking about 250 fento farads of capacitive load the void line is a very thin wire there is also a huge resistance if it comes to 250 front of herods of capacitive load then the resistance would also be significantly High so this RC will limit any gains that you may want to have because of larger post decoder so the final driving size has to be done carefully and leakage is one of the very very big criteria to Define how to size this driver so the entire remaining part of the road decoder could be lvt low VT huh but the final driver will be high VT because how many final drivers are there if it is a 1K row memory instance then they have 1K void line drivers and and if you make them very very big they are going to leak terribly bad so even as you make them big you make them lvt or you make them high VT also so that at least their leakage comes under control you get you get a good performance but the leakage comes under control okay then in logical effort we also saw that tapering would help and uh buffering would help so uh we also discussed that uh the stage ratio that you may want to keep for such loaded RC lines need not be two or three it can be as good as five or six also so that you don't waste leakage you don't waste area and there is minimal power minimal performance impact we looked at that aspect also so again I understand that how many of you have not done the course on DVD the DVD course can you just put a plus one in the chat window okay so at least everyone in the class who's present in the class today has done that course but those of you are not in the class but would want to study from the lectures I would say you will have to watch one more extra video now which is The Logical effort video okay so just one thing so are you calling the word line signal as the global signals here no I'm also calling the pre-decoding outputs AS Global signals okay now wordline is all definitely a global signal but even pre-recorded outputs are Global signals okay so see typically what is done is we saw you know in the previous example I just showed that there are these four lines and then there is a tapping done like this and then there is a nand gate where this is connected and so on um so in reality in reality what is done is uh the stepping like this nand gate is designed like this so there is this pmos which would get the clock and then the nmoses are placed something like this so that they connect to a0 A1 so what is happening over here a 0 bar a 1 bar a two bar A3 bar so this is word line zero this one is word line one word line two word line three and so on are you able to see this so This precharge Bar can also be considered as clock clock for the dynamic Gates there so the the dot that was shown there could actually simply mean that there is a there is a mosfet placed beneath that line so what am I doing I am doing I am doing uh programation by placing a device under a line wherever it is needed are you able to see this any questions this is one kind of programmation so here uh so here uh as we are connecting the presets to the pivots the Pima should be weaker than the inmost stack right uh so Ranjit this is dynamic gate so when the clock comes the pmos will anyway turn off okay correct yes sir I know yes the clock comes we must automatically so we're not talking talking about ratio design over here so but in you usually in the dynamic uh Dynamic Gates we uh placed a a restorer right weak restarts a week restart they would be a restaurant also but that is not a so that I'm only showing programmation over here and it so there will be many other things there would be buffers also there would be so many things [Music] will be there there will be an inverter also at the output of our line something all those things will be there okay just to show the programmation path"
CcFqYYi4CWU,so what am I saying I am saying that depending on which row is to be selected I will actually place my gate you see what is happening when I put my poly over here this line got connected when I place my device over here this time got connected then this line got connected then the sign got connected and so on this is fine or do you see any challenge there foreign foreign over here also how will you share this diffusion it's not happening hello so what else anyone who knows about annual proximity effect no one has heard about annual proximity effects see we discussed about the fabrication process in our in our previous uh course so how are anvils fabricated who can describe that to me [Music] congratulations foreign implantation no you first need to uh use photos to remove that layer okay we have a photo as a then you will expose this and you will remove photos from some places and then you will do implantation yes so let us say this is where you want to make uh this is where you do not want those angles or let us say this is where you want and this could be okay so what happens in reality the boundaries of these Wells this this h is done at a slant will anyways happen at a stand because of the depth yeah and isotope an isotropic huh so what happens is that when you do an implantation they will be ions that will fall like this those that are falling on this line on this Edge would get reflected are you able to see this so I wanted my doping to be of one particular level that there should be only say in in this unit area I actually wanted only four uh ions to go but due to reflection how many ions are going now in this 47 7 are going so what has happened the doping of my P will and my unwell has changed yes so when the doping scene is what happens the ease with which I can make my inversion layer or anything would change so what happens the VT would be different so what has observed is that in a layout if there are transistors which are placed very close to an annual boundary let us say this is the annual boundary you know then this transistor would have a different VT than this one and this is known as envelope proximity effect a well proximity effect sorry wpe okay so what we need to do is we say that I do not like this Behavior where in some post decoders there is more proximity effect and in others there is lesser so you're talking about the same bus but in the same bus some have more proximity effects some have less approximity effect I don't like this so this the farther bus is far away may not bother me but this bus which is close to the end well this is a moderation for me I don't like this so what I do is this particular bus I put all the nmoses equidistant from the envelope but then how do I do the programmation I do the programmation by running a vertical metal uh running a horizontal metal and then putting vrs or contacts like this to achieve the desired functionality again are you able to see this hello so over here so in in the first instance in this particular example what was reprogramming depending on which row I am talking about I was placing this cell somewhere this device I was I was placing devices whereas in this one I am placing vrs so this is via programmation now again do not confuse it or do not uh do not confuse it with the ROM programming because that is not what the intent is the user cannot change the programmation at any point of time this is internal to the memory but over here we are programming only through vrs and the DRC rules that we need to manage could be much simpler than if I would Place devices like that okay so I would prefer to program with vrs over here so what I could do is I could make a cluster of forward lines each this part would be static this part would also be static and in fact what I could do is instead of running my metal horizontally I could simply have one vertical metal and one horizontal metal instead of four horizontal Metals there so instead of making the first part of four different cells I could just make one cell where this is my my cell boundary you may say any questions sir when you are moving to this another metal layer so this you're doing a VR programmation but then you said that we can uh using uh for using separate devices you for the each kind of block we are using each one device only sorry so like when you when earlier you were using the device programmation right you were placing devices yeah we just kept them at equal distance from the envelope yes sir that was so see I could make four cells or I could I could still make just one cell and program this and mass and this VR two things per cell I could do this or I could say that see this this Arrangement is constant so instead of programming this Arrangement also let me Define one cell such that it has four word lines as the output okay and then in every cell this this Arrangement is static only thing that I now need to program is these vrs is this clear till here [Music] see I have to program both the buses now I have to connect a zero A1 bus also and A2 A3 bus also yes sir yes sir so in one case I say I will program both simultaneously yes in another case I say okay let me use clusters of four rows and and Define a cell or Define a repetitive block which has a four rows in it so minimum increment on any row decoder could be four rows you cannot have a 33 row instance you can only have 32 or 36 row instance when I do that what happens I have made this Proclamation fixed now this no longer needs to be a programmation I can actually design it like this right so okay now if I have to design it like this I designed it now look at it over here there are four I have made four horizontal metal lines and I am placing four vrs it may it may appear that oh I don't need to really put phobias I can actually have just one vertical line connecting to all the gates okay connecting to all these Gates and only one horizontal line which would connect to a VR the other three horizontal lines are not needed and I would save overall capacitance on This Global line submit like uh putting program connecting via only on one vertical line I will have one third line connection right but for the rest of how will we managing the rest word lines if there's a vertical line that I am running here I can connect all four now press anyways I am connecting all four together anyways getting shorter with the same line do you see this okay yeah right right yes sir yes yeah got it so so I can actually reduce overall capacitance of the global lines so see address decoding is not simply a two to four decoder and three to eight decoder decision the layout also has a very significant impact on your sizing finally so when you design the layouts in your projects you have to be careful about what is what is happening on the overall scheme of things there what is happening to the other other stages of my design elsewhere okay okay uh like metal vertical running a vertical vertical metal is kind of less as compared to like programming for vrs but it's not just four vrs look at it over here as of now I have four horizontal lines and then four vrs what I am saying is replace it with one horizontal line one vertical line and one via that we are could be here here here or here so overall metal is lesser moreover if you in the row decoder as the overall height uh will be much lesser than the width the width that you will need to travel the rough current number of beer would be uh same as previous no there will be only one so over here we have all dropped here in the next rows the VR was dropped here in the next row the VR was dropped here you see so but only one would come at any point of time in some row decoders this will be like this in another row decoder this will be like this and another row decoder this will be like this and another recorded should we like this uh sir so what we are suggesting is that uh although it's a repetitive cell but in the in each cell we are modifying the them by interconnecting with metal and programming via different position and also reducing the length on the right side like where the metal is not required so it's kind of a standard cell but we are modifying it no no nothing nothing in memory is a standard size okay sorry sorry yeah so the important thing is that when you in a memory you have the flexibility see what did we do in the memory cell in optimizing the area of the memory cell we said I will optimize it as an array the entire inverter for the right driver that we had to use we pushed it in the i o region you remember similarly I am saying in memory periphery also you can look at optimization Beyond just one step consider four cells and one go and then design so that you can save area you can save power you can save capacitances that is all that I'm saying that is the only point that similarly even the thought process can extend beyond just the memory array into the periphery right right okay so sir I have one doubt here sir yes so basically this the static part which is fixed over there the poly will be connected to the vertical M1 lines suppose if you consider it as a model whereas for the programming uh section once the poly will be connected to the horizontal M2 layer and there will be a via between the M2 horizontal and the vertical uh A2 bar A3 bar so the first uh and this in this kind of a setting uh the how do I put it in this kind of a setting M2 will typically be vertical it is it is an M2 that these lines will run okay okay horizontal routing will be M1 and M3 okay so in this case so then in this case the programming part uh programming section the poly will be directly connected to the M1 and there will be a VR between M1 and M2 to connect to the three quarter line yes and the static path will be uh the poly will be directly connected to the M2 layer yes okay understood directly means through a metal one step yes okay so this is how your programmation cell would look like there will be vrs like this so their full layout would look like this but the programmation cell would look like this we will create a new cell you will generate it through a script which would appear like this okay you will simply overlay this cell over the row decoder array to make the required connections so we will stop here we'll come back to you with more details on the course project soon and you can have a short discussion on course project in the next class also in meantime I would want you to form teams before the next class happens okay any questions any pending questions there are one very basic doubt uh it's just for sake of that row decoder would be out of memory or because the area of the road recorder is very high so should we kept Road recorded inside the limits or outside so uh can you have a memory without address decoding no sir so what is left means I am confused in in which part uh we put a through decoder uh yeah it would be yes it would be in control part and X decoder part X decoder partner control partner again sir we have uh four wheelers on the right side like on the A2 and A3 lines so if we are we were talking about reducing them to one only yeah uh so sir wanted to impact the performance because uh we have like four connections here so if we were talking earlier we talked about uh for kind of foreign what kind of current or what kind of load does this uh VRC is okay uh one two nmoses uh Gates poly maybe some polygates three or four polygates okay I was imagining like a bigger case where there are more word lines and if you have that see any post recorded only a few few Gates on your small Gates will be connected to it is it not so okay I got it many memories areas is very very important I do not want to put two vrs or three vrs and based area because of the RCs between those vrs oh right right got it so we have to be minimalistic at places which are repetitive see things which are getting repeated you have to be minimalistic things which are being added only once or twice or a very few times or which are very very critical for uh robustness for example send samples analog in nature such places you give area control region you are okay to give area because just once it is coming or just three or four times it will come if it is a hierarchical architecture but something like a row decoder which is repeating every row be frugal getting into yeah thank you okay uh starting menu for example that will be a part of my row decoding right foreign ages would select Different Different Page like page decoding means different pages are selected you're not changing the row selection there okay so but when I say page selection along the road along the row but it is not true there are only 128 rows per page so how can you have the extra bit there foreign why confusion with row decoding row decoding is separate so but we even talk about column decoding when you're talking about row decoding because there are different decoders so page decoder is different than the row decoder so but a page different or something but foreign what did we see in that example that we were discussing we saw that if there were 1K rows it's just we saw that if there were 1K rows what was happening so 1K words per row so max 8 it means every page had 128 rows now the one page is corresponding to so many rows there right okay yes Anna,https://www.youtube.com/watch?v=CcFqYYi4CWU,"Link: https://www.youtube.com/watch?v=CcFqYYi4CWU
Transcript: so what am I saying I am saying that depending on which row is to be selected I will actually place my gate you see what is happening when I put my poly over here this line got connected when I place my device over here this time got connected then this line got connected then the sign got connected and so on this is fine or do you see any challenge there foreign foreign over here also how will you share this diffusion it's not happening hello so what else anyone who knows about annual proximity effect no one has heard about annual proximity effects see we discussed about the fabrication process in our in our previous uh course so how are anvils fabricated who can describe that to me [Music] congratulations foreign implantation no you first need to uh use photos to remove that layer okay we have a photo as a then you will expose this and you will remove photos from some places and then you will do implantation yes so let us say this is where you want to make uh this is where you do not want those angles or let us say this is where you want and this could be okay so what happens in reality the boundaries of these Wells this this h is done at a slant will anyways happen at a stand because of the depth yeah and isotope an isotropic huh so what happens is that when you do an implantation they will be ions that will fall like this those that are falling on this line on this Edge would get reflected are you able to see this so I wanted my doping to be of one particular level that there should be only say in in this unit area I actually wanted only four uh ions to go but due to reflection how many ions are going now in this 47 7 are going so what has happened the doping of my P will and my unwell has changed yes so when the doping scene is what happens the ease with which I can make my inversion layer or anything would change so what happens the VT would be different so what has observed is that in a layout if there are transistors which are placed very close to an annual boundary let us say this is the annual boundary you know then this transistor would have a different VT than this one and this is known as envelope proximity effect a well proximity effect sorry wpe okay so what we need to do is we say that I do not like this Behavior where in some post decoders there is more proximity effect and in others there is lesser so you're talking about the same bus but in the same bus some have more proximity effects some have less approximity effect I don't like this so this the farther bus is far away may not bother me but this bus which is close to the end well this is a moderation for me I don't like this so what I do is this particular bus I put all the nmoses equidistant from the envelope but then how do I do the programmation I do the programmation by running a vertical metal uh running a horizontal metal and then putting vrs or contacts like this to achieve the desired functionality again are you able to see this hello so over here so in in the first instance in this particular example what was reprogramming depending on which row I am talking about I was placing this cell somewhere this device I was I was placing devices whereas in this one I am placing vrs so this is via programmation now again do not confuse it or do not uh do not confuse it with the ROM programming because that is not what the intent is the user cannot change the programmation at any point of time this is internal to the memory but over here we are programming only through vrs and the DRC rules that we need to manage could be much simpler than if I would Place devices like that okay so I would prefer to program with vrs over here so what I could do is I could make a cluster of forward lines each this part would be static this part would also be static and in fact what I could do is instead of running my metal horizontally I could simply have one vertical metal and one horizontal metal instead of four horizontal Metals there so instead of making the first part of four different cells I could just make one cell where this is my my cell boundary you may say any questions sir when you are moving to this another metal layer so this you're doing a VR programmation but then you said that we can uh using uh for using separate devices you for the each kind of block we are using each one device only sorry so like when you when earlier you were using the device programmation right you were placing devices yeah we just kept them at equal distance from the envelope yes sir that was so see I could make four cells or I could I could still make just one cell and program this and mass and this VR two things per cell I could do this or I could say that see this this Arrangement is constant so instead of programming this Arrangement also let me Define one cell such that it has four word lines as the output okay and then in every cell this this Arrangement is static only thing that I now need to program is these vrs is this clear till here [Music] see I have to program both the buses now I have to connect a zero A1 bus also and A2 A3 bus also yes sir yes sir so in one case I say I will program both simultaneously yes in another case I say okay let me use clusters of four rows and and Define a cell or Define a repetitive block which has a four rows in it so minimum increment on any row decoder could be four rows you cannot have a 33 row instance you can only have 32 or 36 row instance when I do that what happens I have made this Proclamation fixed now this no longer needs to be a programmation I can actually design it like this right so okay now if I have to design it like this I designed it now look at it over here there are four I have made four horizontal metal lines and I am placing four vrs it may it may appear that oh I don't need to really put phobias I can actually have just one vertical line connecting to all the gates okay connecting to all these Gates and only one horizontal line which would connect to a VR the other three horizontal lines are not needed and I would save overall capacitance on This Global line submit like uh putting program connecting via only on one vertical line I will have one third line connection right but for the rest of how will we managing the rest word lines if there's a vertical line that I am running here I can connect all four now press anyways I am connecting all four together anyways getting shorter with the same line do you see this okay yeah right right yes sir yes yeah got it so so I can actually reduce overall capacitance of the global lines so see address decoding is not simply a two to four decoder and three to eight decoder decision the layout also has a very significant impact on your sizing finally so when you design the layouts in your projects you have to be careful about what is what is happening on the overall scheme of things there what is happening to the other other stages of my design elsewhere okay okay uh like metal vertical running a vertical vertical metal is kind of less as compared to like programming for vrs but it's not just four vrs look at it over here as of now I have four horizontal lines and then four vrs what I am saying is replace it with one horizontal line one vertical line and one via that we are could be here here here or here so overall metal is lesser moreover if you in the row decoder as the overall height uh will be much lesser than the width the width that you will need to travel the rough current number of beer would be uh same as previous no there will be only one so over here we have all dropped here in the next rows the VR was dropped here in the next row the VR was dropped here you see so but only one would come at any point of time in some row decoders this will be like this in another row decoder this will be like this and another row decoder this will be like this and another recorded should we like this uh sir so what we are suggesting is that uh although it's a repetitive cell but in the in each cell we are modifying the them by interconnecting with metal and programming via different position and also reducing the length on the right side like where the metal is not required so it's kind of a standard cell but we are modifying it no no nothing nothing in memory is a standard size okay sorry sorry yeah so the important thing is that when you in a memory you have the flexibility see what did we do in the memory cell in optimizing the area of the memory cell we said I will optimize it as an array the entire inverter for the right driver that we had to use we pushed it in the i o region you remember similarly I am saying in memory periphery also you can look at optimization Beyond just one step consider four cells and one go and then design so that you can save area you can save power you can save capacitances that is all that I'm saying that is the only point that similarly even the thought process can extend beyond just the memory array into the periphery right right okay so sir I have one doubt here sir yes so basically this the static part which is fixed over there the poly will be connected to the vertical M1 lines suppose if you consider it as a model whereas for the programming uh section once the poly will be connected to the horizontal M2 layer and there will be a via between the M2 horizontal and the vertical uh A2 bar A3 bar so the first uh and this in this kind of a setting uh the how do I put it in this kind of a setting M2 will typically be vertical it is it is an M2 that these lines will run okay okay horizontal routing will be M1 and M3 okay so in this case so then in this case the programming part uh programming section the poly will be directly connected to the M1 and there will be a VR between M1 and M2 to connect to the three quarter line yes and the static path will be uh the poly will be directly connected to the M2 layer yes okay understood directly means through a metal one step yes okay so this is how your programmation cell would look like there will be vrs like this so their full layout would look like this but the programmation cell would look like this we will create a new cell you will generate it through a script which would appear like this okay you will simply overlay this cell over the row decoder array to make the required connections so we will stop here we'll come back to you with more details on the course project soon and you can have a short discussion on course project in the next class also in meantime I would want you to form teams before the next class happens okay any questions any pending questions there are one very basic doubt uh it's just for sake of that row decoder would be out of memory or because the area of the road recorder is very high so should we kept Road recorded inside the limits or outside so uh can you have a memory without address decoding no sir so what is left means I am confused in in which part uh we put a through decoder uh yeah it would be yes it would be in control part and X decoder part X decoder partner control partner again sir we have uh four wheelers on the right side like on the A2 and A3 lines so if we are we were talking about reducing them to one only yeah uh so sir wanted to impact the performance because uh we have like four connections here so if we were talking earlier we talked about uh for kind of foreign what kind of current or what kind of load does this uh VRC is okay uh one two nmoses uh Gates poly maybe some polygates three or four polygates okay I was imagining like a bigger case where there are more word lines and if you have that see any post recorded only a few few Gates on your small Gates will be connected to it is it not so okay I got it many memories areas is very very important I do not want to put two vrs or three vrs and based area because of the RCs between those vrs oh right right got it so we have to be minimalistic at places which are repetitive see things which are getting repeated you have to be minimalistic things which are being added only once or twice or a very few times or which are very very critical for uh robustness for example send samples analog in nature such places you give area control region you are okay to give area because just once it is coming or just three or four times it will come if it is a hierarchical architecture but something like a row decoder which is repeating every row be frugal getting into yeah thank you okay uh starting menu for example that will be a part of my row decoding right foreign ages would select Different Different Page like page decoding means different pages are selected you're not changing the row selection there okay so but when I say page selection along the road along the row but it is not true there are only 128 rows per page so how can you have the extra bit there foreign why confusion with row decoding row decoding is separate so but we even talk about column decoding when you're talking about row decoding because there are different decoders so page decoder is different than the row decoder so but a page different or something but foreign what did we see in that example that we were discussing we saw that if there were 1K rows it's just we saw that if there were 1K rows what was happening so 1K words per row so max 8 it means every page had 128 rows now the one page is corresponding to so many rows there right okay yes Anna"
KeGaDL7BLuQ,now we enter into this discussion on mismatch what is mismatch I assume all of you know at least this what is mismatched due to process variations during the fabrication there will be a mismatch between uh two different cells in the memory or it can be even in the iOS any two devices even if they are designed of to be of the same size in terms of w by L everything even then just by the virtue of of the fabrication process being the normal process there will be some mismatches between devices this can appear as a variation and cell current this can appear as a variation in leakage this can appear as a variation in for SRAM cell in terms of static noise margin not right margin and so on the impact of variation on static noise margin and right margin we looked at it in much detail when we were designing the memory set am I right so today what we are going to look at is we saw that there is such a huge impact that can happen but why does it happen why do like what are the sources of mismatch and then as a designer why is this discussion important because if you understand what are the sources of mismatch you can then attempt to manage this mismatch in one way or another so what we'll be doing now is we will be reviewing the material so I will be reviewing some parts some slides of a tutorial that was given way back in 2006. uh in in design automation conference in Dax 2006 it was given by synopsis and it's a very very exhaustive tutorial the slides are available online I will also share the slides with all of you on classroom uh but I wanted to I want to cover a few of those slides which are very important for for memory design for memory designers in the class so that is what we will be doing now is that okay so you will get the access to full tutorial I expect you to study the entire tutorial but I'm in the class I will go through the most important aspects of sources of mismatch is that okay so this is what I said it's a tutorial from back 2006 uh my synopsis so when we talk of mismatch or when we talk of variations we need to understand that there are two primary kinds of variations random and systematic so what are random variations random variations are variations which are intrinsic in nature they are kind of global variations they they will appear uh whatever you may do uh whatever you may do those intrinsic relations will appear process variations again the global variations are for example the the we discussed about it you know because of which we get FF lot or SS lot or TT lot gate oxide thickness the entire wafer the weight of site thickness is different is is a little higher it's a little lesser that will mean that this is a Global Effect and then there are pseudo variations which are uh which are event dependent that is for example there could be dynamic IR drop or there could be a temperature gradient in a chip due to which these variations can happen okay uh systematic variations are something like WP that we discussed we discussed WP in the last class so systematic variations are those kind of variations systematic variations are also these kind of variations where you can basically the the difference between random and systematic is of that uh for systematic variations you can model them model them means you can reasonably accurately model them and then you can simulate and see the impact of them on your exact device random variations you can only statistically model them and you can see the statistical impact only you cannot really see the exact impact of uh random variations Okay so that is where we say that over here we have put in this concept of mod we can model these variations and and see what what impact they can bring about okay this for example is an example of systematic variation you made a layout like this you know what your process is in the sense what are your resolution enhancement techniques that you are using in your system since you are aware of those resolution enhancement techniques you can already make a simulator and find out that okay my gate would actually gate region would actually be like this instead of this okay and and so what do you do now to improve the situation to correct the situation you can relax the design rules you can say that okay the these two structures cannot be so close together we have to increase the spacing between these two structures and so on as you would do that you will see that your design becomes more and more uh aligned to what you wanted it to be now this for example is a simulation of the polyline when you draw them like this and these circles have been put there to identify and tell you those places where there is a lack of fidelity where there is some challenge and you see there are there are issues like necking there are issues like line and pullbacks there are issues like non-matching transistor Gates and so on hmm so for example over here it appears that these two gates Were Meant To Be matched they share the same active area but look at the right side the image on the right side shows that they have different lengths finally are you able to see this the length here and the length here is different are you able to see this so length I mean of the right gate it is bigger right because it is extending to the other Ray diffusion also so we are looking at the gate region we are looking at only the gate region not outside the gate region only above the diffusion layer so in this case the diffusion layer would be something like this if I just draw it it would be something like this foreign and you see that the uh that the length of these two devices is different in this region it has also been circled there the thickness and the thickness the thickness of the poly which means length of the device is okay okay yes yeah Hannah the thickness of the poly means length of the device yes yes so it is different so it means these two devices which are supposed to have the same same length and same width would now actually have different characteristics am I right so can you please repeat the statement so [Music] these two devices that are marked with that arrow on the left side they have same width and same length yes sir now look at the right side due to various effects like line pullback due to necking due to whatever so many different because the police have been designed in such a way that they have different politoactive spacing they have different contact pads they have so many defenses amongst them yes are you able to see this so what is fabricated finally be on that OD that will be drawn you will see that the the width of the poly that is the length of the device is going to be different okay yes and this is not a random variation when you made this layout I can anticipate that this is going to happen are you able to see this this is not a random variation when you make the layout you can tell that this is going to happen uh so actually I had to ask one thing sir okay Joe uh right side that is simulation of the this left side layout kind of yeah assimilation of how the poly would finally turn out okay so even before manufacturing able to see this kind of you can't you can yes even before manufacturing there are more there are simulators that can model your resolution enhancement techniques that can model your process and that can give you this kind of a view okay so but uh I'm not able to understand like how it is different because in intrinsic you said that key in random we have intrinsic and sudo yeah these are systematic variations these are systematic variations let us first get this right is that clear these are systematic variations so don't confuse them with random I am not started with random yet okay so these are random because you can model them these are systematic because we can model them yeah this is systematic because we can model them yes we can model them exactly I can tell you that is is left device will have a faster or more current than the right device whatever because I can always say this through this modeling simulation that I did these are systematic variations random variations would be for example as we will look at in in the next few slides doping variations there could be more more uh dopant atoms and under one gate than the other and that is what is random you cannot model it you cannot say that everything else is matched even then a device one will be faster than device two in some samples device one will be faster and some samples device 2 will be faster but with a systematic variation just like well proximity effect you can say oh this device is close to the envelope so this is going to be slower is it not so these are systematic variations okay seven doubt uh in the cell you said that it was the simulation of the layouts these are the information obtained about that necking or whatever effects these are provided on the basis of experience by The Foundry right and Optics simulations okay okay and it is all Optics you know which wavelength is to be used you know the material you know everything you have to model it what's it you said that I know exactly if the right one or the left one would have the narrower length so that kind of uh prediction I was just wondering how it can be you know explained logical problem I was not able to like understand why how to look at it yeah let us look at that layout and this layout uh do you see that the spacing between poly and active is changing what's the left one yeah and the layout left one you see the spacing between poly and active is changing yes sir you can see here so what that what does that mean that when the finally the device will be made they will be bending the bending of poly will happen earlier for the left device and later for the right device right right yeah so then you see that the poly pad the the contact pad is closer to the in the left device and the right device so you see there are so many things that are evident in the layout itself yes yes when you run the optic simulation it will give you that it would say that okay the necking will happen here Downing off will happen here line pullback will happen here yes okay got it the differences are evident and to avoid these differences you make structurally matched layouts when you will design your sensor amplifiers whichever teams start work on sense amplifiers you will be expected to do a common centroid layouts with structural matching even on the metal lines we have social devices okay so that such impact systematic variations are completely done away with there is no systematic offset in your sense amplifier even if it takes a little extra area we will do it okay [Music] um,https://www.youtube.com/watch?v=KeGaDL7BLuQ,"Link: https://www.youtube.com/watch?v=KeGaDL7BLuQ
Transcript: now we enter into this discussion on mismatch what is mismatch I assume all of you know at least this what is mismatched due to process variations during the fabrication there will be a mismatch between uh two different cells in the memory or it can be even in the iOS any two devices even if they are designed of to be of the same size in terms of w by L everything even then just by the virtue of of the fabrication process being the normal process there will be some mismatches between devices this can appear as a variation and cell current this can appear as a variation in leakage this can appear as a variation in for SRAM cell in terms of static noise margin not right margin and so on the impact of variation on static noise margin and right margin we looked at it in much detail when we were designing the memory set am I right so today what we are going to look at is we saw that there is such a huge impact that can happen but why does it happen why do like what are the sources of mismatch and then as a designer why is this discussion important because if you understand what are the sources of mismatch you can then attempt to manage this mismatch in one way or another so what we'll be doing now is we will be reviewing the material so I will be reviewing some parts some slides of a tutorial that was given way back in 2006. uh in in design automation conference in Dax 2006 it was given by synopsis and it's a very very exhaustive tutorial the slides are available online I will also share the slides with all of you on classroom uh but I wanted to I want to cover a few of those slides which are very important for for memory design for memory designers in the class so that is what we will be doing now is that okay so you will get the access to full tutorial I expect you to study the entire tutorial but I'm in the class I will go through the most important aspects of sources of mismatch is that okay so this is what I said it's a tutorial from back 2006 uh my synopsis so when we talk of mismatch or when we talk of variations we need to understand that there are two primary kinds of variations random and systematic so what are random variations random variations are variations which are intrinsic in nature they are kind of global variations they they will appear uh whatever you may do uh whatever you may do those intrinsic relations will appear process variations again the global variations are for example the the we discussed about it you know because of which we get FF lot or SS lot or TT lot gate oxide thickness the entire wafer the weight of site thickness is different is is a little higher it's a little lesser that will mean that this is a Global Effect and then there are pseudo variations which are uh which are event dependent that is for example there could be dynamic IR drop or there could be a temperature gradient in a chip due to which these variations can happen okay uh systematic variations are something like WP that we discussed we discussed WP in the last class so systematic variations are those kind of variations systematic variations are also these kind of variations where you can basically the the difference between random and systematic is of that uh for systematic variations you can model them model them means you can reasonably accurately model them and then you can simulate and see the impact of them on your exact device random variations you can only statistically model them and you can see the statistical impact only you cannot really see the exact impact of uh random variations Okay so that is where we say that over here we have put in this concept of mod we can model these variations and and see what what impact they can bring about okay this for example is an example of systematic variation you made a layout like this you know what your process is in the sense what are your resolution enhancement techniques that you are using in your system since you are aware of those resolution enhancement techniques you can already make a simulator and find out that okay my gate would actually gate region would actually be like this instead of this okay and and so what do you do now to improve the situation to correct the situation you can relax the design rules you can say that okay the these two structures cannot be so close together we have to increase the spacing between these two structures and so on as you would do that you will see that your design becomes more and more uh aligned to what you wanted it to be now this for example is a simulation of the polyline when you draw them like this and these circles have been put there to identify and tell you those places where there is a lack of fidelity where there is some challenge and you see there are there are issues like necking there are issues like line and pullbacks there are issues like non-matching transistor Gates and so on hmm so for example over here it appears that these two gates Were Meant To Be matched they share the same active area but look at the right side the image on the right side shows that they have different lengths finally are you able to see this the length here and the length here is different are you able to see this so length I mean of the right gate it is bigger right because it is extending to the other Ray diffusion also so we are looking at the gate region we are looking at only the gate region not outside the gate region only above the diffusion layer so in this case the diffusion layer would be something like this if I just draw it it would be something like this foreign and you see that the uh that the length of these two devices is different in this region it has also been circled there the thickness and the thickness the thickness of the poly which means length of the device is okay okay yes yeah Hannah the thickness of the poly means length of the device yes yes so it is different so it means these two devices which are supposed to have the same same length and same width would now actually have different characteristics am I right so can you please repeat the statement so [Music] these two devices that are marked with that arrow on the left side they have same width and same length yes sir now look at the right side due to various effects like line pullback due to necking due to whatever so many different because the police have been designed in such a way that they have different politoactive spacing they have different contact pads they have so many defenses amongst them yes are you able to see this so what is fabricated finally be on that OD that will be drawn you will see that the the width of the poly that is the length of the device is going to be different okay yes and this is not a random variation when you made this layout I can anticipate that this is going to happen are you able to see this this is not a random variation when you make the layout you can tell that this is going to happen uh so actually I had to ask one thing sir okay Joe uh right side that is simulation of the this left side layout kind of yeah assimilation of how the poly would finally turn out okay so even before manufacturing able to see this kind of you can't you can yes even before manufacturing there are more there are simulators that can model your resolution enhancement techniques that can model your process and that can give you this kind of a view okay so but uh I'm not able to understand like how it is different because in intrinsic you said that key in random we have intrinsic and sudo yeah these are systematic variations these are systematic variations let us first get this right is that clear these are systematic variations so don't confuse them with random I am not started with random yet okay so these are random because you can model them these are systematic because we can model them yeah this is systematic because we can model them yes we can model them exactly I can tell you that is is left device will have a faster or more current than the right device whatever because I can always say this through this modeling simulation that I did these are systematic variations random variations would be for example as we will look at in in the next few slides doping variations there could be more more uh dopant atoms and under one gate than the other and that is what is random you cannot model it you cannot say that everything else is matched even then a device one will be faster than device two in some samples device one will be faster and some samples device 2 will be faster but with a systematic variation just like well proximity effect you can say oh this device is close to the envelope so this is going to be slower is it not so these are systematic variations okay seven doubt uh in the cell you said that it was the simulation of the layouts these are the information obtained about that necking or whatever effects these are provided on the basis of experience by The Foundry right and Optics simulations okay okay and it is all Optics you know which wavelength is to be used you know the material you know everything you have to model it what's it you said that I know exactly if the right one or the left one would have the narrower length so that kind of uh prediction I was just wondering how it can be you know explained logical problem I was not able to like understand why how to look at it yeah let us look at that layout and this layout uh do you see that the spacing between poly and active is changing what's the left one yeah and the layout left one you see the spacing between poly and active is changing yes sir you can see here so what that what does that mean that when the finally the device will be made they will be bending the bending of poly will happen earlier for the left device and later for the right device right right yeah so then you see that the poly pad the the contact pad is closer to the in the left device and the right device so you see there are so many things that are evident in the layout itself yes yes when you run the optic simulation it will give you that it would say that okay the necking will happen here Downing off will happen here line pullback will happen here yes okay got it the differences are evident and to avoid these differences you make structurally matched layouts when you will design your sensor amplifiers whichever teams start work on sense amplifiers you will be expected to do a common centroid layouts with structural matching even on the metal lines we have social devices okay so that such impact systematic variations are completely done away with there is no systematic offset in your sense amplifier even if it takes a little extra area we will do it okay [Music] um"
XGfA-mMk3jo,okay then the next kind of effect again systematic effect is proximity if there are devices which are placed far apart you know there is more spacing between devices versus devices which are placed close together you will see that the kind of stress that appears in the diffusion region in the region where you have uh your contacts and everything present there it changes look at the Contours on the bottom graphs the stress changes due to which the pmoses and nmosis start to behave differently in fact it was it was said that 28 there is a the P by n ratio changes by 28 the mobility of the animals in the pmos the ratio changes by 28 percent that huge and impact can happen so which stress are you talking about here sir uh stress okay so let us say this is a device there will be Shadow trench and plants over here on the side huh so as soon as the shallow Trends implants come into picture what happens the crystal lattice the crystal lattice is broken um when the crystal lattice breaks there are bonds which are dangling there are bonds which now see a different kind of stress that stress gets as you can see in the Contours that that stress gets transmitted to the gate region also are you able to see this uh so I mean uh shallow Trend streamlined able to get but what is causing stress actually the breaking of the bonds the breaking of the latter structure of the Silicon so due to the STI yeah so otherwise this was all silicon otherwise this was meant to be all silicon This was meant to be complete lattice of silicon is it not you broke it with STI here and there due to which devices now have stress and the stress is different when there is a sparse device sparse lips devices and it is very different when they are densely placed devices because STI can absorb some part of mechanical stress it will not absorb all the mechanical stress or when there is a lot of STI it gives a different kind of stress versus when there is a little bit of STI there okay so so like when we have the dense layout so I can think of key STI the width will be less I mean the shelter may be smaller so that can be that way to different kind of stress I mean the physical okay yeah foreign oscillator the dense ring oscillator operates at a higher frequency than the sparse one overall we saw that there is more than 10 timing variations just because of this effect so it means that stresses change the device characteristics itself I mean yes Mobility changes now if the if there is stress in the Silicon lattice the way the electrons will move around will change when you are under stress does your performance change yes sir exactly the same way the transistor performance also changes Transit he said what exactly is Shadow attention plant we discussed about shallow transm plant in the second lecture of DVD manufacturing process how do you separate two devices from one another you remember we said we would break open the we will make shallow shallow trenches between two devices and we would deposit so before shallow transmission plant technology we would grow uh epic we would grow silicon dioxide on Silicon itself that led to that beaking effect remember between two devices there would be a beep that would form and there was a minimum DRC That was supposed to be maintained we said okay we do not want to go with the speaking etcanda we will we will open up we will open up the silicon and deposit oxide in there so that we can have denser layouts we will not depend on growth because that would mean beaking would happen that would mean more spacing between devices so what density we went for shallow transom plants where the Silicon is broken open between two actives active regions we deposit silicon dioxide okay okay so that is the impact of device variation so see at that point of time some of you may might have felt why we are discussing all these manufacturing steps it is very important because as a designer you need to understand what all affects those manufacturing steps could have on your design okay so uh similarly we already discussed the the dishing in wires you remember that the distinction phenomena in wires because when we do uh chemo mechanical standardization yes sir so how do we avoid this is in between we add some pillars of sio2 in between so that uh the dishing doesn't happen we make some slots inside bite wires Ranjit okay so we add slots inside these wires so that they are those slots act as pillars and dashing doesn't happen so this is again one of the systematic variations you see a wide wire you know that okay there is going to be some loss you see sparsely then sparse density of wires you say okay there is expected to be some loss so why is it important in terms of memories where do you have wires running around add it in the memory added there are word lines there are bit lines so there is a huge density of wires if suppose I say that I want to track my word line capacitance with a word line capacitance and resistance with a signal in the i o region is there such a requirement is there a requirement to match World line with some signals in the io yes no why so can you repeat the question is there a requirement to match the RC offered line with some other signals in the io region yes sir I think uh recharge yeah we talked about the race conditions in the i o the lack was the last slide we discussed we saw that in the i o the pre-charge should have should come before wordline we saw about this condition the raise condition what does this mean that the RC of free chart signal should be similar to that of of or at least there has to be some semblance of some relationship deterministic relationship between RC of uh wordline and RC off the pre-charge signal so if for example now you in the io region you make pre-charged line as a single line running you know with one micron distance spacing to any other line will it behave the same as word line will it behave the same as Bird Line hello sir the future line in the sense you mean like the clock that is going to the preacher circuit in the metal that you're out the metal that you route to to connect the gates finally you will route Metals now yes yes so that metal is is very sparsely placed there is no other metal wire within one micron of it that versus the word lines and the array region will you say that these two lines are matched so I mean I'm looking at the how the wires are placed uh the surrounding of the wires basically yes but okay if the wires are densely placed there will be lesser dishing if the wires are sparsely faced there will be more dishing or vice versa basically softness of copper is different from the softness of silicon dioxide so there are more wires it means there is more copper in that region the CMP process will will polish it in one particular way if there are lesser wires it means there is a different level of hardness in that region the CMP process will polish it in a different way and your wires and delays may not be matched you wanted to match the delays now but the wires have different RC now the delays are not matched so just because the different surroundings yes we can have different notices you see that is the and this is a systematic variation this is what we mean by structural matching that the structure of the layout in terms of density and everything should be matched the bends that you see in the uh for one device should be similarly made for the second device also everything Ranjit well itself if the wires are placed tensor to each other then the chemo mechanical process cannot polish out the dishing cannot happen for the densely placed where yes so those wires will have lesser resistance means [Music] so uh dashing means that CMP in during the CMP process as you see in this right side figure there when there are wide wires they end up eroding eating away the copper more than what was desired because copper is much softer than silicon dioxide so this is the MP process polishes it more so it happens when the wire is not dense when the wire is uh when the virus what do you say when there is a lot of wire a lot of copper because copper is soft dishing will happen basically come into pictures are exactly because according to what I understand is that it depends it totally depends on the grid right loss over here see there are look at the slides there are two new terms that have been introduced field loss and erosion um so when there are so many wires overalls overall softness of that region is lesser than places where there are no wires will happen so but uh suppose if you consider the case of denser launcher uh the dishing will be less but the in uh in intram metal capacitance will increase also increases we don't know resistance is lesser because the wires are taller the resistance is lesser now but see see capacitance increases yeah FEMA increase now do you realize that if R and C values move differently they're moving differently now is it not yes yes sir are reduced by 20 C increased by 10 percent yes you would move in a different direction yes anything whatever it is the two wires word line and preachers line are not matched if they do not have similar density or wires around them yes yes that is the point that needs to be established okay rather so what do you mean by the field loss here sir the the field oxide sio2 loss when you do CMP the field oxide will also get polished now okay and what is error Junction here erosion means uh in between the wires so feed losses in those regions where there was not not much density so you see in in that is exactly what I was mentioning about you know when there is not much wire density the height would Reduce by only this much but where their wires are denser the height would Reduce by a more amount a larger amount and therefore your wires will be thinner or less tall okay okay so that was where we talked about Metal slotting earlier and now today I am introducing this term which is called as dummy fills to you okay so dummy fields are also done so that you have similar level of density at all places however inside the memory inside the memory you do not allow any dummy flips inside the memory you want as a designer everything to be under your control is it not as a designer you want the memory to behave exactly the way you want it nice so inside the memory dummy fills are not allowed but outside the memory that is in the standard cell logic region dummy cells are are done so that dishing and erosion and feed loss does not happen or whatever happens is systematically similar across all wires and all regions in the chip is that okay so like in the previous example we were having different kind of spacing in the io and the array region so uh and I could why I am calling that structure because I am able to see the effects of that deterministically how made today variation but what I am doing to basically mitigate that if I'm happy we add extra metals so these blue ones are hexa metals which are simply added so that density of metals in all regions is similar this is called as dummy fill process so these are right and the bad layer itself yes the blue ones are also metals but they are not connected to any any signal they are floating metals now what does this mean if you allow this in the memory what would happen I said that we do not allow the missiles inside the memory why what would happen area there's no area if we add them inside the memory and it can also interfere with the other wires by coupling capacitance yeah see you estimated you design your i o region for example and you extracted that you did all your verifications with that IO is it not you said okay this I will be repeated 10 10 times 20 times 50 times depending on number of bits you estimated the RC of the signal and then you would do verifications then you would characterize at a time whole time everything now to add the stage of going on Silicon uh the system says oh there are there is sparsity of metals three there let me add dummies dummies of metal three so above your IO now there are dummies of metal three what happens the capacitances of underlying Metal 2 would change the capacitances of other metal three lines in that region would also change so finally what will be fabricated on Silicon will have a very different RC than what your character is what you validated what you design your circuit with can you afford this variation so but I can include this uh capacitance in my extraction itself just before you enter the Fab the means Affairs at that time dummies are added to the layout at the last stage bill could last stage before five out before fabin let us say so so they will be part of my GDs but uh but you have not characterized them okay they will finally become a part of your GDs but when you design you did not know that they will come there so you did not put them show you the capacitances with which you design was way lesser than what finally are there your system will completely go for a toss sir actually my doubt is having because once we have done the layout then we do the parasectic section right and so we here and GDs also is a layout file only so sir I have done the layout and at the layout stage I am adding this uh kind of this dummy field then why can't I characterize them so as I said the dummy fills are added at chip level so you made the layout of a memory a soft designer designed the entire chip around it after everything was done and the chip was being sent for fabout at that time they felt that oh there needs to be 20 more metal 3 so that density is consistent that is when they added these dummy fills now what will you do okay um sock level designer is adding this basically that's why even that Designer is not adding the tool will add um yes sir okay so you cannot model them you have to put a layer there which says no dummy no no dummy no tiling there no dummy feeling there above the memory you have to put that kind of layer which means there will be some additional drcs that's a memory memory designer memory layout designer will have to take care of we will take care of them but we cannot accept uncertainty okay yes sir so slotting we already discussed earlier that we make small slots inside wide wires so that there are kind of pillars of silicon dioxide in between which prevent dishing okay so one more thing so signal lines are same as the dummy film the concept is similar signal line is likely charged word line okay okay level lines are what you designed okay okay it has got added later,https://www.youtube.com/watch?v=XGfA-mMk3jo,"Link: https://www.youtube.com/watch?v=XGfA-mMk3jo
Transcript: okay then the next kind of effect again systematic effect is proximity if there are devices which are placed far apart you know there is more spacing between devices versus devices which are placed close together you will see that the kind of stress that appears in the diffusion region in the region where you have uh your contacts and everything present there it changes look at the Contours on the bottom graphs the stress changes due to which the pmoses and nmosis start to behave differently in fact it was it was said that 28 there is a the P by n ratio changes by 28 the mobility of the animals in the pmos the ratio changes by 28 percent that huge and impact can happen so which stress are you talking about here sir uh stress okay so let us say this is a device there will be Shadow trench and plants over here on the side huh so as soon as the shallow Trends implants come into picture what happens the crystal lattice the crystal lattice is broken um when the crystal lattice breaks there are bonds which are dangling there are bonds which now see a different kind of stress that stress gets as you can see in the Contours that that stress gets transmitted to the gate region also are you able to see this uh so I mean uh shallow Trend streamlined able to get but what is causing stress actually the breaking of the bonds the breaking of the latter structure of the Silicon so due to the STI yeah so otherwise this was all silicon otherwise this was meant to be all silicon This was meant to be complete lattice of silicon is it not you broke it with STI here and there due to which devices now have stress and the stress is different when there is a sparse device sparse lips devices and it is very different when they are densely placed devices because STI can absorb some part of mechanical stress it will not absorb all the mechanical stress or when there is a lot of STI it gives a different kind of stress versus when there is a little bit of STI there okay so so like when we have the dense layout so I can think of key STI the width will be less I mean the shelter may be smaller so that can be that way to different kind of stress I mean the physical okay yeah foreign oscillator the dense ring oscillator operates at a higher frequency than the sparse one overall we saw that there is more than 10 timing variations just because of this effect so it means that stresses change the device characteristics itself I mean yes Mobility changes now if the if there is stress in the Silicon lattice the way the electrons will move around will change when you are under stress does your performance change yes sir exactly the same way the transistor performance also changes Transit he said what exactly is Shadow attention plant we discussed about shallow transm plant in the second lecture of DVD manufacturing process how do you separate two devices from one another you remember we said we would break open the we will make shallow shallow trenches between two devices and we would deposit so before shallow transmission plant technology we would grow uh epic we would grow silicon dioxide on Silicon itself that led to that beaking effect remember between two devices there would be a beep that would form and there was a minimum DRC That was supposed to be maintained we said okay we do not want to go with the speaking etcanda we will we will open up we will open up the silicon and deposit oxide in there so that we can have denser layouts we will not depend on growth because that would mean beaking would happen that would mean more spacing between devices so what density we went for shallow transom plants where the Silicon is broken open between two actives active regions we deposit silicon dioxide okay okay so that is the impact of device variation so see at that point of time some of you may might have felt why we are discussing all these manufacturing steps it is very important because as a designer you need to understand what all affects those manufacturing steps could have on your design okay so uh similarly we already discussed the the dishing in wires you remember that the distinction phenomena in wires because when we do uh chemo mechanical standardization yes sir so how do we avoid this is in between we add some pillars of sio2 in between so that uh the dishing doesn't happen we make some slots inside bite wires Ranjit okay so we add slots inside these wires so that they are those slots act as pillars and dashing doesn't happen so this is again one of the systematic variations you see a wide wire you know that okay there is going to be some loss you see sparsely then sparse density of wires you say okay there is expected to be some loss so why is it important in terms of memories where do you have wires running around add it in the memory added there are word lines there are bit lines so there is a huge density of wires if suppose I say that I want to track my word line capacitance with a word line capacitance and resistance with a signal in the i o region is there such a requirement is there a requirement to match World line with some signals in the io yes no why so can you repeat the question is there a requirement to match the RC offered line with some other signals in the io region yes sir I think uh recharge yeah we talked about the race conditions in the i o the lack was the last slide we discussed we saw that in the i o the pre-charge should have should come before wordline we saw about this condition the raise condition what does this mean that the RC of free chart signal should be similar to that of of or at least there has to be some semblance of some relationship deterministic relationship between RC of uh wordline and RC off the pre-charge signal so if for example now you in the io region you make pre-charged line as a single line running you know with one micron distance spacing to any other line will it behave the same as word line will it behave the same as Bird Line hello sir the future line in the sense you mean like the clock that is going to the preacher circuit in the metal that you're out the metal that you route to to connect the gates finally you will route Metals now yes yes so that metal is is very sparsely placed there is no other metal wire within one micron of it that versus the word lines and the array region will you say that these two lines are matched so I mean I'm looking at the how the wires are placed uh the surrounding of the wires basically yes but okay if the wires are densely placed there will be lesser dishing if the wires are sparsely faced there will be more dishing or vice versa basically softness of copper is different from the softness of silicon dioxide so there are more wires it means there is more copper in that region the CMP process will will polish it in one particular way if there are lesser wires it means there is a different level of hardness in that region the CMP process will polish it in a different way and your wires and delays may not be matched you wanted to match the delays now but the wires have different RC now the delays are not matched so just because the different surroundings yes we can have different notices you see that is the and this is a systematic variation this is what we mean by structural matching that the structure of the layout in terms of density and everything should be matched the bends that you see in the uh for one device should be similarly made for the second device also everything Ranjit well itself if the wires are placed tensor to each other then the chemo mechanical process cannot polish out the dishing cannot happen for the densely placed where yes so those wires will have lesser resistance means [Music] so uh dashing means that CMP in during the CMP process as you see in this right side figure there when there are wide wires they end up eroding eating away the copper more than what was desired because copper is much softer than silicon dioxide so this is the MP process polishes it more so it happens when the wire is not dense when the wire is uh when the virus what do you say when there is a lot of wire a lot of copper because copper is soft dishing will happen basically come into pictures are exactly because according to what I understand is that it depends it totally depends on the grid right loss over here see there are look at the slides there are two new terms that have been introduced field loss and erosion um so when there are so many wires overalls overall softness of that region is lesser than places where there are no wires will happen so but uh suppose if you consider the case of denser launcher uh the dishing will be less but the in uh in intram metal capacitance will increase also increases we don't know resistance is lesser because the wires are taller the resistance is lesser now but see see capacitance increases yeah FEMA increase now do you realize that if R and C values move differently they're moving differently now is it not yes yes sir are reduced by 20 C increased by 10 percent yes you would move in a different direction yes anything whatever it is the two wires word line and preachers line are not matched if they do not have similar density or wires around them yes yes that is the point that needs to be established okay rather so what do you mean by the field loss here sir the the field oxide sio2 loss when you do CMP the field oxide will also get polished now okay and what is error Junction here erosion means uh in between the wires so feed losses in those regions where there was not not much density so you see in in that is exactly what I was mentioning about you know when there is not much wire density the height would Reduce by only this much but where their wires are denser the height would Reduce by a more amount a larger amount and therefore your wires will be thinner or less tall okay okay so that was where we talked about Metal slotting earlier and now today I am introducing this term which is called as dummy fills to you okay so dummy fields are also done so that you have similar level of density at all places however inside the memory inside the memory you do not allow any dummy flips inside the memory you want as a designer everything to be under your control is it not as a designer you want the memory to behave exactly the way you want it nice so inside the memory dummy fills are not allowed but outside the memory that is in the standard cell logic region dummy cells are are done so that dishing and erosion and feed loss does not happen or whatever happens is systematically similar across all wires and all regions in the chip is that okay so like in the previous example we were having different kind of spacing in the io and the array region so uh and I could why I am calling that structure because I am able to see the effects of that deterministically how made today variation but what I am doing to basically mitigate that if I'm happy we add extra metals so these blue ones are hexa metals which are simply added so that density of metals in all regions is similar this is called as dummy fill process so these are right and the bad layer itself yes the blue ones are also metals but they are not connected to any any signal they are floating metals now what does this mean if you allow this in the memory what would happen I said that we do not allow the missiles inside the memory why what would happen area there's no area if we add them inside the memory and it can also interfere with the other wires by coupling capacitance yeah see you estimated you design your i o region for example and you extracted that you did all your verifications with that IO is it not you said okay this I will be repeated 10 10 times 20 times 50 times depending on number of bits you estimated the RC of the signal and then you would do verifications then you would characterize at a time whole time everything now to add the stage of going on Silicon uh the system says oh there are there is sparsity of metals three there let me add dummies dummies of metal three so above your IO now there are dummies of metal three what happens the capacitances of underlying Metal 2 would change the capacitances of other metal three lines in that region would also change so finally what will be fabricated on Silicon will have a very different RC than what your character is what you validated what you design your circuit with can you afford this variation so but I can include this uh capacitance in my extraction itself just before you enter the Fab the means Affairs at that time dummies are added to the layout at the last stage bill could last stage before five out before fabin let us say so so they will be part of my GDs but uh but you have not characterized them okay they will finally become a part of your GDs but when you design you did not know that they will come there so you did not put them show you the capacitances with which you design was way lesser than what finally are there your system will completely go for a toss sir actually my doubt is having because once we have done the layout then we do the parasectic section right and so we here and GDs also is a layout file only so sir I have done the layout and at the layout stage I am adding this uh kind of this dummy field then why can't I characterize them so as I said the dummy fills are added at chip level so you made the layout of a memory a soft designer designed the entire chip around it after everything was done and the chip was being sent for fabout at that time they felt that oh there needs to be 20 more metal 3 so that density is consistent that is when they added these dummy fills now what will you do okay um sock level designer is adding this basically that's why even that Designer is not adding the tool will add um yes sir okay so you cannot model them you have to put a layer there which says no dummy no no dummy no tiling there no dummy feeling there above the memory you have to put that kind of layer which means there will be some additional drcs that's a memory memory designer memory layout designer will have to take care of we will take care of them but we cannot accept uncertainty okay yes sir so slotting we already discussed earlier that we make small slots inside wide wires so that there are kind of pillars of silicon dioxide in between which prevent dishing okay so one more thing so signal lines are same as the dummy film the concept is similar signal line is likely charged word line okay okay level lines are what you designed okay okay it has got added later"
wmdOWoYbP98,okay now we enter into the zone of random mismatch now look at this image on the left side is one cross section view of a transistor and on the right side is the dopant profile which is particularized okay the red the red ones are donors the blue ones are acceptors okay now what happens let us say you scale it down you scale down the technology and you expected 20 so this was your gate region so this was your gate region and you expected 20 dopants over here beneath the gate okay but in reality just give me a minute in reality there were let us say three extra dopants all of a sudden what happens the the the Contours the potential Contours of this gate device will be different from the device that you had designed it to be you will now need more band bending are you able to see this to get to the VT of the device you will need more band bending and therefore you may end up as a high VT device a VT is tightly higher than the regular device that you are intended it to be it can also happen instead of 20 there are 18 ropants now less than less band bending is required for VT to be there and therefore you will see that the device is a little fast are you with me so so this is a random This Is Random random two adjacent devices structurally matched WP is same stresses same everything else is same even then you cannot control how many dopants will be there beneath your gate it is physically not possible um so such such variations which you cannot really model deterministically you model them statistically you say that okay of 100 devices uh 70 devices would have 20 dopants only now 10 devices will have uh uh 22 opens 10 devices would have 18 dopants then remaining five devices would have 25 dopants and another five devices would have 15 dopants and you say that there is a distribution there is a distribution where some devices are faster some devices are slower are you able to see this so I have two questions so one is how why this process why this random so I mean you tell me I want to bombard I want to bombard 20 dopants in a region which is uh let us say one micron by 65 nanometers so one micron by one micron device with minimum length yes so 65 nanometer into one micron in that region I want to bombard 20 dopants and I bombard 20 low points exactly or sometimes they will be 21 sometimes they will be 19. it's a process now it's a natural process you're not placing dopants one by one you're just bombarding and you're letting them diffuse foreign you have a pencil with you pen paper pencil with you something like that yes you have control over your head it is the same pencil that I want you to write your name with 20 times and it has to be exactly the same um yes can it be exactly the same why perfect it's not the Perfection cannot be understood this Supernatural process yeah this is a natural process there will be there are bound to be some variations the the velocity of devices the velocity of dopant atoms that you are sending that you are bombarding that is going to be normally distributed here um I guess so I know so there is no way you can have them exactly the same under every device and you cannot model this you can only statistically model this so statistical models would appear but exact models you cannot have to do the worst case analysis you may say that okay I have to assume pass gate to be at 3.5 Sigma pull down to be at 4 Sigma away and that is my first case that was what we did in this SNM analysis that was what we did in the uh right time right margin analysis also in the previous lecture so we placed devices at the worst places and we saw the impact but it is not that this is bound to happen exactly this way we just want to be sure that statistically we are safe So when you say key statistically determined us but I cannot locate which exactly device evaluation yes that you cannot tell hundred messages but with 70 the first 70 or somewhere randomly distributed 70 we that we cannot say foreign let me put pull up at plus three sigma remember um we did that so we did not say sorry devices we actually for verification for for Designing we actually put devices at different corners and that was when we did it right I mean it's a password it's a similar kind of devices what you desire okay for SNM analysis you want low VT on the pass gate for it for uh write time analysis or right margin analysis you need High VT on the pass gate just so so at time we will use one side of the curve at another time you will use another side of the Curve okay sir yes sir can you come back once let's uh so sir uh this according to this below graph sir so this dopant fluctuation is the major cause to the vth variation yes and Sir one thing also I want to ask sir at lower technology nodes yes that is what is shown on this car yes okay okay so uh again this is about uh the impact it has on the memory cell so as so this is actually the memory cell SNM analysis only where we say that okay for different SNM values how is the distribution when cell ratio is moved from two to three to four okay and this has considered only the random dopen fluctuations as a part of variations as yet other other random things are not put in picture another random factor into is interface roughness what does that mean see finally you have you grow silicon dioxide let us say um at some places there are three atoms of silicon three molecules of silicon dioxide at other places there are four molecules of silicon dioxide at some places a molecule is placed in a particular manner at other places the molecule is placed in a different manner huh so what happens the thickness of silicon dioxide can vary across the gate region some places it is 2.2 nanometer by thick at some places 2.6 nanometers say that some other places 2.4 nanometers thick so what does this mean that even though you said that your gate is 22 nanometer thick or 25 nanometer thick there are variations around it the Gate of sight thickness is not exactly the same huh due to this some devices will operate fast some devices will operate slow adjacent devices both have average thickness of 25 nanometer only 25 angstroms only but in one device it was more towards 24 and the other device that was more towards 26. and it is random you cannot control it are you with me okay so this again is a random variation which you have to model in your Monte Carlo simulations another random variation is lineage roughness what does line as roughness means sinus reference means that you want it to design a poly which is of one particular vict throughout whereas poly in itself is a is a polycrystalline material so there are crystals there huh and when you will do etching when you will do chemical etching or anything you remember that crystals have an isotropic Behavior they behave differently across different directions so there is a crystal which is placed here and the Crystal which is placed here so when you do the etching what happens so let us let us take this example let us say that there are these different crystals of silicon dioxide that form the poly region over here and so on um so when you started to etch when you start to etch what happens the crystal boundaries at the Crystal boundaries the extent of H changes so finally you may have a a polysilicon line so you wanted the it to be completely straight and parallel finally you will have a polysilicon line which could be like this thicker somewhere thin somewhere and so on you notice uh in this image the poly thickness is not constant throughout huh what does this mean this means that the length effective length is changing now let us say there was a contact over here and in another device there was a contact over here the effect is thickness of the gate for transmission of current from source to drain from one contact to the other is going to be different for every device are you able to see this uh sir sir how is the thickness changing I mean along the line it is changing now so thickness so Remains the Same right okay I mean okay let me not use the word thickness let us use the word width the length of your device is changing are you able to see this at the length of the device is changing differently for different devices because of this line as roughness also so it seems that in the same device the length is not constant throughout that is also the case but there will be average length so average length may still be 65 nanometers let us say okay average then the 65 nanometer but because of line has roughness effect uh the current flow which was happening from one contact to the other the effective gate oxide thickness would be different ah the effect of poly length the gate length would be different there will be variations there sir it is written that ler is independent of gate length so so how it is causing variations lar is independent of gate length but it does not say that lar doesn't happen just if ldr is happening do you realize that gate length is effectively changing uh yes sir yes sir what it means that it is independent of gate length means that it is dependent on polycrystalline the size of your crystals in the polysilicon not on the length of your gate whether it is whether it is one micron wide length or it is 65 nanometer length the variation will always be plus minus three nanometers okay that is what it means by this statement it is not a percentage sir sir if if it is dependent on the crystalline uh this thing so sir if with the same crystal we are manufacturing 65 nanometer and then we are moving down lower technology nodes so sir this uh thing will be so constant now that's disler in every technology will be constant but let us say there was a 65 nanometer technology because of this plus minus 3 what is the fastest or what is the minimum length that you will get 62 yes 62 versus 65 what is the percentage difference something like five percent yes now let us come to 20 nanometer technology then it will cause uh yes at lower technology note then it will be significant the impact is much more yes the distance is now around 15 percent uh means that this ler will be same across every uh the channel length but it will be more significant in lower technology not just lower technology notes in the same technology you know if you use minimum length to the impact is more yes sir yes my lower technology lower electronology node is a different technology you've got you actually use a different material yes you could use a finer more granular poly silicon crystals we can use our uh we can be more precise during making these uh so we can use lower uh wavelengths to manufacture so we can avoid this earlier do you do you use wavelength to manufacture uh sorry sir uh sorry we studied that in that uh that Optical Ops so do you do you remove it through OPC how does removal happen finally removal uh we can avoid this poly crystals sorry so uh so so that we may avoid yourself so you will not use policy poly silicon then what will you use so uh foreign Sarah I was just asking sir if we could avoid this uh sorry extra uh rough edges all right now I put acid there yes sir that asset reacts with polysilicon which is exposed and I wash it away yes now where does light come in here there's a chemical reaction that is happening yes here it is a chemical reaction that is happening and that chemical reaction is anisotropic in nature because of the crystalline structure Okay so it's a physical process it's a chemical process yes hello okay sir okay sir The Mask which you make that will be making it with the help of the light right I think that's what he was mentioning before yeah and that is what I am clarifying it is not about the mask at all about the process it is about the process of etching it is about chemo uh the chemical removal of of uh the polysilicon that was extra there so that only polysilipin wires remain it is about that yes yes okay that is what I am clarifying,https://www.youtube.com/watch?v=wmdOWoYbP98,"Link: https://www.youtube.com/watch?v=wmdOWoYbP98
Transcript: okay now we enter into the zone of random mismatch now look at this image on the left side is one cross section view of a transistor and on the right side is the dopant profile which is particularized okay the red the red ones are donors the blue ones are acceptors okay now what happens let us say you scale it down you scale down the technology and you expected 20 so this was your gate region so this was your gate region and you expected 20 dopants over here beneath the gate okay but in reality just give me a minute in reality there were let us say three extra dopants all of a sudden what happens the the the Contours the potential Contours of this gate device will be different from the device that you had designed it to be you will now need more band bending are you able to see this to get to the VT of the device you will need more band bending and therefore you may end up as a high VT device a VT is tightly higher than the regular device that you are intended it to be it can also happen instead of 20 there are 18 ropants now less than less band bending is required for VT to be there and therefore you will see that the device is a little fast are you with me so so this is a random This Is Random random two adjacent devices structurally matched WP is same stresses same everything else is same even then you cannot control how many dopants will be there beneath your gate it is physically not possible um so such such variations which you cannot really model deterministically you model them statistically you say that okay of 100 devices uh 70 devices would have 20 dopants only now 10 devices will have uh uh 22 opens 10 devices would have 18 dopants then remaining five devices would have 25 dopants and another five devices would have 15 dopants and you say that there is a distribution there is a distribution where some devices are faster some devices are slower are you able to see this so I have two questions so one is how why this process why this random so I mean you tell me I want to bombard I want to bombard 20 dopants in a region which is uh let us say one micron by 65 nanometers so one micron by one micron device with minimum length yes so 65 nanometer into one micron in that region I want to bombard 20 dopants and I bombard 20 low points exactly or sometimes they will be 21 sometimes they will be 19. it's a process now it's a natural process you're not placing dopants one by one you're just bombarding and you're letting them diffuse foreign you have a pencil with you pen paper pencil with you something like that yes you have control over your head it is the same pencil that I want you to write your name with 20 times and it has to be exactly the same um yes can it be exactly the same why perfect it's not the Perfection cannot be understood this Supernatural process yeah this is a natural process there will be there are bound to be some variations the the velocity of devices the velocity of dopant atoms that you are sending that you are bombarding that is going to be normally distributed here um I guess so I know so there is no way you can have them exactly the same under every device and you cannot model this you can only statistically model this so statistical models would appear but exact models you cannot have to do the worst case analysis you may say that okay I have to assume pass gate to be at 3.5 Sigma pull down to be at 4 Sigma away and that is my first case that was what we did in this SNM analysis that was what we did in the uh right time right margin analysis also in the previous lecture so we placed devices at the worst places and we saw the impact but it is not that this is bound to happen exactly this way we just want to be sure that statistically we are safe So when you say key statistically determined us but I cannot locate which exactly device evaluation yes that you cannot tell hundred messages but with 70 the first 70 or somewhere randomly distributed 70 we that we cannot say foreign let me put pull up at plus three sigma remember um we did that so we did not say sorry devices we actually for verification for for Designing we actually put devices at different corners and that was when we did it right I mean it's a password it's a similar kind of devices what you desire okay for SNM analysis you want low VT on the pass gate for it for uh write time analysis or right margin analysis you need High VT on the pass gate just so so at time we will use one side of the curve at another time you will use another side of the Curve okay sir yes sir can you come back once let's uh so sir uh this according to this below graph sir so this dopant fluctuation is the major cause to the vth variation yes and Sir one thing also I want to ask sir at lower technology nodes yes that is what is shown on this car yes okay okay so uh again this is about uh the impact it has on the memory cell so as so this is actually the memory cell SNM analysis only where we say that okay for different SNM values how is the distribution when cell ratio is moved from two to three to four okay and this has considered only the random dopen fluctuations as a part of variations as yet other other random things are not put in picture another random factor into is interface roughness what does that mean see finally you have you grow silicon dioxide let us say um at some places there are three atoms of silicon three molecules of silicon dioxide at other places there are four molecules of silicon dioxide at some places a molecule is placed in a particular manner at other places the molecule is placed in a different manner huh so what happens the thickness of silicon dioxide can vary across the gate region some places it is 2.2 nanometer by thick at some places 2.6 nanometers say that some other places 2.4 nanometers thick so what does this mean that even though you said that your gate is 22 nanometer thick or 25 nanometer thick there are variations around it the Gate of sight thickness is not exactly the same huh due to this some devices will operate fast some devices will operate slow adjacent devices both have average thickness of 25 nanometer only 25 angstroms only but in one device it was more towards 24 and the other device that was more towards 26. and it is random you cannot control it are you with me okay so this again is a random variation which you have to model in your Monte Carlo simulations another random variation is lineage roughness what does line as roughness means sinus reference means that you want it to design a poly which is of one particular vict throughout whereas poly in itself is a is a polycrystalline material so there are crystals there huh and when you will do etching when you will do chemical etching or anything you remember that crystals have an isotropic Behavior they behave differently across different directions so there is a crystal which is placed here and the Crystal which is placed here so when you do the etching what happens so let us let us take this example let us say that there are these different crystals of silicon dioxide that form the poly region over here and so on um so when you started to etch when you start to etch what happens the crystal boundaries at the Crystal boundaries the extent of H changes so finally you may have a a polysilicon line so you wanted the it to be completely straight and parallel finally you will have a polysilicon line which could be like this thicker somewhere thin somewhere and so on you notice uh in this image the poly thickness is not constant throughout huh what does this mean this means that the length effective length is changing now let us say there was a contact over here and in another device there was a contact over here the effect is thickness of the gate for transmission of current from source to drain from one contact to the other is going to be different for every device are you able to see this uh sir sir how is the thickness changing I mean along the line it is changing now so thickness so Remains the Same right okay I mean okay let me not use the word thickness let us use the word width the length of your device is changing are you able to see this at the length of the device is changing differently for different devices because of this line as roughness also so it seems that in the same device the length is not constant throughout that is also the case but there will be average length so average length may still be 65 nanometers let us say okay average then the 65 nanometer but because of line has roughness effect uh the current flow which was happening from one contact to the other the effective gate oxide thickness would be different ah the effect of poly length the gate length would be different there will be variations there sir it is written that ler is independent of gate length so so how it is causing variations lar is independent of gate length but it does not say that lar doesn't happen just if ldr is happening do you realize that gate length is effectively changing uh yes sir yes sir what it means that it is independent of gate length means that it is dependent on polycrystalline the size of your crystals in the polysilicon not on the length of your gate whether it is whether it is one micron wide length or it is 65 nanometer length the variation will always be plus minus three nanometers okay that is what it means by this statement it is not a percentage sir sir if if it is dependent on the crystalline uh this thing so sir if with the same crystal we are manufacturing 65 nanometer and then we are moving down lower technology nodes so sir this uh thing will be so constant now that's disler in every technology will be constant but let us say there was a 65 nanometer technology because of this plus minus 3 what is the fastest or what is the minimum length that you will get 62 yes 62 versus 65 what is the percentage difference something like five percent yes now let us come to 20 nanometer technology then it will cause uh yes at lower technology note then it will be significant the impact is much more yes the distance is now around 15 percent uh means that this ler will be same across every uh the channel length but it will be more significant in lower technology not just lower technology notes in the same technology you know if you use minimum length to the impact is more yes sir yes my lower technology lower electronology node is a different technology you've got you actually use a different material yes you could use a finer more granular poly silicon crystals we can use our uh we can be more precise during making these uh so we can use lower uh wavelengths to manufacture so we can avoid this earlier do you do you use wavelength to manufacture uh sorry sir uh sorry we studied that in that uh that Optical Ops so do you do you remove it through OPC how does removal happen finally removal uh we can avoid this poly crystals sorry so uh so so that we may avoid yourself so you will not use policy poly silicon then what will you use so uh foreign Sarah I was just asking sir if we could avoid this uh sorry extra uh rough edges all right now I put acid there yes sir that asset reacts with polysilicon which is exposed and I wash it away yes now where does light come in here there's a chemical reaction that is happening yes here it is a chemical reaction that is happening and that chemical reaction is anisotropic in nature because of the crystalline structure Okay so it's a physical process it's a chemical process yes hello okay sir okay sir The Mask which you make that will be making it with the help of the light right I think that's what he was mentioning before yeah and that is what I am clarifying it is not about the mask at all about the process it is about the process of etching it is about chemo uh the chemical removal of of uh the polysilicon that was extra there so that only polysilipin wires remain it is about that yes yes okay that is what I am clarifying"
4zbGyJ0elMs,so so the graph on the left so the x-axis what is signifying so the graph on the left right so sorry right the below ground oh it is just saying that as you move away from you know as you move from one part of the chip to another uh The Edge the the thick this this variation is simply varying there is no constant there is no what do you say uh there is no pattern there yeah is there a pattern no there's no pattern some places there is more roughness some places there is less roughness it is just how polysilicon got deposited yes sir okay so now this is what we just discussed even if the variations remain constant even if the line is you know Delta L we said is constant you see the impact across Technologies is very different huh that is why as we go to still Advanced Technologies more and more variations are coming into picture and they impact memory design very very significantly okay so yes sir actually here only uh in the first it also I had this question so here it is written that the internet we uh in the random uh variations we had three kind of variations right but here it is saying that the interesting random variations tend to be constant magnitude so what exactly do you mean by the intrinsic random variations I mean roughness line as roughness is intransit to the way devices manufactured interface roughness is intrinsic to the way silicon dioxide is deposited okay they are intrinsic they are not because of something else you know two police are placed right next to each other it is not one poly so this device the the dopants that will come under one one gate is not dependent on any other gate is it dependent whether I placed another gate close to it or far away from it does it can it is it dependent on that no therefore it is called intrinsic variation well proximity effects and others could be considered as extrinsic variations that poly necking and everything they are extrinsic variations and so in the random relations there was also one uh subcategory of sudo so how is it you know what yeah Sudo is something like you have two devices but there is a temperature gradient because of some heat being generated in some place now there is a temperature gradient physically the devices were similar but now due to higher temperature in one cell in in one device and lower on the other the mobility has changed a bit okay there is some higher drop that happened let us say so everything was same but due to 20 millivolt airdrop now the vgs That You observe is little different those are pseudo variations again you cannot say what will happen you know they're dependent on some patterns how you will run the device what what how the user will activate the device and so on okay so now this yes so like in intrinsic we are only taking consideration the device and the process I mean nothing else is there but in the pseudo we are considering in uh apart from the device some external event I mean yeah which we do not have control over okay okay thank you okay now in terms of VT variations there are multiple reasons why VT variations could happen we talked about dopants he talks about interface roughness we talked about uh uh lineage roughness and so on but there are other variations also that there could be band Gap variation there could be work function variation and so on and all of that all of that uh could be because of different reasons well proximity effects so some are systematic some are non-systematic and they all have to be modeled into your device equations so that when you run Monte Carlo simulations at your end you're able to see impact of all of them collectively on your circuit Behavior okay as I mentioned we will share the entire big slides with you you can study at study them in detail but this was just to give you a glimpse of various kinds of variations that happen and as raghav was just asking there are some variations which are environmental in nature for example Supply voltage fluctuations Could Happen temperature could change and there are some variations which are operational in nature for example clock data and you know static and dynamic variations in terms of ir drop Junction temperature and all those things across the chip so when we say environment environmental variation means you decided to run the chip at 1.0 volts instead of 1.1 volts that is a supply voltage variation okay or uh just give me a minute so so it says jumping or there could be clock Jitter which is happening on the Fly okay so these are pseudo so these are the clock Jitter and everything these are pseudo variations pseudo random variations okay they are not intrinsic they are pseudo random but they are there they may happen at some time they may not happen at some time therefore they are dynamics you cannot always assume them to be there but these environmental variations so you can actually simulate at 1.0 volt and see the impact or 1.1 volt and see the impact of it on your system so these environmental variations are a part of your pvt condition uh the operational variations are something that you need to leave margins for okay so again as I said some of the variations can be modeled some cannot be modeled and whatever it is you have to operate Your Design accordingly you want to model as much as possible at times you model the exact variation at times you model the variation in a statistical manner so then you will need to run the Monte Carlo simulations to verify your circuit okay and uh yeah this is a quick summary that there are different kinds of variations and there are ways to handle them you can make structurally good layouts you can make matched layouts so that at least systematic variations are minimized but there are some variations which will normally always remain to handle them you can use larger devices larger weights larger length so that the impact of those variations is reduced the more the gate area of your device the Lesser is the impact of random variations on the device okay so for the sense amplifier when you design the sense amplifier you will not use minimum length devices if you want to reduce the random variations for the memory cell we do not use the minimum length devices two reasons we want to reduce the leakage but also because the variation impact can be very very significant if you use minimum length devices okay sir sir you can explain this dfm thing so dfm means design for manufacturability we saw that there were variations remember the systematic variation slide that we the second slide that we saw necking over at there were bends in the poly and everything yes sir some contact pads were bigger some contact pads were lesser and so on now this led to variations in poly weights yes sir we know that this is systematic variation is such systematic variations can lead to yield loss then the technology teams will give you an additional set of rules which are called as dfm rules designed for manufacturability rules what this means is that if you have sufficient space in that region please give that extra spacing please keep only you know parallel police do not bend the poly here and there so for example for example in 45 nanometer there is a DSM rule which says do not give bends on poly in 32 nanometer we said no bends on poly are allowed at all so what a rule of an advanced technology could still be followed in a older technology so that variations are reduced and that is called as design for manufacturability variations okay so that area loss now okay and this can be done if you design with the DSM already in mind you can actually make very good dance layouts no no area penalty but very dense layouts and you can make them okay yes okay so I will I will post the entire what do you say tutorial and the classroom I would strongly recommend that you study the tutorial in completeness but this in this lecture I kind of have introduced you to the most important very sources of variations and what to do about them but there is much more the entire tutorial is very very big I've just picked up a few slides over here so I would strongly recommend that you see the full tutorial rather so can you move one two slides below I had a so in which there was a table comprehensive table I mean uh before that so before this I mean uh before this also yes sir so I mean uh from for example the first row that I'm seeing so you have sent the dopin profile right and you can they recruit various causes and then you have the variables put here but I can see that you have all the kind of token if if for example certain fluctuations or relations are happening due to dopen profile you will be modeling them as VT variation right yes that you're saying so but on the variable side you have included the well proximate effect that is a structural thing and the dope and fraction that influencing thing so I mean you are modeling random and the structural same DT not same VT what we are saying is when we decide the VT when we decide the beauty we have to be some variable of well proximity effect also coming in some variable of random open fluctuations also coming in and so on so you will see that when you will extract layouts in Advanced Technologies there will be lot of extra variables that will be so abhi observed 65 when you extract a device in 65 nanometer what do you see you see WL pdts Adas and that is the definite that is the kind of a place where the variables end am I right in Advanced Technologies you will see they will there is another variable called a there's another variable called uh CO2 act there is another variable called something else what does that mean we are adding variables additional variables in my extracted net list so that I can model the well proximity effect into devices which are susceptible to it I can model stress effect wherever it is relevant you notice dopant fluctuation has been in Brackets mentioned as intrinsic so you cannot model it through extraction what do you do you model it in statistical simulations through Monte Carlo you see it is mentioned as intrinsic over here so so like I mean I can make like ptk question equations basically but which are multiplied which are so there will be some effect which will be multiplied with the value of well proximity or distance from the well as recorded in your extracted net list yes uh okay so sorry Echo cheese these are just Bolton I actually cheat number clearly what do you mean statistics yes sir what do Monte Carlo simulations do something what is we have a bell shaped curve in which you have a sigma and a mean value and we say that keep most of the devices will be lying at the mean value but Sigma after the sigma certain device will be on this side on that side Quest Academy so that is statistical modeling where you're saying 70 of the devices will be within plus minus Sigma another another 25 percent of our devices are within plus minus two Sigma another uh three percent of devices are within plus minus three sigma not a statistical modeling okay okay that is about statistics now how many devices are within this range we discussed now because you're talking about exactly the same thing okay so yeah so so statistical modeling means that you define how the statistics would be you cannot Define this is okay for well proximity effect ux you got a variable in your uh extracted net list you simply multiplied and you know what the VP change was but for dupense activations you cannot do that you can simply say the statistics link should open fluctuation and then you run Monte Carlo done yes sir okay thank you sir okay guys all,https://www.youtube.com/watch?v=4zbGyJ0elMs,"Link: https://www.youtube.com/watch?v=4zbGyJ0elMs
Transcript: so so the graph on the left so the x-axis what is signifying so the graph on the left right so sorry right the below ground oh it is just saying that as you move away from you know as you move from one part of the chip to another uh The Edge the the thick this this variation is simply varying there is no constant there is no what do you say uh there is no pattern there yeah is there a pattern no there's no pattern some places there is more roughness some places there is less roughness it is just how polysilicon got deposited yes sir okay so now this is what we just discussed even if the variations remain constant even if the line is you know Delta L we said is constant you see the impact across Technologies is very different huh that is why as we go to still Advanced Technologies more and more variations are coming into picture and they impact memory design very very significantly okay so yes sir actually here only uh in the first it also I had this question so here it is written that the internet we uh in the random uh variations we had three kind of variations right but here it is saying that the interesting random variations tend to be constant magnitude so what exactly do you mean by the intrinsic random variations I mean roughness line as roughness is intransit to the way devices manufactured interface roughness is intrinsic to the way silicon dioxide is deposited okay they are intrinsic they are not because of something else you know two police are placed right next to each other it is not one poly so this device the the dopants that will come under one one gate is not dependent on any other gate is it dependent whether I placed another gate close to it or far away from it does it can it is it dependent on that no therefore it is called intrinsic variation well proximity effects and others could be considered as extrinsic variations that poly necking and everything they are extrinsic variations and so in the random relations there was also one uh subcategory of sudo so how is it you know what yeah Sudo is something like you have two devices but there is a temperature gradient because of some heat being generated in some place now there is a temperature gradient physically the devices were similar but now due to higher temperature in one cell in in one device and lower on the other the mobility has changed a bit okay there is some higher drop that happened let us say so everything was same but due to 20 millivolt airdrop now the vgs That You observe is little different those are pseudo variations again you cannot say what will happen you know they're dependent on some patterns how you will run the device what what how the user will activate the device and so on okay so now this yes so like in intrinsic we are only taking consideration the device and the process I mean nothing else is there but in the pseudo we are considering in uh apart from the device some external event I mean yeah which we do not have control over okay okay thank you okay now in terms of VT variations there are multiple reasons why VT variations could happen we talked about dopants he talks about interface roughness we talked about uh uh lineage roughness and so on but there are other variations also that there could be band Gap variation there could be work function variation and so on and all of that all of that uh could be because of different reasons well proximity effects so some are systematic some are non-systematic and they all have to be modeled into your device equations so that when you run Monte Carlo simulations at your end you're able to see impact of all of them collectively on your circuit Behavior okay as I mentioned we will share the entire big slides with you you can study at study them in detail but this was just to give you a glimpse of various kinds of variations that happen and as raghav was just asking there are some variations which are environmental in nature for example Supply voltage fluctuations Could Happen temperature could change and there are some variations which are operational in nature for example clock data and you know static and dynamic variations in terms of ir drop Junction temperature and all those things across the chip so when we say environment environmental variation means you decided to run the chip at 1.0 volts instead of 1.1 volts that is a supply voltage variation okay or uh just give me a minute so so it says jumping or there could be clock Jitter which is happening on the Fly okay so these are pseudo so these are the clock Jitter and everything these are pseudo variations pseudo random variations okay they are not intrinsic they are pseudo random but they are there they may happen at some time they may not happen at some time therefore they are dynamics you cannot always assume them to be there but these environmental variations so you can actually simulate at 1.0 volt and see the impact or 1.1 volt and see the impact of it on your system so these environmental variations are a part of your pvt condition uh the operational variations are something that you need to leave margins for okay so again as I said some of the variations can be modeled some cannot be modeled and whatever it is you have to operate Your Design accordingly you want to model as much as possible at times you model the exact variation at times you model the variation in a statistical manner so then you will need to run the Monte Carlo simulations to verify your circuit okay and uh yeah this is a quick summary that there are different kinds of variations and there are ways to handle them you can make structurally good layouts you can make matched layouts so that at least systematic variations are minimized but there are some variations which will normally always remain to handle them you can use larger devices larger weights larger length so that the impact of those variations is reduced the more the gate area of your device the Lesser is the impact of random variations on the device okay so for the sense amplifier when you design the sense amplifier you will not use minimum length devices if you want to reduce the random variations for the memory cell we do not use the minimum length devices two reasons we want to reduce the leakage but also because the variation impact can be very very significant if you use minimum length devices okay sir sir you can explain this dfm thing so dfm means design for manufacturability we saw that there were variations remember the systematic variation slide that we the second slide that we saw necking over at there were bends in the poly and everything yes sir some contact pads were bigger some contact pads were lesser and so on now this led to variations in poly weights yes sir we know that this is systematic variation is such systematic variations can lead to yield loss then the technology teams will give you an additional set of rules which are called as dfm rules designed for manufacturability rules what this means is that if you have sufficient space in that region please give that extra spacing please keep only you know parallel police do not bend the poly here and there so for example for example in 45 nanometer there is a DSM rule which says do not give bends on poly in 32 nanometer we said no bends on poly are allowed at all so what a rule of an advanced technology could still be followed in a older technology so that variations are reduced and that is called as design for manufacturability variations okay so that area loss now okay and this can be done if you design with the DSM already in mind you can actually make very good dance layouts no no area penalty but very dense layouts and you can make them okay yes okay so I will I will post the entire what do you say tutorial and the classroom I would strongly recommend that you study the tutorial in completeness but this in this lecture I kind of have introduced you to the most important very sources of variations and what to do about them but there is much more the entire tutorial is very very big I've just picked up a few slides over here so I would strongly recommend that you see the full tutorial rather so can you move one two slides below I had a so in which there was a table comprehensive table I mean uh before that so before this I mean uh before this also yes sir so I mean uh from for example the first row that I'm seeing so you have sent the dopin profile right and you can they recruit various causes and then you have the variables put here but I can see that you have all the kind of token if if for example certain fluctuations or relations are happening due to dopen profile you will be modeling them as VT variation right yes that you're saying so but on the variable side you have included the well proximate effect that is a structural thing and the dope and fraction that influencing thing so I mean you are modeling random and the structural same DT not same VT what we are saying is when we decide the VT when we decide the beauty we have to be some variable of well proximity effect also coming in some variable of random open fluctuations also coming in and so on so you will see that when you will extract layouts in Advanced Technologies there will be lot of extra variables that will be so abhi observed 65 when you extract a device in 65 nanometer what do you see you see WL pdts Adas and that is the definite that is the kind of a place where the variables end am I right in Advanced Technologies you will see they will there is another variable called a there's another variable called uh CO2 act there is another variable called something else what does that mean we are adding variables additional variables in my extracted net list so that I can model the well proximity effect into devices which are susceptible to it I can model stress effect wherever it is relevant you notice dopant fluctuation has been in Brackets mentioned as intrinsic so you cannot model it through extraction what do you do you model it in statistical simulations through Monte Carlo you see it is mentioned as intrinsic over here so so like I mean I can make like ptk question equations basically but which are multiplied which are so there will be some effect which will be multiplied with the value of well proximity or distance from the well as recorded in your extracted net list yes uh okay so sorry Echo cheese these are just Bolton I actually cheat number clearly what do you mean statistics yes sir what do Monte Carlo simulations do something what is we have a bell shaped curve in which you have a sigma and a mean value and we say that keep most of the devices will be lying at the mean value but Sigma after the sigma certain device will be on this side on that side Quest Academy so that is statistical modeling where you're saying 70 of the devices will be within plus minus Sigma another another 25 percent of our devices are within plus minus two Sigma another uh three percent of devices are within plus minus three sigma not a statistical modeling okay okay that is about statistics now how many devices are within this range we discussed now because you're talking about exactly the same thing okay so yeah so so statistical modeling means that you define how the statistics would be you cannot Define this is okay for well proximity effect ux you got a variable in your uh extracted net list you simply multiplied and you know what the VP change was but for dupense activations you cannot do that you can simply say the statistics link should open fluctuation and then you run Monte Carlo done yes sir okay thank you sir okay guys all"
QvyyCFOEPAA,so now let's come to random mismatches how do you take care of Random mismatches how do you ensure that random mismatches impact is minimized uh so one one way can be to select the VT of the devices carefully like if we uh like if we know that I am unable to put it into words but I you can like model let us say I chose the VT of 200 millivolts what happens then blueprint functionality functionality you told you you can control that yeah what you were saying something about dope and fluctuations how do I manage that how do I reduce the impact of dope and fluctuations so like uh you told that statistically in doping them statistically then we can manage the doping hmm but how do I design so that there is lesser impact so see raghav's question was how do I model it your question is how do I verify it my question is how do I design it designed like what I'm not able to get the question my question is what should be the design guidelines so that the impact of random mismatches is minimized we discussed this in the last class design modeling is for verification tala I know like I know as a designer what should be the thumb rule there was one full slide on that topic to demonstrate that topic you remember there was a slide on the impact of variations with technology scaling um hello what did You observe in that side so that impact increases as the technology scales down um but impact remains same so as we go down uh the percentage increases like the proposal basically you are decreasing the but the effect remains same so its effect is more pronounced in thinner Aggregates so now do you have the answer of how to design so that you have lesser impact long channels use long Channel length use bigger devices the more the area under your gate the Lesser is the impact of variations not because the variations don't exist the variations will still exist but just that you have changed the base just like in in you know plus minus two nanometer variation in a 28 nanometer technology is some impact but plus minus two nanometer variation and a 40 nanometer technology has doubled the percentage impact and a much higher electrical impact on in terms of variations similarly if you just increase the base increase the even though 28 nanometer is the minimum length that you could draw let us say you draw 40 nanometer so you are kind of emulating the previous Technology's length um and reducing the impact of variations now in fact that is one reason I I actually did mention that in the sense in the sense amplifiers and in the SRAM cell you almost never use the minimum length yes yeah we talked about that so for SRAM cell it also helps in reducing sub threshold currents uh but you do not do it also primarily because you want to reduce the variations impact of variations so now rather coming to the to the question that you asked that oh there are these many so many things lineage roughness gate oxide uh you know the interface uh interface roughness and so many things I do not see any any of that in the model that I have yes because all of those variations are clubbed into VT variations how is VT defined do you remember what is the industrial definition of VT that we talked about in DVD course so it was linked to the current only sub threshold current only not for Central current we said we we said VT is the current uh VT is the voltage gate voltage uh at which the current of one micron per one one milliampere one microampere per Micron width would flow from the gate from the device so all these things whether it is lineage roughness or interface roughness or you know the range of things that we talked about they will lead to some change in current of the device so we model everything as variation in VT and Mobility so so at the very end I can I will only see the VT variation Mobility variation but the source of that will not be I cannot locate it localize it right right from yes yes the models and as a designer do you need to localize it and much more complexity in the device model finally you want the device the simulator to run fast is it not the more number of variables you ask it to calculate the more time the simulator will take so you have to keep the models as simple and synthetic as possible so most of most of times the random variations are modeled using the weighty variations right yeah vtn Mobility variations vtn Mobility okay thanks okay so now that we are talking about variations anything else about uh mismatch or variations that you have questions about from the last session sir about the guideline that we were discussing just now so sir if we were supposed to use uh 22 nanometer and we are using 45 nanometer then I mean it's good to use 45 nanometer right then why to why to actually mention it as 22 and change it to 45 actually uh so in the SRAM cell you will use 40 nanometer um but everywhere else you could use 28 where variations are not important so this is only okay so even I was thinking that only sir I mean that's only limited to to the memory memory cell itself the io and the other things can be done in 20 I mean like below technology lower technology so everything is done in the lowest technology whichever technology you are designing in that is what it is we just said that instead of using the minimum length you use a little larger length Technologies remain same vaishnav that doesn't change because I I chose the larger length yes sir are you able to see this yes sir I understood I mean I was just thinking of this differentiation between the memory so this this uh the thing which we increase that only uh and the concern towards the memory cell itself not not the outer part right so yeah and again don't limit it to memory cell rationals I would say wherever variations are important in analog circuits you will never use an email link you make an op amp you will never use on your length why I mean so we are supposed to see that all the transistors are in saturation and may make that you want to match devices to reduce the offset of an op amp you have to match the devices okay it is not about saturation or anything it is about that you want to match the devices therefore you do not use minimum length does a minimum length device not go into saturation it also goes into saturation yes sir but uh yes it will go over the structure would be in such a way that we are supposed to see all the factors that are present you can do that with minimum length devices no problems okay sir you can always do that it is mismatch which bothers you because of which you use larger link devices it is not it is not a design method specific to srams that is what I am trying to emphasize to you I don't know people don't talk about it because they simply say Okay 100 nanometer length you don't even question them oh we are in 20 nanometer technology why do you use 100 nanometer length have you questioned no no how did you not question because they simply say this is how it works but the reality is you could do everything with 28 nanometer just go and design your folded cascodes and Sample uh op amp with this you could do it with minimum length also the variations will be very high to manage the variations and to have good deal on Silicon you say I will use larger length that is why use 100 nanometer line 150 nanometer length yes sir yeah okay so you don't assume investigate and find out yes sir I'll do that yeah okay yeah so uh if there are no more questions we come to today's lecture then um so yes so as you were saying the technology node will remain the same but we are using a bit larger Channel technology what he was telling me is that memory cell is getting fabricated in in other technology and uh on the same die there is a circuit which is getting fabricated in another technology that's why I got confused okay that is what you want to tell me that is what my question is I think technology technology mode node is defined by what is the minimum length or what is whatever the node is there is always a range of lengths that you can use on your devices okay okay oh so you always assume that for 65 nanometer technology you have to use 65 nanometer gate length yes I I have understood now yeah okay yes yes sir,https://www.youtube.com/watch?v=QvyyCFOEPAA,"Link: https://www.youtube.com/watch?v=QvyyCFOEPAA
Transcript: so now let's come to random mismatches how do you take care of Random mismatches how do you ensure that random mismatches impact is minimized uh so one one way can be to select the VT of the devices carefully like if we uh like if we know that I am unable to put it into words but I you can like model let us say I chose the VT of 200 millivolts what happens then blueprint functionality functionality you told you you can control that yeah what you were saying something about dope and fluctuations how do I manage that how do I reduce the impact of dope and fluctuations so like uh you told that statistically in doping them statistically then we can manage the doping hmm but how do I design so that there is lesser impact so see raghav's question was how do I model it your question is how do I verify it my question is how do I design it designed like what I'm not able to get the question my question is what should be the design guidelines so that the impact of random mismatches is minimized we discussed this in the last class design modeling is for verification tala I know like I know as a designer what should be the thumb rule there was one full slide on that topic to demonstrate that topic you remember there was a slide on the impact of variations with technology scaling um hello what did You observe in that side so that impact increases as the technology scales down um but impact remains same so as we go down uh the percentage increases like the proposal basically you are decreasing the but the effect remains same so its effect is more pronounced in thinner Aggregates so now do you have the answer of how to design so that you have lesser impact long channels use long Channel length use bigger devices the more the area under your gate the Lesser is the impact of variations not because the variations don't exist the variations will still exist but just that you have changed the base just like in in you know plus minus two nanometer variation in a 28 nanometer technology is some impact but plus minus two nanometer variation and a 40 nanometer technology has doubled the percentage impact and a much higher electrical impact on in terms of variations similarly if you just increase the base increase the even though 28 nanometer is the minimum length that you could draw let us say you draw 40 nanometer so you are kind of emulating the previous Technology's length um and reducing the impact of variations now in fact that is one reason I I actually did mention that in the sense in the sense amplifiers and in the SRAM cell you almost never use the minimum length yes yeah we talked about that so for SRAM cell it also helps in reducing sub threshold currents uh but you do not do it also primarily because you want to reduce the variations impact of variations so now rather coming to the to the question that you asked that oh there are these many so many things lineage roughness gate oxide uh you know the interface uh interface roughness and so many things I do not see any any of that in the model that I have yes because all of those variations are clubbed into VT variations how is VT defined do you remember what is the industrial definition of VT that we talked about in DVD course so it was linked to the current only sub threshold current only not for Central current we said we we said VT is the current uh VT is the voltage gate voltage uh at which the current of one micron per one one milliampere one microampere per Micron width would flow from the gate from the device so all these things whether it is lineage roughness or interface roughness or you know the range of things that we talked about they will lead to some change in current of the device so we model everything as variation in VT and Mobility so so at the very end I can I will only see the VT variation Mobility variation but the source of that will not be I cannot locate it localize it right right from yes yes the models and as a designer do you need to localize it and much more complexity in the device model finally you want the device the simulator to run fast is it not the more number of variables you ask it to calculate the more time the simulator will take so you have to keep the models as simple and synthetic as possible so most of most of times the random variations are modeled using the weighty variations right yeah vtn Mobility variations vtn Mobility okay thanks okay so now that we are talking about variations anything else about uh mismatch or variations that you have questions about from the last session sir about the guideline that we were discussing just now so sir if we were supposed to use uh 22 nanometer and we are using 45 nanometer then I mean it's good to use 45 nanometer right then why to why to actually mention it as 22 and change it to 45 actually uh so in the SRAM cell you will use 40 nanometer um but everywhere else you could use 28 where variations are not important so this is only okay so even I was thinking that only sir I mean that's only limited to to the memory memory cell itself the io and the other things can be done in 20 I mean like below technology lower technology so everything is done in the lowest technology whichever technology you are designing in that is what it is we just said that instead of using the minimum length you use a little larger length Technologies remain same vaishnav that doesn't change because I I chose the larger length yes sir are you able to see this yes sir I understood I mean I was just thinking of this differentiation between the memory so this this uh the thing which we increase that only uh and the concern towards the memory cell itself not not the outer part right so yeah and again don't limit it to memory cell rationals I would say wherever variations are important in analog circuits you will never use an email link you make an op amp you will never use on your length why I mean so we are supposed to see that all the transistors are in saturation and may make that you want to match devices to reduce the offset of an op amp you have to match the devices okay it is not about saturation or anything it is about that you want to match the devices therefore you do not use minimum length does a minimum length device not go into saturation it also goes into saturation yes sir but uh yes it will go over the structure would be in such a way that we are supposed to see all the factors that are present you can do that with minimum length devices no problems okay sir you can always do that it is mismatch which bothers you because of which you use larger link devices it is not it is not a design method specific to srams that is what I am trying to emphasize to you I don't know people don't talk about it because they simply say Okay 100 nanometer length you don't even question them oh we are in 20 nanometer technology why do you use 100 nanometer length have you questioned no no how did you not question because they simply say this is how it works but the reality is you could do everything with 28 nanometer just go and design your folded cascodes and Sample uh op amp with this you could do it with minimum length also the variations will be very high to manage the variations and to have good deal on Silicon you say I will use larger length that is why use 100 nanometer line 150 nanometer length yes sir yeah okay so you don't assume investigate and find out yes sir I'll do that yeah okay yeah so uh if there are no more questions we come to today's lecture then um so yes so as you were saying the technology node will remain the same but we are using a bit larger Channel technology what he was telling me is that memory cell is getting fabricated in in other technology and uh on the same die there is a circuit which is getting fabricated in another technology that's why I got confused okay that is what you want to tell me that is what my question is I think technology technology mode node is defined by what is the minimum length or what is whatever the node is there is always a range of lengths that you can use on your devices okay okay oh so you always assume that for 65 nanometer technology you have to use 65 nanometer gate length yes I I have understood now yeah okay yes yes sir"
TAOP4xaId7Y,Okay so let's look at now statistics of vlsi design so while we're talking about all these mismatches and everything huh it is important to now also see what what do I mean by statistical modeling and all that so I'm not taking this course on probability and statistics I'm just giving you a glimpse of the kind of Statistics that we need to be aware of when we design in vlsi uh again we can talk about this in so much detail in our memory design course because memories are most strongly impacted by statistical variations but as we go to final geometry is more Advanced Technologies uh even flip-flops and even uh every other circuit in fact has an impact or sees an impact but memory is being what they are they see the failures first therefore we talk about it in the memories course uh we don't talk about it as much in analog design course because there are trimming bits there are reference currents which you would trim and they would bias the circuit again to the desired point and memories you do not have that kind of flexibility again and therefore statistics become very relevant and in reality the same statistics you can apply it to any other circuit also uh the only thing is that those circuits are not repeated as often uh you don't need to go to Six Sigma accents as we will just see okay so what we are talking about when we say talking about Factor success that if there is a gaussian distribution all of you know what a gaussian distribution is what is the gaussian distribution see it you're searching for the definition of gaussian distribution you don't need to do that what do you understand the question distribution it's uh kind of in nature that uh certain if it's a random variable then the certain probabilities are more towards one in like it's a density more in middle and it spreads out as we go from the mean basically as you go away from the mean the probability reduces for the random variable you are referring it happens in nature also so it's kind of modeling natural something like that so when we when we set out to Model Natural uh processors do you see that okay I want to Target uh uh I want to Target that let us say you're hitting uh you're trying to hit a Dart onto the bullseye I always want to go into the center but I may go a little on the uh towards the left or right or top or bottom or something like that and since my target is always the center you will notice that most of my dots would actually hit close to the center if I have a good hand and I have good practice but there will still be some dots which would go go towards the periphery uh in terms of processes for example we would say that okay I wanted uh 20 particles to be embedded bombarded and and then diffused in my source strain region but not always 20 will be there at times 21 will go at times 22 will go at times 18 will go so these are variations that will naturally happen in any manufacturing process and gaussian distribution models such variations well okay uh but gaussian distribution is not the only distribution that that we are worried about in VLS I have a gaussian distribution is the primary distribution because of which are you know mismatches are introduced in our circuits in our devices in our designs so for example we talked about gate oxide thickness that okay there will be there will be places there will be there will be two atoms there will be two and a half atoms or uh you know the orientation is such that the Gate of fat thickness would vary from 22 to 28 nanometers that was the that was the micrograph that we saw in the last class so in reality since the target was say 25 nanometers most of the samples will be around 25 nanometers in fact if you plot the distribution the probability distribution of the thickness you will see that around 25 nanometers that is the center of this curve there will be maximum number of samples so let us say this is 25 uh 25 angstroms the gate oxide thickness and up to 68 68.2 percent of samples would exist between plus minus one Sigma let us say Sigma was 1 1 angstrom so 26 angstrom and 24 angstrom so between 24 angstrom and 26 angstrom you would have 68 of your samples between 20 3 and 27 angstroms you would have 95 percent of your samples between nine 22 and 28 the measurements that was shown on on that micrograph you would actually have 99 99.7 percent of your surface area having that kind of a range but there will still be places there will still be places which will which would correspond to this remaining 0.3 percent where thickness could be less than 22 or greater than 28. do you get the sense of it that as you go go beyond the nominal the main point uh the number of samples you will get there would reduce have you noticed this in your experience also hello so as we are moving away from the mean the number of samples are reducing yes yeah did you experience this yes so when we say that SNM is Six Sigma qualified what do we mean it means that we are allowing uh I'm like 99 percent I'm like it's the best case I'm like uh we have this uh gap of uh Six Sigma which consists to the 99 or 99.7 percent okay so actually the the Six Sigma uh like some of you might have heard those of you who have worked in the industry for a little while you might have heard the term Six Sigma approach have you heard that so this this is the Six Sigma that they talk about plus minus three sigma that is the Six Sigma that that management approach talks about however when we talk about srams when we say Six Sigma we're talking about Six Sigma on this side one side and we want to ensure that this nominal minus 6 Sigma is also a SNM value which is acceptable to you why do we need to go that far increase yields increases there could be many variations so we need to accept my what is the probability of getting a something there 99.7 are within three sigma why do I need to go to Six Sigma so but there are many cells I mean uh like 1mb could be meaning 1 billion yeah 99.7 means and thousand cells how many would not would not fit [Music] three cells would fail is it acceptable to you the Chipotle so no no Hannah now is it acceptable for a management situation how many projects does a company do or uh you know how many projects does a team in any any particular team would do in a year 20 10 20 depending on the size of the projects and the size of the team now 20 what is the probability of failure happening within those 20 if you are qualified Six Sigma of the management approach if you manage my qualified from this to this and you have only 20 samples to take the probability that that that particular sample will come out of out of range is much lower now since the number of samples in those management principles are on management practices is lesser they go to Six Sigma which means plus minus 3 Sigma since the number of samples that we have to account for in memories is much much higher suppose I want 99 yield with a 16 megabit capacity what is the failure what is the number of failures that are acceptable so you will see that forever for a 16 megabit capacity I need to go to Six Sigma extent to ensure a 99 period because 16 MB means 16 into 10 raised to power 6 into 100 so these many memory cells we are talking about 100 Dice and of this you say one should fail so there can be only one failure in these many samples and that you will see means so many nines before you get a first date and that is why we need to go to plus minus Six Sigma analysis in our designs so we are talking of one die out of 100 dice of one cell one called the cells you tell me can this one die or automatically fail one say one cell fails and anyone die that diesner if you want 99 yield what are you essentially talking about you are saying that in that 16 not 16 megabit in that sixteen hundred megabit capacity which is across hundred eyes one cell fails now the in that same day there could be another cell that is failing that will not lead to any additional loss of yield but again what is the probability that the second failure will also lie on that same die one by hundred is it not yes sir so for all practical purposes you can only accept one failure per 100 dice so this is the kind of capacity in which I want only one failure um I said so can you give an example I'm not clearly getting the concept like okay Sigma part but uh why we have moved from three sigma to Six Sigma is it just because the yield so let us say you designed something with plus minus three sigma sizes yes I have one one megabit memory capacity on the chip one tip okay how many memory cells do I have one one into ten to the power 6 into 100 on one trip yes sir one into ten raised to the power 6 is what I have on one chip now yes sir yes sir so again 99.73 is the pass rate how many cells on that one chip will fail foreign is the pass rate for that for that design how many cells in that particular chip will fit one chip only a b how many cells so if this is the password what is the failure rate what is the probability of failure the password is 0.9973 what is the probability of failure point zero zero two seven yes yes sir so if if every cell can fail with the probability of 0.0027 a collection of 1 million cells would would say how many of them would fail in this probability in this setting one million and two point zero zero zero two seven point zero zero two seven so that would be equal to twenty seven hundred cells yes sir every die will have 2700 failures what will are we talking about okay the number of cells which are failing are less obviously anything that something so we are if we are qualifying six plus minus Six Sigma we are ensuring that 99.999999 eight percent of sales are taken care of okay okay sir only remaining are outliers that also you will see every 100 die there is something failing okay sir yes sir sir you're freshner sir I understood this Six Sigma thing but sir this is okay it's for the 16 MB example this is fine sir I mean one is getting failed so sir but we even designed the memory in I'm like GBS also right so in that case I think Six Sigma is also not sufficient I mean we are supposed to go to 9 Sigma no for there then we will go to repair mechanisms so we'll talk about repair we will talk about repair don't worry okay sir okay but yes when you design when you verify your design you have to verify it for Six Sigma plus minus Six Sigma not the management while our Six Sigma okay so but uh like you're saying that even in one die even if one bit cells fails my whole die will fail but sir like I will have kind of uh I would have modeled or designed something like if my bit still seal there are some like uh other bit cells which can take place of it or we can use it I mean they have talked about it yet so for present understanding even oneself is the dive rejected okay so I'm already telling you we will have some repair we'll talk about repair not today probably next class but if there was no repair then the die has failed yes yes so knowing there's a bit scrambling is that and like repair mechanisms are welcome to it when we talk about bit scrambling about repair mechanism is that okay yes sir so what we are saying is that we have to qualify plus minus Six Sigma now let us talk about two additional numbers what is called as process capability is defined by a number called CP and another number called CPK okay uh both CP and CPK have different uh different impact or different uh uh convey different kind of information about the process huh the first CP indicates that the statistical control in the process is good what do we see what is the upper specification limit minus the lower specification limit upon 6 Sigma of the process we will just look at what this means okay and CPK instead talks about a different parameter it says how far is my upper specification limit from the mean and how far is the lower specification limit from the mean and then you look at it in terms of Sigma now what does this mean now process capability means that is your CP is less than one if your CP is less than one what happens what it means is upper spec limit minus lower spec limit is some value but your Six Sigma is crossing that value are you able to see this if this is equal to less than 1 means that that your design is crossing this upper speculate and local Speculator therefore it is less than one CP equal to 1 exactly equal to 1 means that plus minus 3 Sigma of my curve lies within the specification limit so the failure rate would be 0.3 percent see what did we say that plus minus 3 Sigma Beyond there could be point three in a percent number of samples that was what we just saw foreign 99.7 okay okay yes 1000 can the three failures on it yeah point three percent is samples will still come out of it that is CP equal to 1. what does CP equal to 2 mean CP equal to 2 would mean that each side I have Six Sigma extent which is taken care of huh that is where I said that CP greater than 2 indicates that the process is in good statistical control you can think of getting good lead on the memory are you able to see this so CP is equals to 2 will be our Six Sigma limit minus 6 Sigma yes two CP is greater than two how much yes okay so now that is about process control now anything greater than Oneness also okay yeah I know so now sorry other than just see just wait two minutes let's look at the other parameter which defines process capability let us say that I actually have this CP equal to 2 so I have this kind of a gaussian which is plus minus 6 Sigma on each side but in reality the process may change May shift a little to the left a little to the right the typical process corner is centered right away and the target but slow and fast process Corners are also there is it not so the slow and fast process Corners would be here or could be here as they have shown what does this mean suppose my slow corner is here what does this mean that means that in the lower one we are uh we have even we are going even Beyond minus 12 Sigma minus X Sigma on the lower side but nothing on the positive side is covered yeah so what this means is that all these cells which are on this side of the lobe are getting failed are getting rejected so for the SS lot for example my area is zero percent uh 50 only is that acceptable no sir no so the other parameter talks about process capability in terms of how the centering is how good the centering is ah a capable of producing repeatable products how well can I Center it that is what ctk talks about now let us say you kept the CP equal to 1. or you kept CP equal to exactly equal to two what happens as soon as CPK as soon as CPK degrades huh what happens you notice that your memory yield goes for a toss because on memory to function well you wanted plus minus 6 Sigma therefore you would ideally want CP to be greater than 2 and CPK to be less than 1.33 it only leaves more margin for you and allows you better yield is that okay hello yes sir yes so the values of CPK are the one greater than one can you elaborate on that sir only if so what does see what is the definition of CPK let us look at it how far is my upper spec limit from from mean or how far is my lower spec limit from being so what is happening here what is my uh suppose this is my mean just before mean before the lower spec limit it is not even one Sigma away what is the value of CPK less than 0.33 now uh sir I mean the upper spec limit would be the core value corresponding to minus 6 Sigma the plus Six Sigma entered in there now tell me this what do you understand by speculative however you understand what I'm talking about what is apparently lower points foreign these bounds then I would reject the die Hannah so when I had when I had my process centered here in between right in between upper and lower spec limit I said that my CP is equal to 2 let us say so plus minus 6 Sigma touches the limit how many failures are we talking about very few 99.9999998 percent is passing so very few failures but now due to process variation systematic variation the length is made a little longer so my devices are a little slower my devices are a little slower let us say this Curve will shifts a little to the left now what happens my mean is now closer to the lower spec limit are you able to see this so my CPK which was 2 initially two initially because mean was Six Sigma away Six Sigma by three sigma is two so it was 2 initially if it is now just three sigma away it has now degraded to one point and at that you realize that uh there will be yield loss yes sir 22 23 some you'll also start to happen that is why you want CPK to be less than 1.33 uh greater than 1.33 okay so this is what it is this is what it means CPK equal to 2 and CP equal to 2 very well centered process in the center of it good yields c equal to 2 so the process control is very good random variations are few but systematic variations are higher CPK equal also CP is equal to 0 means you want for a toss even though your process control is very good random variations are very well controlled but your yield will only be 50 percent because fifty percent of the dies are Beyond this upper limit are you able to see this uh sir uh confused regarding which one refers to random and which one you are referring to starting so CP refers to random that says What is the scent of these local variations there CPK refers to where is my lot position so this could be the lot positioning part uh yes sir but I got confused because you mentioned the example of length which we use actually to control random oh but uh you know all devices have like get etched in terms of polyetting happens simultaneously is it not yeah so if only it just happened poly etching is done simultaneously then if for example you edited the particular die for one millisecond more what happens all the devices will now be towards fast yes yes so length variation these systematic length variations would lead to systematic shifts got it now there is also lineage roughness that will be minimized if you use large length devices we can imagine them as FF or the global variations how far yeah how far away from SF Lord or something is your upper spec limit or lower spec limit like the small circles we imagined in the rhombus last semester yeah they are the CP and then CPK are those okay so now with till now we're talking only about gaussian distribution and that is actually,https://www.youtube.com/watch?v=TAOP4xaId7Y,"Link: https://www.youtube.com/watch?v=TAOP4xaId7Y
Transcript: Okay so let's look at now statistics of vlsi design so while we're talking about all these mismatches and everything huh it is important to now also see what what do I mean by statistical modeling and all that so I'm not taking this course on probability and statistics I'm just giving you a glimpse of the kind of Statistics that we need to be aware of when we design in vlsi uh again we can talk about this in so much detail in our memory design course because memories are most strongly impacted by statistical variations but as we go to final geometry is more Advanced Technologies uh even flip-flops and even uh every other circuit in fact has an impact or sees an impact but memory is being what they are they see the failures first therefore we talk about it in the memories course uh we don't talk about it as much in analog design course because there are trimming bits there are reference currents which you would trim and they would bias the circuit again to the desired point and memories you do not have that kind of flexibility again and therefore statistics become very relevant and in reality the same statistics you can apply it to any other circuit also uh the only thing is that those circuits are not repeated as often uh you don't need to go to Six Sigma accents as we will just see okay so what we are talking about when we say talking about Factor success that if there is a gaussian distribution all of you know what a gaussian distribution is what is the gaussian distribution see it you're searching for the definition of gaussian distribution you don't need to do that what do you understand the question distribution it's uh kind of in nature that uh certain if it's a random variable then the certain probabilities are more towards one in like it's a density more in middle and it spreads out as we go from the mean basically as you go away from the mean the probability reduces for the random variable you are referring it happens in nature also so it's kind of modeling natural something like that so when we when we set out to Model Natural uh processors do you see that okay I want to Target uh uh I want to Target that let us say you're hitting uh you're trying to hit a Dart onto the bullseye I always want to go into the center but I may go a little on the uh towards the left or right or top or bottom or something like that and since my target is always the center you will notice that most of my dots would actually hit close to the center if I have a good hand and I have good practice but there will still be some dots which would go go towards the periphery uh in terms of processes for example we would say that okay I wanted uh 20 particles to be embedded bombarded and and then diffused in my source strain region but not always 20 will be there at times 21 will go at times 22 will go at times 18 will go so these are variations that will naturally happen in any manufacturing process and gaussian distribution models such variations well okay uh but gaussian distribution is not the only distribution that that we are worried about in VLS I have a gaussian distribution is the primary distribution because of which are you know mismatches are introduced in our circuits in our devices in our designs so for example we talked about gate oxide thickness that okay there will be there will be places there will be there will be two atoms there will be two and a half atoms or uh you know the orientation is such that the Gate of fat thickness would vary from 22 to 28 nanometers that was the that was the micrograph that we saw in the last class so in reality since the target was say 25 nanometers most of the samples will be around 25 nanometers in fact if you plot the distribution the probability distribution of the thickness you will see that around 25 nanometers that is the center of this curve there will be maximum number of samples so let us say this is 25 uh 25 angstroms the gate oxide thickness and up to 68 68.2 percent of samples would exist between plus minus one Sigma let us say Sigma was 1 1 angstrom so 26 angstrom and 24 angstrom so between 24 angstrom and 26 angstrom you would have 68 of your samples between 20 3 and 27 angstroms you would have 95 percent of your samples between nine 22 and 28 the measurements that was shown on on that micrograph you would actually have 99 99.7 percent of your surface area having that kind of a range but there will still be places there will still be places which will which would correspond to this remaining 0.3 percent where thickness could be less than 22 or greater than 28. do you get the sense of it that as you go go beyond the nominal the main point uh the number of samples you will get there would reduce have you noticed this in your experience also hello so as we are moving away from the mean the number of samples are reducing yes yeah did you experience this yes so when we say that SNM is Six Sigma qualified what do we mean it means that we are allowing uh I'm like 99 percent I'm like it's the best case I'm like uh we have this uh gap of uh Six Sigma which consists to the 99 or 99.7 percent okay so actually the the Six Sigma uh like some of you might have heard those of you who have worked in the industry for a little while you might have heard the term Six Sigma approach have you heard that so this this is the Six Sigma that they talk about plus minus three sigma that is the Six Sigma that that management approach talks about however when we talk about srams when we say Six Sigma we're talking about Six Sigma on this side one side and we want to ensure that this nominal minus 6 Sigma is also a SNM value which is acceptable to you why do we need to go that far increase yields increases there could be many variations so we need to accept my what is the probability of getting a something there 99.7 are within three sigma why do I need to go to Six Sigma so but there are many cells I mean uh like 1mb could be meaning 1 billion yeah 99.7 means and thousand cells how many would not would not fit [Music] three cells would fail is it acceptable to you the Chipotle so no no Hannah now is it acceptable for a management situation how many projects does a company do or uh you know how many projects does a team in any any particular team would do in a year 20 10 20 depending on the size of the projects and the size of the team now 20 what is the probability of failure happening within those 20 if you are qualified Six Sigma of the management approach if you manage my qualified from this to this and you have only 20 samples to take the probability that that that particular sample will come out of out of range is much lower now since the number of samples in those management principles are on management practices is lesser they go to Six Sigma which means plus minus 3 Sigma since the number of samples that we have to account for in memories is much much higher suppose I want 99 yield with a 16 megabit capacity what is the failure what is the number of failures that are acceptable so you will see that forever for a 16 megabit capacity I need to go to Six Sigma extent to ensure a 99 period because 16 MB means 16 into 10 raised to power 6 into 100 so these many memory cells we are talking about 100 Dice and of this you say one should fail so there can be only one failure in these many samples and that you will see means so many nines before you get a first date and that is why we need to go to plus minus Six Sigma analysis in our designs so we are talking of one die out of 100 dice of one cell one called the cells you tell me can this one die or automatically fail one say one cell fails and anyone die that diesner if you want 99 yield what are you essentially talking about you are saying that in that 16 not 16 megabit in that sixteen hundred megabit capacity which is across hundred eyes one cell fails now the in that same day there could be another cell that is failing that will not lead to any additional loss of yield but again what is the probability that the second failure will also lie on that same die one by hundred is it not yes sir so for all practical purposes you can only accept one failure per 100 dice so this is the kind of capacity in which I want only one failure um I said so can you give an example I'm not clearly getting the concept like okay Sigma part but uh why we have moved from three sigma to Six Sigma is it just because the yield so let us say you designed something with plus minus three sigma sizes yes I have one one megabit memory capacity on the chip one tip okay how many memory cells do I have one one into ten to the power 6 into 100 on one trip yes sir one into ten raised to the power 6 is what I have on one chip now yes sir yes sir so again 99.73 is the pass rate how many cells on that one chip will fail foreign is the pass rate for that for that design how many cells in that particular chip will fit one chip only a b how many cells so if this is the password what is the failure rate what is the probability of failure the password is 0.9973 what is the probability of failure point zero zero two seven yes yes sir so if if every cell can fail with the probability of 0.0027 a collection of 1 million cells would would say how many of them would fail in this probability in this setting one million and two point zero zero zero two seven point zero zero two seven so that would be equal to twenty seven hundred cells yes sir every die will have 2700 failures what will are we talking about okay the number of cells which are failing are less obviously anything that something so we are if we are qualifying six plus minus Six Sigma we are ensuring that 99.999999 eight percent of sales are taken care of okay okay sir only remaining are outliers that also you will see every 100 die there is something failing okay sir yes sir sir you're freshner sir I understood this Six Sigma thing but sir this is okay it's for the 16 MB example this is fine sir I mean one is getting failed so sir but we even designed the memory in I'm like GBS also right so in that case I think Six Sigma is also not sufficient I mean we are supposed to go to 9 Sigma no for there then we will go to repair mechanisms so we'll talk about repair we will talk about repair don't worry okay sir okay but yes when you design when you verify your design you have to verify it for Six Sigma plus minus Six Sigma not the management while our Six Sigma okay so but uh like you're saying that even in one die even if one bit cells fails my whole die will fail but sir like I will have kind of uh I would have modeled or designed something like if my bit still seal there are some like uh other bit cells which can take place of it or we can use it I mean they have talked about it yet so for present understanding even oneself is the dive rejected okay so I'm already telling you we will have some repair we'll talk about repair not today probably next class but if there was no repair then the die has failed yes yes so knowing there's a bit scrambling is that and like repair mechanisms are welcome to it when we talk about bit scrambling about repair mechanism is that okay yes sir so what we are saying is that we have to qualify plus minus Six Sigma now let us talk about two additional numbers what is called as process capability is defined by a number called CP and another number called CPK okay uh both CP and CPK have different uh different impact or different uh uh convey different kind of information about the process huh the first CP indicates that the statistical control in the process is good what do we see what is the upper specification limit minus the lower specification limit upon 6 Sigma of the process we will just look at what this means okay and CPK instead talks about a different parameter it says how far is my upper specification limit from the mean and how far is the lower specification limit from the mean and then you look at it in terms of Sigma now what does this mean now process capability means that is your CP is less than one if your CP is less than one what happens what it means is upper spec limit minus lower spec limit is some value but your Six Sigma is crossing that value are you able to see this if this is equal to less than 1 means that that your design is crossing this upper speculate and local Speculator therefore it is less than one CP equal to 1 exactly equal to 1 means that plus minus 3 Sigma of my curve lies within the specification limit so the failure rate would be 0.3 percent see what did we say that plus minus 3 Sigma Beyond there could be point three in a percent number of samples that was what we just saw foreign 99.7 okay okay yes 1000 can the three failures on it yeah point three percent is samples will still come out of it that is CP equal to 1. what does CP equal to 2 mean CP equal to 2 would mean that each side I have Six Sigma extent which is taken care of huh that is where I said that CP greater than 2 indicates that the process is in good statistical control you can think of getting good lead on the memory are you able to see this so CP is equals to 2 will be our Six Sigma limit minus 6 Sigma yes two CP is greater than two how much yes okay so now that is about process control now anything greater than Oneness also okay yeah I know so now sorry other than just see just wait two minutes let's look at the other parameter which defines process capability let us say that I actually have this CP equal to 2 so I have this kind of a gaussian which is plus minus 6 Sigma on each side but in reality the process may change May shift a little to the left a little to the right the typical process corner is centered right away and the target but slow and fast process Corners are also there is it not so the slow and fast process Corners would be here or could be here as they have shown what does this mean suppose my slow corner is here what does this mean that means that in the lower one we are uh we have even we are going even Beyond minus 12 Sigma minus X Sigma on the lower side but nothing on the positive side is covered yeah so what this means is that all these cells which are on this side of the lobe are getting failed are getting rejected so for the SS lot for example my area is zero percent uh 50 only is that acceptable no sir no so the other parameter talks about process capability in terms of how the centering is how good the centering is ah a capable of producing repeatable products how well can I Center it that is what ctk talks about now let us say you kept the CP equal to 1. or you kept CP equal to exactly equal to two what happens as soon as CPK as soon as CPK degrades huh what happens you notice that your memory yield goes for a toss because on memory to function well you wanted plus minus 6 Sigma therefore you would ideally want CP to be greater than 2 and CPK to be less than 1.33 it only leaves more margin for you and allows you better yield is that okay hello yes sir yes so the values of CPK are the one greater than one can you elaborate on that sir only if so what does see what is the definition of CPK let us look at it how far is my upper spec limit from from mean or how far is my lower spec limit from being so what is happening here what is my uh suppose this is my mean just before mean before the lower spec limit it is not even one Sigma away what is the value of CPK less than 0.33 now uh sir I mean the upper spec limit would be the core value corresponding to minus 6 Sigma the plus Six Sigma entered in there now tell me this what do you understand by speculative however you understand what I'm talking about what is apparently lower points foreign these bounds then I would reject the die Hannah so when I had when I had my process centered here in between right in between upper and lower spec limit I said that my CP is equal to 2 let us say so plus minus 6 Sigma touches the limit how many failures are we talking about very few 99.9999998 percent is passing so very few failures but now due to process variation systematic variation the length is made a little longer so my devices are a little slower my devices are a little slower let us say this Curve will shifts a little to the left now what happens my mean is now closer to the lower spec limit are you able to see this so my CPK which was 2 initially two initially 
because mean was Six Sigma away Six Sigma by three sigma is two so it was 2 initially if it is now just three sigma away it has now degraded to one point and at that you realize that uh there will be yield loss yes sir 22 23 some you'll also start to happen that is why you want CPK to be less than 1.33 uh greater than 1.33 okay so this is what it is this is what it means CPK equal to 2 and CP equal to 2 very well centered process in the center of it good yields c equal to 2 so the process control is very good random variations are few but systematic variations are higher CPK equal also CP is equal to 0 means you want for a toss even though your process control is very good random variations are very well controlled but your yield will only be 50 percent because fifty percent of the dies are Beyond this upper limit are you able to see this uh sir uh confused regarding which one refers to random and which one you are referring to starting so CP refers to random that says What is the scent of these local variations there CPK refers to where is my lot position so this could be the lot positioning part uh yes sir but I got confused because you mentioned the example of length which we use actually to control random oh but uh you know all devices have like get etched in terms of polyetting happens simultaneously is it not yeah so if only it just happened poly etching is done simultaneously then if for example you edited the particular die for one millisecond more what happens all the devices will now be towards fast yes yes so length variation these systematic length variations would lead to systematic shifts got it now there is also lineage roughness that will be minimized if you use large length devices we can imagine them as FF or the global variations how far yeah how far away from SF Lord or something is your upper spec limit or lower spec limit like the small circles we imagined in the rhombus last semester yeah they are the CP and then CPK are those okay so now with till now we're talking only about gaussian distribution and that is actually"
XIEfanCvg4k,however in reality in vlsi you will also see log normal distributions you will see poisson distributions and you will also see variable distributions or extreme value Theory being applied to various parts of the LSI design okay each of these distributions could be of interest to you depending on what project you are working on suppose you are working on leakage control then I would say you have to be a very well aware and and you have to take care of things by using log normal distribution suppose you're talking about gate dielectric breakdown then I would want you to work with visible distribution and extreme value Theory but as the LSI designers if you want to do some research and do some good design work also it is important that you are comfortable with some of these very few but very important distributions that are fairly evident and fairly commonly used in vlfi design I heard a sir sometimes so there was a question please ask sir so this CPK things are if that's 1.33 I can see I'm like if I calculate there is around 30 percent of 33 percent of loss during the worst case so shouldn't that be CPK should be greater than 2 then yeah for srams we want to put CPT greater than 2 yes you can say that okay sir oh but you will see that to to make such kind of a process control the complexity and the cost of the process increases therefore we will talk about repair also okay yeah so uh is this Six Sigma only for memory or if we were trying all the ships so you tell me I want everything to be but it is they are difficult to design having this and it's not even required now suppose someone tells me that there are uh 500 000 flip-flops on a particular die I know Phi Sigma would suffice why do I go to Six Sigma how big is it yeah but we have to realize that depending on how big the die is depending on uh how big the design is the number of times a cell is repeated would increase and that is what should what should guide you to decide whether you want to go to Six Sigma or five Sigma or three sigma is sufficient okay so do not do not Rectify it as a rule it's not a rule I have I have gone through all this pain of explaining the statistics to you so that tomorrow if you come to some other thing you are able to decide how many Sigma to qualify there others uh so like in the with the CPK we are modeling the like the Lord basically say if I have the fast forward slot so I will get a certain mean okay again again please don't don't get fixated with just a lot even in slow lot even and typical lot do you think that lot just gets a silicon would come only on slow lot or typical lot no if I say this is the rhombus this was TT this is SF this is FS uh FF and SS do you think that only these five six points would exist no no sir and that range would happen you saw remember the ellipse that you're talking about that we saw in the DVD course also this is an entire range in which something would happen so lot lot lot much so actually the question is key uh then what exactly like I mean able to see the impact that CPK has a different what I see in CP but when we would be modeling say Monte Carlo then what uh does Monte Carlo has control over does it uh shift the mean also or does it only uh considers the sigma variation it depends from it changes from tool to to raghav and it also changes from uh Fab to Fab some Fabs would say that okay I will model the entire all the lots and everything all the variations in one one simulation itself that is called AS Global variations okay at another time you may say that okay I would want to qualify all the Lots so I will run Monte Carlo on all the Lots separately so I will I will qualify all these regions by myself so that depends on your design methodology you could already bring in the lot variation and then say I will only see the variations of CP or you would say that okay I want to see variations due to CP and CPK simultaneously and you would do a global simulation it depends on uh methodology that you want to use for your verification and whether the models that have been given by the process teams they support it or not you can do both ways and so similarly the definition of how much Sigma should I qualify will change also depending upon this event when I choose the global or these kind of yes you can always modify that but yeah it has to it has to come from a good understanding of probability and statistics don't just randomly say I will qualify three sigma only because I am here look at how many samples are we talking about on chip and and what would be the marginal yield loss because you qualified only three sigma and not Six Sigma maneuver and the slow lot okay okay so but you can do that yes as a designer see if you notice my Endeavor across DVD and even MDT is to turn you into good designers circuit designers so I'm telling you all these levers so that you know that there is this flexibility that you can use as a designer okay but again do not get fixated I am giving you the concepts I am giving you why something is done a particular way so that you do not accept anything as a thumb rule or or as a rule as a something which is written in stone I'm not giving you any dictats I'm just showing you the paths then you travel the path whenever you need to okay okay so thanks so uh where all do we need to look at mismatch in assams we already talked about these things stability s m write margin right time read current all of those places we look at mismatch when those of you are working on sense amplifiers you would want to look at the mismatch of or the distribution of offset or like to look at the distribution of output delay and so on um so mismatch is something that we have that we will play with a lot when we are working on memory design even when you're working on analog circuit design for example adcs Dax PLS anything you have to take care of mismatch but in essence there are some places which you definitely need to take care of it okay so these are about circuit level analysis all all that we're talking about is SRAM cell or a sense amplifier these are small circuits but a memory will be functional not only when these small circuits are functional but also when you always have the right kind of architecture so that San arrival is at the right time you remember this this diagram where we said that okay when the word line is selected the bit cell will discharge and differential will appear under some amplifier nodes you remember this what we want to say is that this s a n should arrive at a time so that the minimum offset requirement of the sense amplifier is always met hmm hello you remember this constraint that we had how would you meet this constraint there would be a memory with 100 rows there would be a memory with 500 rows there would be another memory with just 42 columns another memory width 112 or you know 128 or 1K columns how will you ensure that whatever the memory size is essay and Arise at the right time and not earlier or not later so what happens in San arrives later than than the desired time huh sorry sorry if scn would arrive later then maybe the cloak caused low and uh the word line clock goes and we do not because basically everything would become IG or something an unknown State internal nodes yeah see sa and arise along with reset so when San comes at the same time you start to reset the word line you start to recharge you know re pre-charge the bit lines and so on so if SN arrives late it means the result of the memory has been delayed it means the overall cycle time of the memory goes for a toss hmm if I say an arrives early what happens and that in that case there is not the required mismatch and there's not the required differential voltage at the sense amplifier inputs so and due to mismatch your read operation can fail so you do not want to want you do not want San to arrive at very distant time from the optimal time are you able to see this hello so what you want is that when it is a large cut I say let sa and arrive late when it is a small instance let us say and arrive fast enough so to do this what is done is is that in the memory we add what is called as a replica path this replica path what it does is it tracks the worst RCs for both word line and bit line and then generates enable signal there okay that means the cycle time is controlled by the worst case bits earlier not exactly the worst case bit cell the worst placed bit cell please that's what I meant yeah okay the corner one yeah not the worst case the worst case cell could be placed anywhere in the memory the worst case cell could be here sorry sorry got the most distant Place cell so yes you're absolutely right in that because I want that whatever cell is here if this was also the worst cell even then my memory should work so I at least bring my replica path my word line and bitline RC should match okay and then notice that I select more than one cell over here why do I need to select more than one cell over here so those of you who are in the office are yesterday they would they should be able to answer right away because you have a question your hand is raised okay we have to get the digital requirement to enable science amplifier yeah see the important thing is you cannot really have a sense amplifier on the replica bit line and now if you make a make a real sense amplifier here also then where will you bring its trigger from you're stuck in the same Loop so what we say is we will put a inverter kind of sensor or something else something which does not require an enable signal before itself we will put something which would convert which would sense that my replica bit line let us call it as rep BL has discharged and now I can trigger sense amplifier on if my replica BL has discharged enough I would say that my actual bit line has also discharged let us say my I want to discharge my actual bit line by 100 millivolts and let us say the inverter over here trips at uh 300 millivolts uh and I'm operating at uh one volts how many cells should I put here six seven notion three three only no no it trips at 300 millivolts not 700 millivolts not 300 millivolts below vdd Eclipse when replica bit line has gone to 300 millivolts more than seven are you able to see it everyone I need to discharge replica bit line by 700 millivolts so that when San goes it intercepts this particular bit cell or any bit cell at greater than 100 millivolts to be able to do this because they are the same cells that I have put in the replica column I need to put at least seven cells in the replica column which would discharge in a real in a real array only one row gets selected over here I say that seven row should get selected so this is what did you not get things so the discharge rate of this cell and the cell is same they are replica cells same cells have been put at both the places answer now you want the actual bit lines to create a differential of 100 millivolts but you want the replica bit line to have a differential of 700 variables in the same time how many cells on the replica bit line should discharge is it okay is it okay now um [Music] no not yet another way 700 millivolt there because that is how I tuned the sense amplifier of the replica bit line that is when I will trigger the San let us say I tuned it at 600 millivolts then how many cells would I need okay I have 200 and you will need six cells okay Hannah so it is how I tuned this cell this this inverter there okay okay so depending on how you tune the inverter you will need to change the number of cells you require okay so this path the number of cells which are selected by the replica word line over here that should be programmable I should be able to change the number of cells by just removing a little bit of metal band or or something like that okay so those projects which Define the which design the replica bit line or replica path uh we talked about it in yesterday's officers also you have to take care of that the cells are programmable the word line is programmable and what whether it goes to vdd or ground that should also be programmable yes sir how will you replicate this bit cells are exactly I mean I didn't understand uh how are you doing that um keeping this I just repeat the same Okay so ah sir just repeating the cell means okay I do understand layout wise I do understand that we can we can place the same layout over there but uh this cell which we have should be the worst case right and we'll be replicating the same cell all all over my memory cell right so how does that make a difference actually it doesn't replica pixel is supposed to look exactly like the real bit sir yes sir but I mean uh itself be careful you have to qualify the worst case bit cell but in the replica bit line many cells would be there and then they will be selected in parallel so you cannot really have the worst case cell there you just put a replica cell Okay so okay okay sir yeah so what two two take care of the worst case cell what you may do is you may want to tune the inverter at the replica bit line at a still lower voltage so that you need to decide still more still it is regarding this location sir what are the conditions for tuning this invertence what are the conditions for tuning this inverter yeah means how you decided 700 millivolts beautiful okay I decided some random variables because uh I wanted to keep more delay let us say on the I wanted to have a bit nine capacitance to play some role in my determining my timing if I had kept this thing I had let us say the trip point at let us say 0.7 so only 300 millivolt discharge was required hmm so the bit line capacitance would have a lower role to play than determining how much delay is added are you able to see this okay so it is about how what kind of impact I expect because of bit line capacitance versus word line capacitance okay raghav you have your hand raised uh yes sir so I mean I had a question see when we are thinking how many replica cells I should put in a replica orbit line then I'm only considering the discharge right discharge time 300 millivolts so but for example like once I get off the inverter the sensible signal when it will reach that will also depend the sense amplifier is of the like the leftmost cell or the rightmost cell so that Hill is also coming picture yeah you have to consider everything I'm just giving you a very simplistic view here um if I give you the complex view right here even this is complex for you is it not yes sir so that is why so but that is also taken care by the programmable bit cells only the replicas okay yeah you just if you want more delays you reduce the number of cells which would dispatch automatically it will take longer to dispatch if you want to come you want sand to arrive faster you just increase the number of cells automatically the discharge would be faster yes sir yes okay so what does this mean you remember this timing diagram remember we talked about replica World line then also but now I am formally introducing it to you when the replica word line comes after some time reset comes and that is what then resets the memory and keeps makes it available for next cycle so you cannot really have a reset come far far away okay and just like for the read for the read cycle you have a replica right bit line and a write detect circuit also there which generates the reset so differences in read cycle the replica bit line discharge would directly generate the reset whereas in a right cycle there is an additional signal which is called as write detect you want to ensure that the right operation has completed inside the memory cell which would generate the reset okay and then once the reset comes then this same behavior is followed but there is an additional observation that you have to make before you reset the uh before you reset the memory in right cycle okay any questions so why do we need right detect because we can just run a simulation where we can identify what's the worst place which cell how much time it takes to write and then after that automatically yeah so what happens if it is a fast lot do you want to leave that kind of delay even in a fast lot no okay got it if you want to track something that's why I detect also anything else but when you're detecting I detect that can cause stability issues because if you're reading it because you're reading it right so right data would come from the right right replica bit line okay not really worry about stability then okay,https://www.youtube.com/watch?v=XIEfanCvg4k,"Link: https://www.youtube.com/watch?v=XIEfanCvg4k
Transcript: however in reality in vlsi you will also see log normal distributions you will see poisson distributions and you will also see variable distributions or extreme value Theory being applied to various parts of the LSI design okay each of these distributions could be of interest to you depending on what project you are working on suppose you are working on leakage control then I would say you have to be a very well aware and and you have to take care of things by using log normal distribution suppose you're talking about gate dielectric breakdown then I would want you to work with visible distribution and extreme value Theory but as the LSI designers if you want to do some research and do some good design work also it is important that you are comfortable with some of these very few but very important distributions that are fairly evident and fairly commonly used in vlfi design I heard a sir sometimes so there was a question please ask sir so this CPK things are if that's 1.33 I can see I'm like if I calculate there is around 30 percent of 33 percent of loss during the worst case so shouldn't that be CPK should be greater than 2 then yeah for srams we want to put CPT greater than 2 yes you can say that okay sir oh but you will see that to to make such kind of a process control the complexity and the cost of the process increases therefore we will talk about repair also okay yeah so uh is this Six Sigma only for memory or if we were trying all the ships so you tell me I want everything to be but it is they are difficult to design having this and it's not even required now suppose someone tells me that there are uh 500 000 flip-flops on a particular die I know Phi Sigma would suffice why do I go to Six Sigma how big is it yeah but we have to realize that depending on how big the die is depending on uh how big the design is the number of times a cell is repeated would increase and that is what should what should guide you to decide whether you want to go to Six Sigma or five Sigma or three sigma is sufficient okay so do not do not Rectify it as a rule it's not a rule I have I have gone through all this pain of explaining the statistics to you so that tomorrow if you come to some other thing you are able to decide how many Sigma to qualify there others uh so like in the with the CPK we are modeling the like the Lord basically say if I have the fast forward slot so I will get a certain mean okay again again please don't don't get fixated with just a lot even in slow lot even and typical lot do you think that lot just gets a silicon would come only on slow lot or typical lot no if I say this is the rhombus this was TT this is SF this is FS uh FF and SS do you think that only these five six points would exist no no sir and that range would happen you saw remember the ellipse that you're talking about that we saw in the DVD course also this is an entire range in which something would happen so lot lot lot much so actually the question is key uh then what exactly like I mean able to see the impact that CPK has a different what I see in CP but when we would be modeling say Monte Carlo then what uh does Monte Carlo has control over does it uh shift the mean also or does it only uh considers the sigma variation it depends from it changes from tool to to raghav and it also changes from uh Fab to Fab some Fabs would say that okay I will model the entire all the lots and everything all the variations in one one simulation itself that is called AS Global variations okay at another time you may say that okay I would want to qualify all the Lots so I will run Monte Carlo on all the Lots separately so I will I will qualify all these regions by myself so that depends on your design methodology you could already bring in the lot variation and then say I will only see the variations of CP or you would say that okay I want to see variations due to CP and CPK simultaneously and you would do a global simulation it depends on uh methodology that you want to use for your verification and whether the models that have been given by the process teams they support it or not you can do both ways and so similarly the definition of how much Sigma should I qualify will change also depending upon this event when I choose the global or these kind of yes you can always modify that but yeah it has to it has to come from a good understanding of probability and statistics don't just randomly say I will qualify three sigma only because I am here look at how many samples are we talking about on chip and and what would be the marginal yield loss because you qualified only three sigma and not Six Sigma maneuver and the slow lot okay okay so but you can do that yes as a designer see if you notice my Endeavor across DVD and even MDT is to turn you into good designers circuit designers so I'm telling you all these levers so that you know that there is this flexibility that you can use as a designer okay but again do not get fixated I am giving you the concepts I am giving you why something is done a particular way so that you do not accept anything as a thumb rule or or as a rule as a something which is written in stone I'm not giving you any dictats I'm just showing you the paths then you travel the path whenever you need to okay okay so thanks so uh where all do we need to look at mismatch in assams we already talked about these things stability s m write margin right time read current all of those places we look at mismatch when those of you are working on sense amplifiers you would want to look at the mismatch of or the distribution of offset or like to look at the distribution of output delay and so on um so mismatch is something that we have that we will play with a lot when we are working on memory design even when you're working on analog circuit design for example adcs Dax PLS anything you have to take care of mismatch but in essence there are some places which you definitely need to take care of it okay so these are about circuit level analysis all all that we're talking about is SRAM cell or a sense amplifier these are small circuits but a memory will be functional not only when these small circuits are functional but also when you always have the right kind of architecture so that San arrival is at the right time you remember this this diagram where we said that okay when the word line is selected the bit cell will discharge and differential will appear under some amplifier nodes you remember this what we want to say is that this s a n should arrive at a time so that the minimum offset requirement of the sense amplifier is always met hmm hello you remember this constraint that we had how would you meet this constraint there would be a memory with 100 rows there would be a memory with 500 rows there would be another memory with just 42 columns another memory width 112 or you know 128 or 1K columns how will you ensure that whatever the memory size is essay and Arise at the right time and not earlier or not later so what happens in San arrives later than than the desired time huh sorry sorry if scn would arrive later then maybe the cloak caused low and uh the word line clock goes and we do not because basically everything would become IG or something an unknown State internal nodes yeah see sa and arise along with reset so when San comes at the same time you start to reset the word line you start to recharge you know re pre-charge the bit lines and so on so if SN arrives late it means the result of the memory has been delayed it means the overall cycle time of the memory goes for a toss hmm if I say an arrives early what happens and that in that case there is not the required mismatch and there's not the required differential voltage at the sense amplifier inputs so and due to mismatch your read operation can fail so you do not want to want you do not want San to arrive at very distant time from the optimal time are you able to see this hello so what you want is that when it is a large cut I say let sa and arrive late when it is a small instance let us say and arrive fast enough so to do this what is done is is that in the memory we add what is called as a replica path this replica path what it does is it tracks the worst RCs for both word line and bit line and then generates enable signal there okay that means the cycle time is controlled by the worst case bits earlier not exactly the worst case bit cell the worst placed bit cell please that's what I meant yeah okay the corner one yeah not the worst case the worst case cell could be placed anywhere in the memory the worst case cell could be here sorry sorry got the most distant Place cell so yes you're absolutely right in that because I want that whatever cell is here if this was also the worst cell even then my memory should work so I at least bring my replica path my word line and bitline RC should match okay and then notice that I select more than one cell over here why do I need to select more than one cell over here so those of you who are in the office are yesterday they would they should be able to answer right away because you have a question your hand is raised okay we have to get the digital requirement to enable science amplifier yeah see the important thing is you cannot really have a sense amplifier on the replica bit line and now if you make a make a real sense amplifier here also then where will you bring its trigger from you're stuck in the same Loop so what we say is we will put a inverter kind of sensor or something else something which does not require an enable signal before itself we will put something which would convert which would sense that my replica bit line let us call it as rep BL has discharged and now I can trigger sense amplifier on if my replica BL has discharged enough I would say that my actual bit line has also discharged let us say my I want to discharge my actual bit line by 100 millivolts and let us say the inverter over here trips at uh 300 millivolts uh and I'm operating at uh one volts how many cells should I put here six seven notion three three only no no it trips at 300 millivolts not 700 millivolts not 300 millivolts below vdd Eclipse when replica bit line has gone to 300 millivolts more than seven are you able to see it everyone I need to discharge replica bit line by 700 millivolts so that when San goes it intercepts this particular bit cell or any bit cell at greater than 100 millivolts to be able to do this because they are the same cells that I have put in the replica column I need to put at least seven cells in the replica column which would discharge in a real in a real array only one row gets selected over here I say that seven row should get selected so this is what did you not get things so the discharge rate of this cell and the cell is same they are replica cells same cells have been put at both the places answer now you want the actual bit lines to create a differential of 100 millivolts but you want the replica bit line to have a differential of 700 variables in the same time how many cells on the replica bit line should discharge is it okay is it okay now um [Music] no not yet another way 700 millivolt there because that is how I tuned the sense amplifier of the replica bit line that is when I will trigger the San let us say I tuned it at 600 millivolts then how many cells would I need okay I have 200 and you will need six cells okay Hannah so it is how I tuned this cell this this inverter there okay okay so depending on how you tune the inverter you will need to change the number of cells you require okay so this path the number of cells which are selected by the replica word line over here that should be programmable I should be able to change the number of cells by just removing a little bit of metal band or or something like that okay so those projects which Define the which design the replica bit line or replica path uh we talked about it in yesterday's officers also you have to take care of that the cells are programmable the word line is programmable and what whether it goes to vdd or ground that should also be programmable yes sir how will you replicate this bit cells are exactly I mean I didn't understand uh how are you doing that um keeping this I just repeat the same Okay so ah sir just repeating the cell means okay I do understand layout wise I do understand that we can we can place the same layout over there but uh this cell which we have should be the worst case right and we'll be replicating the same cell all all over my memory cell right so how does that make a difference actually it doesn't replica pixel is supposed to look exactly like the real bit sir yes sir but I mean uh itself be careful you have to qualify the worst case bit cell but in the replica bit line many cells would be there and then they will be selected in parallel so you cannot really have the worst case cell there you just put a replica cell Okay so okay okay sir yeah so what two two take care of the worst case cell what you may do is you may want to tune the inverter at the replica bit line at a still lower voltage so that you need to decide still more still it is regarding this location sir what are the conditions for tuning this invertence what are the conditions for tuning this inverter yeah means how you decided 700 millivolts beautiful okay I decided some random variables because uh I wanted to keep more delay let us say on the I wanted to have a bit nine capacitance to play some role in my determining my timing if I had kept this thing I had let us say the trip point at let us say 0.7 so only 300 millivolt discharge was required hmm so the bit line capacitance would have a lower role to play than determining how much delay is added are you able to see this okay so it is about how what kind of impact I expect because of bit line capacitance versus word line capacitance okay raghav you have your hand raised uh yes sir so I mean I had a question see when we are thinking how many replica cells I should put in a replica orbit line then I'm only considering the discharge right discharge time 300 millivolts so but for example like once I get off the inverter the sensible signal when it will reach that will also depend the sense amplifier is of the like the leftmost cell or the rightmost cell so that Hill is also coming picture yeah you have to consider everything I'm just giving you a very simplistic view here um if I give you the complex view right here even this is complex for you is it not yes sir so that is why so but that is also taken care by the programmable bit cells only the replicas okay yeah you just if you want more delays you reduce the number of cells which would dispatch automatically it will take longer to dispatch if you want to come you want sand to arrive faster you just increase the number of cells automatically the discharge would be faster yes sir yes okay so what does this mean you remember this timing diagram remember we talked about replica World line then also but now I am formally introducing it to you when the replica word line comes after some time reset comes and that is what then resets the memory and keeps makes it available for next cycle so you cannot really have a reset come far far away okay and just like for the read for the read cycle you have a replica right bit line and a write detect circuit also there which generates the reset so differences in read cycle the replica bit line discharge would directly generate the reset whereas in a right cycle there is an additional signal which is called as write detect you want to ensure that the right operation has completed inside the memory cell which would generate the reset okay and then once the reset comes then this same behavior is followed but there is an additional observation that you have to make before you reset the uh before you reset the memory in right cycle okay any questions so why do we need right detect because we can just run a simulation where we can identify what's the worst place which cell how much time it takes to write and then after that automatically yeah so what happens if it is a fast lot do you want to leave that kind of delay even in a fast lot no okay got it if you want to track something that's why I detect also anything else but when you're detecting I detect that can 
cause stability issues because if you're reading it because you're reading it right so right data would come from the right right replica bit line okay not really worry about stability then okay"
VjN91ntGYpQ,foreign should be matched that the diffusion and metal profile has to be maintained something that we were talking about in the beginning of today's class also that Rhodes and replica rhodex should be matched again same diffusion and metal profile ensure similar wpe STI and other effects ensure similar IR drop now what to do about eating we're not talked about aging but yeah this is something which which still needs to be solved as a challenge okay then between wordline and I O clocks or sa and they have to all run in the same metal layer I remember having uh seen a failure in a big memory where the two match signals one one it was running in metal one the other one was running in metal three as the process as the you know production started we observed that many many Lots were failing because of memory and then we realized oh the math signals are running in different metal layers see metal layers are all drawn in different steps metal one could be of a different width and could see a different width and height uh whereas metal 3 can see a different width and height even if the material is same even if the material is same they could have different uh statistical positioning or different width and height across different metal layers so if you want to match signals which are uh which could be done in different metal layers always draw them in the same metal layer so that effect of RC is similar hmm in terms of doing the statistical analysis Monte Carlo simulations is something that you already know about but uh you know just to qualify six transistor memory cell within one Sigma range you need 30 to 50 simulations if you have to go to Six Sigma Six Sigma qualification you will need billions of simulation this is prohibitive you cannot really have that kind of a design time so there are other methods which have been introduced which are not just Brute Force Monte Carlo simulations there is something called important sampling which is already implemented in the in eldo and there is something also which is called as a design of experiments which I think is also now getting implemented in in synopsis tools like a spice but I'm not sure so typically eldo is the most advanced Tool uh simulation tool till now which has these Advanced methods of uh of statistical analysis also in built into it okay so some of you if you work on some memory project with me you may get to work on design of experiments if you're talking about weak bit testing or something like that but otherwise Monte Carlo is something that will most commonly use okay yeah so any questions I'm pregnant design so important sampling means that okay I tell the simulator that I want to measure let us say right time and I tell it that larger right time is the risky thing for me so in the simulator will run first 100 simulations with completely random distribution on its variables okay and then it will start to observe some Trend analysis it will do some Trend analysis and it will say that okay when I move my variables in this particular direction that is when the right time increases so whether there will really be failures or not uh to estimate that let me select more samples of that kind only so it is kind of you doing some kind of machine learning while running the simulation and then choosing samples such that they the probability of their failure on CAD is higher okay so now to qualify Six Sigma you do not need to run billions of simulations possibly 10 000 simulations will will help you arrive at the worst case cell because you're gravitating towards the worst lot towards the worst place where the failure could happen is that okay yes sir sir the worst case lot means sir don't we have a specific lot that is worst actually I mean but slowly we do know that okay at this point again sorry for that when I say lot means a vector worst case vectors okay uh different variations on VT of different devices different variations on resistances and so on what is the worst case combination at which you will see the worst case result that is what you are able to emulate much faster than in a regular Monte Carlo simulation okay so a lot did not mean that lot but not our element combination of various shifts okay now design of experiments you can do the same analysis which would require 10 000 simulations with important sampling the possibly thousand or even less than thousand simulations what you do in design of experiment first you say that okay I know that passgate needs to be slow and pull up needs to be fast for the worst case right margin I know this yes sir I say that I will myself inject four and a half Sigma variation on the pass gate and four and a half Sigma variation on the pull up the basket will go towards the slow side the pull-up will go towards the fast side so if I put 4.5 Sigma variation on 1 and 4.5 on the other what have I done 4.5 square plus 4.5 square if I add this this I will arrive at something like 6 Sigma so I am arriving at Six Sigma root mean Square variation by putting 4.5 Sigma variation on the pass gate 4.5 Sigma variation on the pull up and if that that particular simulation passes I said okay my overall design is Six Sigma qualified okay sir got it this is much lesser number of simulations than important sampling do you see that yes sir but now you have to apply your brain as a designer but such a design of experiments isn't that specific towards the thing which you do first I mean like but write it specific for another operation it might be specific yes okay sir uh a fresh engineer who has not understood the design well cannot do this you need expertise to even run design of experiments because you know what you have to know what experiments to design yes sir okay uh and do you realize that for a memory cell then I have understood right margin it is so easy to design but think of implementing it for the for the self timing paths can you design it can you distribute how much variation to put on which which cells which devices of itself can you do that so design of experiments can only be done on very small circuits small sets okay for large paths lots of devices where variations could be distributed you prefer to go to important sampling or Brute Force Monte Carlo uh so so with this example the design of experiment you took the 4.5 Sigma 4.5 Sigma with considering the right maturation so but like uh I have when I qualifying for example bit cell I will have to qualify for all their firms right yes so you will run a different design of experiments for SNM a different design of experiments for read current you will have to do those design everything separately anyway the pvt at which SNM is worst is different from the pvt at which right is worse is it not you anyway have to do a different analysis you have to have a different stimuli so it's okay not a big deal okay so can you move to previous slide so I mean uh replica area I mean after profile how like the stress effect on the active should be same so what does profile mean what do you understand by the term profile so profiling okay you are basically putting different two categories some kind of like a bin you're profiling him so that is classification that is so profile means uh so profile means the boundaries are the same you know the behavior or the environment let us say you know metal profile of Halo metal metal design and environment they have to be similar okay so if you have made this kind of structure in your actual cell you should make similar kind of structure even in your replica okay actually okay okay diffusion of metals that is what it means this is also called as structural matching okay okay anything else okay so we will close the class here and uh will meet next on Tuesday in design of experiments we are basically worsening the suppose gate or device so that means we are hacking into the library and changing the VT uh yes so ldo allows you to do that by not going into the model file okay at spice inspector do not do that yet yeah no okay and and also to be able to do that you should have the models which allow you to do that the model should be defined in such a way that you are able to do that from outside that means it The Foundry should give us a feature and yeah so till the time Founders did not give us the feature we used to do the same thing by you know artificially increasing the length and width and so on okay not a good thing to do but yeah that was how we used to do it earlier okay okay,https://www.youtube.com/watch?v=VjN91ntGYpQ,"Link: https://www.youtube.com/watch?v=VjN91ntGYpQ
Transcript: foreign should be matched that the diffusion and metal profile has to be maintained something that we were talking about in the beginning of today's class also that Rhodes and replica rhodex should be matched again same diffusion and metal profile ensure similar wpe STI and other effects ensure similar IR drop now what to do about eating we're not talked about aging but yeah this is something which which still needs to be solved as a challenge okay then between wordline and I O clocks or sa and they have to all run in the same metal layer I remember having uh seen a failure in a big memory where the two match signals one one it was running in metal one the other one was running in metal three as the process as the you know production started we observed that many many Lots were failing because of memory and then we realized oh the math signals are running in different metal layers see metal layers are all drawn in different steps metal one could be of a different width and could see a different width and height uh whereas metal 3 can see a different width and height even if the material is same even if the material is same they could have different uh statistical positioning or different width and height across different metal layers so if you want to match signals which are uh which could be done in different metal layers always draw them in the same metal layer so that effect of RC is similar hmm in terms of doing the statistical analysis Monte Carlo simulations is something that you already know about but uh you know just to qualify six transistor memory cell within one Sigma range you need 30 to 50 simulations if you have to go to Six Sigma Six Sigma qualification you will need billions of simulation this is prohibitive you cannot really have that kind of a design time so there are other methods which have been introduced which are not just Brute Force Monte Carlo simulations there is something called important sampling which is already implemented in the in eldo and there is something also which is called as a design of experiments which I think is also now getting implemented in in synopsis tools like a spice but I'm not sure so typically eldo is the most advanced Tool uh simulation tool till now which has these Advanced methods of uh of statistical analysis also in built into it okay so some of you if you work on some memory project with me you may get to work on design of experiments if you're talking about weak bit testing or something like that but otherwise Monte Carlo is something that will most commonly use okay yeah so any questions I'm pregnant design so important sampling means that okay I tell the simulator that I want to measure let us say right time and I tell it that larger right time is the risky thing for me so in the simulator will run first 100 simulations with completely random distribution on its variables okay and then it will start to observe some Trend analysis it will do some Trend analysis and it will say that okay when I move my variables in this particular direction that is when the right time increases so whether there will really be failures or not uh to estimate that let me select more samples of that kind only so it is kind of you doing some kind of machine learning while running the simulation and then choosing samples such that they the probability of their failure on CAD is higher okay so now to qualify Six Sigma you do not need to run billions of simulations possibly 10 000 simulations will will help you arrive at the worst case cell because you're gravitating towards the worst lot towards the worst place where the failure could happen is that okay yes sir sir the worst case lot means sir don't we have a specific lot that is worst actually I mean but slowly we do know that okay at this point again sorry for that when I say lot means a vector worst case vectors okay uh different variations on VT of different devices different variations on resistances and so on what is the worst case combination at which you will see the worst case result that is what you are able to emulate much faster than in a regular Monte Carlo simulation okay so a lot did not mean that lot but not our element combination of various shifts okay now design of experiments you can do the same analysis which would require 10 000 simulations with important sampling the possibly thousand or even less than thousand simulations what you do in design of experiment first you say that okay I know that passgate needs to be slow and pull up needs to be fast for the worst case right margin I know this yes sir I say that I will myself inject four and a half Sigma variation on the pass gate and four and a half Sigma variation on the pull up the basket will go towards the slow side the pull-up will go towards the fast side so if I put 4.5 Sigma variation on 1 and 4.5 on the other what have I done 4.5 square plus 4.5 square if I add this this I will arrive at something like 6 Sigma so I am arriving at Six Sigma root mean Square variation by putting 4.5 Sigma variation on the pass gate 4.5 Sigma variation on the pull up and if that that particular simulation passes I said okay my overall design is Six Sigma qualified okay sir got it this is much lesser number of simulations than important sampling do you see that yes sir but now you have to apply your brain as a designer but such a design of experiments isn't that specific towards the thing which you do first I mean like but write it specific for another operation it might be specific yes okay sir uh a fresh engineer who has not understood the design well cannot do this you need expertise to even run design of experiments because you know what you have to know what experiments to design yes sir okay uh and do you realize that for a memory cell then I have understood right margin it is so easy to design but think of implementing it for the for the self timing paths can you design it can you distribute how much variation to put on which which cells which devices of itself can you do that so design of experiments can only be done on very small circuits small sets okay for large paths lots of devices where variations could be distributed you prefer to go to important sampling or Brute Force Monte Carlo uh so so with this example the design of experiment you took the 4.5 Sigma 4.5 Sigma with considering the right maturation so but like uh I have when I qualifying for example bit cell I will have to qualify for all their firms right yes so you will run a different design of experiments for SNM a different design of experiments for read current you will have to do those design everything separately anyway the pvt at which SNM is worst is different from the pvt at which right is worse is it not you anyway have to do a different analysis you have to have a different stimuli so it's okay not a big deal okay so can you move to previous slide so I mean uh replica area I mean after profile how like the stress effect on the active should be same so what does profile mean what do you understand by the term profile so profiling okay you are basically putting different two categories some kind of like a bin you're profiling him so that is classification that is so profile means uh so profile means the boundaries are the same you know the behavior or the environment let us say you know metal profile of Halo metal metal design and environment they have to be similar okay so if you have made this kind of structure in your actual cell you should make similar kind of structure even in your replica okay actually okay okay diffusion of metals that is what it means this is also called as structural matching okay okay anything else okay so we will close the class here and uh will meet next on Tuesday in design of experiments we are basically worsening the suppose gate or device so that means we are hacking into the library and changing the VT uh yes so ldo allows you to do that by not going into the model file okay at spice inspector do not do that yet yeah no okay and and also to be able to do that you should have the models which allow you to do that the model should be defined in such a way that you are able to do that from outside that means it The Foundry should give us a feature and yeah so till the time Founders did not give us the feature we used to do the same thing by you know artificially increasing the length and width and so on okay not a good thing to do but yeah that was how we used to do it earlier okay okay"
Ov2l5jEN4h8,effects and yield recovery from physical defects so what do you mean by physical defects so remember this what is this hello what is this layout of 360 SRAM sensor layout of the 60th Ram cell so now when I'm talking about physical defects what do you mean by physical defects over here so can it be some dust particles or dust particles yes and ler lineage roughness okay what would Eli do debunk if it's a very low Tech node then it can impact the gate set basically um uh make the device faster or slower foreign placement means uh means suppose uh if it's uh automated by Tool metal health suppose a metal layer has not been placed correctly or the kind of stuff oh so if it is because of that then it means that there will be zero eight because of the design failure you design something wrong what else what do you call as defects does this and this is important also because this course is about testing also so finally you will also test stuff so it is important to deliberate on the definition of defects what do you mean by physical defect over here we just looked at the SRAM cell and how different layers simply pile up one over the other yes Ranjit so defects could be a dust particle which are being clogged yeah that vaishnav also said and other than it can be a uh the directory breakdown or some metals which can be uh Metals which are being clogged Metals which are being now uh where the connectivity between the metals is being blocked okay so metals are not connected yes okay uh why would that be uh sir it can be that uh larger magnitude of current flows through this particular interconnect and it can uh I'll be talking about so you're not talking about a fresh lot you're talking about after aging electromagulation stuff like that okay but what could lead to what could be physical defects at the time of manufacturing think more in this direction that you were thinking about sir can it be because I'm like even we were saying one of the example in previous class so the police are not as I'm like as good as we see in the layout I'm like there might be some curvy nature which we simulate before uh Fabrications making rounding okay yes so if you use curvy nature in an interview there will there will be like what are the rounding is the term yes there are some like stuck at faults that we study but I don't know if they are applicable here yeah what is stuck at fault why would it happen so what is the defect that leads to a stuck at fault so there is a kind of shorting of a wire or the wire gets stuck at um if you want to toggle the zero one but it hits one only like say it gets stuck at a particular logic so then we call that as a second fault it could be due to the external creeping in or the sand particles there could be various faults that our model is stuck at faults okay okay so suppose this stuck at fault can also be such that if the poly uh is shorted somehow to the vdt terminal then uh then the animals can continuously discharge to ground and this can be stuck at zero fault or else if the um over here in this layout is there a possibility there no sir no why so Paulie uh vdt we were providing it in like a metal two right because with the bit with the Bitcoin this is Method two this is the method too through which I am providing my vdd yes sir so can the poly shot so but in between the poly and the Metal 2 we would have the intra dielectric layer right yeah but is is really going online matter too does a pmos not get really at its source yes so but it is getting through VR connections right so yeah so it is coming getting it through VR then it is going to metal one then so I mean it will be connected through metal to metal one via right um what happens how will it come to the drain through the tungsten contacts right that is uh throughout they would be coming to the uh the fusion but if we look at Poly this is my gate hmm this is my device this is my poly and over here I made a contact tungsten contact do you think there could be some shorting here um they could be I mean but um so in fact uh in the memory cell you will realize that the DRC between contact and poly is already violated in our regular standard cell layout you will maintain the DRC in a memory cell layout because this image of actionability is you know we know this is the pattern and this is the repeatability of the structure so this ERC is already violated the DRC is already violated means the probability of them just getting shorted is also higher the dielectric is very thin over here are you able to see this this is your poly you add that but it is it is very close to your contacts where you have also violated the DRC so this is the place where quality to be really short can happen and that would lead to stuck at one for one of the internal nodes are you able to see this if this poly shots to vdd what happens this metal one everything because it is connected to the poly is now at vdd so the node is stuck at one the other side will will appear to be stuck at zero could a poly to ground short also happen like this is there a possibility for Quality to ground shot also like this where we would get stuck at zero and stuck at one in a different way maybe the poly which is earlier to the pull down so you could have started this one for example this poly then this polyun contact can get shorted okay what else can happen so this is shorting stuck at zero stock at one what else can happen second Metals in different layers can somehow interact Metals in different layers yeah they will interact the past uh you know in a capacitive manner coupling yeah oh that's no no in in the older ideas is being followed there but still is there a possibility like a tunneling kind of thing happen due to dielectric in in the dielectric intermittal no no no no no yeah okay okay intermittently intrametal if you say yes for example if you see these two metal ones are very close to each other right yes there could be a shot here this metal one and this metal one very close to each other again can lead to a shot so whether this metal one and that metal one shorts whether this Con this contact and and and the poly shots what is the outcome that this poly is held at zdd Hannah sir yes sir in memory we are much more concerned about the I'm like yield right so a diluting drcs so how does that actually I mean and like I don't see any kind of okay we are saving the area but we are we are actually uh I'm like compromising on the functionality right so why to dilute DRS is actually I do understand that we are saving area salmon yes yes sir but you see now you are explaining that this might happen I mean like uh we we might get into a case that we are not even able uh I'm like we are not even uh coming out with a good functionality as such so see let us say you reduced area by 25 percent do you know four times no you reduced area by 25 so instead of so your area instead of a is now 0.75 a so you increase your yield by 33 percent okay you see the benefit of reducing area yes sir um I mean I see both contradictive statements also at the first place because uh in now if you if you can see now we we are violating DS's because we want to reduce data at the first place so we are facing some issue over there which might lead to some yield loss right yes yield loss is five percent so what is the overall gain I need so 33 minus 5 I mean 28. you'll still gain three percent are we able to see this how is that three percent not 33 minus 5 is 28. and earlier it was uh no yes yes I understood I understood what you are saying I mean with with more area we are getting 25 percent with less area we are getting 33 so 33 minus 20. okay so no actually it will be like 28 to your recovery you don't need to subtract 25 25 for the area was lesser but you still have much more recovery even in the presence of marginal lead loss so you still would want to go to those DRC violations all right but you want to recover yield from that also what other things could happen we just looked at shorting what other things could happen what other things could go wrong and can lead to faults how many contacts and we ask do you have inside the memory cell did you do account are you doing account got it okay how many contacts quick question huh well how many via ones how many via ones so 12 contacts how many we are ones seven foreign okay how many via tools four so just up till Metal 2 or metal three level you have 24 contacts and we asked all these contacts and vrs are thin tunnels trenches that you make and then you fill them up said this number will be even reduced right because we are sharing them with the beside cell come to the sharing part we'll come to the sharing part but to fail any one memory cell you have you can't fail any one of those 24 contacts or vrs yes yes sir yes any one of those 24 sales yourself would fail so one cell that many contacts are contacts and vrs and if you're talking about one megabit capacity then 24 million contact Andreas more capacity many more so do you realize the variations of contacts and vrs are much more than the variations on your devices there are only six devices but 24 contacts and vrs,https://www.youtube.com/watch?v=Ov2l5jEN4h8,"Link: https://www.youtube.com/watch?v=Ov2l5jEN4h8
Transcript: effects and yield recovery from physical defects so what do you mean by physical defects so remember this what is this hello what is this layout of 360 SRAM sensor layout of the 60th Ram cell so now when I'm talking about physical defects what do you mean by physical defects over here so can it be some dust particles or dust particles yes and ler lineage roughness okay what would Eli do debunk if it's a very low Tech node then it can impact the gate set basically um uh make the device faster or slower foreign placement means uh means suppose uh if it's uh automated by Tool metal health suppose a metal layer has not been placed correctly or the kind of stuff oh so if it is because of that then it means that there will be zero eight because of the design failure you design something wrong what else what do you call as defects does this and this is important also because this course is about testing also so finally you will also test stuff so it is important to deliberate on the definition of defects what do you mean by physical defect over here we just looked at the SRAM cell and how different layers simply pile up one over the other yes Ranjit so defects could be a dust particle which are being clogged yeah that vaishnav also said and other than it can be a uh the directory breakdown or some metals which can be uh Metals which are being clogged Metals which are being now uh where the connectivity between the metals is being blocked okay so metals are not connected yes okay uh why would that be uh sir it can be that uh larger magnitude of current flows through this particular interconnect and it can uh I'll be talking about so you're not talking about a fresh lot you're talking about after aging electromagulation stuff like that okay but what could lead to what could be physical defects at the time of manufacturing think more in this direction that you were thinking about sir can it be because I'm like even we were saying one of the example in previous class so the police are not as I'm like as good as we see in the layout I'm like there might be some curvy nature which we simulate before uh Fabrications making rounding okay yes so if you use curvy nature in an interview there will there will be like what are the rounding is the term yes there are some like stuck at faults that we study but I don't know if they are applicable here yeah what is stuck at fault why would it happen so what is the defect that leads to a stuck at fault so there is a kind of shorting of a wire or the wire gets stuck at um if you want to toggle the zero one but it hits one only like say it gets stuck at a particular logic so then we call that as a second fault it could be due to the external creeping in or the sand particles there could be various faults that our model is stuck at faults okay okay so suppose this stuck at fault can also be such that if the poly uh is shorted somehow to the vdt terminal then uh then the animals can continuously discharge to ground and this can be stuck at zero fault or else if the um over here in this layout is there a possibility there no sir no why so Paulie uh vdt we were providing it in like a metal two right because with the bit with the Bitcoin this is Method two this is the method too through which I am providing my vdd yes sir so can the poly shot so but in between the poly and the Metal 2 we would have the intra dielectric layer right yeah but is is really going online matter too does a pmos not get really at its source yes so but it is getting through VR connections right so yeah so it is coming getting it through VR then it is going to metal one then so I mean it will be connected through metal to metal one via right um what happens how will it come to the drain through the tungsten contacts right that is uh throughout they would be coming to the uh the fusion but if we look at Poly this is my gate hmm this is my device this is my poly and over here I made a contact tungsten contact do you think there could be some shorting here um they could be I mean but um so in fact uh in the memory cell you will realize that the DRC between contact and poly is already violated in our regular standard cell layout you will maintain the DRC in a memory cell layout because this image of actionability is you know we know this is the pattern and this is the repeatability of the structure so this ERC is already violated the DRC is already violated means the probability of them just getting shorted is also higher the dielectric is very thin over here are you able to see this this is your poly you add that but it is it is very close to your contacts where you have also violated the DRC so this is the place where quality to be really short can happen and that would lead to stuck at one for one of the internal nodes are you able to see this if this poly shots to vdd what happens this metal one everything because it is connected to the poly is now at vdd so the node is stuck at one the other side will will appear to be stuck at zero could a poly to ground short also happen like this is there a possibility for Quality to ground shot also like this where we would get stuck at zero and stuck at one in a different way maybe the poly which is earlier to the pull down so you could have started this one for example this poly then this polyun contact can get shorted okay what else can happen so this is shorting stuck at zero stock at one what else can happen second Metals in different layers can somehow interact Metals in different layers yeah they will interact the past uh you know in a capacitive manner coupling yeah oh that's no no in in the older ideas is being followed there but still is there a possibility like a tunneling kind of thing happen due to dielectric in in the dielectric intermittal no no no no no yeah okay okay intermittently intrametal if you say yes for example if you see these two metal ones are very close to each other right yes there could be a shot here this metal one and this metal one very close to each other again can lead to a shot so whether this metal one and that metal one shorts whether this Con this contact and and and the poly shots what is the outcome that this poly is held at zdd Hannah sir yes sir in memory we are much more concerned about the I'm like yield right so a diluting drcs so how does that actually I mean and like I don't see any kind of okay we are saving the area but we are we are actually uh I'm like compromising on the functionality right so why to dilute DRS is actually I do understand that we are saving area salmon yes yes sir but you see now you are explaining that this might happen I mean like uh we we might get into a case that we are not even able uh I'm like we are not even uh coming out with a good functionality as such so see let us say you reduced area by 25 percent do you know four times no you reduced area by 25 so instead of so your area instead of a is now 0.75 a so you increase your yield by 33 percent okay you see the benefit of reducing area yes sir um I mean I see both contradictive statements also at the first place because uh in now if you if you can see now we we are violating DS's because we want to reduce data at the first place so we are facing some issue over there which might lead to some yield loss right yes yield loss is five percent so what is the overall gain I need so 33 minus 5 I mean 28. you'll still gain three percent are we able to see this how is that three percent not 33 minus 5 is 28. and earlier it was uh no yes yes I understood I understood what you are saying I mean with with more area we are getting 25 percent with less area we are getting 33 so 33 minus 20. okay so no actually it will be like 28 to your recovery you don't need to subtract 25 25 for the area was lesser but you still have much more recovery even in the presence of marginal lead loss so you still would want to go to those DRC violations all right but you want to recover yield from that also what other things could happen we just looked at shorting what other things could happen what other things could go wrong and can lead to faults how many contacts and we ask do you have inside the memory cell did you do account are you doing account got it okay how many contacts quick question huh well how many via ones how many via ones so 12 contacts how many we are ones seven foreign okay how many via tools four so just up till Metal 2 or metal three level you have 24 contacts and we asked all these contacts and vrs are thin tunnels trenches that you make and then you fill them up said this number will be even reduced right because we are sharing them with the beside cell come to the sharing part we'll come to the sharing part but to fail any one memory cell you have you can't fail any one of those 24 contacts or vrs yes yes sir yes any one of those 24 sales yourself would fail so one cell that many contacts are contacts and vrs and if you're talking about one megabit capacity then 24 million contact Andreas more capacity many more so do you realize the variations of contacts and vrs are much more than the variations on your devices there are only six devices but 24 contacts and vrs"
lJtIbONaKXY,foreign so what happens they have family failures but and the important interesting thing to note about it is that in a memory many contacts and vrs are shared some are shared across for example four cells um some are shared across two cells like this rows some are shared across columns so which which contacts and we asked do you think are shared across columns bit line and bitline map columns this one which one would this be that is shared along a robot across columns a word link word line which one would this be vertically shared bit line bit line what about this one which is shared across four ground this could be a bit line this could be vdd so on so there are all these vrs which are shared across the boundaries so if the first one fade suppose this one failed how many cells would fail once one cell would fail if the other one fails how many cells would fail now two sir now if if so do you realize either that one fails or one of these fields that we are losing two cells if this one fails how many cells would fail Force so the same kind of defect a VR or a contact failure can lead to one cell failure or a double bit failure or a quad weight failure are you able to see this same kind of defect that your for example the trench was not made well and due to which the contact or the Via failed it can lead to single bit double bit or a quad bit failure are you able to see this hello yes so uh in memories you will realize and when you will look at the Silicon results you will see that failures are typically single bit double bit or quad bit then in addition to that you also have partial partial columns uh you know or partial row failures where a part of the row is failing or a part of the column is failing but most of the failures in a memory are because of single bit or double bit or quad bit so if you want to recover the yield of the bit cells what do you need to do you need to add two cells one cell four cells or what do you do so I didn't get this part so I mean so I say that okay because of the high density design that I have made I can expect more failures physical failures in my design is it clear till here yes sir so if there are more physical failures I know I can anticipate those physical failures and I can plan to correct them how do you correct a physical failure you say okay I will discard the defective cell and I will pick up the uh pick up a new cell which which is not failing I will pick up another cell which is not failing my question is how would you pick up these new cells would you want to add just one or two cells somewhere or is there another way in which you will activate the new cells sir is that even possible to pick up the new cells actually because the thing which you are doing now is before fabrication right this is after fabrication application has happened ah fabrication has happened and you see there is a failure inside the memory array there is a single bit failure and we want to replace the single bit failure with another cell which you have already placed in a in a bank somewhere or in a location somewhere is that even possible sir um sir maybe one approach could be that we will have the built-in self-test uh uh our design implemented uh for Christians and then if the particular cell is set to fail then uh the charge the decoders will be such that we will be able to root this particular word line selection to the new bank or something like that um well sir these one things I have doubt so like after we had fabricated then we would be doing the testing to figure out which cell is failing and after we have figured out the vessel is feeling then we would be doing kind of selection yeah then we will do the replacement because the seller sweating has replaced the cell this elbows failing I would replace that sir so that during testing I would be able to locate the exact location of the selling bit cell right yeah so now you understand why the scrambling information was very important yes sir okay so what do we do now sanjit said okay let us replace the entire row so if you want to replace the entire row basically the decoder will select a different word line then what we do we need to add in the memory array we need to add before anything else an extra row which is called as a redundant zero I don't even see because it was not required but we added a written intro which we would use if there is a failure somewhere but we did not add just one row we realized that two cells could fail or even four adjacent cells could fail if I had two rows I can correct all such kind of failures so if I can replace two adjacent rows then even vertical dual bit defects or quad bit defects I can I can correct easily are you able to see this sir two rows per cell yes I mean two rows per array I will add or two rows I could add per memory also that depends that is my choice like based upon the qualification that I do I'm suggesting that at Max let's say four bit cells can fail no and we could say there is one defect that could happen in the memory which can lead to Atmos for for self-sailing okay this is the maximum well that one defect can cause then how am I able to say that Q only one defect will occur not more than one direction so see if more than one defect happens on every die let us say if more than one defect happens on every die it means your process is not in control okay as a designer you can take care of some process idiosyncrasies but you cannot take over the entire process you cannot compensate for the entire process simply going haywire especially not as a memory designer where you are definitely concerned by a lot of area so if I was designing plls or something like that then what happens I have just one PLL in the entire chip for that one PLL I can also add some trimming bits I can make the device to be large I can do so many things because it is coming only once but for a if you're talking about a memory cell there are millions of memory cells there you want you do not want to uh you know add all those things so you cannot compensate for process so a PLL will compensate for process apparel will compensate for process variation and then it will say I will always generate one gigahertz clock whether you give me a slow sale a slow lot or you whether you give me a fast lot I will always generate one gigahertz clock that is what a PLL does now a clock generated as that whatever the the thing you give it the whatever lot it will always generate the same clock isn't it yes so that is that is done by the use of some process compensation for a memory cell you can't do all that I know you can do that so what we say is we will add so suppose this one fails what I will do is I will replace two rows either the the row just above it and this row or the row just below it and this row and I will activate the repair row so when this fails the repair row gets activated and the a failing row is removed layer of failing rows are removed so whenever the new address comes what do I need to do I need to compare that address with the failing address and if there is a match I will select the repair word lines if there is no match I will go and select whatever word line was to be selected are you able to see this any questions so I'm saying can you repeat how we zero any on the failing row oh that would run a best run we will do a best run we will test it and we will know this one is selling okay okay got it the direct location we can always find out through a test run now we're talking about repair to complete the repair what do you need to do you need to replace this particular row decoder and row with the repair one how do you do that you simply compare the address with selling address will be selected if they do not match the regular Road recorders will be selected so after the my fabrication is done and I've located this uh my feeling with cells then this uh kind of uh failing address would be I would try to know about this information right yes so once you know the selling address you will have to program it how will you program it there is something called as one-time programmable memory or like fuses so you'll fuse you will blow away some fuses on your tip and say okay this is the fairing address is this clear now what is the loss with this kind of a setup what timing would get degraded if at all I'll set the access to the memory will be uh will be larger it will be a file latency because comparison logic will also be present access to the memory or selection of the word line yeah selection so address setup will increase yes yes yeah when the clock comes the borderline would immediately get selected but what you need to do which word line to select that decision making takes longer now so address setup increases there is no impact on wordline to queue delay are you able to see this so a row redundancy implementation will lead to increased setup but almost no impact on access time now even if you do not become a memory designer even if you become a computer architect or a digital designer this piece of information would be very helpful as to which kind of redundancy to apply in different cases okay now you remember we also talked about partial row failures why would they happen why could partial row failures happen or row failures happen it should due to word line being stuck like programmed by mistake at one point yeah due to some similar fault contact being malformed or we are being malformed or some shot between some metal and some poly or something in the row decoder region and then the reward line would be selected incorrectly on may not get selected at all so those row failures how do you correct them Again by using this scheme you can correct partial row failures also um what is there was some sense amplifier which was failing see row decoder is still digital Logic the probability of it failing is lesser the probability of a sense amplifier offset requirement being high and therefore a sense amplifier failing is higher so how would you recover that if a sense amplifier fails what kind of redundancy would you prefer in that case so the column inverter the inverter so we can basically uh tune the inverter such that or the elliptical cells uh I can the sense enable delay I can adjust so if you adjust the sensenable delay on Silicon rather then what happens the memory would act would would increase its access time wherever memory outputs were supposed to be last you will not be able to latch them now so it's as good as a failure,https://www.youtube.com/watch?v=lJtIbONaKXY,"Link: https://www.youtube.com/watch?v=lJtIbONaKXY
Transcript: foreign so what happens they have family failures but and the important interesting thing to note about it is that in a memory many contacts and vrs are shared some are shared across for example four cells um some are shared across two cells like this rows some are shared across columns so which which contacts and we asked do you think are shared across columns bit line and bitline map columns this one which one would this be that is shared along a robot across columns a word link word line which one would this be vertically shared bit line bit line what about this one which is shared across four ground this could be a bit line this could be vdd so on so there are all these vrs which are shared across the boundaries so if the first one fade suppose this one failed how many cells would fail once one cell would fail if the other one fails how many cells would fail now two sir now if if so do you realize either that one fails or one of these fields that we are losing two cells if this one fails how many cells would fail Force so the same kind of defect a VR or a contact failure can lead to one cell failure or a double bit failure or a quad weight failure are you able to see this same kind of defect that your for example the trench was not made well and due to which the contact or the Via failed it can lead to single bit double bit or a quad bit failure are you able to see this hello yes so uh in memories you will realize and when you will look at the Silicon results you will see that failures are typically single bit double bit or quad bit then in addition to that you also have partial partial columns uh you know or partial row failures where a part of the row is failing or a part of the column is failing but most of the failures in a memory are because of single bit or double bit or quad bit so if you want to recover the yield of the bit cells what do you need to do you need to add two cells one cell four cells or what do you do so I didn't get this part so I mean so I say that okay because of the high density design that I have made I can expect more failures physical failures in my design is it clear till here yes sir so if there are more physical failures I know I can anticipate those physical failures and I can plan to correct them how do you correct a physical failure you say okay I will discard the defective cell and I will pick up the uh pick up a new cell which which is not failing I will pick up another cell which is not failing my question is how would you pick up these new cells would you want to add just one or two cells somewhere or is there another way in which you will activate the new cells sir is that even possible to pick up the new cells actually because the thing which you are doing now is before fabrication right this is after fabrication application has happened ah fabrication has happened and you see there is a failure inside the memory array there is a single bit failure and we want to replace the single bit failure with another cell which you have already placed in a in a bank somewhere or in a location somewhere is that even possible sir um sir maybe one approach could be that we will have the built-in self-test uh uh our design implemented uh for Christians and then if the particular cell is set to fail then uh the charge the decoders will be such that we will be able to root this particular word line selection to the new bank or something like that um well sir these one things I have doubt so like after we had fabricated then we would be doing the testing to figure out which cell is failing and after we have figured out the vessel is feeling then we would be doing kind of selection yeah then we will do the replacement because the seller sweating has replaced the cell this elbows failing I would replace that sir so that during testing I would be able to locate the exact location of the selling bit cell right yeah so now you understand why the scrambling information was very important yes sir okay so what do we do now sanjit said okay let us replace the entire row so if you want to replace the entire row basically the decoder will select a different word line then what we do we need to add in the memory array we need to add before anything else an extra row which is called as a redundant zero I don't even see because it was not required but we added a written intro which we would use if there is a failure somewhere but we did not add just one row we realized that two cells could fail or even four adjacent cells could fail if I had two rows I can correct all such kind of failures so if I can replace two adjacent rows then even vertical dual bit defects or quad bit defects I can I can correct easily are you able to see this sir two rows per cell yes I mean two rows per array I will add or two rows I could add per memory also that depends that is my choice like based upon the qualification that I do I'm suggesting that at Max let's say four bit cells can fail no and we could say there is one defect that could happen in the memory which can lead to Atmos for for self-sailing okay this is the maximum well that one defect can cause then how am I able to say that Q only one defect will occur not more than one direction so see if more than one defect happens on every die let us say if more than one defect happens on every die it means your process is not in control okay as a designer you can take care of some process idiosyncrasies but you cannot take over the entire process you cannot compensate for the entire process simply going haywire especially not as a memory designer where you are definitely concerned by a lot of area so if I was designing plls or something like that then what happens I have just one PLL in the entire chip for that one PLL I can also add some trimming bits I can make the device to be large I can do so many things because it is coming only once but for a if you're talking about a memory cell there are millions of memory cells there you want you do not want to uh you know add all those things so you cannot compensate for process so a PLL will compensate for process apparel will compensate for process variation and then it will say I will always generate one gigahertz clock whether you give me a slow sale a slow lot or you whether you give me a fast lot I will always generate one gigahertz clock that is what a PLL does now a clock generated as that whatever the the thing you give it the whatever lot it will always generate the same clock isn't it yes so that is that is done by the use of some process compensation for a memory cell you can't do all that I know you can do that so what we say is we will add so suppose this one fails what I will do is I will replace two rows either the the row just above it and this row or the row just below it and this row and I will activate the repair row so when this fails the repair row gets activated and the a failing row is removed layer of failing rows are removed so whenever the new address comes what do I need to do I need to compare that address with the failing address and if there is a match I will select the repair word lines if there is no match I will go and select whatever word line was to be selected are you able to see this any questions so I'm saying can you repeat how we zero any on the failing row oh that would run a best run we will do a best run we will test it and we will know this one is selling okay okay got it the direct location we can always find out through a test run now we're talking about repair to complete the repair what do you need to do you need to replace this particular row decoder and row with the repair one how do you do that you simply compare the address with selling address will be selected if they do not match the regular Road recorders will be selected so after the my fabrication is done and I've located this uh my feeling with cells then this uh kind of uh failing address would be I would try to know about this information right yes so once you know the selling address you will have to program it how will you program it there is something called as one-time programmable memory or like fuses so you'll fuse you will blow away some fuses on your tip and say okay this is the fairing address is this clear now what is the loss with this kind of a setup what timing would get degraded if at all I'll set the access to the memory will be uh will be larger it will be a file latency because comparison logic will also be present access to the memory or selection of the word line yeah selection so address setup will increase yes yes yeah when the clock comes the borderline would immediately get selected but what you need to do which word line to select that decision making takes longer now so address setup increases there is no impact on wordline to queue delay are you able to see this so a row redundancy implementation will lead to increased setup but almost no impact on access time now even if you do not become a memory designer even if you become a computer architect or a digital designer this piece of information would be very helpful as to which kind of redundancy to apply in different cases okay now you remember we also talked about partial row failures why would they happen why could partial row failures happen or row failures happen it should due to word line being stuck like programmed by mistake at one point yeah due to some similar fault contact being malformed or we are being malformed or some shot between some metal and some poly or something in the row decoder region and then the reward line would be selected incorrectly on may not get selected at all so those row failures how do you correct them Again by using this scheme you can correct partial row failures also um what is there was some sense amplifier which was failing see row decoder is still digital Logic the probability of it failing is lesser the probability of a sense amplifier offset requirement being high and therefore a sense amplifier failing is higher so how would you recover that if a sense amplifier fails what kind of redundancy would you prefer in that case so the column inverter the inverter so we can basically uh tune the inverter such that or the elliptical cells uh I can the sense enable delay I can adjust so if you adjust the sensenable delay on Silicon rather then what happens the memory would act would would increase its access time wherever memory outputs were supposed to be last you will not be able to latch them now so it's as good as a failure"
QmvMyR56NXE,I would not say column I would rather say bit slice or a set of columns which share a sense amplifier so what what happens when you do this let us say particular cell is failing so you add a bit slice or a set of columns let us say a particular cell is failing then what do you do you do not replace anything you simply disconnect that particular bit line from the IO and instead you connect the adjacent bit line here and then the addition bit line and then you Ripple it to the last IO and the the repair i o gets connected to the last IO there so what has happened so let us say you are initially storing bit 0 here bit one here bit 26 here now you're not storing bit 26 here no see in the road redundancy part what did we do in the Row rendency part if this was row 95 when the 95 address come the contents of row 95 are stored here in column redundancy path we do not do that if it is row 26 I do not store root one if it is bit 26 I do not store bit 26 in this extra column no I store bit 26 in the adjacent bit slice then 27 which was initially 28. so this was 27 this is 28. so I just Ripple it across and then instead of storing bit 64 here I store bit 64 there and over here I store bit 63. are you able to see this sir after fabrication however you I'm like moving these wires as we want I mean so who said I'm moving wires so he said you I mean we will be moving to right side so the wires also move does connection always require moving wires do you know something called a mux yes so how can you use a mux over here okay we are moving the mux so it's just changing the control signal of the mux oh yes yes yes sir okay no physical movement of anything is allowed on Silicon is it yes sir yes got it all that you can play is with electrical signals so you control them input of the marks and the mux would select until here it will select zeroth input and from here onwards it will select first input and it will be programming the control signal of the mugs here we are changing the control signal of box yes okay enough sir sir in this case or the bit order has uh we are telling that the bit order has not changed but the thing is that suppose if we find out that a particular column is faulty and we do the bit slicing then immediately we run the read cycle then the bit orders which from which we read will be changed now sir so if you know something was failing do you know that uh and you did a repair and this then you know that you are not written into this extra column yet and and whatever you are writing or reading now is junk is it not yes sir so you will not read that you will write into the memory all over again and then test it so then suppose if I have 1024 words then all 1024 words should be Rewritten again yes and then there will be loss of data user how do we retrieve a complete testing we are just testing testing monitors okay there's no real data that we're talking about it's all test data isn't this during the run times or is it just before how can you do this around during runtime how can you do a repair operation during runtime can you say that okay I know the memory is failing and then on runtime I will correct it there uh this was what I thought because we'll have some testability feature for each each and uh on the memory and then once it is detected automatically we change the control signals this is what that has done in the beginning at the PowerApp itself or during test itself okay okay yes sir okay so before the memory is written into for the first time during a real application this correction is already taken place okay yes sir good thanks for this question because I I could see that many others could also be confused okay what else any other questions on this uh so when we are designing replica path so it should be designed Beyond this row and the worst case cell would be in this sorry in this column and then yes so when you are designing the replica path you have to consider the redundancy column also to be a part of the memory you cannot ignore it so in many cases as we saw the replica path could be designed uh like this you know in the center in the same manner the the remnants the rendered column could also be designed in the center okay so it's equidistant and doesn't matter you could still you could have a replica path like this but the return column could be here also these are all design decisions you are free to do them take them but yes you are right in saying that you have to ensure that the rendering column also does not fit that you have to ensure okay okay so,https://www.youtube.com/watch?v=QmvMyR56NXE,"Link: https://www.youtube.com/watch?v=QmvMyR56NXE
Transcript: I would not say column I would rather say bit slice or a set of columns which share a sense amplifier so what what happens when you do this let us say particular cell is failing so you add a bit slice or a set of columns let us say a particular cell is failing then what do you do you do not replace anything you simply disconnect that particular bit line from the IO and instead you connect the adjacent bit line here and then the addition bit line and then you Ripple it to the last IO and the the repair i o gets connected to the last IO there so what has happened so let us say you are initially storing bit 0 here bit one here bit 26 here now you're not storing bit 26 here no see in the road redundancy part what did we do in the Row rendency part if this was row 95 when the 95 address come the contents of row 95 are stored here in column redundancy path we do not do that if it is row 26 I do not store root one if it is bit 26 I do not store bit 26 in this extra column no I store bit 26 in the adjacent bit slice then 27 which was initially 28. so this was 27 this is 28. so I just Ripple it across and then instead of storing bit 64 here I store bit 64 there and over here I store bit 63. are you able to see this sir after fabrication however you I'm like moving these wires as we want I mean so who said I'm moving wires so he said you I mean we will be moving to right side so the wires also move does connection always require moving wires do you know something called a mux yes so how can you use a mux over here okay we are moving the mux so it's just changing the control signal of the mux oh yes yes yes sir okay no physical movement of anything is allowed on Silicon is it yes sir yes got it all that you can play is with electrical signals so you control them input of the marks and the mux would select until here it will select zeroth input and from here onwards it will select first input and it will be programming the control signal of the mugs here we are changing the control signal of box yes okay enough sir sir in this case or the bit order has uh we are telling that the bit order has not changed but the thing is that suppose if we find out that a particular column is faulty and we do the bit slicing then immediately we run the read cycle then the bit orders which from which we read will be changed now sir so if you know something was failing do you know that uh and you did a repair and this then you know that you are not written into this extra column yet and and whatever you are writing or reading now is junk is it not yes sir so you will not read that you will write into the memory all over again and then test it so then suppose if I have 1024 words then all 1024 words should be Rewritten again yes and then there will be loss of data user how do we retrieve a complete testing we are just testing testing monitors okay there's no real data that we're talking about it's all test data isn't this during the run times or is it just before how can you do this around during runtime how can you do a repair operation during runtime can you say that okay I know the memory is failing and then on runtime I will correct it there uh this was what I thought because we'll have some testability feature for each each and uh on the memory and then once it is detected automatically we change the control signals this is what that has done in the beginning at the PowerApp itself or during test itself okay okay yes sir okay so before the memory is written into for the first time during a real application this correction is already taken place okay yes sir good thanks for this question because I I could see that many others could also be confused okay what else any other questions on this uh so when we are designing replica path so it should be designed Beyond this row and the worst case cell would be in this sorry in this column and then yes so when you are designing the replica path you have to consider the redundancy column also to be a part of the memory you cannot ignore it so in many cases as we saw the replica path could be designed uh like this you know in the center in the same manner the the remnants the rendered column could also be designed in the center okay so it's equidistant and doesn't matter you could still you could have a replica path like this but the return column could be here also these are all design decisions you are free to do them take them but yes you are right in saying that you have to ensure that the rendering column also does not fit that you have to ensure okay okay so"
XP4O5Clp5l4,so let's move to today's session then and today what we are going to do is we are going to talk about what is called as cache subsystem what do you so you've heard about caches what are caches what is the cash cash is at the small capacity high speed memories that are placed nearer to the processor so that it map so that person doesn't wait uh to get uh the chunks of the memory directly from the main memory you can look at the cache itself mm-hmm so that that is that is a little extra detail my question was actually I was just wanting to arrive at what is a cache so cash by itself means something that remains hidden but that is something which is very readily available to you that is where you would use the term cash and over here when we're talking about cache subsystem uh where as Ranjit mentioned we're talking about uh something which some small memory which could be placed very close to the processor so that the overall access time for the processor is reduced let us look at why it is needed so in a typical system in a typical you know memory system you would see that there is a CPU and then there is a cache which is typically an asram associated with it the SRAM would interact with what we call as a dram and which would then interact with what is called as the hard disk hmm As you move from hardness to caches the speed increases so the caches also there could be L1 L2 L3 kind of caches so L1 means for level one closest to the processor L2 is level 2 and level 3 is closer to the output to the to the main memory that is the dram okay so what has happened over the past many of us that the processor speed has increased kind of exponentially or largely exponentially at a very fast pace whereas the main memory speed has not increased at the same Pace it has been a it is also improving but at a much lower pace so it was uh 2x performance in one and a half years and over here dram 2x performance over 10 years so it is not that it is not improving it is improving but at a much slower pace and therefore because of this you know performance gap between processor and the memory because of this performance Gap we need to use something which we call as caches so what and and there is another reason why this is possible what we say is so there is this uh there is this reference to locality of references mention of locality of a references what this means is that typically when you are running a program on a system or something like that uh you will you will usually use some lines of the same program over and over again for example uh if we say that we are working on this PPT presentation then it is evident that the program the the instruction codes links to uh rendering a PPT onto the screen will be run over and over again I know I would not be using a calculator like when I when my my when I'm showing a PPT then I'm not always using a calculator simultaneously I may use it but I may not always use it for example at this point of time I am using a PowerPoint application I'm using Zoom application I'm using another streaming application so that I am able to communicate with all of you so these three or four things that are running on my computer and uh not much else I do not really need data linked to one of my projects or data links to one of the presentations that I made yesterday to a faculty meeting or anything like that so the information that I need is is not the entire hard disk I do not need the entire hard disk to be made available to me or the processor at all times the processor would usually work on much smaller chunks of data and that this data in terms of address is also referenced close together that uh when I save something let us say when I save a movie or when I save a music somewhere the music file is is long enough uh to say that okay 10 words it will occupy or 100 words it will occupy and so on and these words usually will be consecutive words because that is how you would typically want to store so when the processor would want to render your movie or to need to uh need to amplify the music that you are playing it will be there will be a locality of references in the sense that adjacent address addresses would be accessed uh every passing second or every passing moment is this part there so because we have this uh locality of references we say that uh we do not really need the entire big memory to be accessed every cycle let us use a relatively small SRAM which can be placed physically close to the processor so that not only it would have a smaller access time the physical proximity also reduces bio delays so what we are essentially trying to do is we are trying to keep commonly accessed data in smaller or faster faster memory and when we do this another thing that we take care of is suppose this is L3 cache the L2 cache L1 cache and over here it is processor what we also ensure is the data of L1 cache is also available in L2 cache somewhere and data of L2 cache let us say this is also available somewhere in my L1 cache L3 gash so this is referred to as what is called as inclusion property that uh a lower level memory if we say that L1 is lower level than L2 or L3 is almost always included in the higher level of the memory so all the rate of L1 is available in L2 all the data of L2 is available in L3 hmm ah I have spoken quite a bit moved many slides in one go any questions but I moved fast simply because I felt you have done the ca course most of you and therefore should be able to capture it so by this line physical proximity reduces why delay what are we trying to say uh so the wired rays are reduced what would happen access would be faster hello hello yes sir if I reduce the wire delays the excess would be faster the purpose of using a small SRAM was also the same thing that you are able to because it's a small SRAM not the full dram uh the excess times are shorter are smaller so you are overall able to access the content much faster he said uh if processor means uh if if it is a Miss in the L1 cache if I have to bring it from the dram so first directly I will bring Dr M to L1 or L3 L2 and L1 in hierarchy yeah so that we will come to me so we'll talk about heads and vessels in just a little while any questions there L1 L2 that is especially referring to us the virtual memory that is you're calling the virtual memory here so version memory concept is different if you've done the computer architecture course this reference is coming from there don't worry about it it's not something that you need to worry about I just gave this so that those of you who have done CA course are able to understand it better virtual memory is a standard term so I got disconnected while you are explaining this physical proximity thing can you please explain that okay so my question was very well uh what happens when the wire delay reduces when the wire will able to ex like it will be faster when the delay reduces yeah so it means that you will be able to run the memory at the processor speed yes sir so we were not able to directly access the dram because there is a huge gap in the performance that was what we were looking in the previous slide there's a huge performance Gap Now by keeping the memory closed using a small first we use the nasram then we use a small SRAM and then we placed it close to the processor all these three things using an SRAM srams are Faso dandrums a small SRAM means a smaller slam is definitely faster than a bigger S run and keeping it physically close to the processor so that delays in the wires also reduce okay we're doing all this to fill the performance Gap that we talked about in the previous slide okay okay thank you okay so we are doing all this to that uh bridge that Gap that you were showing earlier 30 RAM and the yes because I want my processor to not keep waiting I want my processor to operate very fast because there's an is also technology only so that same technology is a processor yeah so okay okay so why do we have to store some data of L1 into L2 and some bit of L2 into L3 okay why do you think we need to do that so you're asking why do we need the inclusion property yes why is it that L1 should always be available in L2 and L2 should always be available in L3 why do you think so what what do you what can you imagine are the reason so basically I can imagine if if there is any issue with L1 we'll we can fetch Theta with L2 from N2 yes anything else that you can think of amazing anyone else who can think of something else or sir can this be due to the to maintain the cash coherency yeah so that is the question why do we need to maintain cash currency uh so suppose some we have two course running parallelly and a particular data uh is being read in one of the cores and it is being manipulated it is being completed in other course so when there is uh when the data is written uh suppose in the core B then this particular data is captured by the uh higher level of the cache and then the Snoop control unit uh or senses it and the other core uh The Courier will check whether if the data is changed or not then through the hierarchy that particular data will be changed so let us put it a little simply for the tasks because not everyone in the class may have been CA and and in that detail that you are talking about so uh a very simple thing is that suppose your processor you know when you are processing you said a plus b is equal to C now the content of location C are changed because we did an operation inside the processor yes sir now let us say there is another core which is using similar data or same data should we tell that code that okay c is now updated Okay so now how do I tell Core 2 that c is updated unless I have an L2 there where a b c are all stored and L2 I tell that okay update the C how will processor 2 come to know that there is a change somewhere so that is about cash currency so there are many units they which tell that okay this is how the data is updated and this is how any change in data across or due to One Core is communicated to another core and so on uh I would also bring in the concept of hey but of still more fundamental concept suppose you want to write something in from your processor or to the main memory now now the main memory access takes hundreds of nanoseconds you cannot really do it you cannot really wait those hundreds of nanoseconds so what do you want to do okay I will now write back into L2 and only in L2 and then I will say L2 will automatically plan and write in the Marine memory so if I have to write back some data into L2 then L2 should already have that location with it first so that is another reason why inclusion is important that the higher level of memory should always contain the lower level memory contents in it okay so writing in L2 means we have to first write it as L1 and that will same be copied in L2 directly we are writing you tell me I think we should write in L1 first right yes Hannah you have to otherwise I will maintain the currency between L1 and L2 also the processor would write something in L1 it would write it within one cycle now when L1 so we will talk about this when in in just a few minutes also now when L1 needs to uh put some other data in this particular location the new data that was already written uh in the memory should be written into the L2 cache so when you write into the relative Cache can still be variable when you are being replaced you can write then or whenever if there was a right operation on you you could write them that is a operating system issues but you first write into L1 because the processor is interacting only with L1 processor does not interact directly with L2 and then through L1 you will write an L2 whenever you have on an opportunity or whenever there is a need is that clear yes sir so we like the everything that gets read or write it goes to this whole hierarchy of L1 into L3 and Main memory yes yes so what that would mean a more power consumption in terms of it right we are gaining in terms of speed but in terms of power we are is a cost okay um you anyway had to read okay so but like we are we are reading and writing the same thing at multiple places right I mean firstly I have to go to that and that and that but yeah but look at it like this see a plus b equal to C you did it once but then on the same screen you brought in another data on the same screen you brought in another data so you would actually be ending up doing this a plus b equal to C hundreds of times if there was no cache hierarchy then all these hundred of times you will have to go and access the main memory that is much much more power than doing all these operations right away in a small on-chip cache okay the power control system buses more as compared to this okay yeah you have to go off the chip you have to drive big big buffer so that the off chip signal has some current some significant current and voltage so as soon as you talk of going offset power consumption goes for a toss Focus okay,https://www.youtube.com/watch?v=XP4O5Clp5l4,"Link: https://www.youtube.com/watch?v=XP4O5Clp5l4
Transcript: so let's move to today's session then and today what we are going to do is we are going to talk about what is called as cache subsystem what do you so you've heard about caches what are caches what is the cash cash is at the small capacity high speed memories that are placed nearer to the processor so that it map so that person doesn't wait uh to get uh the chunks of the memory directly from the main memory you can look at the cache itself mm-hmm so that that is that is a little extra detail my question was actually I was just wanting to arrive at what is a cache so cash by itself means something that remains hidden but that is something which is very readily available to you that is where you would use the term cash and over here when we're talking about cache subsystem uh where as Ranjit mentioned we're talking about uh something which some small memory which could be placed very close to the processor so that the overall access time for the processor is reduced let us look at why it is needed so in a typical system in a typical you know memory system you would see that there is a CPU and then there is a cache which is typically an asram associated with it the SRAM would interact with what we call as a dram and which would then interact with what is called as the hard disk hmm As you move from hardness to caches the speed increases so the caches also there could be L1 L2 L3 kind of caches so L1 means for level one closest to the processor L2 is level 2 and level 3 is closer to the output to the to the main memory that is the dram okay so what has happened over the past many of us that the processor speed has increased kind of exponentially or largely exponentially at a very fast pace whereas the main memory speed has not increased at the same Pace it has been a it is also improving but at a much lower pace so it was uh 2x performance in one and a half years and over here dram 2x performance over 10 years so it is not that it is not improving it is improving but at a much slower pace and therefore because of this you know performance gap between processor and the memory because of this performance Gap we need to use something which we call as caches so what and and there is another reason why this is possible what we say is so there is this uh there is this reference to locality of references mention of locality of a references what this means is that typically when you are running a program on a system or something like that uh you will you will usually use some lines of the same program over and over again for example uh if we say that we are working on this PPT presentation then it is evident that the program the the instruction codes links to uh rendering a PPT onto the screen will be run over and over again I know I would not be using a calculator like when I when my my when I'm showing a PPT then I'm not always using a calculator simultaneously I may use it but I may not always use it for example at this point of time I am using a PowerPoint application I'm using Zoom application I'm using another streaming application so that I am able to communicate with all of you so these three or four things that are running on my computer and uh not much else I do not really need data linked to one of my projects or data links to one of the presentations that I made yesterday to a faculty meeting or anything like that so the information that I need is is not the entire hard disk I do not need the entire hard disk to be made available to me or the processor at all times the processor would usually work on much smaller chunks of data and that this data in terms of address is also referenced close together that uh when I save something let us say when I save a movie or when I save a music somewhere the music file is is long enough uh to say that okay 10 words it will occupy or 100 words it will occupy and so on and these words usually will be consecutive words because that is how you would typically want to store so when the processor would want to render your movie or to need to uh need to amplify the music that you are playing it will be there will be a locality of references in the sense that adjacent address addresses would be accessed uh every passing second or every passing moment is this part there so because we have this uh locality of references we say that uh we do not really need the entire big memory to be accessed every cycle let us use a relatively small SRAM which can be placed physically close to the processor so that not only it would have a smaller access time the physical proximity also reduces bio delays so what we are essentially trying to do is we are trying to keep commonly accessed data in smaller or faster faster memory and when we do this another thing that we take care of is suppose this is L3 cache the L2 cache L1 cache and over here it is processor what we also ensure is the data of L1 cache is also available in L2 cache somewhere and data of L2 cache let us say this is also available somewhere in my L1 cache L3 gash so this is referred to as what is called as inclusion property that uh a lower level memory if we say that L1 is lower level than L2 or L3 is almost always included in the higher level of the memory so all the rate of L1 is available in L2 all the data of L2 is available in L3 hmm ah I have spoken quite a bit moved many slides in one go any questions but I moved fast simply because I felt you have done the ca course most of you and therefore should be able to capture it so by this line physical proximity reduces why delay what are we trying to say uh so the wired rays are reduced what would happen access would be faster hello hello yes sir if I reduce the wire delays the excess would be faster the purpose of using a small SRAM was also the same thing that you are able to because it's a small SRAM not the full dram uh the excess times are shorter are smaller so you are overall able to access the content much faster he said uh if processor means uh if if it is a Miss in the L1 cache if I have to bring it from the dram so first directly I will bring Dr M to L1 or L3 L2 and L1 in hierarchy yeah so that we will come to me so we'll talk about heads and vessels in just a little while any questions there L1 L2 that is especially referring to us the virtual memory that is you're calling the virtual memory here so version memory concept is different if you've done the computer architecture course this reference is coming from there don't worry about it it's not something that you need to worry about I just gave this so that those of you who have done CA course are able to understand it better virtual memory is a standard term so I got disconnected while you are explaining this physical proximity thing can you please explain that okay so my question was very well uh what happens when the wire delay reduces when the wire will able to ex like it will be faster when the delay reduces yeah so it means that you will be able to run the memory at the processor speed yes sir so we were not able to directly access the dram because there is a huge gap in the performance that was what we were looking in the previous slide there's a huge performance Gap Now by keeping the memory closed using a small first we use the nasram then we use a small SRAM and then we placed it close to the processor all these three things using an SRAM srams are Faso dandrums a small SRAM means a smaller slam is definitely faster than a bigger S run and keeping it physically close to the processor so that delays in the wires also reduce okay we're doing all this to fill the performance Gap that we talked about in the previous slide okay okay thank you okay so we are doing all this to that uh bridge that Gap that you were showing earlier 30 RAM and the yes because I want my processor to not keep waiting I want my processor to operate very fast because there's an is also technology only so that same technology is a processor yeah so okay okay so why do we have to store some data of L1 into L2 and some bit of L2 into L3 okay why do you think we need to do that so you're asking why do we need the inclusion property yes why is it that L1 should always be available in L2 and L2 should always be available in L3 why do you think so what what do you what can you imagine are the reason so basically I can imagine if if there is any issue with L1 we'll we can fetch Theta with L2 from N2 yes anything else that you can think of amazing anyone else who can think of something else or sir can this be due to the to maintain the cash coherency yeah so that is the question why do we need to maintain cash currency uh so suppose some we have two course running parallelly and a particular data uh is being read in one of the cores and it is being manipulated it is being completed in other course so when there is uh when the data is written uh suppose in the core B then this particular data is captured by the uh higher level of the cache and then the Snoop control unit uh or senses it and the other core uh The Courier will check whether if the data is changed or not then through the hierarchy that particular data will be changed so let us put it a little simply for the tasks because not everyone in the class may have been CA and and in that detail that you are talking about so uh a very simple thing is that suppose your processor you know when you are processing you said a plus b is equal to C now the content of location C are changed because we did an operation inside the processor yes sir now let us say there is another core which is using similar data or same data should we tell that code that okay c is now updated Okay so now how do I tell Core 2 that c is updated unless I have an L2 there where a b c are all stored and L2 I tell that okay update the C how will processor 2 come to know that there is a change somewhere so that is about cash currency so there are many units they which tell that okay this is how the data is updated and this is how any change in data across or due to One Core is communicated to another core and so on uh I would also bring in the concept of hey but of still more fundamental concept suppose you want to write something in from your processor or to the main memory now now the main memory access takes hundreds of nanoseconds you cannot really do it you cannot really wait those hundreds of nanoseconds so what do you want to do okay I will now write back into L2 and only in L2 and then I will say L2 will automatically plan and write in the Marine memory so if I have to write back some data into L2 then L2 should already have that location with it first so that is another reason why inclusion is important that the higher level of memory should always contain the lower level memory contents in it okay so writing in L2 means we have to first write it as L1 and that will same be copied in L2 directly we are writing you tell me I think we should write in L1 first right yes Hannah you have to otherwise I will maintain the currency between L1 and L2 also the processor would write something in L1 it would write it within one cycle now when L1 so we will talk about this when in in just a few minutes also now when L1 needs to uh put some other data in this particular location the new data that was already written uh in the memory should be written into the L2 cache so when you write into the relative Cache can still be variable when you are being replaced you can write then or whenever if there was a right operation on you you could write them that is a operating system issues but you first write into L1 because the processor is interacting only with L1 processor does not interact directly with L2 and then through L1 you will write an L2 whenever you have on an opportunity or whenever there is a need is that clear yes sir so we like the everything that gets read or write it goes to this whole hierarchy of L1 into L3 and Main memory yes yes so what that would mean a more power consumption in terms of it right we are gaining in terms of speed but in terms of power we are is a cost okay um you anyway had to read okay so but like we are we are reading and writing the same thing at multiple places right I mean firstly I have to go to that and that and that but yeah but look at it like this see a plus b equal to C you did it once but then on the same screen you brought in another data on the same screen you brought in another data so you would actually be ending up doing this a plus b equal to C hundreds of times if there was no cache hierarchy then all these hundred of times you will have to go and access the main memory that is much much more power than doing all these operations right away in a small on-chip cache okay the power control system buses more as compared to this okay yeah you have to go off the chip you have to drive big big buffer so that the off chip signal has some current some significant current and voltage so as soon as you talk of going offset power consumption goes for a toss Focus okay"
ZiyX7EU-Mno,so what does cash mean this is just a very quick preview you say that uh in the cache memory I will store the data that we want to store and when I stock of storing this data in each row I will also store an additional piece of information which is called as tag this tag represents some address bits of the main location there original location in the say main memory okay so when you access the memory uh the tag that you read from the memory is compared with the tag which is available in the address field when the request was sent only if the tags match only if the tags match we say that uh you know we come to know if this data that I read from the cache was even relevant to me or not if it was relevant I I transmit this data if it was relevant I transmit this data to the processor if it was not relevant then I would not transmit this data I would instead uh give out an instruction so that the data is pulled from the main memory and stored here is that okay so we're going into more details of this but as a top level operation is it is it okay to understand that there are some tag bits which are a part of address there is a comparator and then there is a Max which would say whether I have to send this data out or another data out is this part clear hello yes sir so do we have to compare every time like with the address time you tell me what do you think I don't think so like it will not be feasible you need to or do you not need hmm so suppose you wanted uh you wanted the coordinates of your home to be released but you are also accessing on the map uh coordinates of your uh college at the same time yes sir now when you were checking the coordinates for the home the latitude time it checked and it ensured that the latitude was of your home question but when the longitude was given out it said 90 latitude was for home so long it would be home yoga will you reach your home or will you reach your office or will you reach some other location all together some other location is it acceptable not not acceptable so whenever you are accessing the cash you have to ensure that the tag is matching okay yes the tag is not matching it means it could be some old data or some other data it is definitely not the data that you are looking for yes sir so uh can you can you please reiterate the flow like uh we have to check the address tag like we have to compare address tag with whatever was stored as tab with the data inside the cache okay okay okay so okay yes so in in the example that we gave the attack could be home latitude home longitude or college latitude College longitude so that could be home and college and you're just checking are am I is the is the person in front of me asking me for my home address or is he asking me for my College address yes sir okay so this check has to be done sir actually I couldn't understand this tag operation I mean I'm sorry I was not able to understand this tag operation sir so yeah tag is not an operation TAG is simply data as we will move forward so this is just a quick preview so I'm not expecting you to understand it fully we will look at the operation in more detail in the next slides but this is just to give you a feel that there are some comparisons happening and after that you give out the data value less,https://www.youtube.com/watch?v=ZiyX7EU-Mno,"Link: https://www.youtube.com/watch?v=ZiyX7EU-Mno
Transcript: so what does cash mean this is just a very quick preview you say that uh in the cache memory I will store the data that we want to store and when I stock of storing this data in each row I will also store an additional piece of information which is called as tag this tag represents some address bits of the main location there original location in the say main memory okay so when you access the memory uh the tag that you read from the memory is compared with the tag which is available in the address field when the request was sent only if the tags match only if the tags match we say that uh you know we come to know if this data that I read from the cache was even relevant to me or not if it was relevant I I transmit this data if it was relevant I transmit this data to the processor if it was not relevant then I would not transmit this data I would instead uh give out an instruction so that the data is pulled from the main memory and stored here is that okay so we're going into more details of this but as a top level operation is it is it okay to understand that there are some tag bits which are a part of address there is a comparator and then there is a Max which would say whether I have to send this data out or another data out is this part clear hello yes sir so do we have to compare every time like with the address time you tell me what do you think I don't think so like it will not be feasible you need to or do you not need hmm so suppose you wanted uh you wanted the coordinates of your home to be released but you are also accessing on the map uh coordinates of your uh college at the same time yes sir now when you were checking the coordinates for the home the latitude time it checked and it ensured that the latitude was of your home question but when the longitude was given out it said 90 latitude was for home so long it would be home yoga will you reach your home or will you reach your office or will you reach some other location all together some other location is it acceptable not not acceptable so whenever you are accessing the cash you have to ensure that the tag is matching okay yes the tag is not matching it means it could be some old data or some other data it is definitely not the data that you are looking for yes sir so uh can you can you please reiterate the flow like uh we have to check the address tag like we have to compare address tag with whatever was stored as tab with the data inside the cache okay okay okay so okay yes so in in the example that we gave the attack could be home latitude home longitude or college latitude College longitude so that could be home and college and you're just checking are am I is the is the person in front of me asking me for my home address or is he asking me for my College address yes sir okay so this check has to be done sir actually I couldn't understand this tag operation I mean I'm sorry I was not able to understand this tag operation sir so yeah tag is not an operation TAG is simply data as we will move forward so this is just a quick preview so I'm not expecting you to understand it fully we will look at the operation in more detail in the next slides but this is just to give you a feel that there are some comparisons happening and after that you give out the data value less"
WT86Y1fPP8M,and then data would be out yeah so let us now look at some key specifications of a cache subsystem we'll come to a better understanding of tag also in just a little while as we discuss these key performance metrics you will see that the purpose of tag will automatically become clear to you so we're talking about a memory access time capacity there are two variables which you will very easily understand am I right what is the capacity of your cache subsystem that you cannot understand now associativity associativity means that suppose I wanted to um store latitudes or some locations addresses some addresses I wanted to store the latitude and longitudes how many latitudes can I store and how many longitudes can I store or can I uh can I can I have uh can I also store let us say a photograph or something else of something in my system so how many uh locations in the cache is a given address eligible to be placed in for example I have uh two buckets latitude and longitude and in bucket one I have 10 locations in bucket two I have 10 locations so associated associativity would be let us say 2 over here and so you would either come in the latitude so I any location in the latitude bucket or any location in the longitude bucket will tell you how many latitudes and longitudes you can save again we will come to it in in much more detail in just a little while uh replacement policy I think this is intuitive suppose my cash is full cache is a very small memory suppose it goes full and I want to store or you know new data run a new program first first sequence now the second sequence needs to be loaded which which part of the cash would you replace that is another key specification for the cache subsystem we will look into it in detail as to what kind of replacement policies exist another feature or another specification around the cache subsystem is do we have a unified cache or a separate instruction and data cache uh in a unified cache both data and instructions could be stored in the same cache but as the second case and suggests you could also keep independent instructional and independent data cache what could be the benefit of keeping independent in the instruction and data caches so if you have independent instruction and data cache uh then as we look at the normal execution of particular instruction first will be the fetch the second decode a fetch decode execute on the memory access and finally uh the right register right stage so if you have unified memory then the fit stage and the memory read stage will uh coincide and there can be a loss of single cycle a cycle type so if you have dedicated instruction and data cache then we can then we have the then we can execute both of them independently and there will be no loss of single time yes also it could happen that there are there is one instruction which is running on multiple data if you have just one cache which is Unified it means every time instruction also needs to be fetched and every time data also needs to be fetched but if you have separate caches what does it mean oh instruction I have already list put it out on my register uh that instruction you can continue to use but uh the data cache you may just access more frequently so that also is one thing one thing that would change so overall power of the system performance of the system can change depending on whether you are using unified or separate caches for instruction and data so let's first look at access time uh we're talking about four things here uh the probability of a hit that is probability of finding the address location that you want to access inside your L1 cache uh do you understand probability of a hit um yeah the main memory is very huge you only saved selective addresses inside your L1 cache or L2 cache and so on Okay so the probability that the address that you are looking for is now available in the L1 or L2 cache is p hit probability hit and then PMS that it was not there now if it was there then what happens the memory the small SRAM simply reads out the data and there is a fast access time there okay however if it uh if the head doesn't happen if there is a mess then you know that you will have to go to a higher level of hierarchy which means that uh the time involved would would be higher would be would be more so there is a different timing now which is called as tmis so probability of hit into the time that it takes when you are when you read after a hit and probability of a mess and the time it takes to fetch the data from a to Cache or wherever so that it is now available in 81 cache and for the processor is referred to as TMS the penalty link to Ms okay and therefore average access time is pH into T hit plus PMS into TMS is this clear hello any questions so why we are writing it as average time shouldn't be right shoulders total time why I access one memory location and uh it was a hit and the time it took to access that particular location was just P hit only here then I will have a different timing which is TMS yes sir so how does this become total time it Still Remains average time there will be instances when there is a team is which is much uh which is much longer so overall uh okay yes sir Hannah okay so that is what is excess time let's take an example a memory like a memory system consists of a cache and the main memory if it takes one cycle to complete a cachet and 100 Cycles to complete a cache Miss what is the memory average excess time can you find this out if the hit rate is say 97 percent can you find this out so 3.97 units 3.97 Cycles is this clear yes sir okay um now if you want less number of missiles you want the probability of it to be higher you can use a bigger cache I don't know if you have a bigger cash the the probability of a mess reduces if your cash could be as big as the main memory there will be zero misses believe me so I am not able to understand this statement so why is there a mess let us answer this question first why is there a message now why is something not available in the cache yes sir we are checking each each row okay then the probability of it will be 100 whatever you wanted is also available in your cache yes yes sir so there will be zero PMS everything will be hit yes that much you cannot do dram is much denser cell than the SRAM if you say that okay I will have the L1 cache like as the same size as my dram there then the area would simply blow up the moreover since the size becomes big the performance gain that you had thought of earlier would no longer be there are able to see this hello any questions so we say that bigger capacity could be better however bigger cases are slower so there is a declining return on investment as the cache size goes up when we talk of cache size we also talk of what is called as cache line length or also called as a block um so the concept of a line length is that uh if there is a mess and you need to fetch something from a higher level of memory then do not bring in just one address bring in one full block why why is bringing a block more important than just one location yes we just talked about it that typically it will be adjacent addresses that would be you know that would be required by the system so you bring in a full block so that uh there are less number of misses there is more number of heads additionally when you do that you will see that uh the overall excess time you know time to fetch reduces because while the first access may take a lot of time subsequent addresses could be faster we call that as Burst Mode so you get two kinds of benefits first the number of Misses reduce second that fetching a bigger address has is overall cheaper in terms of total time than fetching uh just a small one word at a time a bigger block will take lesser time and in comparison to if all the words were accessed individually okay and uh this this function are you able to see this this says that I will bring about let us say 256 words in one block but you want to bring that many words but what happens what happens is that the bus that you have from the memory to your processor is much smaller it can at most transmit two words or four words so whenever you there is a mess how many cycles would you need first you will need to access the the word for the first time then since there were only four words that could be accessed in one cycle you will need what is called as 64 additional Cycles to read the subsequent works are you able to see this I say that my block size is 256 so that 256 consecutive words are written into my L2 cache or else on Cache wherever uh but 256 words may not be able to be transmitted right away so there will be multiple Transmissions required and that is what we are representing by a line length on fetch width and this is the the delay uh taken when the subsequent address or subsequent location is being fetched questions oh okay yeah can I say that t first is T Miss and D subsequent is the heat continuously no no no no so this is the effects this is the fetches you may say TMS totality fetch is equal to TMS who are so you will get two six words from the L2 cache into the L1 cache so that is what a steam is if I get this block from the 11 to block CPU then so CPU will use only one word at a time CPU will give only one address okay the remaining you are copying simply to take benefit of spatiality you said CPU is asked for only one word now but I know that due to the spatial locality thing uh I would I would anyways need to access the second third fourth word also pretty soon so like when I'm accessing my first word let me get all the four words in one go so T hit has not changed P hit has not changed so P hit hats would change because now you are breaking in the entire block together and we're talking about what is called as spatial locality so pH will improve but otherwise uh T hit has not changed T Miss or t fetch has increased a bit in fact because now you need to bring in more words hmm yes has reduced TP Miss has reduced uh P hit has improved PMS has reduced but tmis has increased so how does this play out in terms of total delay so you know as you increase the line size as you increase the line size the total number of suppose your L1 cache was one zero two four words let us say huh and you said my line sizes 256. so how many different programs related words uh how many different programs can it cater to four yes sir so what happens if the numbers of programs increases the numbers of programs that I am running in parallel increases what would happen there will be more message now because I have no no further location is so there will be missiles now huh so uh if my line size is very small then I anyway have frequent message because of spatial locality however if my line size becomes very large even then there are misses are you able to understand this so line size was the number of words we can get at a time right the number of words you will fetch Whenever there is a mess so like the block kind of thing we can get a time right yes line size is equal to block as the block size increases the total number of blocks that you can store in your cash reduces therefore the Miss rate starts to increase again so initially when I'm getting more blocks then uh the hit will become less because we can get the data in that but after that it is that is not clear why it is increasing uh suppose uh one block so each block refers to one particular program that you are running on your processor okay okay now you want to run 10 programs you have only four blocks in your cache the number of Misses would increase now subscribe you're using word on your computer and you are using PowerPoint and you are using zoom and you are using that streaming service huh now you say that I also want to use let us say uh I also want to listen to music while while I'm on the call or whatever so what happens now there is a fifth kind of addresses that you need but so a fifth block that you need to store but your L1 cache is already full with four blocks whenever you want to now access the music path it will have to replace one of these blocks here replace means there was a miss and therefore replacement was necessitated is it clearer now so it is not like that key uh my cash capacity decides what the line size would be that is not the case so you will realize it does because if it was a one kilo bit one kilobyte memory that was that smaller size then I would have probably kept the line size at either 16 or 64. whereas if it was a 256 kilobyte memory I can keep it as small as four or as big as 2 after 6 doesn't matter it could be of interest to see what is the optimal line size otherwise for most of the other capacities higher capacities line size has minimal impact look at this five percent two two to three percent the black line the Orange Line the bottom most orange line is uh something like two to three percent to almost zero percent almost 0.1 um so uh the line size has to be decided in in consonants with the memory capacity Services who is deciding this line line size basically like you as a operating system designer okay or you as a firmware designer so important thing to realize is the hit rate uh the average time is an important parameter performance indicator than just the hit rate because average access time includes the the miss and the missed penalty in terms of timing so while increasing line length improves hit rate but it also increases fetch time is this clear so the TMS will increase as you increase the line size but probability of it would also increase probability of mass would reduce it's a trade-off that you can always work out for your system so this is another view that as the block size increases uh the Miss penalty increased the Miss rate initially fell but then increased and consequently because the penalty was increasing the you know the Miss penalty was increasing and because Miss rate was also increasing the block size you know the the overall access time average exercise time becomes very sensitive to the block size huh so in this particular example for for this this could be an average block size that you may want to keep not even me this we're plotting uh like for the like the 1kb memory right whatever be the capacity so what in the earlier figure we were saying that given which was 256 it was not increasing so that was this particular experiment not others this is not something that we have written in stone okay this is one experiment just to demonstrate something to you we ran two benchmarks and we could come up with this graph you will run 24 benchmarks and you may see the uh even this one you will see that okay there are more misses and something like this could happen I don't know so it's about one Benchmark we observed but it is good enough to give you a feeling that this happens huh Focus okay that's a general relationship yeah yes sir when you explain the TMS equation so you said that uh it corresponds to one uh burst of transfer so so uh is The Cash Line length any in any way related to the burst size so the the fetch width the fetch width you could say could be linked to the total number of uh words I can fetch quickly before selecting the next row yes so the fetch width is the parallel transfer that like uh parallel transfer yes uh okay um let me explain it a bit little more uh you know that a memory let us say 8192 cross 32 memory that we are making in our project huh in our course projects we are making this memory yes sir so let us say this is the memory but my processor is an 8-bit processor so how many words are stored per how many uh address locations would be stored per access so I at any point of time I am accessing 32 bits in a way for my processor I am accessing four words are you able to see this yes sir so that becomes my fetch width okay sir now Burst Mode comes into picture where because that we have we add this concept of let us say mux 16. that is the exact instance we are making yes sir so what we are saying is that physically inside the memory physically inside the memory 16 words are placed right next to each other yes sir so when I when I access any particular row I would say I will read all the 16 words in one go okay 16 l one words let us say l one word so this is processor words okay so one L one word is equal to four processor words okay sorry but I also I also know that 16 L1 words are placed in the same row sorry 16 L1 is happening in cash and the four words that is uh or the processor so the main menu a processor is an 8-bit processor yes sir so for a processor one word yeah it's 32 bits so uh that's right forward so one memory L1 memory access can give you four words in one go now what I am saying is that there is also this concept of marks yes what does Max mean Max means that physically when you access one particular row 16 words will be selected out of then you will Multiplex and select one word as an output yes sir Hannah so because 16 words were selected I say that now 16-16 locally in 16 words Burst Mode so but it will take like at least 16 Cycles right yes yes 16 Cycles but I can read okay so worst happens afterward after this complete line of cash is available so after that we decide what the burst size can be it you've already saved uh the 16 words that we can now access uh at like very quickly yeah so why did we choose 16 because we had mark 16. okay so the market I could use the burst length of eight also or four also because my marks would allow that but can I choose a burst length of 32 no no so can you illustrate how uh marks it like burst size of 8 can be achieved oh I simply would say that okay uh uh Matt foreign but I say that I need eight only so I will read this I will read this I will read this I will read this and so on so 8 okay Implement first length of it yes sir hello smaller burst length to implement challenge which is fine okay so the cache line size is the maximum burst width we can have first size no because we cannot go beyond 16 words burst length cannot go beyond 16 99 wait let me come clear so we are talking about different things line length burst length uh and uh what do you say word is line length is related to cash cash drop system burst length is linked to your memory independent of cash yes sir and we can choose that first length can be varied personally can be very line line length can be buried okay you could say that my line length is a 64 processor words line sizes 64 processor words yes sir but in reality one access would give you only four processor words so it means you will need four accesses to the memory yes sir to get your 16 there yes I know now these four accesses could be Burst Mode accesses okay so that piece of sequence goes down the only purpose is to reduce the subsequent yes okay so now yeah so for the first time it takes more time because we are fetching from the main memory and then uh for the subsequent ones it gets reduced yeah because you could be applying Burst Mode you could be applying multiple things so that it it reduces okay so that is that is where we have these kind of Curves in place then that as you increase the size the first penalty is higher but subsequent words you can reach much faster when we are talking of line we are thinking in terms of blocks but when talking about word burst we are thinking of so the words of the proper memory yeah of the SRAM okay and so each block can refer to like multiple rows yes yeah okay,https://www.youtube.com/watch?v=WT86Y1fPP8M,"Link: https://www.youtube.com/watch?v=WT86Y1fPP8M
Transcript: and then data would be out yeah so let us now look at some key specifications of a cache subsystem we'll come to a better understanding of tag also in just a little while as we discuss these key performance metrics you will see that the purpose of tag will automatically become clear to you so we're talking about a memory access time capacity there are two variables which you will very easily understand am I right what is the capacity of your cache subsystem that you cannot understand now associativity associativity means that suppose I wanted to um store latitudes or some locations addresses some addresses I wanted to store the latitude and longitudes how many latitudes can I store and how many longitudes can I store or can I uh can I can I have uh can I also store let us say a photograph or something else of something in my system so how many uh locations in the cache is a given address eligible to be placed in for example I have uh two buckets latitude and longitude and in bucket one I have 10 locations in bucket two I have 10 locations so associated associativity would be let us say 2 over here and so you would either come in the latitude so I any location in the latitude bucket or any location in the longitude bucket will tell you how many latitudes and longitudes you can save again we will come to it in in much more detail in just a little while uh replacement policy I think this is intuitive suppose my cash is full cache is a very small memory suppose it goes full and I want to store or you know new data run a new program first first sequence now the second sequence needs to be loaded which which part of the cash would you replace that is another key specification for the cache subsystem we will look into it in detail as to what kind of replacement policies exist another feature or another specification around the cache subsystem is do we have a unified cache or a separate instruction and data cache uh in a unified cache both data and instructions could be stored in the same cache but as the second case and suggests you could also keep independent instructional and independent data cache what could be the benefit of keeping independent in the instruction and data caches so if you have independent instruction and data cache uh then as we look at the normal execution of particular instruction first will be the fetch the second decode a fetch decode execute on the memory access and finally uh the right register right stage so if you have unified memory then the fit stage and the memory read stage will uh coincide and there can be a loss of single cycle a cycle type so if you have dedicated instruction and data cache then we can then we have the then we can execute both of them independently and there will be no loss of single time yes also it could happen that there are there is one instruction which is running on multiple data if you have just one cache which is Unified it means every time instruction also needs to be fetched and every time data also needs to be fetched but if you have separate caches what does it mean oh instruction I have already list put it out on my register uh that instruction you can continue to use but uh the data cache you may just access more frequently so that also is one thing one thing that would change so overall power of the system performance of the system can change depending on whether you are using unified or separate caches for instruction and data so let's first look at access time uh we're talking about four things here uh the probability of a hit that is probability of finding the address location that you want to access inside your L1 cache uh do you understand probability of a hit um yeah the main memory is very huge you only saved selective addresses inside your L1 cache or L2 cache and so on Okay so the probability that the address that you are looking for is now available in the L1 or L2 cache is p hit probability hit and then PMS that it was not there now if it was there then what happens the memory the small SRAM simply reads out the data and there is a fast access time there okay however if it uh if the head doesn't happen if there is a mess then you know that you will have to go to a higher level of hierarchy which means that uh the time involved would would be higher would be would be more so there is a different timing now which is called as tmis so probability of hit into the time that it takes when you are when you read after a hit and probability of a mess and the time it takes to fetch the data from a to Cache or wherever so that it is now available in 81 cache and for the processor is referred to as TMS the penalty link to Ms okay and therefore average access time is pH into T hit plus PMS into TMS is this clear hello any questions so why we are writing it as average time shouldn't be right shoulders total time why I access one memory location and uh it was a hit and the time it took to access that particular location was just P hit only here then I will have a different timing which is TMS yes sir so how does this become total time it Still Remains average time there will be instances when there is a team is which is much uh which is much longer so overall uh okay yes sir Hannah okay so that is what is excess time let's take an example a memory like a memory system consists of a cache and the main memory if it takes one cycle to complete a cachet and 100 Cycles to complete a cache Miss what is the memory average excess time can you find this out if the hit rate is say 97 percent can you find this out so 3.97 units 3.97 Cycles is this clear yes sir okay um now if you want less number of missiles you want the probability of it to be higher you can use a bigger cache I don't know if you have a bigger cash the the probability of a mess reduces if your cash could be as big as the main memory there will be zero misses believe me so I am not able to understand this statement so why is there a mess let us answer this question first why is there a message now why is something not available in the cache yes sir we are checking each each row okay then the probability of it will be 100 whatever you wanted is also available in your cache yes yes sir so there will be zero PMS everything will be hit yes that much you cannot do dram is much denser cell than the SRAM if you say that okay I will have the L1 cache like as the same size as my dram there then the area would simply blow up the moreover since the size becomes big the performance gain that you had thought of earlier would no longer be there are able to see this hello any questions so we say that bigger capacity could be better however bigger cases are slower so there is a declining return on investment as the cache size goes up when we talk of cache size we also talk of what is called as cache line length or also called as a block um so the concept of a line length is that uh if there is a mess and you need to fetch something from a higher level of memory then do not bring in just one address bring in one full block why why is bringing a block more important than just one location yes we just talked about it that typically it will be adjacent addresses that would be you know that would be required by the system so you bring in a full block so that uh there are less number of misses there is more number of heads additionally when you do that you will see that uh the overall excess time you know time to fetch reduces because while the first access may take a lot of time subsequent addresses could be faster we call that as Burst Mode so you get two kinds of benefits first the number of Misses reduce second that fetching a bigger address has is overall cheaper in terms of total time than fetching uh just a small one word at a time a bigger block will take lesser time and in comparison to if all the words were accessed individually okay and uh this this function are you able to see this this says that I will bring about let us say 256 words in one block but you want to bring that many words but what happens what happens is that the bus that you have from the memory to your processor is much smaller it can at most transmit two words or four words so whenever you there is a mess how many cycles would you need first you will need to access the the word for the first time then since there were only four words that could be accessed in one cycle you will need what is called as 64 additional Cycles to read the subsequent works are you able to see this I say that my block size is 256 so that 256 consecutive words are written into my L2 cache or else on Cache wherever uh but 256 words may not be able to be transmitted right away so there will be multiple Transmissions required and that is what we are representing by a line length on fetch width and this is the the delay uh taken when the subsequent address or subsequent location is being fetched questions oh okay yeah can I say that t first is T Miss and D subsequent is the heat continuously no no no no so this is the effects this is the fetches you may say TMS totality fetch is equal to TMS who are so you will get two six words from the L2 cache into the L1 cache so that is what a steam is if I get this block from the 11 to block CPU then so CPU will use only one word at a time CPU will give only one address okay the remaining you are copying simply to take benefit of spatiality you said CPU is asked for only one word now but I know that due to the spatial locality thing uh I would I would anyways need to access the second third fourth word also pretty soon so like when I'm accessing my first word let me get all the four words in one go so T hit has not changed P hit has not changed so P hit hats would change because now you are breaking in the entire block together and we're talking about what is called as spatial locality so pH will improve but otherwise uh T hit has not changed T Miss or t fetch has increased a bit in fact because now you need to bring in more words hmm yes has reduced TP Miss has reduced uh P hit has improved PMS has reduced but tmis has increased so how does this play out in terms of total delay so you know as you increase the line size as you increase the line size the total number of suppose your L1 cache was one zero two four words let us say huh and you said my line sizes 256. so how many different programs related words uh how many different programs can it cater to four yes sir so what happens if the numbers of programs increases the numbers of programs that I am running in parallel increases what would happen there will be more message now because I have no no further location is so there will be missiles now huh so uh if my line size is very small then I anyway have frequent message because of spatial locality however if my line size becomes very large even then there are misses are you able to understand this so line size was the number of words we can get at a time right the number of words you will fetch Whenever there is a mess so like the block kind of thing we can get a time right yes line size is equal to block as the block size increases the total number of blocks that you can store in your cash reduces therefore the Miss rate starts to increase again so initially when I'm getting more blocks then uh the hit will become less because we can get the data in that but after that it is that is not clear why it is increasing uh suppose uh one block so each block refers to one particular program that you are running on your processor okay okay now you want to run 10 programs you have only four blocks in your cache the number of Misses would increase now subscribe you're using word on your computer and you are using PowerPoint and you are using zoom and you are using that streaming service huh now you say that I also want to use let us say uh I also want to listen to music while while I'm on the call or whatever so what happens now there is a fifth kind of addresses that you need but so a fifth block that you need to store but your L1 cache is already full with four blocks whenever you want to now access the music path it will have to replace one of these blocks here replace means there was a miss and therefore replacement was necessitated is it clearer now so it is not like that key uh my cash capacity decides what the line size would be that is not the case so you will realize it does because if it was a one kilo bit one kilobyte memory that was that smaller size then I would have probably kept the line size at either 16 or 64. whereas if it was a 256 kilobyte memory I can keep it as small as four or as big as 2 after 6 doesn't matter it could be of interest to see what is the optimal line size otherwise for most of the other capacities higher capacities line size has minimal impact look at this five percent two two to three percent the black line the Orange Line the bottom most orange line is uh something like two to three percent to almost zero percent almost 0.1 um so uh the line size has to be decided in in consonants with the memory capacity Services who is deciding this line line size basically like you as a operating system designer okay or you as a firmware designer so important thing to realize is the hit rate uh the average time is an important parameter performance indicator than just the hit rate because average access time includes the the miss and the missed penalty in terms of timing so while increasing line length improves hit rate but it also increases fetch time is this clear so the TMS will increase as you increase the line size but probability of it would also increase probability of mass would reduce it's a trade-off that you can always work out for your system so this is another view that as the block size increases uh the Miss penalty increased the Miss rate initially fell but then increased and consequently because the penalty was increasing the you know the Miss penalty was increasing and because Miss rate was also increasing the block size you know the the overall access time average exercise time becomes very sensitive to the block size huh so in this particular example for for this this could be an average block size that you may want to keep not even me this we're plotting uh like for the like the 1kb memory right whatever be the capacity so what in the earlier figure we were saying that given which was 256 it was not increasing so that was this particular experiment not others this is not something that we have written in stone okay this is one experiment just to demonstrate something to you we ran two benchmarks and we could come up with this graph you will run 24 benchmarks and you may see the uh even this one you will see that okay there are more misses and something like this could happen I don't know so it's about one Benchmark we observed but it is good enough to give you a feeling that this happens huh Focus okay that's a general relationship yeah yes sir when you explain the TMS equation so you said that uh it corresponds to one uh burst of transfer so so uh is The Cash Line length any in any way related to the burst size so the the fetch width the fetch width you could say could be linked to the total number of uh words I can fetch quickly before selecting the next row yes so the fetch width is the parallel transfer that like uh parallel transfer yes uh okay um let me explain it a bit little more uh you know that a memory let us say 8192 cross 32 memory that we are making in our project huh in our course projects we are making this memory yes sir so let us say this is the memory but my processor is an 8-bit processor so how many words are stored per how many uh address locations would be stored per access so I at any point of time I am accessing 32 bits in a way for my processor I am accessing four words are you able to see this yes sir so that becomes my fetch width okay sir now Burst Mode comes into picture where because that we have we add this concept of let us say mux 16. that is the exact instance we are making yes sir so what we are saying is that physically inside the memory physically inside the memory 16 words are placed right next to each other yes sir so when I when I access any particular row I would say I will read all the 16 words in one go okay 16 l one words let us say l one word so this is processor words okay 
so one L one word is equal to four processor words okay sorry but I also I also know that 16 L1 words are placed in the same row sorry 16 L1 is happening in cash and the four words that is uh or the processor so the main menu a processor is an 8-bit processor yes sir so for a processor one word yeah it's 32 bits so uh that's right forward so one memory L1 memory access can give you four words in one go now what I am saying is that there is also this concept of marks yes what does Max mean Max means that physically when you access one particular row 16 words will be selected out of then you will Multiplex and select one word as an output yes sir Hannah so because 16 words were selected I say that now 16-16 locally in 16 words Burst Mode so but it will take like at least 16 Cycles right yes yes 16 Cycles but I can read okay so worst happens afterward after this complete line of cash is available so after that we decide what the burst size can be it you've already saved uh the 16 words that we can now access uh at like very quickly yeah so why did we choose 16 because we had mark 16. okay so the market I could use the burst length of eight also or four also because my marks would allow that but can I choose a burst length of 32 no no so can you illustrate how uh marks it like burst size of 8 can be achieved oh I simply would say that okay uh uh Matt foreign but I say that I need eight only so I will read this I will read this I will read this I will read this and so on so 8 okay Implement first length of it yes sir hello smaller burst length to implement challenge which is fine okay so the cache line size is the maximum burst width we can have first size no because we cannot go beyond 16 words burst length cannot go beyond 16 99 wait let me come clear so we are talking about different things line length burst length uh and uh what do you say word is line length is related to cash cash drop system burst length is linked to your memory independent of cash yes sir and we can choose that first length can be varied personally can be very line line length can be buried okay you could say that my line length is a 64 processor words line sizes 64 processor words yes sir but in reality one access would give you only four processor words so it means you will need four accesses to the memory yes sir to get your 16 there yes I know now these four accesses could be Burst Mode accesses okay so that piece of sequence goes down the only purpose is to reduce the subsequent yes okay so now yeah so for the first time it takes more time because we are fetching from the main memory and then uh for the subsequent ones it gets reduced yeah because you could be applying Burst Mode you could be applying multiple things so that it it reduces okay so that is that is where we have these kind of Curves in place then that as you increase the size the first penalty is higher but subsequent words you can reach much faster when we are talking of line we are thinking in terms of blocks but when talking about word burst we are thinking of so the words of the proper memory yeah of the SRAM okay and so each block can refer to like multiple rows yes yeah okay"
Qo2Yv7ELaEk,so that is how you would access data but how do you determine if this data that you wanted is in the cache or not or if the data is in the cache how do we find that data so what do we have the information that we have is address of data and we also know how the cache is organized how the cache is organized let us say I say that the the cache is organized in terms of a direct map cache what does direct map cache means direct map cache means that depending on the address of my data I would write two only one particular location in the memory what does that mean uh let us say uh okay direct map but there will be only one location where I will be able to write inside the memory that is what is called as direct map cache then there are set associative caches where you say that okay okay and so on so in a memory in a cache memory uh there is something as we said which is called as tag after that tab you actually have the address bus is broken into different components like index block and byte um so the byte will tell you which word which byte to pick up block will tell you which block which uh amongst the which which word in a given block so for example if your block is uh uh 16 words so which of these 16 words in a block do you need to access then index uh by row and then tag what do they all mean physically let us look at that also we say that uh there is a 24-bit address for a 16 kilobyte cache just calculate for 16 kilobyte how many address bits do you need 14. huh 14 . you need 14 address bits Hannah 16 kilobyte you need only 14 address bits so what to do of the additional 10 bits and they represent this tag index yes they become bad okay now uh in a memory suppose your your data is organized such that there are eight bytes of data in every row so how many how many uh in every block so how many uh address bits would you require to identify which byte to be sent to the processor 11 3 11 3. I have a word now I need only three by three three address bits to identify which of these bytes to send to the processor hmm if I say that there are eight bytes per word or per line how many blocks or how many lines can there be go to capacity is 16 kilobytes I said eight bytes per line how many lines can be there so 12 kilos 2K lines two colors sorry two killings Hannah now if you had to decipher 2K lines how many address bits would you need 11. 11. do you see 24-bit address bus got split as 10 bits for tag 11 bits for Block selection three bits for byte selection in a given block so in the memory what were you storing you were storing eight bytes of data then bits of tag and one bit which could be valid bit we will talk about the purpose of valid bit a little later when you access a particular line or a location the tag is fetched along with it because it is in the same same word when the tag is fetched along with it you compare the 10 address bits of the incoming data and whatever was stored over here inside the memory if they match you say this is my 20 this is the data corresponding to that 24-bit address if they do not match you say I have a miss are you able to see this is the purpose of tag clearance you had a confusion regarding purpose of tax is the purpose of tag clear now so actually I'm still processing actually the bit splitting is just about it so your main memory was huge you would access it with 24-bit addresses your cache is much smaller you need only 14 address bits too access the cash so but the system when it gives sends out the address it sends out the address regarding the main memory so it always sends out 24 bit address and you have to ensure that the address that you fetch from the cache is matching the total 24 bit address hmm that it matches the lower 14 bits is evident because you see that in the physical memory there yes is clear yes now we need to ensure that 24 bit is matching so 14 after checked earlier remaining 10 bits you actually store whatever the address was alongside the data in the memory itself so that when you read the cache you also read the address from where the the top 10 bits from where the address was fetched initially hmm now you compare the top 10 bits of your of your address sent by the processor with the top 10 bits stored over here if they match there is a hit if they don't there is a mess so basically tag is only that uh sort of msbs all that address told 24-bit address kind of thing only yes yeah that is one way to understand it yes so thank you sir okay is it clear for everyone any questions I said I have one question yes so can we go to the previous slide where we uh where we have definitions yeah so over here uh there is a separate field for the block as well as a separate field for the uh tag why is it requires that because tag is something which is unique and uh a tag is associated for a complete block right sir so this is referred to the 20 this this bus is a 24-bit address bus yes sir this block is 11 bits by it is 3 bits we did not have an index in the given example in the next slide then that's okay is it okay so but in the case of uh suppose if we go for set us associative cash then we'll have index as well as the blocking yeah at that point in time then block and tag will uh having both of them would be redirected yourself we will just see that we will just see that yes okay uh as soon as that comes uh let's say let us say this is four bits later nine would go to block two would go to set yes sir but you will still need the 10 bit tag okay you will still need the 10 bit tag because your memory is 14 bit addressable if you use a larger cache if you instead of 16 kilobyte you would use 32 kilobyte your memory becomes 15 bit addressable yes then you will need a 9-bit tab okay you use a still larger cache 64 kilobyte you need an 8-bit tag because it is it is the number of address bits which you are not able to use while accessing the physical memory there um said yes uh so you said that uh when we go for a senate associative I mean first of all just to clarify the block plates are referring to the line number right line so button set Associated we don't know in which line our data would be we only know in which set it would be but the line could be anything so how can there be effects for a line number we will see like have I write it says associated with only one which set the data would go and then we match the tag in every line that's it but we don't learn which line the data is yeah we'll see we'll just see don't worry foreign so let's not run ahead of the class because there's some students who will not understand that also this part until here it is clear everyone uh like different blocks that will be referring to multiple blocks I mean multiple blocks kind of the same time yes so sir basically we are doing this tag and all this thing just to maintain because we have the 24th that system bus is similar see is it just or is it something like I want to go home and I do not want to end up in my office location I am not wanting to assess that 24-bit address I want to access only that one not another random 24-bit address okay so select we are breaking the whole address into Parts when we are calling some bits recalling for the data some for the block some for the tag and so see you on okay the entire address has to be matched hmm,https://www.youtube.com/watch?v=Qo2Yv7ELaEk,"Link: https://www.youtube.com/watch?v=Qo2Yv7ELaEk
Transcript: so that is how you would access data but how do you determine if this data that you wanted is in the cache or not or if the data is in the cache how do we find that data so what do we have the information that we have is address of data and we also know how the cache is organized how the cache is organized let us say I say that the the cache is organized in terms of a direct map cache what does direct map cache means direct map cache means that depending on the address of my data I would write two only one particular location in the memory what does that mean uh let us say uh okay direct map but there will be only one location where I will be able to write inside the memory that is what is called as direct map cache then there are set associative caches where you say that okay okay and so on so in a memory in a cache memory uh there is something as we said which is called as tag after that tab you actually have the address bus is broken into different components like index block and byte um so the byte will tell you which word which byte to pick up block will tell you which block which uh amongst the which which word in a given block so for example if your block is uh uh 16 words so which of these 16 words in a block do you need to access then index uh by row and then tag what do they all mean physically let us look at that also we say that uh there is a 24-bit address for a 16 kilobyte cache just calculate for 16 kilobyte how many address bits do you need 14. huh 14 . you need 14 address bits Hannah 16 kilobyte you need only 14 address bits so what to do of the additional 10 bits and they represent this tag index yes they become bad okay now uh in a memory suppose your your data is organized such that there are eight bytes of data in every row so how many how many uh in every block so how many uh address bits would you require to identify which byte to be sent to the processor 11 3 11 3. I have a word now I need only three by three three address bits to identify which of these bytes to send to the processor hmm if I say that there are eight bytes per word or per line how many blocks or how many lines can there be go to capacity is 16 kilobytes I said eight bytes per line how many lines can be there so 12 kilos 2K lines two colors sorry two killings Hannah now if you had to decipher 2K lines how many address bits would you need 11. 11. do you see 24-bit address bus got split as 10 bits for tag 11 bits for Block selection three bits for byte selection in a given block so in the memory what were you storing you were storing eight bytes of data then bits of tag and one bit which could be valid bit we will talk about the purpose of valid bit a little later when you access a particular line or a location the tag is fetched along with it because it is in the same same word when the tag is fetched along with it you compare the 10 address bits of the incoming data and whatever was stored over here inside the memory if they match you say this is my 20 this is the data corresponding to that 24-bit address if they do not match you say I have a miss are you able to see this is the purpose of tag clearance you had a confusion regarding purpose of tax is the purpose of tag clear now so actually I'm still processing actually the bit splitting is just about it so your main memory was huge you would access it with 24-bit addresses your cache is much smaller you need only 14 address bits too access the cash so but the system when it gives sends out the address it sends out the address regarding the main memory so it always sends out 24 bit address and you have to ensure that the address that you fetch from the cache is matching the total 24 bit address hmm that it matches the lower 14 bits is evident because you see that in the physical memory there yes is clear yes now we need to ensure that 24 bit is matching so 14 after checked earlier remaining 10 bits you actually store whatever the address was alongside the data in the memory itself so that when you read the cache you also read the address from where the the top 10 bits from where the address was fetched initially hmm now you compare the top 10 bits of your of your address sent by the processor with the top 10 bits stored over here if they match there is a hit if they don't there is a mess so basically tag is only that uh sort of msbs all that address told 24-bit address kind of thing only yes yeah that is one way to understand it yes so thank you sir okay is it clear for everyone any questions I said I have one question yes so can we go to the previous slide where we uh where we have definitions yeah so over here uh there is a separate field for the block as well as a separate field for the uh tag why is it requires that because tag is something which is unique and uh a tag is associated for a complete block right sir so this is referred to the 20 this this bus is a 24-bit address bus yes sir this block is 11 bits by it is 3 bits we did not have an index in the given example in the next slide then that's okay is it okay so but in the case of uh suppose if we go for set us associative cash then we'll have index as well as the blocking yeah at that point in time then block and tag will uh having both of them would be redirected yourself we will just see that we will just see that yes okay uh as soon as that comes uh let's say let us say this is four bits later nine would go to block two would go to set yes sir but you will still need the 10 bit tag okay you will still need the 10 bit tag because your memory is 14 bit addressable if you use a larger cache if you instead of 16 kilobyte you would use 32 kilobyte your memory becomes 15 bit addressable yes then you will need a 9-bit tab okay you use a still larger cache 64 kilobyte you need an 8-bit tag because it is it is the number of address bits which you are not able to use while accessing the physical memory there um said yes uh so you said that uh when we go for a senate associative I mean first of all just to clarify the block plates are referring to the line number right line so button set Associated we don't know in which line our data would be we only know in which set it would be but the line could be anything so how can there be effects for a line number we will see like have I write it says associated with only one which set the data would go and then we match the tag in every line that's it but we don't learn which line the data is yeah we'll see we'll just see don't worry foreign so let's not run ahead of the class because there's some students who will not understand that also this part until here it is clear everyone uh like different blocks that will be referring to multiple blocks I mean multiple blocks kind of the same time yes so sir basically we are doing this tag and all this thing just to maintain because we have the 24th that system bus is similar see is it just or is it something like I want to go home and I do not want to end up in my office location I am not wanting to assess that 24-bit address I want to access only that one not another random 24-bit address okay so select we are breaking the whole address into Parts when we are calling some bits recalling for the data some for the block some for the tag and so see you on okay the entire address has to be matched hmm"
AArRKn8Evkw,Okay so now as I said this is what we are looking about direct map there are other kind of associativity one way we could say okay there is this L1 cache uh there is this cache you store the data anywhere and then there is also set Associated where we say a word can go to a set of location decide by the last few bits of the address so example for police so line 12 needs to be placed in an eight line cache in a fully associated memory line 12 could go anywhere in this place okay in a direct map you simply say what is the address of line 12 line 12 would mean 1 1 0 0. it says uh the last three ad bits are one zero zero so I can go only to the fourth block okay Now set associative says that this can be very constraining if some other program also wanted to have uh let us say another program wanted to access zero one zero zero address it would also want to come here or let us say there was another address foreign there was another address which wanted to go there address 20 even then this would want to come here because 1 0 0 is matching so they will all want to come here so there will be lots of Misses that would happen now we do not want that many misses so we say that okay instead of using all the last three bits because my direct memory had eight locations which could be addressed by three bits instead of using all the three bits for determining where to put your data let me use lower two bits instead so 0 1 0 0 1 1 0 0 could both be stored now where they will where will they be stored they will be stored in the set 0. if now I want to access one zero one zero zero I would want to now replace one of these two not exactly one of both of them and for replacing that now I could use one of the replacement policies but now I will not just enter into miss miss and miss I have more options is this part clear the set fully associated with clear hello fully associated with it clear any address I could save any line address I could save anywhere in the memory huh direct map there is one location depending on the last three bits because I have an eight I have an eight line cache depending on the last three address bits for the line it will always come here or such associators where I use the only the last two bits and I say they will come in either of these two locations is this clear hello yeah so now what happens now it means that uh your entries are mapped onto multiple car could be mapped onto multiple locations uh your zero zero zero zero zero one index could store any of these locations there your one zero one at could store any of these locations there so this becomes index address and then the block the number of uh addressing bits for the line reduces okay coming to the valid bit the valid bit is a flag to indicate whether the content in the cache is valid or not is it clear valid weight is about the is a flag which indicates whether the cache content is valid or not if some other processor has written something into the memory somewhere else the valid would go to zero this is also referred to as Dirty Bit in some vocabulary okay except but Dirty Bit it will be associated with each Cash Line user yes so what is happening uh you have a valid bit you have a cash tag and you have cash data over here five address bits will be used to select which byte uh and five address widths will be used to select which line and remaining address bits will be put as tag clear so indexes to select the set number yes okay so uh I think we will not be able to finish this we will continue this in the next class uh because there's still something left and uh we will not be able to close this in today's class so we will stop here any questions so this valid bit is an extra bit right not part of the address yeah it's an extra bit not a part of the address it only tells whether the data is valid or not um so usually this 30 bit will be used whenever uh we are dealing with the cash hit turn when we write on the cache yeah whenever you're dealing with a system where there could be uh multiple processors accessing the same data you definitely need the valid bit yes okay so just give me a moment let me see how many sides are left I think still many are left which is just one or two slides we can close it otherwise no the bit of at least six to seven slides left I think let's let's take the remaining part up in the next class okay uh sir I have one doubt yes sir can we go to the t-fetch part sure [Music] yes uh I said here the in the t-fetch part the ratio line length to the fetch words so this can be the burst length process we can term it as a power slip it could be the burstling but this may not be that is where I wanted to differentiate between burst length and line length okay because it's about the physical uh physical dimensions of the memory okay line length is about what your system decides to put there yeah take care now when you are accessing the main memory and you are writing into the L2 cache the main memory would typically have a burst length of 256 words foreign or line length will almost always be lesser than burst length but when we are doing it from L2 cache to L1 cache and suppose L2 cache has Burst Mode access enabled huh then it may not be the case so you must you may have multiple lines to be accessed for the lines to be written inside uh well your uh your line length could be 16 words but your burst length could be four words so you will need four bursts of data to fill your line in the L1 cache okay okay you need four bursts of data so then then in this case uh the burst length of forwards what with or what we talk it can be the fetch length also it is the fetch width yes it is the immediate fetch width uh as we were discussing about 32-bit 819 um so that could be that okay okay pressure is trying to fetch only eight bits at a time so uh uh Fetch with this eight bits only whereas the burst uh can be four books yes okay yes sir,https://www.youtube.com/watch?v=AArRKn8Evkw,"Link: https://www.youtube.com/watch?v=AArRKn8Evkw
Transcript: Okay so now as I said this is what we are looking about direct map there are other kind of associativity one way we could say okay there is this L1 cache uh there is this cache you store the data anywhere and then there is also set Associated where we say a word can go to a set of location decide by the last few bits of the address so example for police so line 12 needs to be placed in an eight line cache in a fully associated memory line 12 could go anywhere in this place okay in a direct map you simply say what is the address of line 12 line 12 would mean 1 1 0 0. it says uh the last three ad bits are one zero zero so I can go only to the fourth block okay Now set associative says that this can be very constraining if some other program also wanted to have uh let us say another program wanted to access zero one zero zero address it would also want to come here or let us say there was another address foreign there was another address which wanted to go there address 20 even then this would want to come here because 1 0 0 is matching so they will all want to come here so there will be lots of Misses that would happen now we do not want that many misses so we say that okay instead of using all the last three bits because my direct memory had eight locations which could be addressed by three bits instead of using all the three bits for determining where to put your data let me use lower two bits instead so 0 1 0 0 1 1 0 0 could both be stored now where they will where will they be stored they will be stored in the set 0. if now I want to access one zero one zero zero I would want to now replace one of these two not exactly one of both of them and for replacing that now I could use one of the replacement policies but now I will not just enter into miss miss and miss I have more options is this part clear the set fully associated with clear hello fully associated with it clear any address I could save any line address I could save anywhere in the memory huh direct map there is one location depending on the last three bits because I have an eight I have an eight line cache depending on the last three address bits for the line it will always come here or such associators where I use the only the last two bits and I say they will come in either of these two locations is this clear hello yeah so now what happens now it means that uh your entries are mapped onto multiple car could be mapped onto multiple locations uh your zero zero zero zero zero one index could store any of these locations there your one zero one at could store any of these locations there so this becomes index address and then the block the number of uh addressing bits for the line reduces okay coming to the valid bit the valid bit is a flag to indicate whether the content in the cache is valid or not is it clear valid weight is about the is a flag which indicates whether the cache content is valid or not if some other processor has written something into the memory somewhere else the valid would go to zero this is also referred to as Dirty Bit in some vocabulary okay except but Dirty Bit it will be associated with each Cash Line user yes so what is happening uh you have a valid bit you have a cash tag and you have cash data over here five address bits will be used to select which byte uh and five address widths will be used to select which line and remaining address bits will be put as tag clear so indexes to select the set number yes okay so uh I think we will not be able to finish this we will continue this in the next class uh because there's still something left and uh we will not be able to close this in today's class so we will stop here any questions so this valid bit is an extra bit right not part of the address yeah it's an extra bit not a part of the address it only tells whether the data is valid or not um so usually this 30 bit will be used whenever uh we are dealing with the cash hit turn when we write on the cache yeah whenever you're dealing with a system where there could be uh multiple processors accessing the same data you definitely need the valid bit yes okay so just give me a moment let me see how many sides are left I think still many are left which is just one or two slides we can close it otherwise no the bit of at least six to seven slides left I think let's let's take the remaining part up in the next class okay uh sir I have one doubt yes sir can we go to the t-fetch part sure [Music] yes uh I said here the in the t-fetch part the ratio line length to the fetch words so this can be the burst length process we can term it as a power slip it could be the burstling but this may not be that is where I wanted to differentiate between burst length and line length okay because it's about the physical uh physical dimensions of the memory okay line length is about what your system decides to put there yeah take care now when you are accessing the main memory and you are writing into the L2 cache the main memory would typically have a burst length of 256 words foreign or line length will almost always be lesser than burst length but when we are doing it from L2 cache to L1 cache and suppose L2 cache has Burst Mode access enabled huh then it may not be the case so you must you may have multiple lines to be accessed for the lines to be written inside uh well your uh your line length could be 16 words but your burst length could be four words so you will need four bursts of data to fill your line in the L1 cache okay okay you need four bursts of data so then then in this case uh the burst length of forwards what with or what we talk it can be the fetch length also it is the fetch width yes it is the immediate fetch width uh as we were discussing about 32-bit 819 um so that could be that okay okay pressure is trying to fetch only eight bits at a time so uh uh Fetch with this eight bits only whereas the burst uh can be four books yes okay yes sir"
ov3jyGfMOoY,so we saw that if there is a direct map cache then the address would be mapped something like this the lowest few address bits will be used to identify which byte is being addressed from the cache memory and the higher order address bits are put as tags so you see five address bits are being used to select one of the bytes in a particular block and cache index is which block we are being which we which block we are interested in the cache tag stores the higher order address bits which are uh which are used to match which addresses or which which physical address is being put into the passenger do you remember this this slide we have covered this in the last one any questions about this so silence I cannot make out I cannot read your silence at all this means yes this means no I do not know foreign it is a zero to four so there are five address bits that are used to do the byte select okay the remaining five bits are used to select which line we are talking about okay um this is clear yes sir okay then once this is clear what is the next thing that we look at we looked at where in which parts would this data be stored so which parts would this data be stored suppose my uh byte address is the last few bits are zero zero zero zero zero hmm so where would this data be stored so are you ready oh just give me a second just a second candidate 0 16 can be at 0 16 yeah so what we are looking at was are you able to see the slide now yes sir yes sir yeah so what we were looking at was depending on the last the last bits of your uh address in the cache your memory would go into one of the given rows your entry your data could go into one of the given rows so what we were saying was that these grays can only go into this location now let us say there was a program that was using this set of data and there was another program which was using this set of data huh now this gray and this gray are in conflict with each other so when when this program is being executed this gray will see a mess it will fetch the data from the L2 cache and execute then as soon as this program gets the priority again this will see a miss so it will have to again access the L2 cache and get the data back so in a direct map caches there is a clear distinct possibility of lots of conflicts due to which there can be misses are you able to see this yes sir this is the slide we saw last time also so what we were saying was that conflict messages are caused by uh you know different memory locations mapped to the same cache index and there could be two solutions make the cache size bigger or use multiple entries for the same cache index Now using multiple entries for the same cache index what does it mean that at the same cache index more than one kind of address can be saved what did we say here we said that only zero zero one settings can go here if I say multiple entries and even though this address is 0 0 1 I would say that it can if need be let us say also store 0 1 1. or one one one let us say so if need be it can store those two also but primarily it will store this so if I start to do it like this then what happens then when this other address or when this other data had to be written and I saw that this was a valid valid entry and it was very recently used then I say okay let me write it here in the other location in the cache so I will not have a mess I will not being playing the ping pong game that okay every time the program changes there are lots of message and there's a lot of throughput that will not happen any longer ideally if I can just put any address anywhere then that is the best utilization of the entire L1 cache space are you able to see this see if any address could go anywhere so we're not talking,https://www.youtube.com/watch?v=ov3jyGfMOoY,"Link: https://www.youtube.com/watch?v=ov3jyGfMOoY
Transcript: so we saw that if there is a direct map cache then the address would be mapped something like this the lowest few address bits will be used to identify which byte is being addressed from the cache memory and the higher order address bits are put as tags so you see five address bits are being used to select one of the bytes in a particular block and cache index is which block we are being which we which block we are interested in the cache tag stores the higher order address bits which are uh which are used to match which addresses or which which physical address is being put into the passenger do you remember this this slide we have covered this in the last one any questions about this so silence I cannot make out I cannot read your silence at all this means yes this means no I do not know foreign it is a zero to four so there are five address bits that are used to do the byte select okay the remaining five bits are used to select which line we are talking about okay um this is clear yes sir okay then once this is clear what is the next thing that we look at we looked at where in which parts would this data be stored so which parts would this data be stored suppose my uh byte address is the last few bits are zero zero zero zero zero hmm so where would this data be stored so are you ready oh just give me a second just a second candidate 0 16 can be at 0 16 yeah so what we are looking at was are you able to see the slide now yes sir yes sir yeah so what we were looking at was depending on the last the last bits of your uh address in the cache your memory would go into one of the given rows your entry your data could go into one of the given rows so what we were saying was that these grays can only go into this location now let us say there was a program that was using this set of data and there was another program which was using this set of data huh now this gray and this gray are in conflict with each other so when when this program is being executed this gray will see a mess it will fetch the data from the L2 cache and execute then as soon as this program gets the priority again this will see a miss so it will have to again access the L2 cache and get the data back so in a direct map caches there is a clear distinct possibility of lots of conflicts due to which there can be misses are you able to see this yes sir this is the slide we saw last time also so what we were saying was that conflict messages are caused by uh you know different memory locations mapped to the same cache index and there could be two solutions make the cache size bigger or use multiple entries for the same cache index Now using multiple entries for the same cache index what does it mean that at the same cache index more than one kind of address can be saved what did we say here we said that only zero zero one settings can go here if I say multiple entries and even though this address is 0 0 1 I would say that it can if need be let us say also store 0 1 1. or one one one let us say so if need be it can store those two also but primarily it will store this so if I start to do it like this then what happens then when this other address or when this other data had to be written and I saw that this was a valid valid entry and it was very recently used then I say okay let me write it here in the other location in the cache so I will not have a mess I will not being playing the ping pong game that okay every time the program changes there are lots of message and there's a lot of throughput that will not happen any longer ideally if I can just put any address anywhere then that is the best utilization of the entire L1 cache space are you able to see this see if any address could go anywhere so we're not talking"
3rlQVT6MJ0Y,any address could go anywhere that is the best utilization that is what is called as fully Associated memory so what has done is that when the memory is accessed so see the beauty of direct map was uh you know which particular row to access and you would compare only that cache tag with your address but if any address can go anywhere what happens you now do not know which row is to be addressed now any address could be anywhere so any index could be anywhere so my cash tag I need to have a comparator for every line now are you able to see this I need to have a comparator for every line now and I will generate what is called as a match signal and that match signal will be used to select the final address so what kind of memory architecture are we talking about over here where there are comparisons inside the memory itself and then we give out the data are we talking about are they still talking about srams or are we talking about something else now yes he's saying you're talking we are now talking about content addressable memories So based on what is the content in the cash tag I decide to give which cache data to be given out to the processor are you able to see this what is the disadvantage of this fully Associated memory the advantage we already talked about that the total number of Misses will reduce what is the disadvantage time required to comparison so area penalty also yeah I think because they'll they'll be these competitors will I think compare the values in parallel I think so the area will be similar like comparing a single comparator if it Compares uh but I think uh we're using a lot of them here that's what we are saying is that area of this fully Associated cache would be much higher than a regular cache that we talked about okay what else so power also I think because now instead of just just comparing one word you are comparing as many number of words as there are lines as many number of tags as there are lines so not only has the area increased because you need so many parallel parallel comparators now all those parallel comparators are also operational they are consuming power so this also increases overall at the system level the Miss penalty reduces because the number of Misses are lesser or fewer therefore it may have a better overall effective access time but at a huge cost of area and power so can there be an intermediate way the intermediate way is what we call as set associativity so in fully Associated any address could go anywhere in set associative what I do is I Define sets that okay there are these four sets now if the last few bits of a particular address are zero zero zero they do not have just one location to go to as was the case for direct map now we could go to four different locations if it is say four ways at Associated or in different locations if it is a NVA set associative so this example over here is actually not two it is four-way set of state of cash um so what is happening here to here sorry sorry sorry so what is happening there's this one cache there's this other cache in both the places we store cash tag cache data and so on so now let us say uh the first row was to be addressed so what do we do we access both the memories the first row or let us say this row of both the memories the tag is compared with the original address stack at both the sides okay so again we have just one comparator now we have uh no no not one we have one comparator per way instead of one comparator per line we now have one comparator per way so the hour is a little more than a direct map area is a little more than direct map but now the misciplinarity is significantly reduced because for every uh location or for every data I could put it either here or there and at the time of reading I would simply compare which address tag was matched and based on that I give a hit and return the output from the memory to the processor questions sir uh I lost my connections are actually so how is the area increasing sir exactly so data is increasing because instead of one comparator which was there in the direct map cache now we have two comparators so there's also marks involved there in direct map we had many number of comparators in the previous image which you have shown that was a fully Associated one direct math only had one comparator may you could store any data only in one location so only that location only that lines tag you would compare so you have to compare every locations tag and that is where there are so many comparators and set associators if it is a NVA set associative then any line can go into n different places which are all operated and parallel so now if it is a two s two way set Associated memory there are two comparators that have come into picture instead of one if it was a four-way substrate of memory four comparators would have been there are able to see this is this clear so this is a mix of uh fully Associated and direct math uh hello sir yes uh sir I have a question here uh sir address tag is not a unique value user because multiple multiple uh data blocks can have the same address tab if I'm not wrong why such suppose if I have because the address that is the address space of the total memory space that could be there in fact the physical memory would be smaller than that address that is it's a 32-bit address which which is the virtual memory space so suppose if I have a case wherein the memory has memory is 32-bit word whereas the in the cache I have a cache line associated with 16 bits then in that case there must be of the address is stored in the cache tag so at this point in time both if I want to store that this 32 bit from the memory into the cache so I'll have two cache slides which will be having the same Micro Stack no sir okay so typically uh the scenario is the opposite Transit the scenario is that the if the word is 32-bit wide the cache that you would want to use is at least 32-bit byte or let us say 64 or 96 or 128 bit wide so more words are stored in the line than half word okay okay if my cash is only 16 bit wide my processor will have to be 16 bit only okay yes sir tag is unique anything else certain direct mapped cache when we were talking about the conflict misses you told one of the solution was to increase the cache size so how will that uh yeah so let us say instead of a 32 lines instead of 32 lines on your cache you have 64 lines in your cache so now what happens earlier there was uh so let us say the the L2 cache memory is uh 1K big okay so you gave address and because of 1K big up key L2 cache here 32 lines Thirty uh 1K line so for every line in L1 cache there could be 32 locations of L2 cache which would want to come there now let us say my Elven cache have increased to 64 lines so now only 16 lines of the YouTube so the probability of a conflict reducer okay okay thank you sir mm-hmm okay anything else foreign so which which block should be replaced on a mess see for the direct map it is very easy there is only one location if the address is matching you have to Simply replace that however it is a different answer when it or it is a slightly complex Choice when you have a fully Associated or a set associative memory so experiments were done and we see you know particular data set particular architecture and particular program some experiments were done and two different policies were compared random we don't even check which address was used where which which set was being used last and everything and you simply replace it so we saw that okay if the associativity is two-way four-way or eight way there were different results of Mrs so are you able to clearly observe a trend here that as you increase the number of ways the total number of messes are reducing and this is not just for uh this is not just for random replacement policy you will see this trend also for the least recently used replacement policy I know this is intuitive are you able to see the intuition behind it the intuition that we just discussed in the previous slides any doubts foreign hello yes sir and the other Trend that you were just talking about that as you increase the cache size what happens again because now you can store much more data the Miss penalty reduces now if you were using eight way and a very big memory you use whichever of the two algorithms lru are random doesn't make a difference same performance but if you are a source constraint then there could be some 10 percent difference between the two algorithms so this is uh five percent plus six percent and this is five percent minus six percent so overall twelve percent gap between lru and random hmm is this clear are you able to see this that lru could be a better algorithm but if you are if you already have sufficient resources then don't put in the energy to store which which value was last season least recently almost recently used you simply uh randomly replace and it is good enough any questions foreign,https://www.youtube.com/watch?v=3rlQVT6MJ0Y,"Link: https://www.youtube.com/watch?v=3rlQVT6MJ0Y
Transcript: any address could go anywhere that is the best utilization that is what is called as fully Associated memory so what has done is that when the memory is accessed so see the beauty of direct map was uh you know which particular row to access and you would compare only that cache tag with your address but if any address can go anywhere what happens you now do not know which row is to be addressed now any address could be anywhere so any index could be anywhere so my cash tag I need to have a comparator for every line now are you able to see this I need to have a comparator for every line now and I will generate what is called as a match signal and that match signal will be used to select the final address so what kind of memory architecture are we talking about over here where there are comparisons inside the memory itself and then we give out the data are we talking about are they still talking about srams or are we talking about something else now yes he's saying you're talking we are now talking about content addressable memories So based on what is the content in the cash tag I decide to give which cache data to be given out to the processor are you able to see this what is the disadvantage of this fully Associated memory the advantage we already talked about that the total number of Misses will reduce what is the disadvantage time required to comparison so area penalty also yeah I think because they'll they'll be these competitors will I think compare the values in parallel I think so the area will be similar like comparing a single comparator if it Compares uh but I think uh we're using a lot of them here that's what we are saying is that area of this fully Associated cache would be much higher than a regular cache that we talked about okay what else so power also I think because now instead of just just comparing one word you are comparing as many number of words as there are lines as many number of tags as there are lines so not only has the area increased because you need so many parallel parallel comparators now all those parallel comparators are also operational they are consuming power so this also increases overall at the system level the Miss penalty reduces because the number of Misses are lesser or fewer therefore it may have a better overall effective access time but at a huge cost of area and power so can there be an intermediate way the intermediate way is what we call as set associativity so in fully Associated any address could go anywhere in set associative what I do is I Define sets that okay there are these four sets now if the last few bits of a particular address are zero zero zero they do not have just one location to go to as was the case for direct map now we could go to four different locations if it is say four ways at Associated or in different locations if it is a NVA set associative so this example over here is actually not two it is four-way set of state of cash um so what is happening here to here sorry sorry sorry so what is happening there's this one cache there's this other cache in both the places we store cash tag cache data and so on so now let us say uh the first row was to be addressed so what do we do we access both the memories the first row or let us say this row of both the memories the tag is compared with the original address stack at both the sides okay so again we have just one comparator now we have uh no no not one we have one comparator per way instead of one comparator per line we now have one comparator per way so the hour is a little more than a direct map area is a little more than direct map but now the misciplinarity is significantly reduced because for every uh location or for every data I could put it either here or there and at the time of reading I would simply compare which address tag was matched and based on that I give a hit and return the output from the memory to the processor questions sir uh I lost my connections are actually so how is the area increasing sir exactly so data is increasing because instead of one comparator which was there in the direct map cache now we have two comparators so there's also marks involved there in direct map we had many number of comparators in the previous image which you have shown that was a fully Associated one direct math only had one comparator may you could store any data only in one location so only that location only that lines tag you would compare so you have to compare every locations tag and that is where there are so many comparators and set associators if it is a NVA set associative then any line can go into n different places which are all operated and parallel so now if it is a two s two way set Associated memory there are two comparators that have come into picture instead of one if it was a four-way substrate of memory four comparators would have been there are able to see this is this clear so this is a mix of uh fully Associated and direct math uh hello sir yes uh sir I have a question here uh sir address tag is not a unique value user because multiple multiple uh data blocks can have the same address tab if I'm not wrong why such suppose if I have because the address that is the address space of the total memory space that could be there in fact the physical memory would be smaller than that address that is it's a 32-bit address which which is the virtual memory space so suppose if I have a case wherein the memory has memory is 32-bit word whereas the in the cache I have a cache line associated with 16 bits then in that case there must be of the address is stored in the cache tag so at this point in time both if I want to store that this 32 bit from the memory into the cache so I'll have two cache slides which will be having the same Micro Stack no sir okay so typically uh the scenario is the opposite Transit the scenario is that the if the word is 32-bit wide the cache that you would want to use is at least 32-bit byte or let us say 64 or 96 or 128 bit wide so more words are stored in the line than half word okay okay if my cash is only 16 bit wide my processor will have to be 16 bit only okay yes sir tag is unique anything else certain direct mapped cache when we were talking about the conflict misses you told one of the solution was to increase the cache size so how will that uh yeah so let us say instead of a 32 lines instead of 32 lines on your cache you have 64 lines in your cache so now what happens earlier there was uh so let us say the the L2 cache memory is uh 1K big okay so you gave address and because of 1K big up key L2 cache here 32 lines Thirty uh 1K line so for every line in L1 cache there could be 32 locations of L2 cache which would want to come there now let us say my Elven cache have increased to 64 lines so now only 16 lines of the YouTube so the probability of a conflict reducer okay okay thank you sir mm-hmm okay anything else foreign so which which block should be replaced on a mess see for the direct map it is very easy there is only one location if the address is matching you have to Simply replace that however it is a different answer when it or it is a slightly complex Choice when you have a fully Associated or a set associative memory so experiments were done and we see you know particular data set particular architecture and particular program some experiments were done and two different policies were compared random we don't even check which address was used where which which set was being used last and everything and you simply replace it so we saw that okay if the associativity is two-way four-way or eight way there were different results of Mrs so are you able to clearly observe a trend here that as you increase the number of ways the total number of messes are reducing and this is not just for uh this is not just for random replacement policy you will see this trend also for the least recently used replacement policy I know this is intuitive are you able to see the intuition behind it the intuition that we just discussed in the previous slides any doubts foreign hello yes sir and the other Trend that you were just talking about that as you increase the cache size what happens again because now you can store much more data the Miss penalty reduces now if you were using eight way and a very big memory you use whichever of the two algorithms lru are random doesn't make a difference same performance but if you are a source constraint then there could be some 10 percent difference between the two algorithms so this is uh five percent plus six percent and this is five percent minus six percent so overall twelve percent gap between lru and random hmm is this clear are you able to see this that lru could be a better algorithm but if you are if you already have sufficient resources then don't put in the energy to store which which value was last season least recently almost recently used you simply uh randomly replace and it is good enough any questions foreign"
COnbOgzm1HM,okay great so this was about reading now what happens on a right so there are two ways that we can do at you know two choices amongst which we have to choose one which is should I write through that is should I write whatever I am writing into the uh into the cache also into say I'm writing something into L1 cache should I simultaneously also write 12 to cash and then L3 cache and so on or should I write from L1 to L2 only at the time of replacement or another processor needing it so the first one is called right through this is called write back only when the block is only when the block is being removed that you will write back into the L2 cache otherwise you do not spend energy and writing into the relative cache you only change one bit over there whether a particular line is clean or it is dirty is that okay so what is clean and dirty the valid bit the valid bit is one we say okay it is clean if the valid bit is put to zero it means that the information in the level 2 cache is no longer valid it is dirty now if you want to access it to Cache from another processor then L2 cache will place a request that I want to write back from L1 cache and then it will give data data to the other processor hmm is this clear anything else when you drive through it will always be clean right true would always be clean yes but it is it is a waste of energy also because a program May simply access and write them right into the L1 cache very frequently so that is a waste of energy finally uh you if it is something that that the processor just needs as a temporary storage you don't want to go back and write into L2 cache every time when the program ends then the final calculation only you can decide to write in there to Cache any questions I just had a question that the significance of this debate is only when we are when we are going through the ride back screen because then only we have to check that whether that even is clean or not um yes and no in the sense that let us say to two cores are simultaneously using a particular data there it can happen two cores can be using the same data now one of the course updated the data in its L1 cache and also because there was a write-back scheme updated it through the right through scheme updated it in the L2 cache now the first processor which was already using the same data needs to know that okay now this data is no longer valid so now L1 cache will have the Dirty Bit in it instead of the L2 cache so there it even may still be needed because something else wrote Into the L2 cache and now I'm aware that this data is invalid is that okay Akash that's it hmm I guess something is written by processor in L1 that is same copied in L2 so how that same Block in Alto become dirty L2 is not dirty but there was the other processor which was using the same data now it knows that okay L2 has changed okay and my returns are now dirty so I need to read from the L2 again got it hello sir yes sir uh uh pros and cons of each uh under this particular section for the right through it is said read message cannot result in lunch why is that social because if there is any uh read message in the L1 cache then we look into the other cache hierarchy and finally the main memory and if you have that done once we retrieve the data from the main memory uh I will be supposed to place that in the complete cache hierarchy uh foreign what do you do you go to the main memory let us say or the next level of memory and read from there yes sir uh since uh okay but there are two processors again yes processor one picked up the data got a processor one had a readmess it picked up the data and then also to the L1 cache of its onward and it updated the L1 cache let us say three times okay I did not use the right screw policy so the L2 cache remained old it just had a dirty bit on the L2 cache okay now processor 2 wants to access the same data the same line foreign saying that this data is dirty so now you need to write into the L2 cache but from where do you need to write from the main memory no now you need to write from L1 cache into L2 cache L1 cache of course first processor into the L2 cache that right you need to do okay so it was a read message but it triggered a right operation from L1 cache to L to Cache had the first processor followed the right through policy the readmission processor too would have simply accessed L2 cache and given the output because the updated data was already there inside the I2 cache are you able to see this but what happens if you don't have the updated data in L2 cache also at the point in time so then you'll have to get that updated and that is where it is a missed yes sir so now we go to the L3 class that message is not to be picked up from the main memory that means because the the valid bit is dirty Darkness means that you have to pick it up from the processor now okay are able to see this it's not clear sir still okay so someone else in the class can explain to ranjits others find it clear who can explain to Ranjit just fine actually I want to confirm that is the Dirty Bit status is reflecting that changes has been done by the processor that's why we are not looking into main memory right yes oh okay so uh Buster first processor changed the value and it was not stored in L2 and the second processor was trying to locate and it found Dirty Bit is high so instead of going to main memory it go ask to First processor so update in L2 because it was changed by him no sir okay let me remove this and let me try to explain it again graphically let us say there are two processors processor one and processor 2. and they have a shared I2 cache so yeah yeah there is an 11 cache here and there is an L1 cache here now processor one fetched a particular data and brought it to the L2 cache then brought it to the L1 cache and started to use this data as it was running the program it updated the content of the L1 cache if my policy is right back what happens okay it updated the contents of the L1 cache and set the Dirty Bit to be high over here huh okay it set the Dirty Bit to be high over here now after some time P2 wanted to access the same data same address location what happens YouTube places a request to its L1 cache there was a mess so readmess happened and it went to the L2 cache region to see if the information is available in L2 cache to a pleasant surprise that particular address was already there in the I2 cache however it's valid width was zero so it is a dirty information there you have to clear it yes so now what would the processor do if the valid bit was one then it would have simply read this data into the L1 cache over here also now since added bit is zero it means this data is no longer valid hmm so now to to be able to serve the request of the second processor what do we need to do to serve the request of the second processor I need to go back to First processor pick up data from L1 cache over here and write it into the L2 cache so a readmess happened but a inter processor write operation got initiated had it been right through then whatever L1 had updated it would have updated L2 also and when the other processor wanted to access there was no no conflict no challenge it was a seamless movement of data okay okay is this clear and this was clear okay so now when you do a right through how big a right buffer do you need we realize that the excess time of L1 cache will be different from excess time of L2 cache will be different from excess time of L3 cache or main memory that part is clear all of us know this hello yes sir yes sir yes sir so what is happening when I want to write into uh the cash outside or to the main memory then I wrote to the cache but to write with the main memory I will operate at a speed of the processor which is say five 50 megahertz very slow processor and it would write into the dram let us say it operates at 10 megahertz now what happens the dram can write only a in a Time duration of 100 nanoseconds huh whereas my processor is operating at a speed of two nanoseconds so five data may come and over here I would have written only one data are you able to see this yes so in such a setting if I do not have any buffer to store so I could I could read five words in this but I can write over here only one word so I need some buffer local buffer in which to save the contents that I want to write hmm so we need to have a right buffer which is nothing else but a fifo is it clear any questions so these these buffers are there in the cache itself next to the cache in fact not not next to the cache these buffers are there at the interface of the dram of the main memory ah okay because the caches are very highly digital effect yes so that kind of brings us to the end of this section on dashes before we move forward I want to so any questions still here sir uh size how do we make sure that uh do not lose the data it would not store all the data which are in the pipeline so we look at a few things over there we look at a thing like uh what is the line size what is the line size in the dram what is the line size in the L2 cache or whatever lower level cache that you were talking about so if let us say easy example me if the Dira would store five words in one line then you just need a buffer entry of four or five because all the five will be written into the dram in one go however if the dram right size is only let us say 2 or 3. but three words are written in one go then what do you need then you realize that five words are coming three will go out at a time and we could then also put in a probability that what is the probability of right operations and then we can estimate the total number of entries that you may be able or that we may require in the buffer there so this is just a simple mathematical calculation where we find how many addresses or how many words are not getting written in the in the period in which L2 or within which the higher order or the main memory is writing if you are generating more words than what are written in one line in that duration then the buffer size needs to be larger if the number of words that you are generating is the same as the line size then that's no problem is that okay yes sir almost so any anything else about caches so can we discuss something about this designer's nightmare to the story frequency does that mean that uh I'm writing at a very higher frequency and the dram is not able to uh is even able to store it yeah that it keeps uh keeps generating five words now I can store them in fifth right if it is for one two yeah so what is important is that there will be no buffer overflow until the the multiplication of number of words in a line of the dram and the frequency of the dram is greater than number of words in the number of words that can be read from the or that and that the processor may want to write into the dram and the frequency of the drum examples uh let us say s processor into the frequency of the processor means the exactness into uh word length which is uh one has to be less than frequency of dram into length line which could be let us say five so um every two nanoseconds the new word was coming this was 10 nanosecond uh this was 10 megahertz so every uh uh every 100 nanoseconds are new yeah so let us say this was 20. okay 50 megahertz so that was 20 then so every 100 nanoseconds one word was coming so what happened uh 50 megahertz into one and yeah pay 100 Mega uh 10 megahertz into five because I said that dram is much wider that we have the cache that we have used so as many words that are generated from the processor they can all go into the dram no challenges at all now let us say my processor frequency instead of 50 was 100 now what happens if my processor frequency was hindered then 100 million words are generated every cycle every second let us say if this was 10 megahertz and this was five only how many can I write 50 million only so where do the remaining 50 million go I will have to size my right buffer so big that the remaining 50 million should go there yes so there's no problem in that route right because we already know what can be the maximum data that can out come out yeah but then there is an excess time for this right buffer that comes into picture there is an area penalty that comes with this right before this doesn't come for free um oh yeah that is a problem yeah that is the problem I have just to do it in my mind I can do whatever I want to do but in in reality it costs okay there is extra power that is getting wasted so many things are lost yes okay anything else,https://www.youtube.com/watch?v=COnbOgzm1HM,"Link: https://www.youtube.com/watch?v=COnbOgzm1HM
Transcript: okay great so this was about reading now what happens on a right so there are two ways that we can do at you know two choices amongst which we have to choose one which is should I write through that is should I write whatever I am writing into the uh into the cache also into say I'm writing something into L1 cache should I simultaneously also write 12 to cash and then L3 cache and so on or should I write from L1 to L2 only at the time of replacement or another processor needing it so the first one is called right through this is called write back only when the block is only when the block is being removed that you will write back into the L2 cache otherwise you do not spend energy and writing into the relative cache you only change one bit over there whether a particular line is clean or it is dirty is that okay so what is clean and dirty the valid bit the valid bit is one we say okay it is clean if the valid bit is put to zero it means that the information in the level 2 cache is no longer valid it is dirty now if you want to access it to Cache from another processor then L2 cache will place a request that I want to write back from L1 cache and then it will give data data to the other processor hmm is this clear anything else when you drive through it will always be clean right true would always be clean yes but it is it is a waste of energy also because a program May simply access and write them right into the L1 cache very frequently so that is a waste of energy finally uh you if it is something that that the processor just needs as a temporary storage you don't want to go back and write into L2 cache every time when the program ends then the final calculation only you can decide to write in there to Cache any questions I just had a question that the significance of this debate is only when we are when we are going through the ride back screen because then only we have to check that whether that even is clean or not um yes and no in the sense that let us say to two cores are simultaneously using a particular data there it can happen two cores can be using the same data now one of the course updated the data in its L1 cache and also because there was a write-back scheme updated it through the right through scheme updated it in the L2 cache now the first processor which was already using the same data needs to know that okay now this data is no longer valid so now L1 cache will have the Dirty Bit in it instead of the L2 cache so there it even may still be needed because something else wrote Into the L2 cache and now I'm aware that this data is invalid is that okay Akash that's it hmm I guess something is written by processor in L1 that is same copied in L2 so how that same Block in Alto become dirty L2 is not dirty but there was the other processor which was using the same data now it knows that okay L2 has changed okay and my returns are now dirty so I need to read from the L2 again got it hello sir yes sir uh uh pros and cons of each uh under this particular section for the right through it is said read message cannot result in lunch why is that social because if there is any uh read message in the L1 cache then we look into the other cache hierarchy and finally the main memory and if you have that done once we retrieve the data from the main memory uh I will be supposed to place that in the complete cache hierarchy uh foreign what do you do you go to the main memory let us say or the next level of memory and read from there yes sir uh since uh okay but there are two processors again yes processor one picked up the data got a processor one had a readmess it picked up the data and then also to the L1 cache of its onward and it updated the L1 cache let us say three times okay I did not use the right screw policy so the L2 cache remained old it just had a dirty bit on the L2 cache okay now processor 2 wants to access the same data the same line foreign saying that this data is dirty so now you need to write into the L2 cache but from where do you need to write from the main memory no now you need to write from L1 cache into L2 cache L1 cache of course first processor into the L2 cache that right you need to do okay so it was a read message but it triggered a right operation from L1 cache to L to Cache had the first processor followed the right through policy the readmission processor too would have simply accessed L2 cache and given the output because the updated data was already there inside the I2 cache are you able to see this but what happens if you don't have the updated data in L2 cache also at the point in time so then you'll have to get that updated and that is where it is a missed yes sir so now we go to the L3 class that message is not to be picked up from the main memory that means because the the valid bit is dirty Darkness means that you have to pick it up from the processor now okay are able to see this it's not clear sir still okay so someone else in the class can explain to ranjits others find it clear who can explain to Ranjit just fine actually I want to confirm that is the Dirty Bit status is reflecting that changes has been done by the processor that's why we are not looking into main memory right yes oh okay so uh Buster first processor changed the value and it was not stored in L2 and the second processor was trying to locate and it found Dirty Bit is high so instead of going to main memory it go ask to First processor so update in L2 because it was changed by him no sir okay let me remove this and let me try to explain it again graphically let us say there are two processors processor one and processor 2. and they have a shared I2 cache so yeah yeah there is an 11 cache here and there is an L1 cache here now processor one fetched a particular data and brought it to the L2 cache then brought it to the L1 cache and started to use this data as it was running the program it updated the content of the L1 cache if my policy is right back what happens okay it updated the contents of the L1 cache and set the Dirty Bit to be high over here huh okay it set the Dirty Bit to be high over here now after some time P2 wanted to access the same data same address location what happens YouTube places a request to its L1 cache there was a mess so readmess happened and it went to the L2 cache region to see if the information is available in L2 cache to a pleasant surprise that particular address was already there in the I2 cache however it's valid width was zero so it is a dirty information there you have to clear it yes so now what would the processor do if the valid bit was one then it would have simply read this data into the L1 cache over here also now since added bit is zero it means this data is no longer valid hmm so now to to be able to serve the request of the second processor what do we need to do to serve the request of the second processor I need to go back to First processor pick up data from L1 cache over here and write it into the L2 cache so a readmess happened but a inter processor write operation got initiated had it been right through then whatever L1 had updated it would have updated L2 also and when the other processor wanted to access there was no no conflict no challenge it was a seamless movement of data okay okay is this clear and this was clear okay so now when you do a right through how big a right buffer do you need we realize that the excess time of L1 cache will be different from excess time of L2 cache will be different from excess time of L3 cache or main memory that part is clear all of us know this hello yes sir yes sir yes sir so what is happening when I want to write into uh the cash outside or to the main memory then I wrote to the cache but to write with the main memory I will operate at a speed of the processor which is say five 50 megahertz very slow processor and it would write into the dram let us say it operates at 10 megahertz now what happens the dram can write only a in a Time duration of 100 nanoseconds huh whereas my processor is operating at a speed of two nanoseconds so five data may come and over here I would have written only one data are you able to see this yes so in such a setting if I do not have any buffer to store so I could I could read five words in this but I can write over here only one word so I need some buffer local buffer in which to save the contents that I want to write hmm so we need to have a right buffer which is nothing else but a fifo is it clear any questions so these these buffers are there in the cache itself next to the cache in fact not not next to the cache these buffers are there at the interface of the dram of the main memory ah okay because the caches are very highly digital effect yes so that kind of brings us to the end of this section on dashes before we move forward I want to so any questions still here sir uh size how do we make sure that uh do not lose the data it would not store all the data which are in the pipeline so we look at a few things over there we look at a thing like uh what is the line size what is the line size in the dram what is the line size in the L2 cache or whatever lower level cache that you were talking about so if let us say easy example me if the Dira would store five words in one line then you just need a buffer entry of four or five because all the five will be written into the dram in one go however if the dram right size is only let us say 2 or 3. but three words are written in one go then what do you need then you realize that five words are coming three will go out at a time and we could then also put in a probability that what is the probability of right operations and then we can estimate the total number of entries that you may be able or that we may require in the buffer there so this is just a simple mathematical calculation where we find how many addresses or how many words are not getting written in the in the period in which L2 or within which the higher order or the main memory is writing if you are generating more words than what are written in one line in that duration then the buffer size needs to be larger if the number of words that you are generating is the same as the line size then that's no problem is that okay yes sir almost so any anything else about caches so can we discuss something about this designer's nightmare to the story frequency does that mean that uh I'm writing at a very higher frequency and the dram is not able to uh is even able to store it yeah that it keeps uh keeps generating five words now I can store them in fifth right if it is for one two yeah so what is important is that there will be no buffer overflow until the the multiplication of number of words in a line of the dram and the frequency of the dram is greater than number of words in the number of words that can be read from the or that and that the processor may want to write into the dram and the frequency of the drum examples uh let us say s processor into the frequency of the processor means the exactness into uh word length which is uh one has to be less than frequency of dram into length line which could be let us say five so um every two nanoseconds the new word was coming this was 10 nanosecond uh this was 10 megahertz so every uh uh every 100 nanoseconds are new yeah so let us say this was 20. okay 50 megahertz so that was 20 then so every 100 nanoseconds one word was coming so what happened uh 50 megahertz into one and yeah pay 100 Mega uh 10 megahertz into five because I said that dram is much wider that we have the cache that we have used so as many words that are generated from the processor they can all go into the dram no challenges at all now let us say my processor frequency instead of 50 was 100 now what happens if my processor frequency was hindered then 100 million words are generated every cycle every second let us say if this was 10 megahertz and this was five only how many can I write 50 million only so where do the remaining 50 million go I will have to size my right buffer so big that the remaining 50 million should go there yes so there's no problem in that route right because we already know what can be the maximum data that can out come out yeah but then there is an excess time for this right buffer that comes into picture there is an area penalty that comes with this right before this doesn't come for free um oh yeah that is a problem yeah that is the problem I have just to do it in my mind I can do whatever I want to do but in in reality it costs okay there is extra power that is getting wasted so many things are lost yes okay anything else"
xCCbA0kWC8w,today's session so today we are going to talk about drams what are drams what is the dram sir single mosfet with a capacitor why is it called a dram why is it called Dynamic Ram not Statigram so if it knows charging and dischargeable capacitance so even in a static Ram the internal nodes are also capacitors there's parasitic capacitors there they get charged and discharged we need to refresh them here we can leave them so in the dram the way the capacitance charging and the starting happens refresh is a mandatory enough it is a mandatory requirement it does not required at all in srams so you definitely need to have a clock which would come at a regular frequency so that your dram contents are refreshed SRAM doesn't need a clock every now and then is that okay now uh as as already mentioned by one of you dram is denser it has one transistor and one capacitor instead of six transistors in the SRAM so how does the dram cell look like this is how a dram cell is if you want to write into this cell what do you do you take bit line to the desired level turn the word line on and this node will get charged or discharged to the desired level now the C should be small and this M1 should be big why to charge transportation charge faster to charge faster so that the internal node can get charged up very fast uh and do you realize that when I turn the word line on there is actually charge sharing that is happening between BL and int because in reality BL is also a capacitor henna so if this C is very large then what happens let us say this is CBL and let us say this C storage it's very large what happens uh the chart sharing would happen and instead of almost vdd being stored at int I will end up storing vdd minus a Delta V and this Delta V would be large are you able to see this when this C Storage is small then the voltage at int will be vdd minus Delta small Delta V weighted minus this this Delta V is smaller are you able to appreciate this point yes okay so we are talking with respect to the bit line capacitance like with respect to bit line capacitance C should be small yeah so with respect to the time capacity should be small means small overall yes so as small as possible but there is an opposing constraint also that opposing constraint is that the B should also be large but we come to that let us first look at how the read operation happens to do the read operation the word line would turn on and this capacitor would share charge onto the bit line and then the sense amplifier turns on and both int and bitline are discharged are you able to see this so where would the bitline recharge be over here so can you please repeat this this one so what part did you understand and what did you not understand I will then repeat accordingly so we were talking about the uh like the reading but I got disconnected so um when you want to read this particular cell what do you do you turn the word line on yes what happened Advanced CDL and C store get connected yes sir yes sharing happens yes and you sense how which direction the charge sharing is in if it if and determine if C stored a zero or a one through the sense amplifier amplifier now discharges both bitline and int or charges both bitline and int so sense amplifiers why why is it charging bit line right because it arrives from my question that I was asking after this at what voltage will you pre-charge the bit line okay what voltage will you precise the bit line suppose you want to read a zero what should be the voltage so we can either pre-charge the bit line to vdd or vdd by 2 but VD by 2 will be even more prominent recharging the bit line to vdmi 2 is more promising because then what happens is that when you are sharing a vdd from the internal node then you know that bitline would rise and when you are chart sharing 0 from the internal node then you know bitline will fall so they are moving in two different directions and you can utilize you know that to your advantage recharging it to full vdd what can happen is that even if int has gone to some voltage because of charge leakage or whatever bit line may end up discharging a bit and that can be a problem for you you might end up reading that as a zero instead of a one hello foreign operation the internal node had already due to leakage or whatever had reached a level of vdd minus 200 millivolts yes sir so in reality because it was storing a one I would not expect my bit line to fall anything but line should remain stable but because internal node was 200 millivolts over bit line Falls a bit chart sharing would happen on another node you had stored a zero so in that case the bit line would have naturally falled much higher so now the difference between 0 and 1 appears to be like this pretty close to vdd pretty close to vdd but this has to be considered as one and this has to be considered as 0. on the other hand if you are pre-charging to VD by 2 then even if internal node has discharged a bit your bit line would rise and in case when the zero was stored the bit line would fall [Music] this is the distance between the two of them okay and you will see that this margin could be higher is that okay is much beneficial because the margin is greater yes now comes the third thing which is called refresh which means that see this internal node would leak over time where would it leak where the junction capacitance of the same mosfet there is some threshold current going through this mosfet so so many things are happening so this internal capacitance would leak and node would leak and what you want is that uh to restore the cell content suppose it has leaked by 200 millivolts if you do a read operation right there and then then what happens this will still be read as vdd and I will restore vdd value onto end node so this this is called as dummy read okay this is not a user triggered read this read happens anyways so that the contents of the dram are maintained this is the refresh part and to increase the duration between these dummy reads so do you realize that when the dummy reader is happening actually it cannot happen so your dram is unavailable for use the customer or the user is waiting until your dummy read closes only then a real read can be initiated again so you want to increase the spacing between dummy reads because that that reduces the unavailability of your dram for this you need to reduce the leakage of int node to reduce the leakage of int node there are two ways first uh keep M1 to be very small second if you cannot keep MN to be very small or even if you are able to keep them in to be small keep C to be as big as possible so that even if some charge leaks out the dip in the voltage level is not very significant instead of 200 millivolts only 100 millivolt depth is coming so now you can double the duration bit or double the interval between two refresh Cycles so while in the first slide earlier slide we had said that M1 should be big and C should be small that was what we had said there over here we are talking about exactly the opposite thing foreign capacitor C because if let us say I leak is the current that is leaking if the capacitor is large then it will take extra time for the voltage on this end node to fall so restoring the value of end node will be easier so your thresholders and node should not fall below 200 variables or 300 millivolts so the duration it would take for it node to fall for the same leakage current will be higher if the capacitance is larger okay okay so you can increase this interval there okay so these are contradicted requirements on the capacitance sizing and the M1 sizing are you able to see this so but increasing the capacitor will increase the access temperature it will increase the access time why do you say so um it will charge it will charge the beauty by 2 of bit line higher much higher or much lower so capacitor large means that it will actually help your read operation also you finally would have the sense amplifier driving the bit line and the internal node only one internal node is going to be visible to the sense amplifier this capacitance has ended front of array let us say this capacitance is 5 into farad so soft one it appears as 105 into farads not a very big deal suppose if you want to uh say that to reduce the leakage uh we are increasing the capacitive capacitor which is storing the contents so then it will go uh it can increase only by two magnitudes so you do not yeah so you do not reduce leakage by increasing the size of C be careful you just increase the interval between refresh leakage here you can reduce only by reducing M1 by changing the size of C by using a larger C you are just increasing this interval between two refreshed Cycles okay it will not change because you use the larger C in fact leakage would only increase because the higher weight like a higher VDS will remain for a longer duration of time but um you increase the interval at which you will do the read operation uh dummy read there okay so we are calling this dummy like the refreshers from hearing right yes okay okay we are calling it as dummy read because no one asked us to read it this is just being done yes sir um the reference between remains as BTD by 2 only right so the sense amplifier uh what does the what does the sense Amplifier do it will amplify the difference between bitline and bit line bar to full vdd and ground is it not yes sir so the bit line would go to full vdd if that was what was required or it will go to full ground if that was what was required as bit line goes to ground the internal node will also discharge or as it grows to ground may turn out would charge up is that clear instead of how we will generate actually VD by two so because really supplies we will come to that disappear foreign [Applause] it it is a power wasting concern foreign but they are much denser is so what do you understand by the term refresh when we talk about drams what do you understand I'm not saying that your understanding may be correct or not correct what do you understand as of now foreign so you want to replenish the charge onto the internal node okay whether it was a zero or a one you want to bring it back to the original level am I right yeah so during read operation what happens uh internal load uh so what happens uh either a internal node will decrease by some voltage Delta V or it will be a very less voltage to either decrease by some voltage or it will increase by some voltage yeah I know and then you activate the sense amplifier what happens um goes to zero and as a consequence even int goes to zero the decline goes to 0 int yes sir yes I'm going to reverse so you were reading a zero when you initially connected the bit line and and the internal node internal node also Rose to be Redeemer 2 minus Delta thank you because of charge sharing yeah now when you activate the sense amplifier bit line goes to zero and simultaneous the int also goes to zero so whatever loss of charge had happened you replenish that charge okay and that is why it is called refresh you refresh that charge okay so every reader will do this kind of mechanism so this is how real happens okay but for refresh even if a read operation is not triggered by the user you will do dummy reads every row you will access once every one millisecond and uh okay okay got it anything else sir how does okay yes Malika sir how does increasing the size of the capacitor lead to uh he's in the dummy duration so you tell me uh sense amplifier has a offset dependent on voltage but I want my internal my voltage to be at least this much there so that I can sense a zero or a one yes so and we are saying capacitor will lead charged through M1 so voltages Q into Q is equal to CV so Q by C is the voltage if you uh if you increase the charge that you can store on the capacitor then even if the same current is leaking the data we would be lesser yes the capacitance is larger so since I'm required a required a particular Delta V now that data V is lesser in the same duration so you can actually let it discharge for some more time okay okay and then do the refresh so that is how a large capacitor helps in increasing the interval between two refresh Cycles Okay so mm-hmm anything else uh so I understood why we are refreshing but can you please explain how we are refreshing the internal mode we simply read they simply read every every row okay so when you read a row what happens amplifiable fully charged or fully discharge the internal node so any loss of charge which would have happened because of leakage is taken care of okay okay sir just for qualifications good question very good question is director transmission gate uh like this and get itself something many if you just try to work it out what did we say that I have my bit line at VD by 2. let's go to the reader slide again I had my bitline ability by 2. uh when the internal node got connected I discharged a bit and then sense amplifier and showed bitline went to zero and as bitline went to zero because this is on this also goes to zero this is simple yes sir now if endnote stored one what would happen bitline would rise then once the sense amplifier turns on it will take it to one now this one on the bit line needs to transfer to int node how would you do it okay foreign your enemies are charging the capacitor from the bit line your sending tasks through M12 sorry I should pass your transmission oh so then let's kind of double the area and you do something else think of assist schemes that we used in srams can you do something like that over here what did the SS schemes do so can we have WL at vdd Plus vth yes so we can override the word line if you override the word line what happens yes compensated is there a refresh operation clear now if you take word line to a level Which is higher than vdd I can compensate for the VT drop that would happen because of the pass gate therefore drams would have something some charge pump that would raise the level of word line to a value Which is higher than regular word line okay any questions okay so if this is clear that is memory the dram cell operation is clear then we look at in terms of refresh overhead see we said that refresh needs to happen at a regular interval so because leakage goes exponentially with temperature the refresh rate can actually go very high at high temperatures what is happening that you count through all the row addresses once per a refresh interval and in that duration the memory cell contents are refreshed what this means is that in that duration when you are kind of reading these uh doing dummy read on the memory array in that duration you cannot do another operation because read is happening you cannot now do any other read or write on the dram so the dram is unavailable during the refresh period are you with me are you able to see this yes sir and this also gives a brief good calculation of that is the uh if there's a ATM 8192 cross 8192 array and every excess is 10 nanoseconds so how much total time is given there is lost in refresh so that overhead is also being calculated [Music] is that okay any questions sir what is this 10 nanoseconds are exactly talking about drams for comparison between those both so that we can say which one is better exactly what do you understand by read time and without the refresh only I'm like only only regarding the read time what is what is read time according to you so I mean said the read operation should be completed and like from the starting from the word line to the end where we uh read the capacitor value so I think that should be the right time yes exactly that is what it is so we don't have the refresh uh time in this refresh time different from read time what did we just say refresh is equal to dummy rate yes yes but yes so this read time is the refresh time so you need to see how many rows are we talking about how many rows are we talking about eight one nine two rows in this example so eight one nine two times into ten nanoseconds upon in at what interval it's at three milliseconds underwear so 3 into 10 raised to a minus three into the S by 3. and finally we get the percentage overhead fine,https://www.youtube.com/watch?v=xCCbA0kWC8w,"Link: https://www.youtube.com/watch?v=xCCbA0kWC8w
Transcript: today's session so today we are going to talk about drams what are drams what is the dram sir single mosfet with a capacitor why is it called a dram why is it called Dynamic Ram not Statigram so if it knows charging and dischargeable capacitance so even in a static Ram the internal nodes are also capacitors there's parasitic capacitors there they get charged and discharged we need to refresh them here we can leave them so in the dram the way the capacitance charging and the starting happens refresh is a mandatory enough it is a mandatory requirement it does not required at all in srams so you definitely need to have a clock which would come at a regular frequency so that your dram contents are refreshed SRAM doesn't need a clock every now and then is that okay now uh as as already mentioned by one of you dram is denser it has one transistor and one capacitor instead of six transistors in the SRAM so how does the dram cell look like this is how a dram cell is if you want to write into this cell what do you do you take bit line to the desired level turn the word line on and this node will get charged or discharged to the desired level now the C should be small and this M1 should be big why to charge transportation charge faster to charge faster so that the internal node can get charged up very fast uh and do you realize that when I turn the word line on there is actually charge sharing that is happening between BL and int because in reality BL is also a capacitor henna so if this C is very large then what happens let us say this is CBL and let us say this C storage it's very large what happens uh the chart sharing would happen and instead of almost vdd being stored at int I will end up storing vdd minus a Delta V and this Delta V would be large are you able to see this when this C Storage is small then the voltage at int will be vdd minus Delta small Delta V weighted minus this this Delta V is smaller are you able to appreciate this point yes okay so we are talking with respect to the bit line capacitance like with respect to bit line capacitance C should be small yeah so with respect to the time capacity should be small means small overall yes so as small as possible but there is an opposing constraint also that opposing constraint is that the B should also be large but we come to that let us first look at how the read operation happens to do the read operation the word line would turn on and this capacitor would share charge onto the bit line and then the sense amplifier turns on and both int and bitline are discharged are you able to see this so where would the bitline recharge be over here so can you please repeat this this one so what part did you understand and what did you not understand I will then repeat accordingly so we were talking about the uh like the reading but I got disconnected so um when you want to read this particular cell what do you do you turn the word line on yes what happened Advanced CDL and C store get connected yes sir yes sharing happens yes and you sense how which direction the charge sharing is in if it if and determine if C stored a zero or a one through the sense amplifier amplifier now discharges both bitline and int or charges both bitline and int so sense amplifiers why why is it charging bit line right because it arrives from my question that I was asking after this at what voltage will you pre-charge the bit line okay what voltage will you precise the bit line suppose you want to read a zero what should be the voltage so we can either pre-charge the bit line to vdd or vdd by 2 but VD by 2 will be even more prominent recharging the bit line to vdmi 2 is more promising because then what happens is that when you are sharing a vdd from the internal node then you know that bitline would rise and when you are chart sharing 0 from the internal node then you know bitline will fall so they are moving in two different directions and you can utilize you know that to your advantage recharging it to full vdd what can happen is that even if int has gone to some voltage because of charge leakage or whatever bit line may end up discharging a bit and that can be a problem for you you might end up reading that as a zero instead of a one hello foreign operation the internal node had already due to leakage or whatever had reached a level of vdd minus 200 millivolts yes sir so in reality because it was storing a one I would not expect my bit line to fall anything but line should remain stable but because internal node was 200 millivolts over bit line Falls a bit chart sharing would happen on another node you had stored a zero so in that case the bit line would have naturally falled much higher so now the difference between 0 and 1 appears to be like this pretty close to vdd pretty close to vdd but this has to be considered as one and this has to be considered as 0. on the other hand if you are pre-charging to VD by 2 then even if internal node has discharged a bit your bit line would rise and in case when the zero was stored the bit line would fall [Music] this is the distance between the two of them okay and you will see that this margin could be higher is that okay is much beneficial because the margin is greater yes now comes the third thing which is called refresh which means that see this internal node would leak over time where would it leak where the junction capacitance of the same mosfet there is some threshold current going through this mosfet so so many things are happening so this internal capacitance would leak and node would leak and what you want is that uh to restore the cell content suppose it has leaked by 200 millivolts if you do a read operation right there and then then what happens this will still be read as vdd and I will restore vdd value onto end node so this this is called as dummy read okay this is not a user triggered read this read happens anyways so that the contents of the dram are maintained this is the refresh part and to increase the duration between these dummy reads so do you realize that when the dummy reader is happening actually it cannot happen so your dram is unavailable for use the customer or the user is waiting until your dummy read closes only then a real read can be initiated again so you want to increase the spacing between dummy reads because that that reduces the unavailability of your dram for this you need to reduce the leakage of int node to reduce the leakage of int node there are two ways first uh keep M1 to be very small second if you cannot keep MN to be very small or even if you are able to keep them in to be small keep C to be as big as possible so that even if some charge leaks out the dip in the voltage level is not very significant instead of 200 millivolts only 100 millivolt depth is coming so now you can double the duration bit or double the interval between two refresh Cycles so while in the first slide earlier slide we had said that M1 should be big and C should be small that was what we had said there over here we are talking about exactly the opposite thing foreign capacitor C because if let us say I leak is the current that is leaking if the capacitor is large then it will take extra time for the voltage on this end node to fall so restoring the value of end node will be easier so your thresholders and node should not fall below 200 variables or 300 millivolts so the duration it would take for it node to fall for the same leakage current will be higher if the capacitance is larger okay okay so you can increase this interval there okay so these are contradicted requirements on the capacitance sizing and the M1 sizing are you able to see this so but increasing the capacitor will increase the access temperature it will increase the access time why do you say so um it will charge it will charge the beauty by 2 of bit line higher much higher or much lower so capacitor large means that it will actually help your read operation also you finally would have the sense amplifier driving the bit line and the internal node only one internal node is going to be visible to the sense amplifier this capacitance has ended front of array let us say this capacitance is 5 into farad so soft one it appears as 105 into farads not a very big deal suppose if you want to uh say that to reduce the leakage uh we are increasing the capacitive capacitor which is storing the contents so then it will go uh it can increase only by two magnitudes so you do not yeah so you do not reduce leakage by increasing the size of C be careful you just increase the interval between refresh leakage here you can reduce only by reducing M1 by changing the size of C by using a larger C you are just increasing this interval between two refreshed Cycles okay it will not change because you use the larger C in fact leakage would only increase because the higher weight like a higher VDS will remain for a longer duration of time but um you increase the interval at which you will do the read operation uh dummy read there okay so we are calling this dummy like the refreshers from hearing right yes okay okay we are calling it as dummy read because no one asked us to read it this is just being done yes sir um the reference between remains as BTD by 2 only right so the sense amplifier uh what does the what does the sense Amplifier do it will amplify the difference between bitline and bit line bar to full vdd and ground is it not yes sir so the bit line would go to full vdd if that was what was required or it will go to full ground if that was what was required as bit line goes to ground the internal node will also discharge or as it grows to ground may turn out would charge up is that clear instead of how we will generate actually VD by two so because really supplies we will come to that disappear foreign [Applause] it it is a power wasting concern foreign but they are much denser is so what do you understand by the term refresh when we talk about drams what do you understand I'm not saying that your understanding may be correct or not correct what do you understand as of now foreign so you want to replenish the charge onto the internal node okay whether it was a zero or a one you want to bring it back to the original level am I right yeah so during read operation what happens uh internal load uh so what happens uh either a internal node will decrease by some voltage Delta V or it will be a very less voltage to either decrease by some voltage or it will increase by some voltage yeah I know and then you activate the sense amplifier what happens um goes to zero and as a consequence even int goes to zero the decline goes to 0 int yes sir yes I'm going to reverse so you were reading a zero when you initially connected the bit line and and the internal node internal node also Rose to be Redeemer 2 minus Delta thank you because of charge sharing yeah now when you activate the sense amplifier bit line goes to zero and simultaneous the int also goes to zero so whatever loss of charge had happened you replenish that charge okay and that is why it is called refresh you refresh that charge okay so every reader will do this kind of mechanism so this is how real happens okay but for refresh even if a read operation is not triggered by the user you will do dummy reads every row you will access once every one millisecond and uh okay okay got it anything else sir how does okay yes Malika sir how does increasing the size of the capacitor lead to uh he's in the dummy duration so you tell me uh sense amplifier has a offset dependent on voltage but I want my internal my voltage to be at least this much there so that I can sense a zero or a one yes so and we are saying capacitor will lead charged through M1 so voltages Q into Q is equal to CV so Q by C is the voltage if you uh if you increase the charge that you can store on the capacitor then even if the same current is leaking the data we would be lesser yes the capacitance is larger so since I'm required a required a particular Delta V now that data V is lesser in the same duration so you can actually let it discharge for some more time okay okay and then do the refresh so that is how a large capacitor helps in increasing the interval between two refresh Cycles Okay so mm-hmm anything else uh so I understood why we are refreshing but can you please explain how we are refreshing the internal mode we simply read they simply read every every row okay so when you read a row what happens amplifiable fully charged or fully discharge the internal node so any loss of charge which would have happened because of leakage is taken care of okay okay sir just for qualifications good question very good question is director transmission gate uh like this and get itself something many if you just try to work it out what did we say that I have my bit line at VD by 2. let's go to the reader slide again I had my bitline ability by 2. uh when the internal node got connected I discharged a bit and then sense amplifier and showed bitline went to zero and as bitline went to zero because this is on this also goes to zero this is simple yes sir now if endnote stored one what would happen bitline would rise then once the sense amplifier turns on it will take it to one now this one on the bit line needs to transfer to int node how would you do it okay foreign your enemies are charging the capacitor from the bit line your sending tasks through M12 sorry I should pass your transmission oh so then let's kind of double the area and you do something else think of assist schemes that we used in srams can you do something like that over here what did the SS schemes do so can we have WL at vdd Plus vth yes so we can override the word line if you override the word line what happens yes compensated is there a refresh operation clear now if you take word line to a level Which is higher than vdd I can compensate for the VT drop that would happen because of the pass gate therefore drams would have something some charge pump that would raise the level of word line to a value Which is higher than regular word line okay any questions okay so if this is clear that is memory the dram cell operation is clear then we look at in terms of refresh overhead see we said that refresh needs to happen at a regular interval so because leakage goes exponentially with temperature the refresh rate can actually go very high at high temperatures what is happening that you count through all the row addresses once per a refresh interval and in that duration the memory cell contents are refreshed what this means is that in that duration when you are kind of reading these uh doing dummy read on the memory array in that duration you cannot do another operation because read is happening you cannot now do any other read or write on the dram so the dram is unavailable during the refresh period are you with me are you able to see this yes sir and this also gives a brief good calculation of that is the uh if there's a ATM 8192 cross 8192 array and every excess is 10 nanoseconds so how much total time is given there is lost in refresh so that overhead is also being calculated [Music] is that okay any questions sir what is this 10 nanoseconds are exactly talking about drams for comparison between those both so that we can say which one is better exactly what do you understand by read time and without the refresh only I'm like only only regarding the read time what is what is read time according to you so I mean said the read operation should be completed and like from the starting from the word line to the end where we uh read the capacitor value so I think that should be the right time yes exactly that is what it is so we don't have the refresh uh time in this refresh time different from read time what did we just say refresh is equal to dummy rate yes yes but yes so this read time is the refresh time so you need to see how many rows are we talking about how many rows are we talking about eight one nine two rows in this example so eight one nine two times into ten nanoseconds upon in at what interval it's at three milliseconds underwear so 3 into 10 raised to a minus three into the S by 3. and finally we get the percentage overhead fine"
6JyCfEH0GJQ,yes sir okay so now we look at how this capacitor is designed see we are saying that there is one transistor one capacitor in the dram cell how do we make the capacitor so let's look at this thing over here over here void line is running in the polysilicon so wordline is taken care of bit line connects to one edge of the one in one terminal of the uh likes one either Source or drain of the nmos and the other side has to have a capacitor that capacitor could be made by using poly having a little dielectric in between and then again putting some poly huh so how will this look like in a screenshot something like this where um different what do we say there's a polyphen structure has been used so that overall capacitance is higher this represents the blue one represents the bit line region the pink one is the capacitor the green ones are the other plate other side of the capacitor this is the polygate this is clear are you able to see this so this structure of poly is making them in parallel so to increase the capacitance yes in the in the so you're going vertically you're adding fins yeah so that in the same area you are able to implement a much higher capacitor okay okay so this is how this could look like in a in a bigger setting where the capacitor could actually be made so over here and the bit line is over here and uh the capacitor is now made between uh somewhere above far above metal four metal five you make these capacitors is that okay capacitor can be implemented in two ways in the previous one we said uh it is right there in the poly so much below metal one at first whereas it can also be implemented by a metal and metal capacitor so mem capacitor where the poly uh the the plug on the source drain actually comes to a much higher voltage level much higher metal level and over there this dielectric is added this is called as capacitor over bit foreign there are other ways to make capacitors so capacitance over a bit we just saw the fin capacitor we also just saw uh we will just look at tens capacitors dense capacitors what do they involve they involve us begin a trench into the silicon substrate and when that is done uh I I make I deposit a very thin line of dielectric there and then I fill this with poly again so now in the trends capacitor you do not even need to go up high up and do not need to waste area and due to contacts and vrs or anything like that the trends can be designed right there inside your memory cell right next to the source drain region it can be connected like that just like this you see the trench is connected to the transistor Source Range region any questions foreign yes okay the transform is actually complex in designing and you see this is how the DRC is defined the aspect ratio if I keep the tense to be wide I can go very very deep yes sir my capacitance can be large if I do not want to give but I lose area if I do not want to give area then due to the very nature of it being a trench I go to lesser depths and my capacitor reduces this is intuitive when they wanted to use Azure capacitance you are ready to probably give more area also but it is important to understand that if area is the primary thing then you can do something more about it by doing away for example with the depth is that okay say area is the main concern over here like yes you reduce the area you reduce the area you therefore end up reducing the depth and the capacitance value yes amount of capacitance so area and capacitance are a direct Head to Head trade-off hmm so what did we look at till now that the capacitor should be big if the capacitor is bigger I can do faster more robust read I can reduce refresh requirements uh I want to keep a bit capacitor but I want to reduce the area penalty and uh see the capacitor is Big what happens to discharge or charge the capacitor also takes longer so right time also increases but we somehow should ensure that right is non-timing critical how do we do that we already talked about wordline Overdrive we talked of it in terms of ensuring that there is no VT drop at the store node uh but in reality when you do Wireline overdrive you also speed things up a bit so right right operation should not be timing critical only read operation should be timing critical hmm so if I want to reduce if I want to reduce area then capacitor becomes smaller um however bit nine capacitance either remain same or increases a bit length of actions per bit cell so the reality is that too as the scaling happens I should use bigger capacitor as I go to more more final geometries I need bigger capacitor but the density requirements of the advanced technology would limit me to use a smaller capacitor in Advanced Technologies Trends capacitors therefore are limited because the dense capacitors try to reduce area try to reduce when you when you want to reduce the area in the tense capacitors the capacitance value reduces but you want to increase the capacitance so uh the metal and metal capacitance all the capacitance over bit is more promising for Advanced Technologies is that okay yes sir when you use metal and metal capacitor there are more steps involved more steps involved means more defectivity can come into picture there can be yield loss uh otherwise there are you know any decision that we make also has an impact on speed on performance Improvement not just area so all these three things have to be kept in mind when we are deciding which kind of technology to go for now if you're going to join any circuit design company then it doesn't make a difference because that's this this thing will be decided for you by the company itself but if you're going to join a company which does not have its own Fab and does not have its own capacitance creation process then you have a choice whether you want to go to tsmc or Global foundries or St or someone to choose the technology and it is for that that this discussion is relevant for you okay so until now what we have seen is that dram cell is based on capacitor storage which is non-general non-regenerative in nature it has very high density to boost off gigabits per centimeter Square and there is therefore for Imaging processors Graphics processors or multimedia processors there is a huge onship dram also that we are talking about however there is a challenge in scaling the dram capacitors and uh the parasitics become more and more important as we go to Advanced Technologies so speed takes a hit especially in the morning hours the speed takes a hit huh and uh okay for these are you definitely need periodic refresh is it cleared in here once again the picture in last night why the about the aid loss yeah so um the more the number of fabrication steps involved the more the probability that there will be some misalignment or some extract effectivity that will come into picture since the stem of the dram capacitor the MIM capacitor needs to be built across multiple process steps multiple layers anywhere if there is a misalignment there could be a loss in the yield because of some Capital systems or something that comes into a picture thank you sir yes,https://www.youtube.com/watch?v=6JyCfEH0GJQ,"Link: https://www.youtube.com/watch?v=6JyCfEH0GJQ
Transcript: yes sir okay so now we look at how this capacitor is designed see we are saying that there is one transistor one capacitor in the dram cell how do we make the capacitor so let's look at this thing over here over here void line is running in the polysilicon so wordline is taken care of bit line connects to one edge of the one in one terminal of the uh likes one either Source or drain of the nmos and the other side has to have a capacitor that capacitor could be made by using poly having a little dielectric in between and then again putting some poly huh so how will this look like in a screenshot something like this where um different what do we say there's a polyphen structure has been used so that overall capacitance is higher this represents the blue one represents the bit line region the pink one is the capacitor the green ones are the other plate other side of the capacitor this is the polygate this is clear are you able to see this so this structure of poly is making them in parallel so to increase the capacitance yes in the in the so you're going vertically you're adding fins yeah so that in the same area you are able to implement a much higher capacitor okay okay so this is how this could look like in a in a bigger setting where the capacitor could actually be made so over here and the bit line is over here and uh the capacitor is now made between uh somewhere above far above metal four metal five you make these capacitors is that okay capacitor can be implemented in two ways in the previous one we said uh it is right there in the poly so much below metal one at first whereas it can also be implemented by a metal and metal capacitor so mem capacitor where the poly uh the the plug on the source drain actually comes to a much higher voltage level much higher metal level and over there this dielectric is added this is called as capacitor over bit foreign there are other ways to make capacitors so capacitance over a bit we just saw the fin capacitor we also just saw uh we will just look at tens capacitors dense capacitors what do they involve they involve us begin a trench into the silicon substrate and when that is done uh I I make I deposit a very thin line of dielectric there and then I fill this with poly again so now in the trends capacitor you do not even need to go up high up and do not need to waste area and due to contacts and vrs or anything like that the trends can be designed right there inside your memory cell right next to the source drain region it can be connected like that just like this you see the trench is connected to the transistor Source Range region any questions foreign yes okay the transform is actually complex in designing and you see this is how the DRC is defined the aspect ratio if I keep the tense to be wide I can go very very deep yes sir my capacitance can be large if I do not want to give but I lose area if I do not want to give area then due to the very nature of it being a trench I go to lesser depths and my capacitor reduces this is intuitive when they wanted to use Azure capacitance you are ready to probably give more area also but it is important to understand that if area is the primary thing then you can do something more about it by doing away for example with the depth is that okay say area is the main concern over here like yes you reduce the area you reduce the area you therefore end up reducing the depth and the capacitance value yes amount of capacitance so area and capacitance are a direct Head to Head trade-off hmm so what did we look at till now that the capacitor should be big if the capacitor is bigger I can do faster more robust read I can reduce refresh requirements uh I want to keep a bit capacitor but I want to reduce the area penalty and uh see the capacitor is Big what happens to discharge or charge the capacitor also takes longer so right time also increases but we somehow should ensure that right is non-timing critical how do we do that we already talked about wordline Overdrive we talked of it in terms of ensuring that there is no VT drop at the store node uh but in reality when you do Wireline overdrive you also speed things up a bit so right right operation should not be timing critical only read operation should be timing critical hmm so if I want to reduce if I want to reduce area then capacitor becomes smaller um however bit nine capacitance either remain same or increases a bit length of actions per bit cell so the reality is that too as the scaling happens I should use bigger capacitor as I go to more more final geometries I need bigger capacitor but the density requirements of the advanced technology would limit me to use a smaller capacitor in Advanced Technologies Trends capacitors therefore are limited because the dense capacitors try to reduce area try to reduce when you when you want to reduce the area in the tense capacitors the capacitance value reduces but you want to increase the capacitance so uh the metal and metal capacitance all the capacitance over bit is more promising for Advanced Technologies is that okay yes sir when you use metal and metal capacitor there are more steps involved more steps involved means more defectivity can come into picture there can be yield loss uh otherwise there are you know any decision that we make also has an impact on speed on performance Improvement not just area so all these three things have to be kept in mind when we are deciding which kind of technology to go for now if you're going to join any circuit design company then it doesn't make a difference because that's this this thing will be decided for you by the company itself but if you're going to join a company which does not have its own Fab and does not have its own capacitance creation process then you have a choice whether you want to go to tsmc or Global foundries or St or someone to choose the technology and it is for that that this discussion is relevant for you okay so until now what we have seen is that dram cell is based on capacitor storage which is non-general non-regenerative in nature it has very high density to boost off gigabits per centimeter Square and there is therefore for Imaging processors Graphics processors or multimedia processors there is a huge onship dram also that we are talking about however there is a challenge in scaling the dram capacitors and uh the parasitics become more and more important as we go to Advanced Technologies so speed takes a hit especially in the morning hours the speed takes a hit huh and uh okay for these are you definitely need periodic refresh is it cleared in here once again the picture in last night why the about the aid loss yeah so um the more the number of fabrication steps involved the more the probability that there will be some misalignment or some extract effectivity that will come into picture since the stem of the dram capacitor the MIM capacitor needs to be built across multiple process steps multiple layers anywhere if there is a misalignment there could be a loss in the yield because of some Capital systems or something that comes into a picture thank you sir yes"
N3uvkAlsa7A,so this appears to be the same as uh SRAM array am I right you have multiple cells rows columns and column selectors row decoders everything this appears to be the same as a regular SRAM array except there is one difference that it is always a square the number of rows is equal to number of columns in a dram why do you think this is required or why do you think this is done to come around to have same cap on wordline and Bitcoin I did not say that the widths of the cell is same as the height of the memory cell I just said number of rows is equal to number of columns I also did not say that the drain capacitance is equal to the gate capacitance I just said rho is equal to number of columns in this decoding bit uh come user might be sorry address decoding bit come use more so actually a very very close so what happens is uh let us say we had a four megabit dram so you have 2K cross 2K array and so four megabits access correctly you would otherwise need 22 bits 22 address bits that is a huge response hello yeah so there's a huge very big address past 22-bit address bus that we are talking about uh to be able to give that kind of bandwidth that many number of pins is not possible when you have off-chip drams or you do not want to Route too many signals so drams therefore say that okay we will organize our data such that 11 bits are used to decode the rows and 11 bits are used to decode the address the columns what we will do is we will first send 11 bits of row address then we will send 11 bits of column address and then I will be able to read one particular bit from this array this is row address this is column address and then I will be able to get this data on the Q bus are you able to see this so what's the benefit of sending 11 11 like are we using less resources yes your password is now 11 instead of 22. okay okay so but but uh what about the power consumption like power cover all the power consumption will be same like 11 11 22 when at a at an instant the power consumption is reduced by half and that's okay that's okay finally you are using much lesser resource in terms of area yes what have you done you have instead of uh reading the entire uh your app getting your bit in one go you are getting it after two cycles not exactly two cycles so what we call as read address stroke leave here we call this as read address stroke Ras and we call uh CA we come up with what is called a cas so there are these two signals read address strobe and column address row which define whether I am giving a row address stroke and column address 2 which define whether I am giving a row address or a column address okay so if I want to have a 16 bit dram I will have a I will have multiple pages multiple pages to get to this 16-bit uh interface every if I call this as a this could block so let us call this as one array or a block so one block gives out one bit if I have 16 blocks then I would need 16 bits at the output so this particular memory is organized as five and two rows and five and two columns huh so 512 rows five and two columns for four megabit capacity and uh I have 16 bits so I go to 16 such pages one page two page three page 4 Page and 16 such pages is that okay so can you repeat this point okay 16 bit okay logically do you realize that in this one page one array I could read only one bit yes yes sir no if I have a 8-bit word I will have to have eight such circuits there yes sir so if I have a cross two dram there are two such Pages if I have a cross four dram four such pages eight D of course eight D Ram eight such pages Banks let us call them let us call them as Banks is that okay hello whatever is foreign there are four sets of data buffers huh row decoding could still be common because so row and column decoding could still be common I have not repeated them you notice this okay yes sir yes sir yes sir number of bits down over yes however in a real implementation you may need to have row decoders again and again you may want to share them across multiple blocks so over here logically I could share them across all the blocks but physically that would mean a lot of capacitances lot of RC to handle so I could repeat through decoders four times instead of eight times column decoders four times instead of eight times because I could share those column decoders across two different pages are you able to see this now all these Road decoders actually get the same row address all the column decoders will get the same column address and therefore you could share them across multiple Banks is it clear now hello any questions so this is very different organization than what you have in the SRAM that is why I'm spending some time on it I will not spend times on those structures or parts which are exactly the same or very similar to how we have in the SRAM but you do realize that this is a very different topology or very different memory organization so it's important that you understand this well is that okay so so if there is a a 4M bit cross 4 then we will just take one zero two four cross one zero two four memory array and ten bits each to decode so if it is 1 0 and 1 of uh Cross Four then I would probably have just one block over here yes but since it is okay since it is 4 megabit total capacity and upon 4 I would say that each each of these things would be 256. 256 kbits so 1K cross one okay you're right okay five one two cross five and two kids you're right,https://www.youtube.com/watch?v=N3uvkAlsa7A,"Link: https://www.youtube.com/watch?v=N3uvkAlsa7A
Transcript: so this appears to be the same as uh SRAM array am I right you have multiple cells rows columns and column selectors row decoders everything this appears to be the same as a regular SRAM array except there is one difference that it is always a square the number of rows is equal to number of columns in a dram why do you think this is required or why do you think this is done to come around to have same cap on wordline and Bitcoin I did not say that the widths of the cell is same as the height of the memory cell I just said number of rows is equal to number of columns I also did not say that the drain capacitance is equal to the gate capacitance I just said rho is equal to number of columns in this decoding bit uh come user might be sorry address decoding bit come use more so actually a very very close so what happens is uh let us say we had a four megabit dram so you have 2K cross 2K array and so four megabits access correctly you would otherwise need 22 bits 22 address bits that is a huge response hello yeah so there's a huge very big address past 22-bit address bus that we are talking about uh to be able to give that kind of bandwidth that many number of pins is not possible when you have off-chip drams or you do not want to Route too many signals so drams therefore say that okay we will organize our data such that 11 bits are used to decode the rows and 11 bits are used to decode the address the columns what we will do is we will first send 11 bits of row address then we will send 11 bits of column address and then I will be able to read one particular bit from this array this is row address this is column address and then I will be able to get this data on the Q bus are you able to see this so what's the benefit of sending 11 11 like are we using less resources yes your password is now 11 instead of 22. okay okay so but but uh what about the power consumption like power cover all the power consumption will be same like 11 11 22 when at a at an instant the power consumption is reduced by half and that's okay that's okay finally you are using much lesser resource in terms of area yes what have you done you have instead of uh reading the entire uh your app getting your bit in one go you are getting it after two cycles not exactly two cycles so what we call as read address stroke leave here we call this as read address stroke Ras and we call uh CA we come up with what is called a cas so there are these two signals read address strobe and column address row which define whether I am giving a row address stroke and column address 2 which define whether I am giving a row address or a column address okay so if I want to have a 16 bit dram I will have a I will have multiple pages multiple pages to get to this 16-bit uh interface every if I call this as a this could block so let us call this as one array or a block so one block gives out one bit if I have 16 blocks then I would need 16 bits at the output so this particular memory is organized as five and two rows and five and two columns huh so 512 rows five and two columns for four megabit capacity and uh I have 16 bits so I go to 16 such pages one page two page three page 4 Page and 16 such pages is that okay so can you repeat this point okay 16 bit okay logically do you realize that in this one page one array I could read only one bit yes yes sir no if I have a 8-bit word I will have to have eight such circuits there yes sir so if I have a cross two dram there are two such Pages if I have a cross four dram four such pages eight D of course eight D Ram eight such pages Banks let us call them let us call them as Banks is that okay hello whatever is foreign there are four sets of data buffers huh row decoding could still be common because so row and column decoding could still be common I have not repeated them you notice this okay yes sir yes sir yes sir number of bits down over yes however in a real implementation you may need to have row decoders again and again you may want to share them across multiple blocks so over here logically I could share them across all the blocks but physically that would mean a lot of capacitances lot of RC to handle so I could repeat through decoders four times instead of eight times column decoders four times instead of eight times because I could share those column decoders across two different pages are you able to see this now all these Road decoders actually get the same row address all the column decoders will get the same column address and therefore you could share them across multiple Banks is it clear now hello any questions so this is very different organization than what you have in the SRAM that is why I'm spending some time on it I will not spend times on those structures or parts which are exactly the same or very similar to how we have in the SRAM but you do realize that this is a very different topology or very different memory organization so it's important that you understand this well is that okay so so if there is a a 4M bit cross 4 then we will just take one zero two four cross one zero two four memory array and ten bits each to decode so if it is 1 0 and 1 of uh Cross Four then I would probably have just one block over here yes but since it is okay since it is 4 megabit total capacity and upon 4 I would say that each each of these things would be 256. 256 kbits so 1K cross one okay you're right okay five one two cross five and two kids you're right"
OonyTryCHFY,is that okay so can you repeat this point okay 16 will tell okay logically do you realize that in this one page one array I could read only one bit yes yes no if I have a 8-bit word I will have to have eight sub circuits there um yes sir so if I have a cross two dram there are two such phases if I have a cross four dram four such pages eight D of course eight D Ram eight such pages Banks let us call them let us call them as Banks is that okay hello whatever is foreign there are four sets of data buffers huh row decoding could still be common because so row and column decoding could still be common I have not repeated them you notice this okay yes sir yes yes number of bits down over yes however in a real implementation you may need to have row decoders again and again you may want to share them across multiple blocks so over here logically I could share them across all the blocks but physically that would mean a lot of capacitances lot of RC to handle so I could repeat through decoders four times instead of eight times column decoders four times instead of eight times because I could share those column decoders across two different pages are you able to see this now all these Road decoders actually get the same row address all the column decoders will get the same column address and therefore you could share them across multiple Banks is it clear now hello any questions so this is very different organization than what you have in the SRAM that is why I'm spending some time on it I will not spend times on those structures or parts which are exactly the same or very similar to how we have in the SRAM but you do realize that this is a very different topology or very different memory organization so it's important that you understand this well is that okay you said say if there is a a 4M bit cross 4 then we will just take one zero two four cross one zero two four memory array and ten bits each to decode so if it is 1 0 and 1 uh of uh Cross Four then I would probably have just one block over here but since it is okay since it is 4 megabit total capacity and upon 4 I would say that each each of these things would be 256. 256 kbits so 1K plus 1K you're right okay five one two cross five and two kids four minutes you're right is that okay yes sir so a logical way to or The Logical diagram of this appears something like this there is a related stroke there is a call column a row address rope column address stroke right enable output enabled and then address bus and data bus okay foreign what have you done your merged data buses into one and we already discussed about how ra Ras and Cas signals are used to merge or reduce reduce the width of the address bus is it clear in an SM also you are either use the Cubase or the data bus but you do not take make that kind of an effort because srams are always embedded dram are usually main memories they are off just off chip so there is a very strong constraint on number of pins that you could have for the drams and therefore everything is done to reduce the pin out of the dram there any questions all right okay no no sound means no questions then so if XK words five and two cross five and two array this is exactly this is the this is The Logical diagram of this memory you may say okay this is logical diagram of that that memory and uh five and two bits are read out per page we could say there are 16 pages so we kind of match that particular memory that we had and uh subset of bits are returned to the CPU so the column decoder there are multiple column decoders and then the subset of these excesses are reported to the CPU the key timings that are linked to a dram to data output hmm TRC which is minimum time between one read at a stroke and another one okay so in addition to whatever time it takes for uh memory to give out data PRC also involves recharge of the bit lines and reset of the memory circuits there so TRC is greater than Trac ticket and then the column address stroke or TCS is the minimum time from CS to valid data now notice that if Trac was 16 nanoseconds this is much lower why because now since amplifier output is already there all that you need to do is do some address decoding and and select which bit to give out whereas for the for the first timing you not only had to do the decoding of the lower row region uh that is the row recorder but also discharge the bit line activate the sense amplifier and then give an output so the RAC is therefore greater than pcas okay and then PCC is the minimum time from the start of one column access to the start of next what do you think this would involve why do you think there is this extra gap between uh pcas and PCC what extra stuff would be involved there it says foreign what could be the extra stuff involved there charging of bit lines laughs uh when you change the column address when you change the column addresses um bit lines are not even being touched once amplifier operation has already happened it is more about resetting the state machine resetting the state machine so that the new decoding can now you know resetting the latches everything so that the new decoding can now start basically coupling now I'm sorry basically settling down huh now uh there are two kinds of reads that could happen in a system in a dram we call them as early read or late read what does that mean so let us look at it over here so you gave read a row address rope and row addresses were put on the bus sense amplifiers were operated and something was done on the sense amplifiers some output is ledged onto the sensor amplifiers now after some time you give the column address rope and after the column address decoding some output can be made available on the output bus what has happened even while you were still reading the rows output enable had gone to low so as soon as as soon as column addresses or sense amplifiers are selected the output can come out on the day out bus so there is one kind of timing over here this is called as early read where output enable was already low there was no no decision making done at that time in late read what happens is much after column address has been given so we assume that output was actually available in the memory but output enable went low much later in this case as soon as output enable went low data out will appear much faster so you see this duration is much smaller than this duration cas2 okay this is called as late read abhi you're not probably able to understand what is the benefit of lay treat but when we will talk about you know uh architectural ways to recover speed or recover performance of drams then this concept of early read and late read will come into picture so just keep this in mind that there are two kinds of reads early reads and late reads and I tell you that over here since the bus is in high impedance Zone for a large part of the time the bus could be used by something else that is the hunter there okay and then you do the late read is that okay early release is that part clear friends we are not in a physical class where I could see your faces and know if you have understood or not we are still in an online class so yes please ask why did follow me sorry I don't want different binded column address came first sorry okay I am not looking at it from my web column address came at the same time output enable was low earlier and in the other case output enable came low much larger the column address or Cas had come so why was the enabled later in second so that is what I said the reason of this why we will talk about later but do we understand the functionality okay here's the benefit of this we will talk about that later but do we understand the functionality part of it huh there are two different timings one timing is much shorter than the other timing okay yes sir similarly for right there could be early right or late right in the sense that uh the data could be large uh the data could be latched as soon as it appeared and the column address appeared or as soon as Cas came or you know the right operation can start right away or data could be last and right operation would start later because again for some reason we will talk about that reason later but just like for over there we had the dependence on arrival time of oel over here we have the dependence on arrival time of wer um okay,https://www.youtube.com/watch?v=OonyTryCHFY,"Link: https://www.youtube.com/watch?v=OonyTryCHFY
Transcript: is that okay so can you repeat this point okay 16 will tell okay logically do you realize that in this one page one array I could read only one bit yes yes no if I have a 8-bit word I will have to have eight sub circuits there um yes sir so if I have a cross two dram there are two such phases if I have a cross four dram four such pages eight D of course eight D Ram eight such pages Banks let us call them let us call them as Banks is that okay hello whatever is foreign there are four sets of data buffers huh row decoding could still be common because so row and column decoding could still be common I have not repeated them you notice this okay yes sir yes yes number of bits down over yes however in a real implementation you may need to have row decoders again and again you may want to share them across multiple blocks so over here logically I could share them across all the blocks but physically that would mean a lot of capacitances lot of RC to handle so I could repeat through decoders four times instead of eight times column decoders four times instead of eight times because I could share those column decoders across two different pages are you able to see this now all these Road decoders actually get the same row address all the column decoders will get the same column address and therefore you could share them across multiple Banks is it clear now hello any questions so this is very different organization than what you have in the SRAM that is why I'm spending some time on it I will not spend times on those structures or parts which are exactly the same or very similar to how we have in the SRAM but you do realize that this is a very different topology or very different memory organization so it's important that you understand this well is that okay you said say if there is a a 4M bit cross 4 then we will just take one zero two four cross one zero two four memory array and ten bits each to decode so if it is 1 0 and 1 uh of uh Cross Four then I would probably have just one block over here but since it is okay since it is 4 megabit total capacity and upon 4 I would say that each each of these things would be 256. 256 kbits so 1K plus 1K you're right okay five one two cross five and two kids four minutes you're right is that okay yes sir so a logical way to or The Logical diagram of this appears something like this there is a related stroke there is a call column a row address rope column address stroke right enable output enabled and then address bus and data bus okay foreign what have you done your merged data buses into one and we already discussed about how ra Ras and Cas signals are used to merge or reduce reduce the width of the address bus is it clear in an SM also you are either use the Cubase or the data bus but you do not take make that kind of an effort because srams are always embedded dram are usually main memories they are off just off chip so there is a very strong constraint on number of pins that you could have for the drams and therefore everything is done to reduce the pin out of the dram there any questions all right okay no no sound means no questions then so if XK words five and two cross five and two array this is exactly this is the this is The Logical diagram of this memory you may say okay this is logical diagram of that that memory and uh five and two bits are read out per page we could say there are 16 pages so we kind of match that particular memory that we had and uh subset of bits are returned to the CPU so the column decoder there are multiple column decoders and then the subset of these excesses are reported to the CPU the key timings that are linked to a dram to data output hmm TRC which is minimum time between one read at a stroke and another one okay so in addition to whatever time it takes for uh memory to give out data PRC also involves recharge of the bit lines and reset of the memory circuits there so TRC is greater than Trac ticket and then the column address stroke or TCS is the minimum time from CS to valid data now notice that if Trac was 16 nanoseconds this is much lower why because now since amplifier output is already there all that you need to do is do some address decoding and and select which bit to give out whereas for the for the first timing you not only had to do the decoding of the lower row region uh that is the row recorder but also discharge the bit line activate the sense amplifier and then give an output so the RAC is therefore greater than pcas okay and then PCC is the minimum time from the start of one column access to the start of next what do you think this would involve why do you think there is this extra gap between uh pcas and PCC what extra stuff would be involved there it says foreign what could be the extra stuff involved there charging of bit lines laughs uh when you change the column address when you change the column addresses um bit lines are not even being touched once amplifier operation has already happened it is more about resetting the state machine resetting the state machine so that the new decoding can now you know resetting the latches everything so that the new decoding can now start basically coupling now I'm sorry basically settling down huh now uh there are two kinds of reads that could happen in a system in a dram we call them as early read or late read what does that mean so let us look at it over here so you gave read a row address rope and row addresses were put on the bus sense amplifiers were operated and something was done on the sense amplifiers some output is ledged onto the sensor amplifiers now after some time you give the column address rope and after the column address decoding some output can be made available on the output bus what has happened even while you were still reading the rows output enable had gone to low so as soon as as soon as column addresses or sense amplifiers are selected the output can come out on the day out bus so there is one kind of timing over here this is called as early read where output enable was already low there was no no decision making done at that time in late read what happens is much after column address has been given so we assume that output was actually available in the memory but output enable went low much later in this case as soon as output enable went low data out will appear much faster so you see this duration is much smaller than this duration cas2 okay this is called as late read abhi you're not probably able to understand what is the benefit of lay treat but when we will talk about you know uh architectural ways to recover speed or recover performance of drams then this concept of early read and late read will come into picture so just keep this in mind that there are two kinds of reads early reads and late reads and I tell you that over here since the bus is in high impedance Zone for a large part of the time the bus could be used by something else that is the hunter there okay and then you do the late read is that okay early release is that part clear friends we are not in a physical class where I could see your faces and know if you have understood or not we are still in an online class so yes please ask why did follow me sorry I don't want different binded column address came first sorry okay I am not looking at it from my web column address came at the same time output enable was low earlier and in the other case output enable came low much larger the column address or Cas had come so why was the enabled later in second so that is what I said the reason of this why we will talk about later but do we understand the functionality okay here's the benefit of this we will talk about that later but do we understand the functionality part of it huh there are two different timings one timing is much shorter than the other timing okay yes sir similarly for right there could be early right or late right in the sense that uh the data could be large uh the data could be latched as soon as it appeared and the column address appeared or as soon as Cas came or you know the right operation can start right away or data could be last and right operation would start later because again for some reason we will talk about that reason later but just like for over there we had the dependence on arrival time of oel over here we have the dependence on arrival time of wer um okay"
YeUscAMF9B4,okay so uh now how do we access the dram so there is a CPU it sends information to the memory controller memory controller then sends information to the dram how does it do it first sends the address and the read row address probe then it sends the address and the column address stroke when it sends the column address to band the address the information from the sense amplifier comes to the data in out buffers this is then sent back to the memory controller and then that is sent back to the CPU so if you look at it in terms of timings so there is this first timing called row command delay prcd which means the row decoders were activated memory was the bit cell bit lines discharged and something was latched onto the sense amplifiers then you do tcas in which the memory controller sent the address to the column decoder and then the sense amplifier sent back the output to the memory controller that is tcas hmm Trac is equal to trcd Plus tcas are you able to see this any questions because RAC meant when you gave the reward a stroke to the time when the output was enabled on the was available on the output bus that means the rcd plus TCS hmm then you need to give some time for pre-charging of the bit line let us say that is the pre so this pre-charging of the bit line happens after trcd or tras and therefore the next uh what do you say rows row command can be given after bit lines have been pre-charged so tras plus T pre that is TRC this is also called as row cycle time is it okay is it clear till here any questions foreign so we've looked at multiple timings until now trcd pcas so this is this is the time which is the shortest time do you realize that this is the fastest that your dram can give output so this is the time that is given uh you know talked about in the ads that this is the fastest dram that we have and so on huh uh PRC is something that a minute system designers and the drama manufacturers know is important and uh for a computer architect you're not really bothered about when I can do the next row access what you're bothered about is I had a mess how quickly can you give the output to me so Trac is what is of interest to the computer architect there is that okay any questions when you said that the charge is done while reading only why is it a separate component here so pritas is done after the sense amplifier information has been given out and uh you no longer need the sense amplifier outputation and you know uh it has to be a separate component now when the rcd can understand and I cannot come in rcd okay so in terms of latency how much time it actually takes from the CPU to this you will see that uh depending on what operation we are talking about whether it is only cash collimator stroke that is required or row address rope and column address row both required or you need to access two different rows therefore these are also required based on that even E2 or E3 will be used but in reality there will be lots of delays first first you will put transaction request into the queue then it goes to the memory controller then it goes to the command sequencer then it goes to the the command is sent to the dram then dram takes its own sweet time the ones that are that you talked about and then all this information is sent back to the CPU you now realize why access to the main memory could be of the order of microseconds or hundreds of nanoseconds dram doesn't take that much time by itself but there are so many additional transactions that need to happen that it takes a lot of time are you able to see this yes so when you talk of a dram and performance of a dram if you just focus on this part it may not really change the system performance significantly if you really want to improve the system performance you have to look at all A B C D E and F and then see whichever is dominating and reduce those timings is that okay yes sir yeah so let's just take you know one one sample 60 nanoseconds is the Trac 110 nanoseconds is the PRC column is 15 then time between column accesses is 35. but in Practical as we just said there are so many other things that come into picture this 15 goes to 40 to 50 nanoseconds take care and then because and then in reality that 40 to 50 or whatever becomes 180 to 250 nanoseconds latency when it comes to the processor part is that okay so that A B C D E and F so a plus b plus C plus d plus s is a huge amount could be anything between 120 to 180 nanoseconds whereas your memory trse is at 60. is that okay,https://www.youtube.com/watch?v=YeUscAMF9B4,"Link: https://www.youtube.com/watch?v=YeUscAMF9B4
Transcript: okay so uh now how do we access the dram so there is a CPU it sends information to the memory controller memory controller then sends information to the dram how does it do it first sends the address and the read row address probe then it sends the address and the column address stroke when it sends the column address to band the address the information from the sense amplifier comes to the data in out buffers this is then sent back to the memory controller and then that is sent back to the CPU so if you look at it in terms of timings so there is this first timing called row command delay prcd which means the row decoders were activated memory was the bit cell bit lines discharged and something was latched onto the sense amplifiers then you do tcas in which the memory controller sent the address to the column decoder and then the sense amplifier sent back the output to the memory controller that is tcas hmm Trac is equal to trcd Plus tcas are you able to see this any questions because RAC meant when you gave the reward a stroke to the time when the output was enabled on the was available on the output bus that means the rcd plus TCS hmm then you need to give some time for pre-charging of the bit line let us say that is the pre so this pre-charging of the bit line happens after trcd or tras and therefore the next uh what do you say rows row command can be given after bit lines have been pre-charged so tras plus T pre that is TRC this is also called as row cycle time is it okay is it clear till here any questions foreign so we've looked at multiple timings until now trcd pcas so this is this is the time which is the shortest time do you realize that this is the fastest that your dram can give output so this is the time that is given uh you know talked about in the ads that this is the fastest dram that we have and so on huh uh PRC is something that a minute system designers and the drama manufacturers know is important and uh for a computer architect you're not really bothered about when I can do the next row access what you're bothered about is I had a mess how quickly can you give the output to me so Trac is what is of interest to the computer architect there is that okay any questions when you said that the charge is done while reading only why is it a separate component here so pritas is done after the sense amplifier information has been given out and uh you no longer need the sense amplifier outputation and you know uh it has to be a separate component now when the rcd can understand and I cannot come in rcd okay so in terms of latency how much time it actually takes from the CPU to this you will see that uh depending on what operation we are talking about whether it is only cash collimator stroke that is required or row address rope and column address row both required or you need to access two different rows therefore these are also required based on that even E2 or E3 will be used but in reality there will be lots of delays first first you will put transaction request into the queue then it goes to the memory controller then it goes to the command sequencer then it goes to the the command is sent to the dram then dram takes its own sweet time the ones that are that you talked about and then all this information is sent back to the CPU you now realize why access to the main memory could be of the order of microseconds or hundreds of nanoseconds dram doesn't take that much time by itself but there are so many additional transactions that need to happen that it takes a lot of time are you able to see this yes so when you talk of a dram and performance of a dram if you just focus on this part it may not really change the system performance significantly if you really want to improve the system performance you have to look at all A B C D E and F and then see whichever is dominating and reduce those timings is that okay yes sir yeah so let's just take you know one one sample 60 nanoseconds is the Trac 110 nanoseconds is the PRC column is 15 then time between column accesses is 35. but in Practical as we just said there are so many other things that come into picture this 15 goes to 40 to 50 nanoseconds take care and then because and then in reality that 40 to 50 or whatever becomes 180 to 250 nanoseconds latency when it comes to the processor part is that okay so that A B C D E and F so a plus b plus C plus d plus s is a huge amount could be anything between 120 to 180 nanoseconds whereas your memory trse is at 60. is that okay"
6-vUPjakndo,design so what we're looking at in the last class was until timings we looked at earlier late read we'll do a quick review of the timings again so first thing is that when you want to access a dram dram array is organized as a as a square we already discussed that then in addition to that the dram array you know as many number of bits you may have that many number of arrays would exist so it appears like a cube it appears like a n cross n cross M cuboid as many number of bits as many pages would be there and uh we are able to read and write all the n m number of bits at the time at the same time however each embed access requires one Ras cycle that is row address drop cycle and one column address stroke cycle is this clear still here yes sir then there are these timings that we discussed the rope rcd the row cycle delay the column address delay the read add the read address uh access time the pre-charge time the read cycle time and the column cycle time huh and then uh just give me a second so my system is playing some pranks today so any questions still here how do you think we would recharge bit lengths to be ready by 2 over here it is written that bit lines are precharged will be by 2. how do you think you would do that hmm how do you think it would be charged to VD by to the bit lines if you were to do it what would you do so we have to put a like a voltage regulator between the source of the bit line okay could there be a simpler way yes previously we have seen a few points stabilization thing in the system so we can use the same structure of that thing over here foreign you're talking about cue Point stabilization okay so can we put a resistance which will give equal resistance a bit line so it will act as a voltage divider and V2 divided what about power consumption at that time yeah yes yes so see whenever you think of a solution think of all the three aspects power performance and area you have to look at all the various aspects linked to the circuit there so think about it will come to the answer in a little uh the answer would also be interesting in in the uh so these are these are kind of Link questions how do you pre-charge bitline to VD by to how do you ensure that you have a reference bit line because the cell only has one bit line so how will you bring in the second bit line to the sense amplifier all those things so all those things you have to think about continue to think about that while we are proceeding with the class so we also discussed that okay there is a memory controller there is a memory chip or processor and there would be uh so there's this processor there's a memory chip and to the memory controller the processor would send information to the memory chip get the data in there and all this all this paraphernalia plays around we had looked at the delays total delays where we said that uh for a for a memory which has 20 to 50 nanoseconds of delays the overall CPU latency that they will observe will be of the order of 200 to 250 nanoseconds you remember because there is a memory controller in between there is a lot of sequencing that needs to be done synchronization that needs to be done because of which the delays actually increase quite a bit are you with me hello yes sir yes sir okay so now it means that the delays are bad and we somehow need to improve the performance so what is done is see at any point of time at any point of time I anyway access the entire row once I select a particular row all the sense amplifiers for that particular page will read [Music] hmm similarly now there are M pages so for all the M Pages these n columns would have been read so in in in fact by the time the read operation completes I have completed actually accessed M cross and cells of the dram yes if I say that again using the uh the property of locality of reference that typically data of a program or an image would be shared or would be stored in consecutive locations then first I have actually accessed M cross n Bits of one particular feature and that can be made available to me in a in terms of since amplifier latches or whichever way you want to look at it huh I have written the term n cross M SRAM so because that is we are talking about latches these lattice could be a sense amplifier lashes also but I could just put additional latches there somewhere so that I have a m cross n Bits of data available with me in the in the output plane and then as I want to access subsequent words all that I need to do is so first I gave our address and the column address to get the first word out then I only need to change the column address and I will get the remaining and word route or remaining and minus words out this access is called as Burst Mode or fast page mode so what has happened even though my rcd everything was very high my finally Peak bandwidth or Peak access rate is dependent on tcas only and this is faster much faster than if I would say that uh my access time is Trac so this the first Ambit accesses the RAC the subsequent ones are TCA are you able to see this just to clarify one thing as you have said in the previous lecture the TCC is a time between two cas es yeah so you you call it as TCC then okay okay thank you okay so let us look at this example let us say hello that n cross M SRAM is additional to that caches or is that a cache should be uh so I said this could be I'm calling it an enclos and restaurant this could be a set of actually it could actually be an across Ms Ram or it could simply be some samplifier latches which I say are kind of storing data for that that period of time it could be additional to cash it could be additional to the dram also okay yes sir so now let us say that uh there is a 16-bit cross 1md ram huh and there are four numbers in the package so the total so this is one one diram and it is saying there are four numbers in the package so if package has one dram second dram 30 Ram 40 Ram all start one over the other physically different that is stacked one over the other and now the question is uh you know it also gives the what do you say read cycle time read write cycle time and uh page mode access time and everything it is given now what is the bandwidth for one word you have 64 bits in each word so eight bytes upon 110 nanoseconds the bandwidth is only 69.35 megabit megabytes per second if I were to access another word two words then so 110 plus 40 my bandwidth at once jumped from 69 to 101 that is almost uh let us say 45 increase in bandwidth and if I want to find Peak bandwidth then do you realize that I am actually able to read 8 bytes every 40 nanoseconds so my Peak bandwidth is actually 190. megabytes per second um and the maximum sustained bandwidth because I have a one megabit stage one megabit page which means I have 256 rows and 256 columns if I have 256 columns I can access so my the SRAM down below would be 256 cross 64. because 64 bits are there so I can actually access 256 64-bit words in one row access so if I talk of Maximum sustained bandwidth then there are 256 words of 8 bytes each total time taken is 110 nanoseconds for the first read and 40 nanoseconds for the remaining to 255 reads and sustained bandwidth is 189.43 megabytes per second you see the transition from 69 to 189 that is the benefit of burst mode or fast page mode any questions so one package I have 16 bits four package at 64. one package only one die one die has 16 bits so there are 16 pages per die and there are four such dies on the inside the package so 64 bits can be accessed so at the time I am accessing 256 cross 64 bits yes is it okay since the last expression we have taken 256 words only because we are considering one single row like inner row we'll we are changing the columns right yes okay okay so you can anything else or is this clear so this bandwidth is indicating the output of dram like Elevate the bandwidth is coming from dram to processor will be one bit only way in each cycle why skin bit only why is my data see I have said that I wanted a 64-bit module so I could have a 64 bit byte data bus now okay yeah why would it be 16 bits each each die will have database so 64. yeah but the package has four dies in it so there are 64 cents that the package has Anna so the processor output data to database access only one one die no who said one die so this is okay so let us let us go into a little more detail of multi-di packages we talked about it in DVD I think I do not distinctly remember in multi-die packages what has done is there is a substrate okay which has all the pins there these are what are soldered onto your pcbs okay and multiple dies means that each diodes have its pins connecting to different package level pins okay so if I have a 64-bit module it means there were 64 pins available uh die 1 connected to 16 bits Die 2 connected to another 16 bit type 3 connected to another 16 bits Type 4 connected to another 16 bits so 64 bits are accessible in parallel otherwise I would not have called it a 64-bit module foreign [Music] yes sir here first we need to do a loaded body and then after that we we can decode the column addresses so we will need maximum sustain bandwidth what is the significance of the speed bandwidth uh big band versus the is the bandwidth that you would require in your buffer for example if you have two different uh frequencies interfacing at some place and you need a buffer so the peak bandwidth is what you would require to design the or to decide the depth of the buffer there okay so it's just like that the maximum bandwidth that that it can go yes oh thank you okay so now that was one way to look at it we said that there is a simple organization CPU needed 64 bits and 64 bits were available in the cache and 64 bits are available in the memory also however there could be multiple ways in which performance can be further improved so we already saw Burst Mode improved performance there are other ways to improve performance which is we say we will use a wide memory what does that mean that means that CPU needs let us say 32 bits only but my cache and my final main memory would have 64 bits or 56-bit words so I access only one word but that word is so wide that in reality I'm accessing two or or eight or many many more words you remember the concept of line length when we were talking about L2 caches but how many words would be there in one line hello block size yes so that is this is that example where we say that even L1 cache has a line length of four words so four words are accessed in every cycle out of those four words depending on the multiplexer like the the which of those four words is required by the processor some address bits will go into the multiplexer there and the CPU would get the access to those that information and then from Cache to memory it is the same very wide bus let us say 26 bit byte bus the problem with this approach is that your L1 cache has also become very wide so it starts to become slow whereas the purpose of putting the cache in between was that the CPU should be able to get data much faster so this is not really the best way to design the best would be if I could mix both of these and arrive at what we call as interleaved design so CPU to Cache same password if it has a 16 bit processor then 16 but bit bus fat 64-bit processor then 64-bit password whatever it is foreign controller and can access multiple Banks and that multiplexing happens at the memory bank to Cache transfer level so the four the four modules example that we just saw it is something like this that we had a suppose a CPU was 16 bit cache was also 16 bit but I had four modules of 16 bit each foreign and they will all be accessed all the 64 bits will be accessed in one row and transfer to the cache through this bus is it clear sir in wide in widewell option what we are doing we are increasing the word per row so that we can read more words uh number of so okay so invite what I have done is that if my word width was 16 earlier I increase the word width to let us say 32 or 64. so when I read one word of the cache I'm actually reading uh two or four equivalent words for the CPU is that okay we are we are increasing the size of one word yes and we are getting this word from memory to Cache yeah cash also has a wide wide Behavior there so cache is also wide okay its length length also will increase accordingly no actually the length would reduce in in the wide implementation line length is actually um if it was getting forward it will get two words if I increase the what size is okay so if you want to put it like that what you are what you are then imagining or what you are then saying is is that my CPU is 16 bit my cache L1 cache you're saying is 32 32 and my this is 64. is that what you're saying yes sir yeah in that case you are right if but if this was 16 then I would rather say this is 16 16 and 16. okay so so like I'm not able to get on work basis we are improving the performance or on board basis we are measuring the performance like how quickly memory is giving the data to the cache or how click the CPU is fetching the foreign I got like I am not able to see the performance gain can you so what was the performance again if my if my final let us say I do access time was lesser because I am I have four words available to me right away instead of one word I have four words available to me right away then oh first word will take some time but the remaining three words are right there multiplexer delay is the only delay there okay Thomas has improved now yes sir yes sir and and for the elderly parts interlude part uh over here you are getting a larger line into the cache writing into the cache from the main memory to the cache may take a little longer but that's not a problem uh because the first word you would have anyways received first by the time the request for the next word comes the next word and third word would also already be written so we have uh like we are readily available more number of words yes okay okay same thing as Burst Mode yes yes thank you thank you now this is not there or this is not fully satisfying to designers just yet so what we also did was that when we were interleaving the memories instead of initiating access after you know D1 is fully available and everything the one is reset and everything we say that let us start to access in a staggered manner such that when I start to access bank 0 Again by that time its earlier operation pre-charge Operation has already finished see if it was One Bank only then my next row access would be starting only after a long time after free chat has happened and something has happened next okay our next column accessory so there was some additional delay there was ta plus then T reset for the column for the column that was there Hannah so when we interleave memories because we are now have independent arrays we can utilize this pre-charge time or whatever reset time of any bank is to access the same information same words from the other Banks so my overall throughput increases is that okay I said basically just like pipelining we are accessing these memory banks yes within that time frame very good yes [Music] we will access all the banks all the dice at a time so here what we are doing here accessing Banks industry okay okay it's a bank same type we are accessing blank in a different time okay so now let us look at how the performance improves in all those three cases for the simple case if you have to access four words what would you need to do four into one plus ten plus one then is the cycle time and one cycle for sending data to and from the memory so 1 plus 10 plus 1 into 4. if it was the wide memory then the total delay would be one plus ten plus one however if it is an interleaved memory then one plus ten plus one will be there but the other three words will be accessed without any extra penalty just one cycle penalty and therefore this is 15. foreign to three so that you need to access the second row on the same page only after four addresses have been read so there is a reduced constraint on time that you take to reset time that you take to pre-charge and you can reduce those sizes you can save power you can do many more things in this additional bandwidth that you have is that okay so I'm not able to visualize this example can you please elaborate to double clue foreign [Music] [Music] greater weights of cash and bus and getting lesser time but in in interlude we are using uh lesser width of cash and bus and still getting the equivalent time using this increasing bandwidth yeah equivalent means similar order not equal 15 to 20 percent of every body at time 25 percent yes that you could talk about or Peak sustained bandwidth that we could talk about so the challenge between or the comparison between the two is five memory it is a huge cost that many extra pins need to be there there is a multiplexer that needs to be put between cache and CPU which may lead to more delays interleaved on the other hand on the other hand is uh not as much area increase uh each die is smaller in area so each die has a better yield and all those things the only challenges if you want to expand the memory by little amount just you know let me add just two two gigabytes into this 128 gigabytes memory that will not be possible because in interlude memory you have a very clear defined structure and then you go to this sorry what is this diagram this diagram so because we already have this defined structure so change in the memory is quite difficult and internally yes okay okay okay,https://www.youtube.com/watch?v=6-vUPjakndo,"Link: https://www.youtube.com/watch?v=6-vUPjakndo
Transcript: design so what we're looking at in the last class was until timings we looked at earlier late read we'll do a quick review of the timings again so first thing is that when you want to access a dram dram array is organized as a as a square we already discussed that then in addition to that the dram array you know as many number of bits you may have that many number of arrays would exist so it appears like a cube it appears like a n cross n cross M cuboid as many number of bits as many pages would be there and uh we are able to read and write all the n m number of bits at the time at the same time however each embed access requires one Ras cycle that is row address drop cycle and one column address stroke cycle is this clear still here yes sir then there are these timings that we discussed the rope rcd the row cycle delay the column address delay the read add the read address uh access time the pre-charge time the read cycle time and the column cycle time huh and then uh just give me a second so my system is playing some pranks today so any questions still here how do you think we would recharge bit lengths to be ready by 2 over here it is written that bit lines are precharged will be by 2. how do you think you would do that hmm how do you think it would be charged to VD by to the bit lines if you were to do it what would you do so we have to put a like a voltage regulator between the source of the bit line okay could there be a simpler way yes previously we have seen a few points stabilization thing in the system so we can use the same structure of that thing over here foreign you're talking about cue Point stabilization okay so can we put a resistance which will give equal resistance a bit line so it will act as a voltage divider and V2 divided what about power consumption at that time yeah yes yes so see whenever you think of a solution think of all the three aspects power performance and area you have to look at all the various aspects linked to the circuit there so think about it will come to the answer in a little uh the answer would also be interesting in in the uh so these are these are kind of Link questions how do you pre-charge bitline to VD by to how do you ensure that you have a reference bit line because the cell only has one bit line so how will you bring in the second bit line to the sense amplifier all those things so all those things you have to think about continue to think about that while we are proceeding with the class so we also discussed that okay there is a memory controller there is a memory chip or processor and there would be uh so there's this processor there's a memory chip and to the memory controller the processor would send information to the memory chip get the data in there and all this all this paraphernalia plays around we had looked at the delays total delays where we said that uh for a for a memory which has 20 to 50 nanoseconds of delays the overall CPU latency that they will observe will be of the order of 200 to 250 nanoseconds you remember because there is a memory controller in between there is a lot of sequencing that needs to be done synchronization that needs to be done because of which the delays actually increase quite a bit are you with me hello yes sir yes sir okay so now it means that the delays are bad and we somehow need to improve the performance so what is done is see at any point of time at any point of time I anyway access the entire row once I select a particular row all the sense amplifiers for that particular page will read [Music] hmm similarly now there are M pages so for all the M Pages these n columns would have been read so in in in fact by the time the read operation completes I have completed actually accessed M cross and cells of the dram yes if I say that again using the uh the property of locality of reference that typically data of a program or an image would be shared or would be stored in consecutive locations then first I have actually accessed M cross n Bits of one particular feature and that can be made available to me in a in terms of since amplifier latches or whichever way you want to look at it huh I have written the term n cross M SRAM so because that is we are talking about latches these lattice could be a sense amplifier lashes also but I could just put additional latches there somewhere so that I have a m cross n Bits of data available with me in the in the output plane and then as I want to access subsequent words all that I need to do is so first I gave our address and the column address to get the first word out then I only need to change the column address and I will get the remaining and word route or remaining and minus words out this access is called as Burst Mode or fast page mode so what has happened even though my rcd everything was very high my finally Peak bandwidth or Peak access rate is dependent on tcas only and this is faster much faster than if I would say that uh my access time is Trac so this the first Ambit accesses the RAC the subsequent ones are TCA are you able to see this just to clarify one thing as you have said in the previous lecture the TCC is a time between two cas es yeah so you you call it as TCC then okay okay thank you okay so let us look at this example let us say hello that n cross M SRAM is additional to that caches or is that a cache should be uh so I said this could be I'm calling it an enclos and restaurant this could be a set of actually it could actually be an across Ms Ram or it could simply be some samplifier latches which I say are kind of storing data for that that period of time it could be additional to cash it could be additional to the dram also okay yes sir so now let us say that uh there is a 16-bit cross 1md ram huh and there are four numbers in the package so the total so this is one one diram and it is saying there are four numbers in the package so if package has one dram second dram 30 Ram 40 Ram all start one over the other physically different that is stacked one over the other and now the question is uh you know it also gives the what do you say read cycle time read write cycle time and uh page mode access time and everything it is given now what is the bandwidth for one word you have 64 bits in each word so eight bytes upon 110 nanoseconds the bandwidth is only 69.35 megabit megabytes per second if I were to access another word two words then so 110 plus 40 my bandwidth at once jumped from 69 to 101 that is almost uh let us say 45 increase in bandwidth and if I want to find Peak bandwidth then do you realize that I am actually able to read 8 bytes every 40 nanoseconds so my Peak bandwidth is actually 190. megabytes per second um and the maximum sustained bandwidth because I have a one megabit stage one megabit page which means I have 256 rows and 256 columns if I have 256 columns I can access so my the SRAM down below would be 256 cross 64. because 64 bits are there so I can actually access 256 64-bit words in one row access so if I talk of Maximum sustained bandwidth then there are 256 words of 8 bytes each total time taken is 110 nanoseconds for the first read and 40 nanoseconds for the remaining to 255 reads and sustained bandwidth is 189.43 megabytes per second you see the transition from 69 to 189 that is the benefit of burst mode or fast page mode any questions so one package I have 16 bits four package at 64. one package only one die one die has 16 bits so there are 16 pages per die and there are four such dies on the inside the package so 64 bits can be accessed so at the time I am accessing 256 cross 64 bits yes is it okay since the last expression we have taken 256 words only because we are considering one single row like inner row we'll we are changing the columns right yes okay okay so you can anything else or is this clear so this bandwidth is indicating the output of dram like Elevate the bandwidth is coming from dram to processor will be one bit only way in each cycle why skin bit only why is my data see I have said that I wanted a 64-bit module so I could have a 64 bit byte data bus now okay yeah why would it be 16 bits each each die will have database so 64. yeah but the package has four dies in it so there are 64 cents that the package has Anna so the processor output data to database access only one one die no who said one die so this is okay so let us let us go into a little more detail of multi-di packages we talked about it in DVD I think I do not distinctly remember in multi-die packages what has done is there is a substrate okay which has all the pins there these are what are soldered onto your pcbs okay and multiple dies means that each diodes have its pins connecting to different package level pins okay so if I have a 64-bit module it means there were 64 pins available uh die 1 connected to 16 bits Die 2 connected to another 16 bit type 3 connected to another 16 bits Type 4 connected to another 16 bits so 64 bits are accessible in parallel otherwise I would not have called it a 64-bit module foreign [Music] yes sir here first we need to do a loaded body and then after that we we can decode the column addresses so we will need maximum sustain bandwidth what is the significance of the speed bandwidth uh big band versus the is the bandwidth that you would require in your buffer for example if you have two different uh frequencies interfacing at some place and you need a buffer so the peak bandwidth is what you would require to design the or to decide the depth of the buffer there okay so it's just like that the maximum bandwidth that that it can go yes oh thank you okay so now that was one way to look at it we said that there is a simple organization CPU needed 64 bits and 64 bits were available in the cache and 64 bits are available in the memory also however there could be multiple ways in which performance can be further improved so we already saw Burst Mode improved performance there are other ways to improve performance which is we say we will use a wide memory what does that mean that means that CPU needs let us say 32 bits only but my cache and my final main memory would have 64 bits or 56-bit words so I access only one word but that word is so wide that in reality I'm accessing two or or eight or many many more words you remember the concept of line length when we were talking about L2 caches but how many words would be there in one line hello block size yes so that is this is that example where we say that even L1 cache has a line length of four words so four words are accessed in every cycle out of those four words depending on the multiplexer like the the which of those four words is required by the processor some address bits will go into the multiplexer there and the CPU would get the access to those that information and then from Cache to memory it is the same very wide bus let us say 26 bit byte bus the problem with this approach is that your L1 cache has also become very wide so it starts to become slow whereas the purpose of putting the cache in between was that the CPU should be able to get data much faster so this is not really the best way to design the best would be if I could mix both of these and arrive at what we call as interleaved design so CPU to Cache same password if it has a 16 bit processor then 16 but bit bus fat 64-bit processor then 64-bit password whatever it is foreign controller and can access multiple Banks and that multiplexing happens at the memory bank to Cache transfer level so the four the four modules example that we just saw it is something like this that we had a suppose a CPU was 16 bit cache was also 16 bit but I had four modules of 16 bit each foreign and they will all be accessed all the 64 bits will be accessed in one row and transfer to the cache through this bus is it clear sir in wide in widewell option what we are doing we are increasing the word per row so that we can read more words uh number of so okay so invite what I have done is that if my word width was 16 earlier I increase the word width to let us say 32 or 64. so when I read one word of the cache I'm actually reading uh two or four equivalent words for the CPU is that okay we are we are increasing the size of one word yes and we are getting this word from memory to Cache yeah cash also has a wide wide Behavior there so cache is also wide okay its length length also will increase accordingly no actually the length would reduce in in the wide implementation line length is actually um if it was getting forward it will get two words if I increase the what size is okay so if you want to put it like that what you are what you are then imagining or what you are then saying is is that my CPU is 16 bit my cache L1 cache you're saying is 32 32 and my this is 64. is that what you're saying yes sir yeah in that case you are right if but if this was 16 then I would rather say this is 16 16 and 16. okay so so like I'm not able to get on work basis we are improving the performance or on board basis we are measuring the performance like how quickly memory is giving the data to the cache or how click the CPU is fetching the foreign I got like I am not able to see the performance gain can you so what was the performance again if my if my final let us say I do access time was lesser because I am I have four words available to me right away instead of one word I have four words available to me right away then oh first word will take some time but the remaining three words are right there multiplexer delay is the only delay there okay Thomas has improved now yes sir yes sir and and for the elderly parts interlude part uh over here you are getting a larger line into the cache writing into the cache from the main memory to the cache may take a little longer but that's not a problem uh because the first word you would have anyways received first by the time the request for the next word comes the next word and third word would also already be written so we have uh like we are readily available more number of words yes okay okay same thing as Burst Mode yes yes thank you thank you now this is not there or this is not fully satisfying to designers just yet so what we also did was that when we were interleaving the memories instead of initiating access after you know D1 is fully available and everything the one is reset and everything we say that let us start to access in a staggered manner such that when I start to access bank 0 Again by that time its earlier operation pre-charge Operation has already finished see if it was One Bank only then my next row access would be starting only after a long time after free chat has happened and something has happened next okay our next column accessory so there was some additional delay there was ta plus then T reset for the column for the column that was there Hannah so when we interleave memories because we are now have independent arrays we can utilize this pre-charge time or whatever reset time of any bank is to access the same information same words from the other Banks so my overall throughput increases is that okay I said basically just like pipelining we are accessing these memory banks yes within that time frame very good yes [Music] we will access all the banks all the dice at a time so here what we are doing here accessing Banks industry okay okay it's a bank same type we are accessing blank in a different time okay so now let us look at how the performance improves in all those three cases for the simple case if you have to access four words what would you need to do four into one plus ten plus one then is the cycle time and one cycle for sending data to and from the memory so 1 plus 10 plus 1 into 4. if it was the wide memory then the total delay would be one plus ten plus one however if it is an interleaved memory then one plus ten plus one will be there but the other three words will be accessed without any extra penalty just one cycle penalty and therefore this is 15. foreign to three so that you need to access the second row on the same page only after four addresses have been read so there is a reduced constraint on time that you take to reset time that you take to pre-charge and you can reduce those sizes you can save power you can do many more things in this additional bandwidth that you have is that okay so I'm not able to 
visualize this example can you please elaborate to double clue foreign [Music] [Music] greater weights of cash and bus and getting lesser time but in in interlude we are using uh lesser width of cash and bus and still getting the equivalent time using this increasing bandwidth yeah equivalent means similar order not equal 15 to 20 percent of every body at time 25 percent yes that you could talk about or Peak sustained bandwidth that we could talk about so the challenge between or the comparison between the two is five memory it is a huge cost that many extra pins need to be there there is a multiplexer that needs to be put between cache and CPU which may lead to more delays interleaved on the other hand on the other hand is uh not as much area increase uh each die is smaller in area so each die has a better yield and all those things the only challenges if you want to expand the memory by little amount just you know let me add just two two gigabytes into this 128 gigabytes memory that will not be possible because in interlude memory you have a very clear defined structure and then you go to this sorry what is this diagram this diagram so because we already have this defined structure so change in the memory is quite difficult and internally yes okay okay okay"
BfhEwOlGDIk,so another set of Innovations happened which so that was one aspect another set of Innovations happened where at around DQ so this was let us say sample drum you would Row Central address and column address there will be valid output for some time and then you would in this duration you will reset the memory and then you would send the next true address the next column address and so on huh this is the simple drum however if I say that there is this additional SRAM array in in between the dram and the multiplexer then what happens then I could simply I would access one row get all the data of all the columns or all the two six words in one go and then I would just need to change the column address over and over again to get the remaining 255 words there's also we saw this is the fast fast page Burst Mode access I'm just showing it to you in terms of timing diagrams differently now now further Improvement of fast page mode how do you do that you say that uh I so while my old data is still valid I have sent the new column address and uh since I had sent the column address earlier at first my next access will come happen faster look at this only after old data was no longer valid I sent the row address row or the column address stroke there over here we are saying as soon as I have finally sampled let us say valid output I can switch over to access the next valid output so I can update the column address also within the cycle is that okay that time it will not affect to valid data out like foreign duration for which my previous data will be valid after the new address rope comes so that is a function of full time if that whole time is less then this then this gray region will shorten if that whole time is large then whether this grave region shortens or not doesn't matter you know that uh you're able to access faster I want to verify like in the row address when we give the row address that row will be decoded and since amplifier sends the agile so that is last either at the sense amplifier level or at the layer of this n cross Ms and some uh memory SRAM okay um not again we again column address like saratos and symbols this could be fully Random Access now can you do just one word and then the next word that I needed was I'm in a very different place stable inside the memory access then here we are talking about reading the burst operation reading same row yeah same row that has been accessed and is now available in the SRAM when do I initiate the next read on the SRAM there is then we have to give a row address parameters so even in this even in this Edo dram if the addressing is completely random you go back to the original first case are you able to see this the advance go go back to the dram team so this is still further where we say that I do not need to send addresses again and again and again I would rather have a clock signal and then at every clock I will initiate the new access so valid data comes much much faster now hello [Music] only like we give our address oh yes saying that column address will change only one by one yes is okay,https://www.youtube.com/watch?v=BfhEwOlGDIk,"Link: https://www.youtube.com/watch?v=BfhEwOlGDIk
Transcript: so another set of Innovations happened which so that was one aspect another set of Innovations happened where at around DQ so this was let us say sample drum you would Row Central address and column address there will be valid output for some time and then you would in this duration you will reset the memory and then you would send the next true address the next column address and so on huh this is the simple drum however if I say that there is this additional SRAM array in in between the dram and the multiplexer then what happens then I could simply I would access one row get all the data of all the columns or all the two six words in one go and then I would just need to change the column address over and over again to get the remaining 255 words there's also we saw this is the fast fast page Burst Mode access I'm just showing it to you in terms of timing diagrams differently now now further Improvement of fast page mode how do you do that you say that uh I so while my old data is still valid I have sent the new column address and uh since I had sent the column address earlier at first my next access will come happen faster look at this only after old data was no longer valid I sent the row address row or the column address stroke there over here we are saying as soon as I have finally sampled let us say valid output I can switch over to access the next valid output so I can update the column address also within the cycle is that okay that time it will not affect to valid data out like foreign duration for which my previous data will be valid after the new address rope comes so that is a function of full time if that whole time is less then this then this gray region will shorten if that whole time is large then whether this grave region shortens or not doesn't matter you know that uh you're able to access faster I want to verify like in the row address when we give the row address that row will be decoded and since amplifier sends the agile so that is last either at the sense amplifier level or at the layer of this n cross Ms and some uh memory SRAM okay um not again we again column address like saratos and symbols this could be fully Random Access now can you do just one word and then the next word that I needed was I'm in a very different place stable inside the memory access then here we are talking about reading the burst operation reading same row yeah same row that has been accessed and is now available in the SRAM when do I initiate the next read on the SRAM there is then we have to give a row address parameters so even in this even in this Edo dram if the addressing is completely random you go back to the original first case are you able to see this the advance go go back to the dram team so this is still further where we say that I do not need to send addresses again and again and again I would rather have a clock signal and then at every clock I will initiate the new access so valid data comes much much faster now hello [Music] only like we give our address oh yes saying that column address will change only one by one yes is okay"
Y9_7E27hRZw,so now with with the speed aspect taken care of huh we look at how to design the reference the question that uh that came earlier in the class how do you get the reference bit line hmm so what we do is in our typical uh dram we would use a level restoring sense amplifier what does level restoring sense amplifier mean it means that there is no pass gate in between now so the sense amplifier is connected and coupled with the bit line at all times are you able to see this when this ensemplifier will operate the bit lines would go to 0 and 1. so how this cell simplifier operation is happening so how does the regular sense amplifier operation happens can you describe that I will then tell the changes what do we not doing a regular sense amplifier foreign when you turn this one on that was when laughing action happened also silicon yeah that is why it is called level restoring foreign foreign Okay so chica so the second bit line is one thing could be that for the sense amplifier you say that alternate rows will the bit lines connected to alternate rows will be called bit line bit line connected to the other alternate set of rows will be called the bit line bar okay and now both are connected to the sense amplifier in between one act as a reference the other acts as a so which one would act as a reference let us say I am selecting so for my particular read operation I selected this particular row so let us say this was uh row 0 Row one Row 2 row 3 4 and so on so which bit line or where do we now get the reference from let us say row 0 was the one that was selected it means this side would discharge if there was a zero stored here the problem is if if this does not have or if the how do I put it we'll come to that later so uh the thing is that you access one row and the remaining rows act as the reference so one bit nine second bit line there are two bit lines and they act as a reference so when when we're done come either beat line or bit line Square will be selected so whichever is not selected will act as a reference okay yes so each wheel acts as a reference for the other this was the written by Mitsubishi so what did others do others also said that okay let us have a dummies and sample of a dummy cell somewhere and if I am selecting this bank that is let us say I am selecting this particular cell then the reference would come from this Bank the other one is that okay are you able to see this so you've generated a reference again but now from the bit line on the other side of the array you know you're talking about that there is this kind of an organization of pages 128k128 they were sharing the sun amplifier this is how they were sharing the sense amplifier yes and it's okay yes so now any any further questions here Mr Blue since amplifier um that is connected to rechargeable Point Internal node computer earlier we had a device to this distinguish between them abhi internal notes pre-charge and bitline pictures like they are shorted right yeah yeah yeah indiran yes that is what happens as you read the refresh also happens simultaneously it's just not I'm talking about the free charge like bit nine could you please and in SRAM bitline freecharge and since the amplifier the internal nude picture there were two different things okay sometimes oh yes because there was an internal node in the sense amplifier the sun simplifier doesn't even have an internal node so although yes I know any questions so your bit line and so you use first equalize okay you had let us say taken one bit line to vdd other bit line to zero you say I will equalize as soon as you equalize what happens vdd and zero so both the bit lines have same capacitance so what is the voltage at both the bit lines then doesn't really require a regulator or a potential divider or anything but you have connected to supply how do we get that is I'm sorry that The Equalizer recharge apply vdd by 2dm right so our purpose you can so that has become overlapped don't worry about that so what we are saying is that if this if this was due to sensor amplifier operation this was uh charged to one and this was charged to zero when you will equalize when you will equalize what happens both become vdd by 2. they said due to Equalization both of them yes yes okay you do not need the regulator at all then you would give the word line so once the word line comes depending on um uh depending on whether your memory cell had a zero or a one the one of the bit lines would rise or fall a little hmm sap will go high San will go up so sap was high it will start to go low so this pmos turns on San was low it starts to go higher so this landmass turns on so which what that means is that this latch is now operational are you able to see this as soon as the latch operation starts I will distinguish between 0 and 1. then at the beginning of next cycle I will initiate Equalization again um bit line pre-charge able bit line pre-charge and equalizing process yes all right and what are the extra capacitor cpcca oh they're just shown to represent the bit line capacitance there thank you so that is,https://www.youtube.com/watch?v=Y9_7E27hRZw,"Link: https://www.youtube.com/watch?v=Y9_7E27hRZw
Transcript: so now with with the speed aspect taken care of huh we look at how to design the reference the question that uh that came earlier in the class how do you get the reference bit line hmm so what we do is in our typical uh dram we would use a level restoring sense amplifier what does level restoring sense amplifier mean it means that there is no pass gate in between now so the sense amplifier is connected and coupled with the bit line at all times are you able to see this when this ensemplifier will operate the bit lines would go to 0 and 1. so how this cell simplifier operation is happening so how does the regular sense amplifier operation happens can you describe that I will then tell the changes what do we not doing a regular sense amplifier foreign when you turn this one on that was when laughing action happened also silicon yeah that is why it is called level restoring foreign foreign Okay so chica so the second bit line is one thing could be that for the sense amplifier you say that alternate rows will the bit lines connected to alternate rows will be called bit line bit line connected to the other alternate set of rows will be called the bit line bar okay and now both are connected to the sense amplifier in between one act as a reference the other acts as a so which one would act as a reference let us say I am selecting so for my particular read operation I selected this particular row so let us say this was uh row 0 Row one Row 2 row 3 4 and so on so which bit line or where do we now get the reference from let us say row 0 was the one that was selected it means this side would discharge if there was a zero stored here the problem is if if this does not have or if the how do I put it we'll come to that later so uh the thing is that you access one row and the remaining rows act as the reference so one bit nine second bit line there are two bit lines and they act as a reference so when when we're done come either beat line or bit line Square will be selected so whichever is not selected will act as a reference okay yes so each wheel acts as a reference for the other this was the written by Mitsubishi so what did others do others also said that okay let us have a dummies and sample of a dummy cell somewhere and if I am selecting this bank that is let us say I am selecting this particular cell then the reference would come from this Bank the other one is that okay are you able to see this so you've generated a reference again but now from the bit line on the other side of the array you know you're talking about that there is this kind of an organization of pages 128k128 they were sharing the sun amplifier this is how they were sharing the sense amplifier yes and it's okay yes so now any any further questions here Mr Blue since amplifier um that is connected to rechargeable Point Internal node computer earlier we had a device to this distinguish between them abhi internal notes pre-charge and bitline pictures like they are shorted right yeah yeah yeah indiran yes that is what happens as you read the refresh also happens simultaneously it's just not I'm talking about the free charge like bit nine could you please and in SRAM bitline freecharge and since the amplifier the internal nude picture there were two different things okay sometimes oh yes because there was an internal node in the sense amplifier the sun simplifier doesn't even have an internal node so although yes I know any questions so your bit line and so you use first equalize okay you had let us say taken one bit line to vdd other bit line to zero you say I will equalize as soon as you equalize what happens vdd and zero so both the bit lines have same capacitance so what is the voltage at both the bit lines then doesn't really require a regulator or a potential divider or anything but you have connected to supply how do we get that is I'm sorry that The Equalizer recharge apply vdd by 2dm right so our purpose you can so that has become overlapped don't worry about that so what we are saying is that if this if this was due to sensor amplifier operation this was uh charged to one and this was charged to zero when you will equalize when you will equalize what happens both become vdd by 2. they said due to Equalization both of them yes yes okay you do not need the regulator at all then you would give the word line so once the word line comes depending on um uh depending on whether your memory cell had a zero or a one the one of the bit lines would rise or fall a little hmm sap will go high San will go up so sap was high it will start to go low so this pmos turns on San was low it starts to go higher so this landmass turns on so which what that means is that this latch is now operational are you able to see this as soon as the latch operation starts I will distinguish between 0 and 1. then at the beginning of next cycle I will initiate Equalization again um bit line pre-charge able bit line pre-charge and equalizing process yes all right and what are the extra capacitor cpcca oh they're just shown to represent the bit line capacitance there thank you so that is"
ycf1epOzzgM,another replica part or the reference wetline is designed now we come to another part which which will then lead us to non-volatile Memories also which is the charge pump what is a charge pump what is a charge pump yeah no one has heard about charge pump earlier so charge pump is a circuit which increases voltage from the levels that are available so I have a voltage available which is one volt I can generate a 2 volt 3 volt 10 volts output by using one volt similarly I have something available as ground and I could generate negative voltage on the ground that is also a charge pump now those of you who are working on the negative wordline negative bit line right driver can you send something what could be a charge from what could the charge pump look like some circuit with the capacitor uh there is a capacitor which stores charge and then that charge is pumped on to another capacitor due to which the voltage between the plates of the other capacitor Rises very much the extra charge has pumped up the voltage um so this is how it would be up it would appear so there is a capacitor there is another capacitor and it is the interplay of these two capacitors that leads to or that results in a V out which is higher than what was V in how do we do that so we divide the operation into multiple phases the first phase is let us say charge phase so what is done in charge phase uh S3 and S2 are closed appear to be like resistances so what happens there is a charge that flows from V in until the side and the charge from the other side of this capacitor goes to zero so capacitor CF is holding some charge onto it some voltage would appear what voltage that would be equivalent to VN or a little drop around it but finally stabilizing at VN okay then we move into the next phase which is about charging so then we move to the next step which is about charging the C out charge phase and this kind of a path was created foreign what does discharge mean now I close these two resistances in these two switches and I open the ones that were closed earlier all of a sudden one happens this plate which earlier had a zero on it now at once has a VN on it what does that mean because we know that this side has much more charged was more charged so this plus VN goes to 2vn you can and this VN or this CS this node is connected to V out so we can actually say V out is approximately equal to twice v n are you able to see this what have I done I first stored charge onto this particular capacitor and then I change the charge of the other voltage on the other side other plate of the capacitor so that discharge could now be pumped down to the output capacitance or the output load is it clear this is the new circuit the red one um let us look at it in terms of a Time series so that was just one one step doesn't really happen like that in reality when the charge form starts to operate then the in the voltage uh vgg over here which we say is the V output voltage would see this kind of increase depth increase and then almost becoming stable the black curve how is it operating who can explain okay so let us say ring oscillator gave a output one so what happened the C was initially zero it will go to one until it has gone to one this transistor is off huh and D would go to 0 from 1 to 0. so this transistor is off so this side of the this node holds the earlier voltage only earlier charge only and the other side has has this charge to zero what happens there could be an impact around the diode chicken otherwise you would transfer some charge to this particular capacitor VG and then you would change the voltage of the other plate so that you have two VG available to you 2bg will not come instantaneously it will come over time is it okay are you able to see the functionality is it clear hello any questions friends is it clear so let me add more inverters and charging phase will increase so it will quickly go to that right yes if you add more inverter starting phase would increase we could probably have a slightly higher rise per cycle um we could probably rise a little higher per cycle but the thing is that uh you want you want to be fast so higher per cycle but that would take a little longer so uh I will have more number of cycles that I would need uh no fewer number of Cycles but the Cycles are larger in themselves over here we have used fewer inverters so every every cycle is short but I may need more Cycles to go to the desired voltage level okay so what is happening is uh I say that there is this vgg so this is the equivalent circuit there there's a capacitor CS this one and this capacitor uh shares the load or spams the charge onto the load capacitor which is much larger and overall the timing improves is this okay great so again we will come to approximately 2v high after some time so we will stop here we will start with non-volatile memories in the last class if there are any pending questions regarding drams you can ask that if there are any questions related to projects we can discuss those also in the last class PRC PRC which was given 110 milliseconds which carries uh free charge plus tras we saw that free charge is only about equalizing the two bit line so I think it's very it will take very less time so Ras was itself 30 millisecond but we are 17 80 millisecond we are taking as a recharge here why so have you tried equalizing two signals bit line and bitline bar uh when you are pre-charging them in the SRAM itself let us say forget about the dram and the SRAM there are there is a bit line on bit9 bar and you want to what do you say and you want to equalize them he put an equalizer there how long does it take do you think [Music] no but I think the bit line C is very high that's why is it taking too much time yeah that is definitely there but uh even Equalization from from let us say vdd by 2 minus 40 millivolts and vdd by 2 plus 40 millivolts two wheel divide almost VD by 2 on both the bit lines means that you are transferring information across a pass gate so this is vdd by 2 minus 40 millivolts and v d by 2 plus 40 millivolts so what happens you are you are transferring charge at a VDS of approximately 80 millivolts the system is fine VDS as as this becomes 30 and 30 it goes to 60. as it becomes uh this VDS goes lower the total time it would take to charge would increase because VDS is low so the current that is Flowing has reduced is that okay it's experimentally we see that will be more clear like if the difference is small that will take lots of time to problems yes Hannah [Music] anything else so in the early read operation in the last lecture we saw that Cas will come later but there was a junk because the output was high so how that will be distinguished from junk data out and chunk like output was high enough so so junk you don't bother about you simply latch output only after TXS but memory is giving output based on or output access time yeah yeah memory could be giving output wherever but when when do you latch the memory output that is what is important now thank you memory output will be last somewhere either in the next stage of flip flop somewhere it would be last at the system level also you will need to that's memory output somewhere so you do that after excess time then there is no problem of whether there was junk before the access time or not is it yes the controller has to work like CSI tabi output link um that will look for oel right the cheap output chip enables signal so it should take the data from memory yeah right yeah but over time per CAF on CS is a internal signal of memory huh so that is a memory controller will start taking the output so we there I have right yeah so you will bring again it will either bring oen after uh after the uh output is stable let us say which could be called as lay tree or if oen was all low already then there would be some junk on the output but you will last the output only later being driven to the bus without the bus would also latch it somewhere that latching should happen after the Total Access time has elapsed is that okay,https://www.youtube.com/watch?v=ycf1epOzzgM,"Link: https://www.youtube.com/watch?v=ycf1epOzzgM
Transcript: another replica part or the reference wetline is designed now we come to another part which which will then lead us to non-volatile Memories also which is the charge pump what is a charge pump what is a charge pump yeah no one has heard about charge pump earlier so charge pump is a circuit which increases voltage from the levels that are available so I have a voltage available which is one volt I can generate a 2 volt 3 volt 10 volts output by using one volt similarly I have something available as ground and I could generate negative voltage on the ground that is also a charge pump now those of you who are working on the negative wordline negative bit line right driver can you send something what could be a charge from what could the charge pump look like some circuit with the capacitor uh there is a capacitor which stores charge and then that charge is pumped on to another capacitor due to which the voltage between the plates of the other capacitor Rises very much the extra charge has pumped up the voltage um so this is how it would be up it would appear so there is a capacitor there is another capacitor and it is the interplay of these two capacitors that leads to or that results in a V out which is higher than what was V in how do we do that so we divide the operation into multiple phases the first phase is let us say charge phase so what is done in charge phase uh S3 and S2 are closed appear to be like resistances so what happens there is a charge that flows from V in until the side and the charge from the other side of this capacitor goes to zero so capacitor CF is holding some charge onto it some voltage would appear what voltage that would be equivalent to VN or a little drop around it but finally stabilizing at VN okay then we move into the next phase which is about charging so then we move to the next step which is about charging the C out charge phase and this kind of a path was created foreign what does discharge mean now I close these two resistances in these two switches and I open the ones that were closed earlier all of a sudden one happens this plate which earlier had a zero on it now at once has a VN on it what does that mean because we know that this side has much more charged was more charged so this plus VN goes to 2vn you can and this VN or this CS this node is connected to V out so we can actually say V out is approximately equal to twice v n are you able to see this what have I done I first stored charge onto this particular capacitor and then I change the charge of the other voltage on the other side other plate of the capacitor so that discharge could now be pumped down to the output capacitance or the output load is it clear this is the new circuit the red one um let us look at it in terms of a Time series so that was just one one step doesn't really happen like that in reality when the charge form starts to operate then the in the voltage uh vgg over here which we say is the V output voltage would see this kind of increase depth increase and then almost becoming stable the black curve how is it operating who can explain okay so let us say ring oscillator gave a output one so what happened the C was initially zero it will go to one until it has gone to one this transistor is off huh and D would go to 0 from 1 to 0. so this transistor is off so this side of the this node holds the earlier voltage only earlier charge only and the other side has has this charge to zero what happens there could be an impact around the diode chicken otherwise you would transfer some charge to this particular capacitor VG and then you would change the voltage of the other plate so that you have two VG available to you 2bg will not come instantaneously it will come over time is it okay are you able to see the functionality is it clear hello any questions friends is it clear so let me add more inverters and charging phase will increase so it will quickly go to that right yes if you add more inverter starting phase would increase we could probably have a slightly higher rise per cycle um we could probably rise a little higher per cycle but the thing is that uh you want you want to be fast so higher per cycle but that would take a little longer so uh I will have more number of cycles that I would need uh no fewer number of Cycles but the Cycles are larger in themselves over here we have used fewer inverters so every every cycle is short but I may need more Cycles to go to the desired voltage level okay so what is happening is uh I say that there is this vgg so this is the equivalent circuit there there's a capacitor CS this one and this capacitor uh shares the load or spams the charge onto the load capacitor which is much larger and overall the timing improves is this okay great so again we will come to approximately 2v high after some time so we will stop here we will start with non-volatile memories in the last class if there are any pending questions regarding drams you can ask that if there are any questions related to projects we can discuss those also in the last class PRC PRC which was given 110 milliseconds which carries uh free charge plus tras we saw that free charge is only about equalizing the two bit line so I think it's very it will take very less time so Ras was itself 30 millisecond but we are 17 80 millisecond we are taking as a recharge here why so have you tried equalizing two signals bit line and bitline bar uh when you are pre-charging them in the SRAM itself let us say forget about the dram and the SRAM there are there is a bit line on bit9 bar and you want to what do you say and you want to equalize them he put an equalizer there how long does it take do you think [Music] no but I think the bit line C is very high that's why is it taking too much time yeah that is definitely there but uh even Equalization from from let us say vdd by 2 minus 40 millivolts and vdd by 2 plus 40 millivolts two wheel divide almost VD by 2 on both the bit lines means that you are transferring information across a pass gate so this is vdd by 2 minus 40 millivolts and v d by 2 plus 40 millivolts so what happens you are you are transferring charge at a VDS of approximately 80 millivolts the system is fine VDS as as this becomes 30 and 30 it goes to 60. as it becomes uh this VDS goes lower the total time it would take to charge would increase because VDS is low so the current that is Flowing has reduced is that okay it's experimentally we see that will be more clear like if the difference is small that will take lots of time to problems yes Hannah [Music] anything else so in the early read operation in the last lecture we saw that Cas will come later but there was a junk because the output was high so how that will be distinguished from junk data out and chunk like output was high enough so so junk you don't bother about you simply latch output only after TXS but memory is giving output based on or output access time yeah yeah memory could be giving output wherever but when when do you latch the memory output that is what is important now thank you memory output will be last somewhere either in the next stage of flip flop somewhere it would be last at the system level also you will need to that's memory output somewhere so you do that after excess time then there is no problem of whether there was junk before the access time or not is it yes the controller has to work like CSI tabi output link um that will look for oel right the cheap output chip enables signal so it should take the data from memory yeah right yeah but over time per CAF on CS is a internal signal of memory huh so that is a memory controller will start taking the output so we there I have right yeah so you will bring again it will either bring oen after uh after the uh output is stable let us say which could be called as lay tree or if oen was all low already then there would be some junk on the output but you will last the output only later being driven to the bus without the bus would also latch it somewhere that latching should happen after the Total Access time has elapsed is that okay"
iTGgOPn1Jc0,on Thursday okay so this is just a table which shows the history of how things have evolved so when we talked about Mass memories there were volatile memories and non-volatile memories and volatile memories there are srams drams and we had seen a another set of taxonomy in the first session where we said okay C4s and uh so you know non-random Access Memories like fifos and cams and everything also figures in there on the read-only memory side which is non-volatile that is what we are going to focus on we had Mass crons mask crowns are the ones that we talked about that there is this metal one mask or metal uh two masks or via one mask which would be modified which would be changed to store a zero or a one inside the memory so Mass ROMs are very dense and as we discussed we could change data the layer of programmation the better it is because then there is lesser turnaround time after you decide the program that you want to program inside the ROM but this is mass ROMs are just at the time of application you have programmed them if you need to change their content then the entire mask needs to be ordered all over again whichever mask is in in which you are doing programmation that mask needs to be ordered again and that's a huge cost on the other hand there could be programmable ROMs for example drums the benefit is that you do not need to have or know the program at the time of application so in a way you are a little more secure because no one can simply delay your chip and find out the program are you able to understand this concept the concept of security and how it is a little more in programmable ROMs so like we can change like we can program it again so that's why we are saying it is very secure security can say better here the fabricate facility does not know our code yeah not not just the fabrication facility also anyone who picks up your chip and starts to deliver it does not be able to make out at least not yet huh so what do you have you have uh electrically programmable ROMs and electrically erasable and reliable ROMs so electrically programmable ROMs can you think of something yes fuses which you could blow electrically you could blow these fuses electrically so once you apply a high voltage across them and they store a zero or a one accordingly uh can someone delay and find out about this okay so after programming they can yeah and someone is delaying your chip after programming has been done they can easily find out what the program is so would you put your safe data or secure data in eprom no sir no if you had to put it in eprom then mask ROM is a much denser option I would rather do it in Maxwell yes okay then the other one is EE prop electrically erasable and programmable ROM and then there are conventional EV problems there and Flash EE from there you look at both of these in little more detail okay in today's session itself and you will see a lot of these Innovations were initiated by Intel because intel was always at the Leading Edge of Technology today it is not but at point of time it was flash on the other hand was introduced by Toshiba because enter uh Intel content because it intel was the kind of toss Bearer for eeproms they designed something in in 1979 they continued with it because they were the only supplier but then Toshiba found an alternate solution which today kind of uh how do you put it has taken up the entire uh non-volatile memory space am I right all of us know flash memories those SD cards that we have in our phones all trash memories so in terms of density as I mentioned ROM is the densest then one time survival or electrically programmable where we could blow fuses you know their density is a little less but the flexibility is a little higher then Flash uh where where you actually uh uh kind of read write into entire at least right into a large array of cells and then Eep problems where the density is not as high but I could uh what do you say I have byte rewrite capability I don't need to write an entire page in a Flash you need to erase the entire page and do something like that you know each round that's not required and then there are coming you know upcoming memories like uh srams and and M Rams and uh PCM and so on so we'll just in the last session of this course we'll also talk about such memory options so a quick Refresh on uh RAM cells are you able to see that these are you know all three are kind of round cells over here are able to understand the functionality of our answer where we say that in one particular wherever you want to write a one there will be a diode where we don't want to write a one that I would will not be there or when we want to write a one there will be a a transistor there which connects the bit line to vdd when wordline arrives or we may not have anything for writing a one but for writing a zero we may have uh uh uh what do you say nmos that connects the bit line to ground so that we read a zero hmm so absence of presence of the transistor slash diode determines whether there is a Unwritten or a zero written you remember which we did this this one already in in the previous in one of the previous classes it's a refresh hmm yes so we also looked at uh what a ram cell would look like again and and then the next slide we'll look at what a nand cell would look like so can you tell me what what is written on this uh word line three bit nine zero one nine three what is written over here zero or one zero zero those are one one by default yeah so we have a bun over here what about in here one same one one what about here oh one of them so let us look at this word line one what was written on word line one zero one one zero zero one one zero ah so absence of presence of a transistor tells you whether you have a 0 or a 100 on a particular location similarly for the now you know the nor layout where you have word lines which lines on this side and uh you see the transistors are always there this poly is continuously running the transistors are always there it's just that they're not connected no Transformers always there but whether I put these contacts or not that defines whether uh I am writing a zero or a one on the bit line are you able to see this yes which layer is the proclamation happening over here what is the programmation layer you can see that over here so metal one my metal ones remains in what is changing foreign [Music] what is happening there wordlines are active low so active low and what does then what would I say is written over here so 1 over 1 1 1 1 okay what has written uh over here what one so one zero one zero one zero one zero take care so uh the presence of a transistor says that the data bit is active low so this is and whenever there is a transistor it means that that switch is now coming into pictures and it is active low it will not allow current to flow so one zero zero one something like that okay now over here in this particular uh layout what is happening are you able to see this clearly are you able to see the yellow layer over here yes sir um so what does what is being done over here somewhere you have it other places you don't have it so what is happening using this yellow no we're not giving Viridian ground using yellow we are just changing the VT of the device um when you change the beauty of the device what happens you take word line to a level which is intermediate between the two VTS one of the transistors will be asked or the transistor will be on the transit service will be off over there we say no the star happens so we store a zero whether it is on we say it as one is this clear so can you please explain that like by changing the VTE how do things are treated so let us say this is the device this is the word line you take word line 2.75 volts yes now the the device by having an implant could have a VT of 0.5 volts and if it is there is no implant the VT will be 0.85 volts let us say yes so 4.5 volts it will conducted 4.85 it will not happen foreign will behave some bitline will discharge another one will not discharge yes sir yes sir so I have kind of used the implant to program the memory cell so these yellow parts are the implants yes thank you okay so what they're saying is that when the implant is present it is as if the transistor is not there and so on so over here what we have done is we made this man wrong by making those implants I ask you a question if I could what have I done by implants I've changed the video of the device and therefore change whether it's stored as 0 or a one now can I make it dynamic implant is fixed once fabricate nothing else can happen to it but can I modulate the VT of a device dynamically wherever I wanted to write a 0 I will write a low VT wherever I want to write a one I will put a high VT there yes sir by changing the body choose it you could change the substrate and therefore we could change the ability of the device very good there are other ways to do it what are those other ways what we call as floating gate devices so what is done is that we somehow add some charge onto the intermediate gate the floating gate okay we add some charge onto the floating gate and that either ensures that the device is all has a low VT because it is always on or it has a high VT because this charge on the gate would prevent further inversion layer to start to form on the substrate are you able to see this so can you please reiterate this point so what I'm saying is they're just floating it over here if I say I am added some positive charges onto the floating gate what happens because the floating rate now has positive charges more electrons will get attracted toward the surface of the substrate yes if electrons are already there at the substrate what kind of voltage do you need to apply to turn the transistor on so less voltage like that's voltage you are kind of modulating the device VT to be a lower value yes sir I mean if instead of positive charge I would transmit negative charge onto the floating gate then what would happen so More Voltage we need to voltage to switch on the device yes because now uh these negative charges on the floating gate will repel any further more negative charges coming in the P substrate there that is fine yes sir how are we uh sending negative charges to get through the gate signal only the signal on the gate we'll see if I'm able to do that I will be able to do something Hannah okay how we do it we'll just see so um what we do we apply a very high voltage on the gate so that it attracts electrons and then we also apply a very high voltage to the drain so that there is a very high energy or very high acceleration of the electrons in the inversion layer because there are so many electrons inversion layer and what do you say you wanted to form a inversion layer in the substrate region these extra electrons in the inversion layer will now in the in the floating gate will now repel the inversion layer formation so you'll need to apply a much higher positive voltage to be able to read a or to be able to store a 0 there negative voltage there so that is where the complexity comes in are you able to see this so I can I can imagine two capacitors here one is between the two gates and one is between the other the plate becomes one full substrate and the just waitable yes so there are two capacitors in series over here okay right if I want to remove the if I want to remove this trap charge I apply a zero volts and uh and I uh you know I kind of let the charge move out hmm is that okay so can you explain how it happened today by putting in 0 volts the charges are removed so charges will flow from this point yeah we will just come to more detail of the arrays operation but what we are saying is that by just changing the the voltages and polarity at different terminals of the device I can trap charge I can remove charge and I can modulate the amount of charge in the gate is that part here yes sir now that is where we then start to look at in little more detail what that means is that I can actually change the VT of the device and then if I turn the word lines on or do whatever the different amount of current will show are you able to see this I change the video of the device so when the device was low VT at a at a low vwl itself there was some current whereas the other was off so now I am able to tell whether we uh implanted implanted uh programmable Ram keyboard is exactly the same thing is this thing clear yes sir so what we are saying is that when I add charge on to the um onto the floating gate then what happens my VT shifts huh and also what happens the overall gate coupling to the substrate reduces and the gate coupling ratio that starts to figure in what is to Define what is the voltage of the floating gate there as the voltage of the floating gate changes as the voltage at the floating gate changes I would have a different slope for the devices there so not just is there a lateral shift happening the change in slope is also happening as I change the uh charge that is trapped inside the floating it is that okay sir I have doubt sir what is the so there are two things going on one is we are changing the vtn secondly we are trying also to turn on the transistor after the video has been changed so sir what is the what are the two different levers to change the VT and how is it different from the the signal which is trying to turn the transistor on so different ways to change the retail is just available how are you independently changing the VT because uh oh how are you actually writing something into one independent gate is that the question kind of because you believe that there will be uh word lines that would be shared bit lines that should be shared so more than once I would get impacted [Music] um okay I will be framed out later yeah okay so we'll see anyways that question we will answer in a little while then we'll look at the memory array as to how to change the video how to put the voltages so that only the transistors where you want to change the VT only they are the VT changes at other places it doesn't look into that a little later okay but do you realize that as uh what do you say when the floating gate is added or something like that happens then the slope of of IDs various characteristics would change is that is that evident to you this one the first curve yes why would this change because the coupling is changed yes because the gate capacitance has changed then the shift from here to here or from here to here that has happened because the uh charts stored on this floating capacitor has changed first is because the coupling has changed the two capacitances are now in series which where it were not earlier second is that uh what was the second one that I was saying the second is that um the charge as you store it it changes the VT of the device both the things happen in simultaneously um so as I said because see of X is lower let me remove my markings the slide would then tell you as you make Cox lower the slope changes huh and uh as you change the amount of charge on the floating gate the VT also shifts both things,https://www.youtube.com/watch?v=iTGgOPn1Jc0,"Link: https://www.youtube.com/watch?v=iTGgOPn1Jc0
Transcript: on Thursday okay so this is just a table which shows the history of how things have evolved so when we talked about Mass memories there were volatile memories and non-volatile memories and volatile memories there are srams drams and we had seen a another set of taxonomy in the first session where we said okay C4s and uh so you know non-random Access Memories like fifos and cams and everything also figures in there on the read-only memory side which is non-volatile that is what we are going to focus on we had Mass crons mask crowns are the ones that we talked about that there is this metal one mask or metal uh two masks or via one mask which would be modified which would be changed to store a zero or a one inside the memory so Mass ROMs are very dense and as we discussed we could change data the layer of programmation the better it is because then there is lesser turnaround time after you decide the program that you want to program inside the ROM but this is mass ROMs are just at the time of application you have programmed them if you need to change their content then the entire mask needs to be ordered all over again whichever mask is in in which you are doing programmation that mask needs to be ordered again and that's a huge cost on the other hand there could be programmable ROMs for example drums the benefit is that you do not need to have or know the program at the time of application so in a way you are a little more secure because no one can simply delay your chip and find out the program are you able to understand this concept the concept of security and how it is a little more in programmable ROMs so like we can change like we can program it again so that's why we are saying it is very secure security can say better here the fabricate facility does not know our code yeah not not just the fabrication facility also anyone who picks up your chip and starts to deliver it does not be able to make out at least not yet huh so what do you have you have uh electrically programmable ROMs and electrically erasable and reliable ROMs so electrically programmable ROMs can you think of something yes fuses which you could blow electrically you could blow these fuses electrically so once you apply a high voltage across them and they store a zero or a one accordingly uh can someone delay and find out about this okay so after programming they can yeah and someone is delaying your chip after programming has been done they can easily find out what the program is so would you put your safe data or secure data in eprom no sir no if you had to put it in eprom then mask ROM is a much denser option I would rather do it in Maxwell yes okay then the other one is EE prop electrically erasable and programmable ROM and then there are conventional EV problems there and Flash EE from there you look at both of these in little more detail okay in today's session itself and you will see a lot of these Innovations were initiated by Intel because intel was always at the Leading Edge of Technology today it is not but at point of time it was flash on the other hand was introduced by Toshiba because enter uh Intel content because it intel was the kind of toss Bearer for eeproms they designed something in in 1979 they continued with it because they were the only supplier but then Toshiba found an alternate solution which today kind of uh how do you put it has taken up the entire uh non-volatile memory space am I right all of us know flash memories those SD cards that we have in our phones all trash memories so in terms of density as I mentioned ROM is the densest then one time survival or electrically programmable where we could blow fuses you know their density is a little less but the flexibility is a little higher then Flash uh where where you actually uh uh kind of read write into entire at least right into a large array of cells and then Eep problems where the density is not as high but I could uh what do you say I have byte rewrite capability I don't need to write an entire page in a Flash you need to erase the entire page and do something like that you know each round that's not required and then there are coming you know upcoming memories like uh srams and and M Rams and uh PCM and so on so we'll just in the last session of this course we'll also talk about such memory options so a quick Refresh on uh RAM cells are you able to see that these are you know all three are kind of round cells over here are able to understand the functionality of our answer where we say that in one particular wherever you want to write a one there will be a diode where we don't want to write a one that I would will not be there or when we want to write a one there will be a a transistor there which connects the bit line to vdd when wordline arrives or we may not have anything for writing a one but for writing a zero we may have uh uh uh what do you say nmos that connects the bit line to ground so that we read a zero hmm so absence of presence of the transistor slash diode determines whether there is a Unwritten or a zero written you remember which we did this this one already in in the previous in one of the previous classes it's a refresh hmm yes so we also looked at uh what a ram cell would look like again and and then the next slide we'll look at what a nand cell would look like so can you tell me what what is written on this uh word line three bit nine zero one nine three what is written over here zero or one zero zero those are one one by default yeah so we have a bun over here what about in here one same one one what about here oh one of them so let us look at this word line one what was written on word line one zero one one zero zero one one zero ah so absence of presence of a transistor tells you whether you have a 0 or a 100 on a particular location similarly for the now you know the nor layout where you have word lines which lines on this side and uh you see the transistors are always there this poly is continuously running the transistors are always there it's just that they're not connected no Transformers always there but whether I put these contacts or not that defines whether uh I am writing a zero or a one on the bit line are you able to see this yes which layer is the proclamation happening over here what is the programmation layer you can see that over here so metal one my metal ones remains in what is changing foreign [Music] what is happening there wordlines are active low so active low and what does then what would I say is written over here so 1 over 1 1 1 1 okay what has written uh over here what one so one zero one zero one zero one zero take care so uh the presence of a transistor says that the data bit is active low so this is and whenever there is a transistor it means that that switch is now coming into pictures and it is active low it will not allow current to flow so one zero zero one something like that okay now over here in this particular uh layout what is happening are you able to see this clearly are you able to see the yellow layer over here yes sir um so what does what is being done over here somewhere you have it other places you don't have it so what is happening using this yellow no we're not giving Viridian ground using yellow we are just changing the VT of the device um when you change the beauty of the device what happens you take word line to a level which is intermediate between the two VTS one of the transistors will be asked or the transistor will be on the transit service will be off over there we say no the star happens so we store a zero whether it is on we say it as one is this clear so can you please explain that like by changing the VTE how do things are treated so let us say this is the device this is the word line you take word line 2.75 volts yes now the the device by having an implant could have a VT of 0.5 volts and if it is there is no implant the VT will be 0.85 volts let us say yes so 4.5 volts it will conducted 4.85 it will not happen foreign will behave some bitline will discharge another one will not discharge yes sir yes sir so I have kind of used the implant to program the memory cell so these yellow parts are the implants yes thank you okay so what they're saying is that when the implant is present it is as if the transistor is not there and so on so over here what we have done is we made this man wrong by making those implants I ask you a question if I could what have I done by implants I've changed the video of the device and therefore change whether it's stored as 0 or a one now can I make it dynamic implant is fixed once fabricate nothing else can happen to it but can I modulate the VT of a device dynamically wherever I wanted to write a 0 I will write a low VT wherever I want to write a one I will put a high VT there yes sir by changing the body choose it you could change the substrate and therefore we could change the ability of the device very good there are other ways to do it what are those other ways what we call as floating gate devices so what is done is that we somehow add some charge onto the intermediate gate the floating gate okay we add some charge onto the floating gate and that either ensures that the device is all has a low VT because it is always on or it has a high VT because this charge on the gate would prevent further inversion layer to start to form on the substrate are you able to see this so can you please reiterate this point so what I'm saying is they're just floating it over here if I say I am added some positive charges onto the floating gate what happens because the floating rate now has positive charges more electrons will get attracted toward the surface of the substrate yes if electrons are already there at the substrate what kind of voltage do you need to apply to turn the transistor on so less voltage like that's voltage you are kind of modulating the device VT to be a lower value yes sir I mean if instead of positive charge I would transmit negative charge onto the floating gate then what would happen so More Voltage we need to voltage to switch on the device yes because now uh these negative charges on the floating gate will repel any further more negative charges coming in the P substrate there that is fine yes sir how are we uh sending negative charges to get through the gate signal only the signal on the gate we'll see if I'm able to do that I will be able to do something Hannah okay how we do it we'll just see so um what we do we apply a very high voltage on the gate so that it attracts electrons and then we also apply a very high voltage to the drain so that there is a very high energy or very high acceleration of the electrons in the inversion layer because there are so many electrons inversion layer and what do you say you wanted to form a inversion layer in the substrate region these extra electrons in the inversion layer will now in the in the floating gate will now repel the inversion layer formation so you'll need to apply a much higher positive voltage to be able to read a or to be able to store a 0 there negative voltage there so that is where the complexity comes in are you able to see this so I can I can imagine two capacitors here one is between the two gates and one is between the other the plate becomes one full substrate and the just waitable yes so there are two capacitors in series over here okay right if I want to remove the if I want to remove this trap charge I apply a zero volts and uh and I uh you know I kind of let the charge move out hmm is that okay so can you explain how it happened today by putting in 0 volts the charges are removed so charges will flow from this point yeah we will just come to more detail of the arrays operation but what we are saying is that by just changing the the voltages and polarity at different terminals of the device I can trap charge I can remove charge and I can modulate the amount of charge in the gate is that part here yes sir now that is where we then start to look at in little more detail what that means is that I can actually change the VT of the device and then if I turn the word lines on or do whatever the different amount of current will show are you able to see this I change the video of the device so when the device was low VT at a at a low vwl itself there was some current whereas the other was off so now I am able to tell whether we uh implanted implanted uh programmable Ram keyboard is exactly the same thing is this thing clear yes sir so what we are saying is that when I add charge on to the um onto the floating gate then what happens my VT shifts huh and also what happens the overall gate coupling to the substrate reduces and the gate coupling ratio that starts to figure in what is to Define what is the voltage of the floating gate there as the voltage of the floating gate changes as the voltage at the floating gate changes I would have a different slope for the devices there so not just is there a lateral shift happening the change in slope is also happening as I change the uh charge that is trapped inside the floating it is that okay sir I have doubt sir what is the so there are two things going on one is we are changing the vtn secondly we are trying also to turn on the transistor after the video has been changed so sir what is the what are the two different levers to change the VT and how is it different from the the signal which is trying to turn the transistor on so different ways to change the retail is just available how are you independently changing the VT because uh oh how are you actually writing something into one independent gate is that the question kind of because you believe that there will be uh word lines that would be shared bit lines that should be shared so more than once I would get impacted [Music] um okay I will be framed out later yeah okay so we'll see anyways that question we will answer in a little while then we'll look at the memory array as to how to change the video how to put the voltages so that only the transistors where you want to change the VT only they are the VT changes at other places it doesn't look into that a little later okay but do you realize that as uh what do you say when the floating gate is added or something like that happens then the slope of of IDs various characteristics would change is that is that evident to you this one the first curve yes why would this change because the coupling is changed yes because the gate capacitance has changed then the shift from here to here or from here to here that has happened because the uh charts stored on this floating capacitor has changed first is because the coupling has changed the two capacitances are now in series which where it were not earlier second is that uh what was the second one that I was saying the second is that um the charge as you store it it changes the VT of the device both the things happen in simultaneously um so as I said because see of X is lower let me remove my markings the slide would then tell you as you make Cox lower the slope changes huh and uh as you change the amount of charge on the floating gate the VT also shifts both things"
GXgJDULJdAA,now as we saw if I have a sensing threshold say wordline voltage in between these two regions then I will sense 0 and 1 correctly if there is this empty space between two two VT distributions they can be easily a space where I could fit a transition from one data to another is this okay what would happen if there were two distributions that would overlapping what happened in such a case ambiguous data yeah you don't know whether you are reading a zero zero or a zero one or a one zero whatever was the was the data that you wanted to read in this region there is ambiguity because you put there's a significant probability of reading a zero and there's a significant probability of reading a one also at that particular voltage so what's the solution of this problem yes they can also we we say that the thresholds have to be different and so different that this may is sensing voltage huh and uh if due to low voltage you're not able to do it you limit the minimum voltage at which the circuit would operate so over here I am bringing them a little closer and I'm I'm also bringing in this aspect that if I could somehow keep four so one two three four four such distributions I would actually be talking about two bits being stored in this particular transistor are you able to see this so I am confused sorry so how we are like we are having this four curves set players so there are four curves how would you label them you would probably call it zero zero zero one one zero one one yes how many bits are we talking about over here okay so that's our distributors yes okay okay so this this could be understood like a uh multi-level cell where in every cell there are four levels four different values of current which could be flowing and you can measure them and you can say that okay this is the data stored two bits that are two bits there huh or there could be a multi-bit set so this is multi-level cell multi-level itself has stored two bits huh I could actually have used two transistors also each to store one bit so that is a multivit fill and the first one that we talked about is a multi-level set so sorry okay so uh so you can have only one VT for one transistor right I mean you can shift it dynamically but yes so sir how are you storing two bits in one in one transistor if there can be only one meter yeah but by in terms of Shifting granularity I can say that I can shift four different VTS or I can have four different VTS on the cell depending on my programmation yes sir there are four different videos how would you identify those can you identify four different vertices one bit only no sir that is where you need two bits or you say that you're storing two bits onto that cell okay so okay clear enough okay you have questions your hands are raised I just noticed them so like we are having four different VTS so uh let us assume we are saying this is and there are four different transistors like these four different VTS am I correct yeah okay okay so I I wanted to confirm that this four levels are due by the virtue of the voltage applied on the gate and these four levels are by the virtue of how do I put it off different charges stored in the floating gate because of which four different VTS appear so butter so you mean to say that and still okay I will [Music] so this was not a single transistor I was imagining this has a single transistor most VT we are changing by the gate voltage continuously and then labeling them as we do not change the voltage continuously when we write into the cells we just program it so that a particular VT appears on that gate the new then you change the word line level so we'll see how to do read and write in a multi multi-bit or multi Wireline multi-level setting but uh that is what you're doing okay so just to confirm so the data stored here is actually the VT level because that is the thing you are wearing here VT level is 198 millivolts is that the data so no but uh because it's one 98 millivolt I can reduce whether it is zero zero or zero one one zero one one so data stored as whatever label you have given to each of those four distributions yes sir okay so but we'll be measuring the VT only or whatever vtv said yeah we will be measuring something that differentiates between these four different uh transistors who could be at different BT,https://www.youtube.com/watch?v=GXgJDULJdAA,"Link: https://www.youtube.com/watch?v=GXgJDULJdAA
Transcript: now as we saw if I have a sensing threshold say wordline voltage in between these two regions then I will sense 0 and 1 correctly if there is this empty space between two two VT distributions they can be easily a space where I could fit a transition from one data to another is this okay what would happen if there were two distributions that would overlapping what happened in such a case ambiguous data yeah you don't know whether you are reading a zero zero or a zero one or a one zero whatever was the was the data that you wanted to read in this region there is ambiguity because you put there's a significant probability of reading a zero and there's a significant probability of reading a one also at that particular voltage so what's the solution of this problem yes they can also we we say that the thresholds have to be different and so different that this may is sensing voltage huh and uh if due to low voltage you're not able to do it you limit the minimum voltage at which the circuit would operate so over here I am bringing them a little closer and I'm I'm also bringing in this aspect that if I could somehow keep four so one two three four four such distributions I would actually be talking about two bits being stored in this particular transistor are you able to see this so I am confused sorry so how we are like we are having this four curves set players so there are four curves how would you label them you would probably call it zero zero zero one one zero one one yes how many bits are we talking about over here okay so that's our distributors yes okay okay so this this could be understood like a uh multi-level cell where in every cell there are four levels four different values of current which could be flowing and you can measure them and you can say that okay this is the data stored two bits that are two bits there huh or there could be a multi-bit set so this is multi-level cell multi-level itself has stored two bits huh I could actually have used two transistors also each to store one bit so that is a multivit fill and the first one that we talked about is a multi-level set so sorry okay so uh so you can have only one VT for one transistor right I mean you can shift it dynamically but yes so sir how are you storing two bits in one in one transistor if there can be only one meter yeah but by in terms of Shifting granularity I can say that I can shift four different VTS or I can have four different VTS on the cell depending on my programmation yes sir there are four different videos how would you identify those can you identify four different vertices one bit only no sir that is where you need two bits or you say that you're storing two bits onto that cell okay so okay clear enough okay you have questions your hands are raised I just noticed them so like we are having four different VTS so uh let us assume we are saying this is and there are four different transistors like these four different VTS am I correct yeah okay okay so I I wanted to confirm that this four levels are due by the virtue of the voltage applied on the gate and these four levels are by the virtue of how do I put it off different charges stored in the floating gate because of which four different VTS appear so butter so you mean to say that and still okay I will [Music] so this was not a single transistor I was imagining this has a single transistor most VT we are changing by the gate voltage continuously and then labeling them as we do not change the voltage continuously when we write into the cells we just program it so that a particular VT appears on that gate the new then you change the word line level so we'll see how to do read and write in a multi multi-bit or multi Wireline multi-level setting but uh that is what you're doing okay so just to confirm so the data stored here is actually the VT level because that is the thing you are wearing here VT level is 198 millivolts is that the data so no but uh because it's one 98 millivolt I can reduce whether it is zero zero or zero one one zero one one so data stored as whatever label you have given to each of those four distributions yes sir okay so but we'll be measuring the VT only or whatever vtv said yeah we will be measuring something that differentiates between these four different uh transistors who could be at different BT"
3P7-HDWuHa0,so flash memories are also called so okay eeproms electrically programmable ROMs could be erased by a flashing UV light okay they have a small window on their package through which you flash UV light and the eproms can be erased ee problems are electrically erasable and cannot you know you could do read write arrays all kinds of things on a byte or a word vessels flash memories are again eeproms um but they enable reset or set of the entire array in one book that is why they are called flash a flash the entire array can be programmed into zero or one and you could also write you know this is raised you erase line of flash but then you can write you know location by location foreign so how does the floating gate work if it is a regular read write operation practically nothing changes what has been done over here is that you what do you say speed up the electrons apply a vertical field so that electrons which are very high speed very high kinetic energy would inject themselves into the floating gate at another end you will apply uh either a negative or a zero volt over here on the gate so that all the negative stars in this region can be transmitted back to the class is that okay so it can be transmitted back to the source region over here okay okay so what are we looking at uh how to write so we use hot electrons in Flash we use uh UV radiations in eeproms and we also do to write or erase you know whatever the program or it is we also use what is called as FN paneling that's a physics you how many have read about FN tunneling or something no one okay we will talk about it and uh FN tunneling is used for E from both program and it is over here okay so we just said and if it is a UV uh UV erase or something then you notice there is this uh hole in the package and you can actually see the diabetes are able to notice a die beneath there yes another area yes so uh this UV light is shined UV light when it is shined more electron pairs are generated and they can be used to erase the entire thing everything has those electrons now however making a package which has uh opening in it that is costly writing a ROM you know shining UV through the entire package it takes time and uh if you wanted to use this die for any other purpose it can be tricky huh because uh UV light would fall on many cells simultaneously because programming selective programming for different cells apparently can be very difficult uh so this is this is a slide that we showed I think in DVD or some time on different kind of leakages that would be there inside a mosfet you remember those of you have done DVD you remember this yes are you talking about different kinds of currents that could be flowing in a leaking leaking through a transistor uh and things which were problems earlier uh can actually be used to your benefit injection for example is a problem in a regular CMOS process but for Flash you use actually how you use hot card injection to if to be able to do something huh and gate of site tunneling is actually used to program and erase eproms so things which were problematic earlier are being used inside uh slash self uh as an advantage to be able to program or erase the flash cell [Music] let us look at this FN tunneling kind of a thing so are you able to see this band diagram yes sir huh so there is this valence band balance band conduction band conduction band this is the oxide what happens no electron can actually flow why because uh first the oxide thickness and the region across which this voltage range happens is very wide so tunneling cannot happen and this is a dielectric you'll have to apply a very high voltage to take things here and then they will go there however when I actually apply a voltage across these two band mending also happens this this voltage starts to appear across a dielectric also are you able to see this appears to be like this then what happens is electrons see that okay there is this only this thing that I need to cross see there is no energy level in between this but I could always jump that is what is called tunneling so I could always jump and uh and tunnel and therefore I would be able to program or erase the particular location this is called as FN tunneling or electron tunneling is that okay any questions if I apply a high voltage there let us say 15 volts and on a substrate I apply a very low voltage then what happens there is this voltage drop across the oxide and instead of really going all the way up from conduction band to the top of this CB oxide uh we we just tunnel across the CV oxide so at a lower voltage we are able to do electron transfer electron injection hmm because of tunneling what does it need it needs a high electric field across the gate oxide layer so and the gate oxide layer to be reasonably thin the gate oxide layer is very thick and tunneling would not happen huh friends please give some acknowledgment sir can we attribute the thin gate oxide layer as a reason for the more space for electrons to flow high energy electrons in this case that as soon as the bending happens even a little bit of bending can mean that the tunneling length is achieved whether I am able to Tunnel or I do tunnel electrons there or not is a different issue but the tunneling length has been achieved so to be able to achieve that fast we need the overall oxide layer thickness to be less yes so basically uh this physical thing only I was talking about okay got it okay so yes so if you are applying a very high voltage and if the oxide layer is very thin so is there a risk for dielectric breakdown in this case yes foreign we'll see one example in a little while Okay so so yes so how effectively is different from correctly what is the difference if in tunneling actually involves uh the field to be modified very significantly so that because of this bending in the field this steep bend that is happening in the field there I am able to operate the memory okay so that triangular so if you notice I had five volts there minus 12 volts here where would the electrons go towards substrate the source okay is that okay and when I want to uh what do you say erase then all that I need to do is apply a positive charge on the bulk and use the igb capacitance to do the healthcare them to to uh we use the high voltage here and we kind of tunnel electrons out from there is that okay huh so both the diagrams in the previous slide are doing the same thing right um yeah one is doing git to Source channeling the other is doing gate to bulk paneling yeah thank you but tunneling only and over here I'm actually showing you that tunneling through this small animation you apply voltage apply More Voltage you apply still More Voltage so the electron actually had to acquire a higher energy to be able to go there but now because it could actually slide onto the slide onto the slope very easily the distance is very short this tunneling happens hmm so when you increase the applied voltage the effective barrier which reduces um yes sir okay so if you look at it over here see the amount of tunneling current and the slope here this is the slope at which the current would flow and this is the other one six nine one one thousand the slopes have the slopes change as you change the uh uh what do you say the voltage voltage at which the tunneling would happen yes because this FN tunneling starts to take place what governs the tunneling rate two things oxide rate and thickness of the uh uh and the feed that you are applying across the oxide that governs the tunneling rate has to what is the tunneling current there if you apply very high voltage even for a thick gate oxide you will be able to do the tunneling in a fast enough time however if you have dense devices you need to be careful you apply a lower voltages because they can give you the required speed already what happens is an advanced technology applied very very high voltages so dielectric breakdown yes the direction breakdown can happen do you care,https://www.youtube.com/watch?v=3P7-HDWuHa0,"Link: https://www.youtube.com/watch?v=3P7-HDWuHa0
Transcript: so flash memories are also called so okay eeproms electrically programmable ROMs could be erased by a flashing UV light okay they have a small window on their package through which you flash UV light and the eproms can be erased ee problems are electrically erasable and cannot you know you could do read write arrays all kinds of things on a byte or a word vessels flash memories are again eeproms um but they enable reset or set of the entire array in one book that is why they are called flash a flash the entire array can be programmed into zero or one and you could also write you know this is raised you erase line of flash but then you can write you know location by location foreign so how does the floating gate work if it is a regular read write operation practically nothing changes what has been done over here is that you what do you say speed up the electrons apply a vertical field so that electrons which are very high speed very high kinetic energy would inject themselves into the floating gate at another end you will apply uh either a negative or a zero volt over here on the gate so that all the negative stars in this region can be transmitted back to the class is that okay so it can be transmitted back to the source region over here okay okay so what are we looking at uh how to write so we use hot electrons in Flash we use uh UV radiations in eeproms and we also do to write or erase you know whatever the program or it is we also use what is called as FN paneling that's a physics you how many have read about FN tunneling or something no one okay we will talk about it and uh FN tunneling is used for E from both program and it is over here okay so we just said and if it is a UV uh UV erase or something then you notice there is this uh hole in the package and you can actually see the diabetes are able to notice a die beneath there yes another area yes so uh this UV light is shined UV light when it is shined more electron pairs are generated and they can be used to erase the entire thing everything has those electrons now however making a package which has uh opening in it that is costly writing a ROM you know shining UV through the entire package it takes time and uh if you wanted to use this die for any other purpose it can be tricky huh because uh UV light would fall on many cells simultaneously because programming selective programming for different cells apparently can be very difficult uh so this is this is a slide that we showed I think in DVD or some time on different kind of leakages that would be there inside a mosfet you remember those of you have done DVD you remember this yes are you talking about different kinds of currents that could be flowing in a leaking leaking through a transistor uh and things which were problems earlier uh can actually be used to your benefit injection for example is a problem in a regular CMOS process but for Flash you use actually how you use hot card injection to if to be able to do something huh and gate of site tunneling is actually used to program and erase eproms so things which were problematic earlier are being used inside uh slash self uh as an advantage to be able to program or erase the flash cell [Music] let us look at this FN tunneling kind of a thing so are you able to see this band diagram yes sir huh so there is this valence band balance band conduction band conduction band this is the oxide what happens no electron can actually flow why because uh first the oxide thickness and the region across which this voltage range happens is very wide so tunneling cannot happen and this is a dielectric you'll have to apply a very high voltage to take things here and then they will go there however when I actually apply a voltage across these two band mending also happens this this voltage starts to appear across a dielectric also are you able to see this appears to be like this then what happens is electrons see that okay there is this only this thing that I need to cross see there is no energy level in between this but I could always jump that is what is called tunneling so I could always jump and uh and tunnel and therefore I would be able to program or erase the particular location this is called as FN tunneling or electron tunneling is that okay any questions if I apply a high voltage there let us say 15 volts and on a substrate I apply a very low voltage then what happens there is this voltage drop across the oxide and instead of really going all the way up from conduction band to the top of this CB oxide uh we we just tunnel across the CV oxide so at a lower voltage we are able to do electron transfer electron injection hmm because of tunneling what does it need it needs a high electric field across the gate oxide layer so and the gate oxide layer to be reasonably thin the gate oxide layer is very thick and tunneling would not happen huh friends please give some acknowledgment sir can we attribute the thin gate oxide layer as a reason for the more space for electrons to flow high energy electrons in this case that as soon as the bending happens even a little bit of bending can mean that the tunneling length is achieved whether I am able to Tunnel or I do tunnel electrons there or not is a different issue but the tunneling length has been achieved so to be able to achieve that fast we need the overall oxide layer thickness to be less yes so basically uh this physical thing only I was talking about okay got it okay so yes so if you are applying a very high voltage and if the oxide layer is very thin so is there a risk for dielectric breakdown in this case yes foreign we'll see one example in a little while Okay so so yes so how effectively is different from correctly what is the difference if in tunneling actually involves uh the field to be modified very significantly so that because of this bending in the field this steep bend that is happening in the field there I am able to operate the memory okay so that triangular so if you notice I had five volts there minus 12 volts here where would the electrons go towards substrate the source okay is that okay and when I want to uh what do you say erase then all that I need to do is apply a positive charge on the bulk and use the igb capacitance to do the healthcare them to to uh we use the high voltage here and we kind of tunnel electrons out from there is that okay huh so both the diagrams in the previous slide are doing the same thing right um yeah one is doing git to Source channeling the other is doing gate to bulk paneling yeah thank you but tunneling only and over here I'm actually showing you that tunneling through this small animation you apply voltage apply More Voltage you apply still More Voltage so the electron actually had to acquire a higher energy to be able to go there but now because it could actually slide onto the slide onto the slope very easily the distance is very short this tunneling happens hmm so when you increase the applied voltage the effective barrier which reduces um yes sir okay so if you look at it over here see the amount of tunneling current and the slope here this is the slope at which the current would flow and this is the other one six nine one one thousand the slopes have the slopes change as you change the uh uh what do you say the voltage voltage at which the tunneling would happen yes because this FN tunneling starts to take place what governs the tunneling rate two things oxide rate and thickness of the uh uh and the feed that you are applying across the oxide that governs the tunneling rate has to what is the tunneling current there if you apply very high voltage even for a thick gate oxide you will be able to do the tunneling in a fast enough time however if you have dense devices you need to be careful you apply a lower voltages because they can give you the required speed already what happens is an advanced technology applied very very high voltages so dielectric breakdown yes the direction breakdown can happen do you care"
6NeeAKPOXvY,all right now this is where I was talking about that we will talk about how to have controlled region in which tunneling could happen or something like that so instead of using a flat surface there they make a notch on the surface of the substrate now what happens because of this Notch the physical thickness of the oxide is lesser over here this then can act as a place where tunneling could be used to enhance uh or where the tunneling rate can be enhanced very significantly by using such uh test structures so if it's very like lower deck node we discussed that there is a limit on the like the fabrication at fabric the the light which is uh passed to basically in the fabrication so that this is even lesser not your lesser width or lesser Dimension not sure what I'm talking about how is this possible then because we told that we were told that there is a saturation Beyond which you cannot do so this could be by atomic layer deposition or by you know just a specific gate oxide Edge or something like that look at it over here uh Flo this is called as a flow talks EE from floating gate oxide okay so e problem but with a floating gate oxide and you have created this you've created this uh how do I put it 10 nanometer width region over here at all other places it was 20 to 30 nanometers just above the substrate you made a slight additional dent on the oxide when you were etching and you made it lesser so it's a complex process it's not that it will happen easily but then when that happens this one we have already done okay uh this we already understand now operation uh programmation and erase okay ask me is this clear do I need to explain the slide is this clear enough so then Rome right is it the name yeah like that yeah to erase the array we just need to pass very high voltage on word line right yes and bit langels appears for the day yes so what happens let us look at the programming first so you apply VPP I think that's good that you spend some time on this you apply VPP onto the line and after the word Line This voltage becomes gpv minus VT that is the voltage that goes to the control gate if you apply 0 on the bit line then whichever transistors had a VP minus V T there they would attract the electrons and they would uh program huh through FN tunneling now to erase what do you do you have to apply the opposite polarity so wordline is now zero but bit Line is now kept at VPP minus VT so all the charge in the floating gate would now rush out onto the bit line is that okay doing read bit line can be are really by two Y Line could be RPD so this is Proclamation where we say VPP very high voltage but during regular read operation your stuff could be at vdd by 2 vdd and so on it need not be at a very high voltage programmation voltage meaning yes so uh again this is about tunneling at the source drain region where we say that we could apply voltage and arrays would happen from here program would happen from HCI plus tunneling effect okay this is the same thing as the other diagram that I have shown where where there was an arrow like this and arrow going like this it's the same thing just in a different graphical format yes so uh in terms of Technology if you look at it then what we are saying is that there are two kinds of oxide there is a paneling oxide which should be very thin where we could also think of having putting notches so that it becomes easier to tunnel there is this floating gate and between floating it and the control gate there is what is called as an inter polyoxide thank you the interpolier side is designed thick to prevent any tunneling from hap to happen from floating gate to the control gate at least there should be no tunneling that would happen because of uh because of this inter polyoxide all the tunneling that you want to do is you want to do a cross external oxide only so tunnel oxide is eight nanometers this one floating gate is 100 nanometers and the inter polyoxide is then is now 16 nanometers so electrons can tunnel from here to here but not from here to here is this okay so the isn't it look like the SOI technology like a floating gate the tunnel oxide set free to know I don't know um no I would not say that it is SOI so because there is struggling between floating rate and the substrate so I I guess like I have um is something like this fully depleted so I would be up you know something like this where you would have a gate like this there is one oxide here yes this is anyways oxide but this is a silicon not poly silicon gate and this is polysilicon okay if you are not intending to store any charge in this silicon there is a source and a drain which would have some voltages applied to it and the charge would simply flow whereas in this particular cell we intent to store charge in the floating gate yes sir yes sir that's why it is different Hannah this is not a silicon kind of a conductor or a substrate where you would be able to design something okay so okay okay so again as I said programmation through hot carrier injection and erase through FN tunneling repeating it over and over again so that you realize that there are two different operations and both are necessary both appear to be completely negative initially that such high voltages are required and so on but or that they lead to increased leakage but then we're using it both these things to our benefit when we're talking about flash memories all program missionaries in the flash memories is that okay yes okay and then again this is the arrays operation uh that was hiring operation this is arrays operation and uh I think we come to the architecture next class is that okay we will stop here but still you have done it's not sir yes what is the order of magnitude of phase operation or program operation for timing we'll look into this next class okay so it would be more than SM right oh yes definitely yeah because these are tunneling currents they are much much smaller than cell currents that we have in srams yes I know so we want to Tunnel tunneling Warrior foreign you cannot really increase tunneling currents also too high sure anything else okay there are no further questions and I would just,https://www.youtube.com/watch?v=6NeeAKPOXvY,"Link: https://www.youtube.com/watch?v=6NeeAKPOXvY
Transcript: all right now this is where I was talking about that we will talk about how to have controlled region in which tunneling could happen or something like that so instead of using a flat surface there they make a notch on the surface of the substrate now what happens because of this Notch the physical thickness of the oxide is lesser over here this then can act as a place where tunneling could be used to enhance uh or where the tunneling rate can be enhanced very significantly by using such uh test structures so if it's very like lower deck node we discussed that there is a limit on the like the fabrication at fabric the the light which is uh passed to basically in the fabrication so that this is even lesser not your lesser width or lesser Dimension not sure what I'm talking about how is this possible then because we told that we were told that there is a saturation Beyond which you cannot do so this could be by atomic layer deposition or by you know just a specific gate oxide Edge or something like that look at it over here uh Flo this is called as a flow talks EE from floating gate oxide okay so e problem but with a floating gate oxide and you have created this you've created this uh how do I put it 10 nanometer width region over here at all other places it was 20 to 30 nanometers just above the substrate you made a slight additional dent on the oxide when you were etching and you made it lesser so it's a complex process it's not that it will happen easily but then when that happens this one we have already done okay uh this we already understand now operation uh programmation and erase okay ask me is this clear do I need to explain the slide is this clear enough so then Rome right is it the name yeah like that yeah to erase the array we just need to pass very high voltage on word line right yes and bit langels appears for the day yes so what happens let us look at the programming first so you apply VPP I think that's good that you spend some time on this you apply VPP onto the line and after the word Line This voltage becomes gpv minus VT that is the voltage that goes to the control gate if you apply 0 on the bit line then whichever transistors had a VP minus V T there they would attract the electrons and they would uh program huh through FN tunneling now to erase what do you do you have to apply the opposite polarity so wordline is now zero but bit Line is now kept at VPP minus VT so all the charge in the floating gate would now rush out onto the bit line is that okay doing read bit line can be are really by two Y Line could be RPD so this is Proclamation where we say VPP very high voltage but during regular read operation your stuff could be at vdd by 2 vdd and so on it need not be at a very high voltage programmation voltage meaning yes so uh again this is about tunneling at the source drain region where we say that we could apply voltage and arrays would happen from here program would happen from HCI plus tunneling effect okay this is the same thing as the other diagram that I have shown where where there was an arrow like this and arrow going like this it's the same thing just in a different graphical format yes so uh in terms of Technology if you look at it then what we are saying is that there are two kinds of oxide there is a paneling oxide which should be very thin where we could also think of having putting notches so that it becomes easier to tunnel there is this floating gate and between floating it and the control gate there is what is called as an inter polyoxide thank you the interpolier side is designed thick to prevent any tunneling from hap to happen from floating gate to the control gate at least there should be no tunneling that would happen because of uh because of this inter polyoxide all the tunneling that you want to do is you want to do a cross external oxide only so tunnel oxide is eight nanometers this one floating gate is 100 nanometers and the inter polyoxide is then is now 16 nanometers so electrons can tunnel from here to here but not from here to here is this okay so the isn't it look like the SOI technology like a floating gate the tunnel oxide set free to know I don't know um no I would not say that it is SOI so because there is struggling between floating rate and the substrate so I I guess like I have um is something like this fully depleted so I would be up you know something like this where you would have a gate like this there is one oxide here yes this is anyways oxide but this is a silicon not poly silicon gate and this is polysilicon okay if you are not intending to store any charge in this silicon there is a source and a drain which would have some voltages applied to it and the charge would simply flow whereas in this particular cell we intent to store charge in the floating gate yes sir yes sir that's why it is different Hannah this is not a silicon kind of a conductor or a substrate where you would be able to design something okay so okay okay so again as I said programmation through hot carrier injection and erase through FN tunneling repeating it over and over again so that you realize that there are two different operations and both are necessary both appear to be completely negative initially that such high voltages are required and so on but or that they lead to increased leakage but then we're using it both these things to our benefit when we're talking about flash memories all program missionaries in the flash memories is that okay yes okay and then again this is the arrays operation uh that was hiring operation this is arrays operation and uh I think we come to the architecture next class is that okay we will stop here but still you have done it's not sir yes what is the order of magnitude of phase operation or program operation for timing we'll look into this next class okay so it would be more than SM right oh yes definitely yeah because these are tunneling currents they are much much smaller than cell currents that we have in srams yes I know so we want to Tunnel tunneling Warrior foreign you cannot really increase tunneling currents also too high sure anything else okay there are no further questions and I would just"
TfmSuqpYtUc,yes sir okay so now we've come to look at what slash architecture is about um so uh again we have row decoders and column decoders and just like the dram the address bus is shared here also so what does that mean when I say to the address bus is shared what would that mean square is structured uh not it's okay so either yes it is either we can say it as a squared o a square array or we could say that it is something which is uh or we could say it as something which is uh where you will have to send address in multiple phases less resources yes again this is very critical over here because uh Slash is always object if the flash would be on chip then again you need not have this multiplexing of a row and column address on that test pass but if slash is but if flash is uh how do we put it uh off chip then there are a number of pins that are involved there and that is what needs to be taken care of so again over here we have word line which goes goes on the control gate now and the bit line which is connected to the drain is this clear so notice there is this Source switch source which means ground connection being coming from here and so what kind of a flash is this this is the control gate on the word line uh wordline connected to the control gate and uh bit lines connected to the drain region so what kind of flash is this nor or not what kind of flash would be this hello yeah why is this not because awesome foreign on one side and Source on the other side so all the devices are in parallel to each other anyone goes anyone of the device allows current to flow bit line would discharge because anyone because that is the logic that is being applied this is not yes okay so when we have this nor Flash what are what is being done to again to do the read operation what do we do we just take the bit line on the the word line to a level which is between the DT of say 0 and 1. okay now at this particular word line level all these devices they will sync current and the devices over here will not sync current the cells that sync current they are said to have let us say zero stored on them the other ones are said to have one stored on them is it okay foreign yes we've ensured that uh the straight-off let us say cell storing zero is three volts the cell storing one is seven volts so there is a huge margin in between them and we are keeping word line at somewhere in between them okay yes how do you do a right how do you do a program so that was the read operation how do you do your program or any rate so what happens is let us say there are so many of these word lines there you would to erase to erase this thing you would put word line at minus 10 volts and he would put bulk at six to eight volts what will happen will happen and all the electrons that were there in the floating gate will be repelled repelled into the bulk region bulk has a high positive voltage and control kit has a very high negative voltage so all the electrons in the controls it will get repaired and you will have cell DT again which is in this range okay when I want to program we already discussed this last time also when I want to program wordline is at plus 10 volts bit line is actually let us say 5 volts the other bit line is up zero so what is happening charge you will be trapped you create a high VDS across the gate across the device so uh charges are energized and then you have a vertical field also so charges electrons are attracted to the gate they will reach through the the gate oxide and enter into the floating gate there as a consequence VT would increase is this clear any questions I'm just floating okay so why are you okay why are we keeping select line SLS floating so it is not select my net Source line okay sorry yeah the source line is also left loading because you are doing FN tunneling into the bulk yes okay so we want them to escape via bulk and node also source okay obviously they won't be able to okay and then that is the read operation that we just discussed so just for clarification okay from the floating gate and it has gone into what do we say well uh in a source side yes yes so the layout of such a cell appears something like this huh the green one is the source line that is sent to the diffusion layer and yellow one or shown over here is the let us say control gate floating gate is shown with this light gray kind of a thing and then there is isolation between the cells now this is STI and do you see that with every cell there is a set of contacts that are there and everything that is there so what happens it takes a little bit more area than then you would have desired this is how the cell would look like sorry this is how the cell would look like you see the control gate this is the control gate over there and these are the floating Gates so the control gate is one one continuous line why is that why is that the case because it is the common word line that this is the rule this this is word line view which is uh cross section at this place along the B axis so control gate is continuous floating gate is just above the device and this is the source and drain region there now if I intersect or intercept from here then this is the view that I see I see the contacts for the bit line and I see the source Range region for the device also there so the thin wide strip between CG and FG is that the dielectric very thin I'm sorry the dielectric is very thin thin like this one and in between CG and mg also okay good okay any further questions is this clear okay so now in a nor flash then what what you do you organize the entire memory into blocks huh and in every block you have uh these nostrils which are arranged uh with the help of flow decoders and everything and this is the you know every every cross section over here represents such a bit cell such a slash cell over there when you want to read now let us say you were storing two bits in this memory cell let us say if you are storing two bits in this memory cell and you want to read then there are two ways that you could read one way is that you apply one voltage on the gate and then measure the current that the front bit lines are discharging so what what what does that mean that means that uh the current that is consumed by a cell which is let us say this is zero zero zero one one zero and one one so current consumed by 0 0 is obviously zero zero one is equal to ic2 1 0 is equal to ic3 and 1 1 is equal to ic4 if you can identify what is the current that that is being sunk into the memory cell you can tell what what data you are storing what two bits you are storing in your memory sir is this part clear so you will need a currents and sampler wires is the left trigger clear yes now when you want to read what do you do when you want to read in the voltage mode what do you do you say that I want to measure when is IC getting sunk in my particular cell so let us say for one cell IC got reached at vd4 itself and and another cell ID got reached at vg1 so what this means is that this is let us say 0 0 this then is 1 1 and you could say 0 1 1 0 over here clearly when you operate in voltage mode you have fixed the IEC per cell so you require lesser currents it is lesser power and also you know in one go you could be able to make out a lot of stuff so parallelism is also High are you able to see this any questions so just for clarification with one current uh measuring we can uh read around four four states right we can we can read that foreign value we can reach for the we can identify what voltage will myself think that kind of current and I can kind of estimate the VT of my device yes sir from there we can decide zero zero or zero one yeah so okay I'm just confusing in if there will be four devices uh connected and to one bit line and uh that in that case would not create because the word line would be selected one I'm sorry so if we say that we were doing say let us say voltage mode read operation then what what does the circuit looks like what does a circuit look like it could appear something like this I want to sync let us say some cell current IBL okay so this is my bit line and I know what is the cell current that is being sunk here okay with this cell current I uh I kind of put a bit line limit as that more than this current will not be sung by the bit line and uh there is the CBL which I discharge with the current of IC and when I start to do that I kind of mirror it to get the current kic go go in this um a voltage would appear over here okay a voltage would appear over here and depending on uh IR minus K I C there could be some charge that would flow from a high voltage sense amplifier into this region this output is Amplified so this ID is then Amplified through this amplifier stage you see yeah one head it is H over here so this is Amplified with the with the with over H times over here and uh when the steady state is reached we simply measure the VG VG at this point tells me what is the voltage at which that kind of current is being discharged from my bit line so I will be able to estimate whether it is V4 vt3 vt2 or vt1 questions Okay so is that okay uh sir IIT who is controlling ID can you tell again to IR I have a reference current K times IC plus ID should be equal to oh yes okay so as i k i see where is so does the ID and then I say amplifier to give us the output basically okay is it clear so we're just amplifying K times once and then doing this subtraction at this reference voltage and then multiplying it with h times so how we are deciding this k at this H value take on what basis I'm sorry how we are deciding this K value and H value on what places we are deciding these values uh that is that is the kind of current budget the speed that you need and so on what is the power budget that you want to keep and what is the speed at which you want to operate okay okay because if the K is large a large amount of current would flow the references so it depends on the on the current that you want to sink and the sensitivity of the that you require of your circuit all these factors okay one basic down why did you say that current mode of read operation is not parallel while okay I got it my voltage won't be parallel but by the current mode would not be parallel we are only applying one gate voltage and it is giving us four different currents so why can't we sense them simultaneously um so okay so if I want to sentence simultaneously I will need to have portions amplifiers okay sir and then I can send them Services yes what is the contrast between yeah federalism and bonus this kind of current is flowing over here you have limited the current to IC yeah the power distribution is power detection okay so that is the only thing yeah yeah okay thank you okay,https://www.youtube.com/watch?v=TfmSuqpYtUc,"Link: https://www.youtube.com/watch?v=TfmSuqpYtUc
Transcript: yes sir okay so now we've come to look at what slash architecture is about um so uh again we have row decoders and column decoders and just like the dram the address bus is shared here also so what does that mean when I say to the address bus is shared what would that mean square is structured uh not it's okay so either yes it is either we can say it as a squared o a square array or we could say that it is something which is uh or we could say it as something which is uh where you will have to send address in multiple phases less resources yes again this is very critical over here because uh Slash is always object if the flash would be on chip then again you need not have this multiplexing of a row and column address on that test pass but if slash is but if flash is uh how do we put it uh off chip then there are a number of pins that are involved there and that is what needs to be taken care of so again over here we have word line which goes goes on the control gate now and the bit line which is connected to the drain is this clear so notice there is this Source switch source which means ground connection being coming from here and so what kind of a flash is this this is the control gate on the word line uh wordline connected to the control gate and uh bit lines connected to the drain region so what kind of flash is this nor or not what kind of flash would be this hello yeah why is this not because awesome foreign on one side and Source on the other side so all the devices are in parallel to each other anyone goes anyone of the device allows current to flow bit line would discharge because anyone because that is the logic that is being applied this is not yes okay so when we have this nor Flash what are what is being done to again to do the read operation what do we do we just take the bit line on the the word line to a level which is between the DT of say 0 and 1. okay now at this particular word line level all these devices they will sync current and the devices over here will not sync current the cells that sync current they are said to have let us say zero stored on them the other ones are said to have one stored on them is it okay foreign yes we've ensured that uh the straight-off let us say cell storing zero is three volts the cell storing one is seven volts so there is a huge margin in between them and we are keeping word line at somewhere in between them okay yes how do you do a right how do you do a program so that was the read operation how do you do your program or any rate so what happens is let us say there are so many of these word lines there you would to erase to erase this thing you would put word line at minus 10 volts and he would put bulk at six to eight volts what will happen will happen and all the electrons that were there in the floating gate will be repelled repelled into the bulk region bulk has a high positive voltage and control kit has a very high negative voltage so all the electrons in the controls it will get repaired and you will have cell DT again which is in this range okay when I want to program we already discussed this last time also when I want to program wordline is at plus 10 volts bit line is actually let us say 5 volts the other bit line is up zero so what is happening charge you will be trapped you create a high VDS across the gate across the device so uh charges are energized and then you have a vertical field also so charges electrons are attracted to the gate they will reach through the the gate oxide and enter into the floating gate there as a consequence VT would increase is this clear any questions I'm just floating okay so why are you okay why are we keeping select line SLS floating so it is not select my net Source line okay sorry yeah the source line is also left loading because you are doing FN tunneling into the bulk yes okay so we want them to escape via bulk and node also source okay obviously they won't be able to okay and then that is the read operation that we just discussed so just for clarification okay from the floating gate and it has gone into what do we say well uh in a source side yes yes so the layout of such a cell appears something like this huh the green one is the source line that is sent to the diffusion layer and yellow one or shown over here is the let us say control gate floating gate is shown with this light gray kind of a thing and then there is isolation between the cells now this is STI and do you see that with every cell there is a set of contacts that are there and everything that is there so what happens it takes a little bit more area than then you would have desired this is how the cell would look like sorry this is how the cell would look like you see the control gate this is the control gate over there and these are the floating Gates so the control gate is one one continuous line why is that why is that the case because it is the common word line that this is the rule this this is word line view which is uh cross section at this place along the B axis so control gate is continuous floating gate is just above the device and this is the source and drain region there now if I intersect or intercept from here then this is the view that I see I see the contacts for the bit line and I see the source Range region for the device also there so the thin wide strip between CG and FG is that the dielectric very thin I'm sorry the dielectric is very thin thin like this one and in between CG and mg also okay good okay any further questions is this clear okay so now in a nor flash then what what you do you organize the entire memory into blocks huh and in every block you have uh these nostrils which are arranged uh with the help of flow decoders and everything and this is the you know every every cross section over here represents such a bit cell such a slash cell over there when you want to read now let us say you were storing two bits in this memory cell let us say if you are storing two bits in this memory cell and you want to read then there are two ways that you could read one way is that you apply one voltage on the gate and then measure the current that the front bit lines are discharging so what what what does that mean that means that uh the current that is consumed by a cell which is let us say this is zero zero zero one one zero and one one so current consumed by 0 0 is obviously zero zero one is equal to ic2 1 0 is equal to ic3 and 1 1 is equal to ic4 if you can identify what is the current that that is being sunk into the memory cell you can tell what what data you are storing what two bits you are storing in your memory sir is this part clear so you will need a currents and sampler wires is the left trigger clear yes now when you want to read what do you do when you want to read in the voltage mode what do you do you say that I want to measure when is IC getting sunk in my particular cell so let us say for one cell IC got reached at vd4 itself and and another cell ID got reached at vg1 so what this means is that this is let us say 0 0 this then is 1 1 and you could say 0 1 1 0 over here clearly when you operate in voltage mode you have fixed the IEC per cell so you require lesser currents it is lesser power and also you know in one go you could be able to make out a lot of stuff so parallelism is also High are you able to see this any questions so just for clarification with one current uh measuring we can uh read around four four states right we can we can read that foreign value we can reach for the we can identify what voltage will myself think that kind of current and I can kind of estimate the VT of my device yes sir from there we can decide zero zero or zero one yeah so okay I'm just confusing in if there will be four devices uh connected and to one bit line and uh that in that case would not create because the word line would be selected one I'm sorry so if we say that we were doing say let us say voltage mode read operation then what what does the circuit looks like what does a circuit look like it could appear something like this I want to sync let us say some cell current IBL okay so this is my bit line and I know what is the cell current that is being sunk here okay with this cell current I uh I kind of put a bit line limit as that more than this current will not be sung by the bit line and uh there is the CBL which I discharge with the current of IC and when I start to do that I kind of mirror it to get the current kic go go in this um a voltage would appear over here okay a voltage would appear over here and depending on uh IR minus K I C there could be some charge that would flow from a high voltage sense amplifier into this region this output is Amplified so this ID is then Amplified through this amplifier stage you see yeah one head it is H over here so this is Amplified with the with the with over H times over here and uh when the steady state is reached we simply measure the VG VG at this point tells me what is the voltage at which that kind of current is being discharged from my bit line so I will be able to estimate whether it is V4 vt3 vt2 or vt1 questions Okay so is that okay uh sir IIT who is controlling ID can you tell again to IR I have a reference current K times IC plus ID should be equal to oh yes okay so as i k i see where is so does the ID and then I say amplifier to give us the output basically okay is it clear so we're just amplifying K times once and then doing this subtraction at this reference voltage and then multiplying it with h times so how we are deciding this k at this H value take on what basis I'm sorry how we are deciding this K value and H value on what places we are deciding these values uh that is that is the kind of current budget the speed that you need and so on what is the power budget that you want to keep and what is the speed at which you want to operate okay okay because if the K is large a large amount of current would flow the references so it depends on the on the current that you want to sink and the sensitivity of the that you require of your circuit all these factors okay one basic down why did you say that current mode of read operation is not parallel while okay I got it my voltage won't be parallel but by the current mode would not be parallel we are only applying one gate voltage and it is giving us four different currents so why can't we sense them simultaneously um so okay so if I want to sentence simultaneously I will need to have portions amplifiers okay sir and then I can send them Services yes what is the contrast between yeah federalism and bonus this kind of current is flowing over here you have limited the current to IC yeah the power distribution is power detection okay so that is the only thing yeah yeah okay thank you okay"
zrs59Kk-lNo,let us look at the flash memory we can use exactly the same things in the in here also but in the flash memory you are kind in a n flash memory you actually have a string of devices connected to each other in land structure H so 16 or 32 cells may be connected as with one select transistor huh and uh program BT let us say is greater than zero and eras BT is less than zero interestingly the source and drain region over here now do not need a contact see in the nor flash you needed a contact for the drain where the bit line would connect and a contact for the source where the source line would connect over here we have uh bit line select and let us say ground select signals there are two regular mosfets they do not have the control gate and everything kind of mechanism there and uh only they connect to Source or they connect to the bit line there there is no requirement of contact in between the flash cells now so the density of the N flash is much higher than that of of the N flash is this thing clear uh yes so since we are not using the contact then we can say is more answer yeah uh but then how the operation will happen so can you yeah that will come to anyways okay so now look at it like this you simply have word lines and there is no need for having any contact over here so these these Gates can actually come much closer so these Gates can actually come much closer and you can have a denser memory cell n flash is therefore multiple times denser than the nor Flash okay in a nor flash you had one transistor per bit whereas in a uh nand flash you have 18 transistors the The Source The Source select and the uh gate select signals are extra so 18 thrip per 16 bits this therefore is much denser is it okay okay clear yes sir sir can you please explain once again how the gates are coming closer you do not need a contact in here now see in the nor flash there was a contact that was required at the drain what contact was that for bit line and then you also needed a source L to be run yes sir so uh over here they're saying there is only one contact over here for the bit line and one contact over here for the ground no other moving out of the uh what do you say okay so got because you have lesser contacts you can be much denser okay so this is how it appears in the in the kind of a layout where uh after every say poly you had a contact or Source Line running in and over here for the N it's completely just a string of uh devices no space for contacts hm yes sir so for the nor flash contact is what limits further scaling of area land flash can actually scale down at the same PA as the poly toly facing scales down at least that was what the initial thought was and you see this is how so many transistors this is how you non flash is denser okay another cross-sectional image where you see that different word lines simply go like this there is a source line uh that connects to the source and there is a drain line which connects to the bit lineing the prev final reason I'm sorry am I audible yeah you are audible but a little low on volume I wanted to know in the the right the main reason for the N to be Den was the poing so uh I'm not I'm not convinced with the reason of that n to more can just highlight okay because now let me repeat see in a n flash you had a you had a contact for the source and you had a contact for bit line am I right yes then there would be another poly over here so what is the spacing between two polyes contact plus two Copo spacing okay one Copo here one Copo here and the contact width whereas if the if there was no contacting in between as in the case of stand yes as is the case of land then the two cells can actually be much closer you just need you also mentioned in one SL the number of trans perit reing the N or more yes over here we said if we storing 16 transistors we have 16 transistors in this string there are two extra transistors for the gate and the bit line select for the ground and bit line select and two extra transistors n denser because of that contacts are not there in between them yeah my thank you so what are the scaling challenges linked to a n flash so I'm writing something you should actually ask details from uh Kalan in the next class first is performance see as you scale down the currents would reduce second is BT distribution as you scale down because the the floating floating gate is now smaller uh mismatches will happen more prominently and uh there will be a challenge of BT distribution over there and then since we are applying very high voltages you're talking about + 10 minus5 or you know uh minus 10 and uh 6 to 8 volts on the bulk talking about very high voltages put across the the control gate to the bulk part so with these high voltages there can be a lot of issues on reliability so in land flash or even in N flash reliability is something that you should always be extremely careful about h so again when we want to program what do you do you only so in a n flash for programming so in a n flash what did we say programming with hard carrier inci yes sir but in a nand Flash we actually do this also with fnn we simply create an inversion layer here 0 volt on the bulk and 18 to 20 volts on the control gate electrons simply get the energy to jump into the float gate if you want to erase you simply change the connection zero goes onto the control gate and 18 to 20 Vol that is something of similar order going onto the bulk so all the electrons are thrown out from the float gate into the bulk again so it [Music] yeah but feling is much slower than now okay okay so now it appears okay at a cell level but you being memory designers you also have to see what happens to the cells in the same row which are not to be selected so I want to program let us say this particular cell huh so it's word line would go to 18 volts but the same word line is going to so many other columns also huh so how do you prevent right and other columns how do you prevent writing the on you say that I will apply a different voltage on Vass huh and a different voltage on different voltage on the bit line if you apply a different voltage on the bit line what happens the charges are conserved in the other column when we apply this 8 volts over here we in a way kind of ensure that the bit lines or the source and R which were kind of left floating are not really floating there then they have a distinct voltage on them and because of that what happens this 8 volts so look at it like this this transistor the gate is at 10 volts bit line is at 8 volts what goes what happens to this internal node over here what would appear here if the VT of this device is 2 volts what will appear on this node eight only 8 volt so this 8 volt will actually you will see pass to this last device now when the 8vt is there on it source and drain what happens you want to apply HCI huh but now you cannot apply FCI why because uh 8 volt has got transmitted over here until everything and therefore the kinetic en or the uh inversion layer that is formed will not have that kind of a thing happening is that okay yes sir H and you could actually so okay for the for the flash memory there is this one important figure of Merit which is like uh this figure of Merit which is like uh what is the ratio of gate coupling what is the capacitance of the gate versus total capacitance okay that needs to be taken care of and that was one scheme where we had to apply you know now how many voltages are we talking about 0 volts 8 volt Vols 10 volts and 18 volts four voltages you're talking about it means four different voltage Regulators can I do something else so there was this uh paper a very old one at that which talked about uh self boosted slash huh so what happens there uh first of all bl1 uh prech charges all transistors to VD minus V and if I put this at vdd then bl1 will pre-charge everything to vdd minus VT everywhere it will become VD minus VT am I right yes sir huh then uh SSL goes off what happens all the channels all the all the channels of all the transistors on bl1 one become floating huh yes sir so uh in a way you used bdd only you reduce the supply voltage there huh instead of using a different PDD and and uh with some constraints you actually ensuring that this particular cell is not programmed that this V is such that you do not program this is that okay so let us look at it again we hadt here and we taking VD to zero when I want to write into this particular step yes sir so when it was vdd what was happening at all these places vdd minus VT must have got transmitted yes sir uh not exactly VD minus VT V pass uh V pass which is 10 volts minus VT yes sir yes sir huh if vdd is less than that then entire VD would get transmitted if it is more than that then that little part would uh then VD minus VT will get transmitted yes sir okay so what happens you taken this to zero then as soon as you take this to zero it is zero everywhere if it is zero what happens FN teling starts okay huh over here that doesn't start because over here it is VD minus VP a okay okay sir you not put the device in inversion region at all yes sir yes sir so the programmation will not happen Okay okay sir okay any further questions on this okay so then if you look at the timings if you start to look at the timings then chip enable is low it means your chip is active uh is uh chip enable low chip enable bar is low so your cell is active then uh address latch column latch everything these are coming command latch address latch are coming so so when the command latch comes your iOS you start to latch the command when the address latch comes you start to latch the uh L the address of the column and then in subsequent cycle of the row okay and then you wait you wait for data to be transferred for this column for this row okay and you do a data out is this clear I will let me remove mine and show the so this is the first is the command phase then we have the address phase then the data transfer phase and once the data transfer has completed you kind of say okay we will read out the this though it has been shown to be a small BD is actually a long pH okay now when I want to program what do I need to do I again need to give a command I need to give a column address and the row addresses and then I start to send and my data that I want to program in the memory okay yes so we are able to okay so there is also would you say a counter or something which tells us that programmation is completed or not once it is completed we start the next operation there okay so now let's look at if we were to design a 1 gabit flash memory how would we organize it so first thing is that 1 gabit thing will be separated into two to Banks of five and2 megabits let us say huh and in each Bank there will be blocks what is a block suppose your memory cell had 32 cells in it so the block will have 32 cells and the block would have 32 words okay so this is 32 then each block there are 32 words all cells on one word line form what is called a page all of them will get programmed together at any given point of time uh when you select say one word line at 18 Ms to program all the cells all the uh transistors on that particular row would get selected on program all at one is this clear H now why do you think over here we've added 32 bits over here also 32 bits by why are these 32 bits extra bits there word line sales all are program together it that that the sense amplifiers also connected to them you heard about eror correction codes I just heard about huh just just to know when I spoke you got to know huh or you knew about it earlier uh just know the name in C you just know the name okay so error correction codes are used so that if there is some error that is that is script and either either at writing or during read from a particular digital circuit uh by storing the codes there I can actually decipher and decipher what the error was first I will I can first detect that there is an error and then decipher what there was and correct the correct the content of the memory this is extremely necessary for for Flash uh there was a point in time it was also extremely necessary for what do you say dams huh uh it it adds error resilience in the presence of noise so you will see that U error correction is used widely then this set of 32 pages is called one block okay now when you erase the memory so when you program you program row by row so you program every page in one go but when you erase the memory you erase the entire block H so that means that particular Row in every page erasing the entire block every row yeah so all the 32 rows or 32 cells uh are part of the block and not just 32 cells all the rows of those all the 32 rows of that n cell if the N cell has 32 bits are a part of the page okay sir what would happen if you increase the page size what would happen if you increase the page size software terms May or be hello so as you increase the page size as I said the entire page would be deleted oh as increase the page size uh you uh you're actually line length you know the data that you're fetching from the from the main memory from this flash into the main memory or elsewhere increases so the delay would increase but the line length is essentially increasing H sir would that also mean lesser number of bits will be required for error correction uh why would you say that sir what does it depend on the number of bits in error correction is that the uh size of the word yes the length of the word for example if the word is 32 bit wide you will need for a SE dead code five error correction bits so it's like parity generation something like that parity is always one bit okay but uh error correction code generation is dependent on uh what do you say how many bits your database have okay sir hm so we already saw the sense latches and the data AES and this is how my one logical page is broken into two visic pages H so now what we are saying is that there are 8K + 256 8K + 256 bits that are being read on the left side and same bits that are being read on the right side or written from the left and right side huh so over here if I say that uh this is my flash memory uh 125 mm squ 1 GB fash memory then uh there are bit lines that are running like this huh over here in every block how many uh word lines do I have 32 and there are one24 blocks so there are 32k word lines in in total,https://www.youtube.com/watch?v=zrs59Kk-lNo,"Link: https://www.youtube.com/watch?v=zrs59Kk-lNo
Transcript: let us look at the flash memory we can use exactly the same things in the in here also but in the flash memory you are kind in a n flash memory you actually have a string of devices connected to each other in land structure H so 16 or 32 cells may be connected as with one select transistor huh and uh program BT let us say is greater than zero and eras BT is less than zero interestingly the source and drain region over here now do not need a contact see in the nor flash you needed a contact for the drain where the bit line would connect and a contact for the source where the source line would connect over here we have uh bit line select and let us say ground select signals there are two regular mosfets they do not have the control gate and everything kind of mechanism there and uh only they connect to Source or they connect to the bit line there there is no requirement of contact in between the flash cells now so the density of the N flash is much higher than that of of the N flash is this thing clear uh yes so since we are not using the contact then we can say is more answer yeah uh but then how the operation will happen so can you yeah that will come to anyways okay so now look at it like this you simply have word lines and there is no need for having any contact over here so these these Gates can actually come much closer so these Gates can actually come much closer and you can have a denser memory cell n flash is therefore multiple times denser than the nor Flash okay in a nor flash you had one transistor per bit whereas in a uh nand flash you have 18 transistors the The Source The Source select and the uh gate select signals are extra so 18 thrip per 16 bits this therefore is much denser is it okay okay clear yes sir sir can you please explain once again how the gates are coming closer you do not need a contact in here now see in the nor flash there was a contact that was required at the drain what contact was that for bit line and then you also needed a source L to be run yes sir so uh over here they're saying there is only one contact over here for the bit line and one contact over here for the ground no other moving out of the uh what do you say okay so got because you have lesser contacts you can be much denser okay so this is how it appears in the in the kind of a layout where uh after every say poly you had a contact or Source Line running in and over here for the N it's completely just a string of uh devices no space for contacts hm yes sir so for the nor flash contact is what limits further scaling of area land flash can actually scale down at the same PA as the poly toly facing scales down at least that was what the initial thought was and you see this is how so many transistors this is how you non flash is denser okay another cross-sectional image where you see that different word lines simply go like this there is a source line uh that connects to the source and there is a drain line which connects to the bit lineing the prev final reason I'm sorry am I audible yeah you are audible but a little low on volume I wanted to know in the the right the main reason for the N to be Den was the poing so uh I'm not I'm not convinced with the reason of that n to more can just highlight okay because now let me repeat see in a n flash you had a you had a contact for the source and you had a contact for bit line am I right yes then there would be another poly over here so what is the spacing between two polyes contact plus two Copo spacing okay one Copo here one Copo here and the contact width whereas if the if there was no contacting in between as in the case of stand yes as is the case of land then the two cells can actually be much closer you just need you also mentioned in one SL the number of trans perit reing the N or more yes over here we said if we storing 16 transistors we have 16 transistors in this string there are two extra transistors for the gate and the bit line select for the ground and bit line select and two extra transistors n denser because of that contacts are not there in between them yeah my thank you so what are the scaling challenges linked to a n flash so I'm writing something you should actually ask details from uh Kalan in the next class first is performance see as you scale down the currents would reduce second is BT distribution as you scale down because the the floating floating gate is now smaller uh mismatches will happen more prominently and uh there will be a challenge of BT distribution over there and then since we are applying very high voltages you're talking about + 10 minus5 or you know uh minus 10 and uh 6 to 8 volts on the bulk talking about very high voltages put across the the control gate to the bulk part so with these high voltages there can be a lot of issues on reliability so in land flash or even in N flash reliability is something that you should always be extremely careful about h so again when we want to program what do you do you only so in a n flash for programming so in a n flash what did we say programming with hard carrier inci yes sir but in a nand Flash we actually do this also with fnn we simply create an inversion layer here 0 volt on the bulk and 18 to 20 volts on the control gate electrons simply get the energy to jump into the float gate if you want to erase you simply change the connection zero goes onto the control gate and 18 to 20 Vol that is something of similar order going onto the bulk so all the electrons are thrown out from the float gate into the bulk again so it [Music] yeah but feling is much slower than now okay okay so now it appears okay at a cell level but you being memory designers you also have to see what happens to the cells in the same row which are not to be selected so I want to program let us say this particular cell huh so it's word line would go to 18 volts but the same word line is going to so many other columns also huh so how do you prevent right and other columns how do you prevent writing the on you say that I will apply a different voltage on Vass huh and a different voltage on different voltage on the bit line if you apply a different voltage on the bit line what happens the charges are conserved in the other column when we apply this 8 volts over here we in a way kind of ensure that the bit lines or the source and R which were kind of left floating are not really floating there then they have a distinct voltage on them and because of that what happens this 8 volts so look at it like this this transistor the gate is at 10 volts bit line is at 8 volts what goes what happens to this internal node over here what would appear here if the VT of this device is 2 volts what will appear on this node eight only 8 volt so this 8 volt will actually you will see pass to this last device now when the 8vt is there on it source and drain what happens you want to apply HCI huh but now you cannot apply FCI why because uh 8 volt has got transmitted over here until everything and therefore the kinetic en or the uh inversion layer that is formed will not have that kind of a thing happening is that okay yes sir H and you could actually so okay for the for the flash memory there is this one important figure of Merit which is like uh this figure of Merit which is like uh what is the ratio of gate coupling what is the capacitance of the gate versus total capacitance okay that needs to be taken care of and that was one scheme where we had to apply you know now how many voltages are we talking about 0 volts 8 volt Vols 10 volts and 18 volts four voltages you're talking about it means four different voltage Regulators can I do something else so there was this uh paper a very old one at that which talked about uh self boosted slash huh so what happens there uh first of all bl1 uh prech charges all transistors to VD minus V and if I put this at vdd then bl1 will pre-charge everything to vdd minus VT everywhere it will become VD minus VT am I right yes sir huh then uh SSL goes off what happens all the channels all the all the channels of all the transistors on bl1 one become floating huh yes sir so uh in a way you used bdd only you reduce the supply voltage there huh instead of using a different PDD and and uh with some constraints you actually ensuring that this particular cell is not programmed that this V is such that you do not program this is that okay so let us look at it again we hadt here and we taking VD to zero when I want to write into this particular step yes sir so when it was vdd what was happening at all these places vdd minus VT must have got transmitted yes sir uh not exactly VD minus VT V pass uh V pass which is 10 volts minus VT yes sir yes sir huh if vdd is less than that then entire VD would get transmitted if it is more than that then that little part would uh then VD minus VT will get transmitted yes sir okay so what happens you taken this to zero then as soon as you take this to zero it is zero everywhere if it is zero what happens FN teling starts okay huh over here that doesn't start because over here it is VD minus VP a okay okay sir you not put the device in inversion region at all yes sir yes sir so the programmation will not happen Okay okay sir okay any further questions on this okay so then if you look at the timings if you start to look at the timings then chip enable is low it means your chip is active uh is uh chip enable low chip enable bar is low so your cell is active then uh address latch column latch everything these are coming command latch address latch are coming so so when the command latch comes your iOS you start to latch the command when the address latch comes you start to latch the uh L the address of the column and then in subsequent cycle of the row okay and then you wait you wait for data to be transferred for this column for this row okay and you do a data out is this clear I will let me remove mine and show the so this is the first is the command phase then we have the address phase then the data transfer phase and once the data transfer has completed you kind of say okay we will read out the this though it has been shown to be a small BD is actually a long pH okay now when I want to program what do I need to do I again need to give a command I need to give a column address and the row addresses and then I start to send and my data that I want to program in the memory okay yes so we are able to okay so there is also would you say a counter or something which tells us that programmation is completed or not once it is completed we start the next operation there okay so now let's look at if we were to design a 1 gabit flash memory how would we organize it so first thing is that 1 gabit thing will be separated into two to Banks of five and2 megabits let us say huh and in each Bank there will be blocks what is a block suppose your memory cell had 32 cells in it so the block will have 32 cells and the block would have 32 words okay so this is 32 then each block there are 32 words all cells on one word line form what is called a page all of them will get programmed together at any given point of time uh when you select say one word line at 18 Ms to program all the cells all the uh transistors on that particular row would get selected on program all at one is this clear H now why do you think over here we've added 32 bits over here also 32 bits by why are these 32 bits extra bits there word line sales all are program together it that that the sense amplifiers also connected to them you heard about eror correction codes I just heard about huh just just to know when I spoke you got to know huh or you knew about it earlier uh just know the name in C you just know the name okay so error correction codes are used so that if there is some error that is that is script and either either at writing or during read from a particular digital circuit uh by storing the codes there I can actually decipher and decipher what the error was first I will I can first detect that there is an error and then decipher what there was and correct the correct the content of the memory this is extremely necessary for for Flash uh there was a point in time it was also extremely necessary for what do you say dams huh uh it it adds error resilience in the presence of noise so you will see that U error correction is used widely then this set of 32 pages is called one block okay now when you erase the memory so when you program you program row by row so you program every page in one go but when you erase the memory you erase the entire block H so that means that particular Row in every page erasing the entire block every row yeah so all the 32 rows or 32 cells uh are part of the block and not just 32 cells all the rows of those all the 32 rows of that n cell if the N cell has 32 bits are a part of the page okay sir what would happen if you increase the page size what would happen if you increase the page size software terms May or be hello so as you increase the page size as I said the entire page would be deleted oh as increase the page size uh you uh you're actually line length you know the data that you're fetching from the from the main memory from this flash into the main memory or elsewhere increases so the delay would increase but the line length is essentially increasing H sir would that also mean lesser number of bits will be required for error correction uh why would you say that sir what does it depend on the number of bits in error correction is that the uh size of the word yes the length of the word for example if the word is 32 bit wide you will need for a SE dead code five error correction bits so it's like parity generation something like that parity is always one bit okay but uh error correction code generation is dependent on uh what do you say how many bits your database have okay sir hm so we already saw the sense latches and the data AES and this is how my one logical page is broken into two visic pages H so now what we are saying is that there are 8K + 256 8K + 256 bits that are being read on the left side and same bits that are being read on the right side or written from the left and right side huh so over here if I say that uh this is my flash memory uh 125 mm squ 1 GB fash memory then uh there are bit lines that are running like this huh over here in every block how many uh word lines do I have 32 and there are one24 blocks so there are 32k word lines in in total"
qfgNEuzW2Qo,and below the sense amplifiers you have what is called as a page register which is a memory which again includes VCC which is a memory with ECC and uh this ensures quick uh or decoupling of the speed of the flash from the speed of the processor or the processing system altogether because the burst mode and everything can actually be implemented in this Pages for itself so is this composed of a Samsung sorry stage register is composed of SRAM cells it can be examples it can be props ideally because this is a large number of registers this is the large number of storage elements you would use an SRAM dancer but Islam would mean some little bit extra complexity also if you do not want to go into that complexity you can just make a resistor Bank anyway your this cube is very dense Focus now this is The Logical view of this what we are saying is there is a cell there is this concept of bird then there are there is a page pages all the bit lines uh all the all the cells sharing the same word line that is a page and a block is a group of multiple pages where the bit lines are the multiple bit lines and both multiple word lines in there okay as I said entire page is programmed at once an entire block is erased at once okay if you increase the page size let us say so yeah we increase the memory size eight Ambit say a week went to 16 megabytes megabit I maintained same page size and block size what happens read per page remains same because the size of the page are remained same the program per page remains same and erase the block the delay the relation remains same huh now if I go to uh larger memory with let us say larger page size now larger block size now then you will notice that uh this timing program per page timing can start to reduce a bit why would that be the case hello so because more number of cells have been programmed at once [Music] because your face size are increased so if you wanted to update a particular file you now need lesser program operations huh if you change the block size then what happens then you notice the erase time over here has reduced because we raise the entire Block in one go now that that size has increased so the erase time has reduced over here we saw a significant reduction and how do we put it um program time we also saw a reduction in page time in in the erase time but uh that was the major chunk over here and that has reduced okay so if you're talking about I'm sorry I'll just take another one minute because I want you to be prepared for uh kalyan's lecture that's it just two more slides we're talking about 125 millimeters Square One gigabit nine slash then the other numbers that you could look at uh just keep these numbers in mind and then compare with the numbers that Kalyan may share tomorrow on day after tomorrow okay and you can actually find out read speeds same kind of formula that used when we were working on dram when finding the peak bandwidth over there exactly the same way you just need to understand how the page is organized what kind of time it takes for data transfer what kind of time it takes for command transfer number of Cycles for command transfer and so on and you can arrive at a read speed write speed and erase speed and you see erase speed is much much faster why compute block as it is the complete block gets raised in one go um so the total amount of time you need is is lesser however realize that you need two milliseconds to erase you need two milliseconds to erase but because now the number of times this erase has to happen is lesser overall it is speed is much higher okay now a quick comparison v9 I'm not not as very high speed random access and byte programming over here high speed programming high speed erasing small block size but it has very slow Random Access additionally by programming cannot be done uh for the nor the programming and arrays are also slow and nor flash could be suitable for replacement of eeproms and uh because these are usually smaller in size whereas nand flash can actually be used as a data memory all the SD cards that we use they're all nand Flash because it's dense they're for cheaper okay any questions [Music] so all those schemes that we looked at in dram and also we explored to be used here because they are not linked to data to the dram per se are they no they are all about internship data transfer so all those schemes you can put over here also in control by controlling it because there are one more confusion then sir we initially saw when we see the set timing diagram we were initially sending the column address and then we are sending the row address so would it create any rates condition during the Burst Mode access so again you would uh you would want to do it according to what is the requirement there okay when you select one particular row you are actually selecting the entire page reading my entire page anyways so you may not need any further uh further thing for Burst Mode access something like inside the memory when you brought it to the plane of your SRAM then you can decide whether to you house fast or how slow to read yes okay [Music],https://www.youtube.com/watch?v=qfgNEuzW2Qo,"Link: https://www.youtube.com/watch?v=qfgNEuzW2Qo
Transcript: and below the sense amplifiers you have what is called as a page register which is a memory which again includes VCC which is a memory with ECC and uh this ensures quick uh or decoupling of the speed of the flash from the speed of the processor or the processing system altogether because the burst mode and everything can actually be implemented in this Pages for itself so is this composed of a Samsung sorry stage register is composed of SRAM cells it can be examples it can be props ideally because this is a large number of registers this is the large number of storage elements you would use an SRAM dancer but Islam would mean some little bit extra complexity also if you do not want to go into that complexity you can just make a resistor Bank anyway your this cube is very dense Focus now this is The Logical view of this what we are saying is there is a cell there is this concept of bird then there are there is a page pages all the bit lines uh all the all the cells sharing the same word line that is a page and a block is a group of multiple pages where the bit lines are the multiple bit lines and both multiple word lines in there okay as I said entire page is programmed at once an entire block is erased at once okay if you increase the page size let us say so yeah we increase the memory size eight Ambit say a week went to 16 megabytes megabit I maintained same page size and block size what happens read per page remains same because the size of the page are remained same the program per page remains same and erase the block the delay the relation remains same huh now if I go to uh larger memory with let us say larger page size now larger block size now then you will notice that uh this timing program per page timing can start to reduce a bit why would that be the case hello so because more number of cells have been programmed at once [Music] because your face size are increased so if you wanted to update a particular file you now need lesser program operations huh if you change the block size then what happens then you notice the erase time over here has reduced because we raise the entire Block in one go now that that size has increased so the erase time has reduced over here we saw a significant reduction and how do we put it um program time we also saw a reduction in page time in in the erase time but uh that was the major chunk over here and that has reduced okay so if you're talking about I'm sorry I'll just take another one minute because I want you to be prepared for uh kalyan's lecture that's it just two more slides we're talking about 125 millimeters Square One gigabit nine slash then the other numbers that you could look at uh just keep these numbers in mind and then compare with the numbers that Kalyan may share tomorrow on day after tomorrow okay and you can actually find out read speeds same kind of formula that used when we were working on dram when finding the peak bandwidth over there exactly the same way you just need to understand how the page is organized what kind of time it takes for data transfer what kind of time it takes for command transfer number of Cycles for command transfer and so on and you can arrive at a read speed write speed and erase speed and you see erase speed is much much faster why compute block as it is the complete block gets raised in one go um so the total amount of time you need is is lesser however realize that you need two milliseconds to erase you need two milliseconds to erase but because now the number of times this erase has to happen is lesser overall it is speed is much higher okay now a quick comparison v9 I'm not not as very high speed random access and byte programming over here high speed programming high speed erasing small block size but it has very slow Random Access additionally by programming cannot be done uh for the nor the programming and arrays are also slow and nor flash could be suitable for replacement of eeproms and uh because these are usually smaller in size whereas nand flash can actually be used as a data memory all the SD cards that we use they're all nand Flash because it's dense they're for cheaper okay any questions [Music] so all those schemes that we looked at in dram and also we explored to be used here because they are not linked to data to the dram per se are they no they are all about internship data transfer so all those schemes you can put over here also in control by controlling it because there are one more confusion then sir we initially saw when we see the set timing diagram we were initially sending the column address and then we are sending the row address so would it create any rates condition during the Burst Mode access so again you would uh you would want to do it according to what is the requirement there okay when you select one particular row you are actually selecting the entire page reading my entire page anyways so you may not need any further uh further thing for Burst Mode access something like inside the memory when you brought it to the plane of your SRAM then you can decide whether to you house fast or how slow to read yes okay [Music]"
X5egItiB9xw,so good afternoon everyone uh let me formally welcome dr ashish uh he's been working with st microelectronics india for more than 20 years now and uh you know with the conversation that we were just having you know that we go back a long long time uh he obtained his phd from iit delhi in 2017 and before that he did his mtech and solid state technology from iit kharagpur in 2000. his major area of interest is circuit design with a larger emphasis on memory circuits and systems he has more than 17 patent current subsystems and many more already filed which will get granted over time and he also publishes uh quite politically in various international forums so today he will talk to us about uh you know safety and how you know safety is important for us for automotive applications for example and other applications and how do we make circuit and architectural changes to bring that safety into the embedded memories and therefore at the system level okay so let's welcome ashish and over to you ashish with that so uh good afternoon everybody let me introduce you with the topic the topic is circuit and architecture for safety critical embedded memories so many of you might have well understanding of sram memories and roms and maybe other memories as well and when i say about safety or security what does it mean first we will have to develop an understanding of that what we actually intend to embed in these memories as a function as a capability when we say safety and security so this is the outline of this lecture so first i will introduce you with the context and then for the need of a safe and secure memory and how we design a robust memory for low failure rate and how the data theft and static memories take place and safety and security specific safety and security circuits implementation in static memories and we will take up your questions your doubts so so this is important considering a robust operation for safety critical applications when we say safety critical applications first think about the automotive application and also you think about the banking applications your credit cards your debit cards and your online transactions everything so do you think that there is a need to have a secure or safe transaction at each and every step for both these domains when you are driving a car you need to be safe you don't expect any particular function or electrical function or mechanical function to break down uh risking your lives right are you putting you in trouble in between when you were traveling and the same is true for the banking transactions you don't want your data your passwords to be had your account to be added so these are the two major uh domains where we need to be very very sensitive for implementing security and safety this is a very contextual world where you call safe or secure now there has been efforts to address both aspects through software as well as through hardware implementation any system is basically uh comprising of an interaction of software with hardwares and on top of that a system is developed so there are many many implementations where software algorithms take care of the safety and security aspects and for those areas where a very high level of security is required you need to augment with hardware as well specific hardware implementations as well so these automotive safety integrity levels this is called acell this is a standard basically i use for standard and iso 26262 covers the safety aspects for the automotive segment so um when you are now talking about the autonomous vehicles right we all are talking about the autonomous vehicle driverless vehicle smart systems and all those things then definitely a sense of fear comes into your mind and all of you are compelled to think how this will be successful in indian context although this is being tested successfully at a global level but definitely the complexity of implementation and the risk of implementation is in everyone's mind every one of you will consider that there is no driver how the semiconductor chip or the how the ai will be able to address the uh the safety aspects like if somebody comes suddenly in between how the suddenly you can't apply the brake or in a crowded market place how the vehicle will move and all now so or if the vehicle is moving at a very high speed however this will take care of the uh surroundings when uh suddenly something comes flying or there is a pothole in the road so there are many many aspects which needs to be addressed when you are talking about autonomous vehicles so there also you need to augment the system with the multiple sensors and artificial intelligence embedded around old sensors so if you have any relevant questions please do not hesitate to stop me in between definitely at the end we'll take questions but in case something comes into your mind in between you can ask those questions so that you do not forget it later and everyone can address and come with the consensus understanding now what is acl automatic safety integrity level is basically categorizing the safety standards with respect to four considerations the particular function the probability of exposure how much it is exposed the controllability severity and and these the addition of these three the combination of these three is basically deciding with respect to the um ac standard in if case in case there is a threat of life if some particular function like the break function failure is going to be a threat of life definitely this is this should follow the highest level of safety standard that is the d this is the highest level of safety standard and a is the least one now coming to memory we could understand and appreciate the requirement for a safety function uh inclusion of the safety function in the system but when it comes to memory what role the memory plays and how this memory can be addressed or the how the safety of security functions can be incorporated in memory so all of you know that the any operation or any uh execution command that the macro controller takes that takes by reading and writing from the memories itself so in case there is a failure or there is some error in the controlling bird or the control itself then the controller might misbehave and this will result into a security or safety uh failure uh like say i would say a sudden unintended acceleration if you have not to test the paddle of your wheels accelerator and still there is a sudden acceleration that might be caused by some uh say bit failure or maybe some acr or some other failure phenomena exhibiting by the memory the failures of airbags on the impact the airbags are expected to open and save your life but in case this failure occurs so all such phenomena needs to be very very robust in order not to fail and the overall system together need to address these aspects collectively they need to be compliant enough together to address the phenomena they are required to operate and similarly the financing transactions financial transactions hacking can also be taking place excuse me my question is related to the hiking of the memory or it is robustness of the memory can you be a bit louder when we talk when we talk about the safe and secure memory does it it is related to the hiking of the memory the memory can be hanged or it is related to the robustness of the memory what is the ultimate impact when a memory is hacked the hacker can perform the intended operation that is unintended for you and if the memory is not robust enough and there is some bit failure then that also can perform some operation that is not intended for you so both are equally important and soc if a system misbehaves the underlying cause may be anything that is a safety or security compromise so both thing needs to be addressed on equal footing with equal importance and that is a very very important aspect of memory design sometimes or many times we do not focus on both the aspects and there comes the weakness or the loopholes there are the safety features or the actions can be compromised later on when we will progress in the discussion uh this thing will be more clear to you okay okay thank you sir so that's why the third line when i am saying these issues should be addressed with respect to a robust memory design and also a system in place to detect a failure in case of this happens say puffs physical unclotable locations are a feature a very important feature and that is implemented using srams in order to implement safe coding a random code generation that can be used internally within the hardware and will not be known to anybody outside the world and this code if that is hacked then this aspect of safety has no meaning right so you all of you know that sram when powered up will behave in a random manner the initialization of the israel you understand this thing yes right yeah so because when sram is powered up when the chip is uh say at uh no supply voltage is your supply voltage and you are powering it up then depending on the process mismatches that are present in this within the six transistors of the memory cell the cell is expected to uh powered up in a specific data condition either zero or one but this is perfectly random cell to cell chip to chip everywhere so this is a an example of pure random code so yes so you're saying uh like hacking while reading the memory like in the last slide you were saying yes the data is stolen while reading those are like you are saying they are probing the ports outside the memory yeah yeah i i'll come to that how that okay i think you see that and definitely that is the case uh this is done during the reading when the memory is being accessed by the cpu during that access the hacker keeps a vigil on the data path and tries to read the data what command is being sent to this cpu in and in what sequence oh yes uh say my audible hello yeah yeah your article so so let's say i have a cache hierarchy kind of a thing and you some some like hacker plans a side channel tag on it and you kind of you know uh you know i mean uh you read the hacker would try to read the return all those things so would it be kind of visible i mean it would not be in a way visible to the victim right i mean what data the hacker has read from the memory or something like that so uh what i mean there are some ways to detect those failures those steps right uh there would be some ways right in general cases in general cases i would i import what i feel is that they might not be visible to the victim right yeah you will not be knowing that's why that's why you are not supposed to protect the operation of the memory or the s soc or the complete system and you cannot this is not in your hand this is in hacker's hand to hack the data and this is in system that is operating in systems architecture's hand to prevent from such attacks you cannot take any action on that when you are a user you cannot do that prevention is not in your hand that's why these features these security features the safety features are bound to be integrated in a combination of software and hardware either hardware should detect this or software should detect this okay yes i'm thankful okay um wherever we okay fine so a robust memory with extremely low failure rate should be targeted for safety critical applications that is the inherent failure rate inherently memory how how the memory can fail inherently memory can fail due to multiple reasons i have listed few of them like say process variations that are not properly accounted for in the design soft error rate robustness with respect to single event latch up high temperature compliance that means we should be working fine at high temperature and should not uh fail functionally and robustness with with respect to the aging of the device so you understand all these five points or um should i explain all these points okay let me briefly explain yes okay so soft rate is the soft error rate is understood by all of you this is the phenomena where the bit cell flips by the radiation from where this radiation comes this radiations is present in environment all the time maybe differently from place to place environment environment but some amount of radiation is always present everywhere in the form of cascaded cosmic rays so you understand cosmic rays so the kashmiri showers are mainly responsible for these softwares and then environment and the cheap package in package also there are radioactive elements and those radioactive elements emit some radiation and those radiations pass through your memory cell and may cause a failure and then with respect to the single even latcher single latch of phenomena you must have studied in your female score session so when the chip is operating at higher voltage and also at higher temperature then particularly this phenomena occurs when there is a very high dc consumption in the chip and the chip altogether fails to operate or sometimes if the magnitude of current is not very high the electric is localized this may result into the random failures then high temperature compliance at high temperature you all don't understand that the ion of mass device decreases and this decrease of current should be well considered when you are designing a memory the chip should be validated in cad and also on silicon at high temperatures and similarly for aging you should test your chip with respect to the required timeline if you want to use a particular product for 20 years or 10 years under certain environmental conditions like 140 degree celsius or from automotive now this is 175 degree celsius then under that conditions with accelerated aging instrument methodology you need to test your semiconductor chips that yes there is not going to be any failure if that is not done then at certain point of time your semiconductor device your card or maybe your very critical biomedical applications like say pacemakers or human embedded semiconductor systems can start malfunctioning and that can be life threatening so validating your design your design with respect to aging of the device and eating is a prominent where aging when you say aging this is basically nbti if you understand nbti phenomena this is negative bias and temperature and stability and what this phenomenon does this phenomena close down the device increases the vt of the pmos primarily certainly this is also present for nmos but at less severe so when this aging phenomena is present and you have not validated with respect to aging then after certain lifetime your product will start malfunctioning within the required lifespan i think whatever i said is clear to you if you understood all these things we can go ahead if any doubt you can ask me right okay good so for any failure occurring there should be a mechanism to detect and take a preventive action and what all these preventive actions can be done those can be taken at the design state or those can be taken at when the system has failed or your the component has failed and you can take a preventive mechanism a provision to prevent the system failure like if your memory has failed your system if the system is able to detect that yes your memory has failed you should be able to or your system itself can be able to take a preventive mechanism like i would see when you uh try to login in the banking system by say your wrong password what happens this allows you five uh five attempts and after that it still locks the system that you cannot uh attempt anymore for a particular duration so this is a safety mechanism put in place by the software and similarly there can be safety mechanisms placed by the hardware as well and the hardware detects a fault that is the ram is failing and the hardware is able to detect yes that the ram has failed the data red is incorrect there is an intrusion then there can be a hardware reset the system itself can trigger a hardware reset and prohibit the further operations this can lock the device so this sort of safety mechanisms are also very important to consider for such applications so few points i have listed here use of appropriate assist circuits to ensure functionality and robustness so that with respect to environmental rift under standard operating condition you do not frequently face a safety issue a failure a reoccurring failures then and stable and robust process technology this is the thing to be addressed as technology as well like scr is completely dependent on the process technology the way you define the resistivity of your well the way you design the process steps of the mos transistors will also decide what would be the critical charge required for an sram cell to deflect and if that critical charge required for the stem cell to be flipped is higher definitely your memory would be robust an adequate design margin to address the design ppm the design margin you will understand that when you are designing you ensure a certain level of differential adsense amplifier that is that is the simplest and easiest example of design margin so there are multiple margins there are multiple margins to honor in the memory and if you have kept a margin keeping a view of the safety or the security aspect that may occur under certain environmental conditions then this will help for a more safer semiconductor or system design then design device aging consideration during validation validation using uh stress conditions like aging or specific high voltage spikes are applied and under that conditions in the functionality of the device is checked the redundancy redundancy and the repair capacity in memory is a very very important aspect the failure what we are going to talk about are in fact most of them are rare and when such failures occurs the memory or the system in itself should have the capability and provision to repair itself suppose you have designed a memory of say 4k words and we have you have got a redundancy of say um of 48 words or something like that then in case your memory fails then you have an option to replace those failed words or failed bits with respect to the newly available locations that may work fine and the last one but the very very important one is the transient fault detection and correction and this is the hardest one to detect and correct but there is a lot of focus in today when we are talking about say adas or automated vehicles this aspect is being addressed specifically in semiconductor design how to detect transient faults and corrections you understand what your transient faults sorry they occur for a very less amount of time and then die out well partially correct yeah they occur for a very short amount of time but if they occur very short amount uh span of time why this is difficult to put payment mechanism for such faults tanya's faults are basically false under external environment impacting a particular function of any component not in a severe manner but maybe in a softer manner and that is not going to exhibit at t is equal to 0 or even at is equal to 15 years but under slight alternation condition this will result into a failure like say if you are having um a particle is striking a particle is striking transit a transitioning node that is having lessened capacitance but that creates a path a discharge path through the driving uh nmos or the pmos then what would that result into that may not result into a full transition but that may result into a delay in the signal and that delay might exhibit itself in a failure so you should have a capability to detect such small delays that may cause catastrophic failures in your system you cannot delay permanently uh such detections or put in place a mechanism that is very very pessimistic for the design because that will affect the performance of your system so you need to maintain the performance of your system as well as you need to put in place the safety mechanism by putting a detection mechanism in place so that is the essence behind this so later on there will be couple of examples that will help you to understand more with respect to these transient faults so this slide is a very important slides for understanding how data theft is done in static memories so you see here the familiar snm cell is put here this is your sram cell very familiar 60 srm cell now if you see a laser scanning a mage of the sram cells then with respect to the data is stored in the memory cell the color of the imaging will differ so laser scanning image of the sram cell can reveal what data is stored inside the memory so this is a way when a hacker can do this and detect the store data fault injection fault injections is in the photo flash this is a device photo flash for very small amount of time very short duration and also in a very focused area when i say in a very focused area then this injection of say laser or photoelectrons can be put within a memory cell also nowadays and usually this is done to probe the data over a span of one i o if your one i o consists of say it's a mux of 16 so within expand of 16 himself if one is able to disturb the data that is being read then he is able to prove your data what is done usually in labs using these photo flash automated system an automatic mechanism is put in place where this sort of attack random attacks but systematic that means these attacks are done a millions of times whenever the data is read for millions of cycles and based on the fault injected and the data read ultimately the data content of the whole fm array is found that can be determined so there are dedicated dedicated labs and systems put in place those who want to hack the systems for major gains by hacking the banking transaction systems and all you regularly you see those servers being hacked and codes being tested so this sort of dedicated massive operations are planned or executed in order to break through into the system so maybe you might be aware only of the software attacks that are made to break into a computer or systems but these hardware attacks and the extraction of codes are and see i would say a leap ahead approach to do such activities so another slide based on that so this is deflected infrared light backside image of the microcontrollers that is seen here shown here um so with by analyzing the deflected uh backside images the rom contents are also extracted because you know that the rom is basically a programmation by either by metals metal programming programmable or by the via programmable so these informations can easily be extracted by the backside reflected infrared image now what are the safety and security implementation in static memories i would list down a few of those here so word line fault detection the first one is that is the very widely used methodology is to use the word line for detection so um this schemes aims to detect any deviations from normal word line selection like in the memory how does a memory uh operates uh let me come to this section here if you will see that uh basic uh say functional diagram for a memory this is your core region this is your control region this is a row decoder region and the red one this is the highlighted one is the one one line here this is the one bar line now when when you are accessing your memory what you are doing what you intend you in turn that only one word line should be high what will happen if two word line gets high by any fault within the memory or by any intuition outside intuition if two word lines are selected can any one of you guess what will happen if two word lines are selected at a time collecting multiple bits and will be activated at the same time in the same row in the same column see one line is selecting rows right not column like if multiple rows are selected then like in a single column multiple rows selected multiple bit cells of different you can say those are selected then their data can be uh read wrong on the bit lines why because it's okay so you can say like uh two cells i'm reading from two cells and the same column um then when their bit line will be shorted with their internal nodes so if both the cells have different data then we'll have we will not know okay like bit line console like discharge statistics in your pattern right right perfectly right very good so your data will no more be the valid this will be randomly corrupted so there should be a mechanism or there is a mechanism usually put in place to detect such issues that occurs during runtime of the memory then use of beta debates use of ecc weak big detection and replacements use of backup latches for safety critical nodes now uh one line fault detection i think this the essence what we do and why we do that is clear to you details of how we do i will come to that i think use of parity bits at this point is should be understood by you uh because you might be studying in your courses also right of course so through penalty checks you want to ensure that the word that is read that is correct or not right assuming that your parity bit is not corrected then comes the use of ecc ecc is error correction code ecc is just an extension of a variative it's the way this is implemented and ecc also takes help of the additional bits in the word in order to assess whether the red data is the correct one or not so when you write into a memory say if you have a 32-bit memory you want to use then you will have to use a seven bit period tv seven additional bits for tell for acc and uh these ecc bits while writing into the data uh c locations while writing this word you will also write these issue bits and during read you will have a recalculation from the read out data and matching with this and this will help you to find out whether the red data is correct or there is any fault this is the standard practice cc might be known to all of you and this is a very very powerful tool today to detect any fault mostly single bit faults ecc is used mostly to detect single bit forms because when you go for say multiple detecting multiple bit faults why don't we use this you understand the thing why ec is usually limited to single bit for it first of all you understand ecce listen okay then if you understand ecc then you must be knowing that ecc is usually used for detecting single bit calls or at the most two bit words not more than that where comes the limitation why can't this be used uh to detect if you are using a 32-bit memory then all the bits are faulty why can't we use to detect a 32-bit fault this is because the hardware or the complex complexity in the algorithm that will lead to explosion in area of the memory so area is in very important aspects whenever you are designing a memory and whatever features may be safety may be security or may be a low power whatever you are implementing you have to be very very much vigilant not to impact the area too much and that is the reason this is limited to one or two with call detection and weak big detection and replacement is another concept where we detect the bits that can fail marginally and we intend to replace the access to these bits before they have failed so what is the difference between redundancy and this the same set of redundancy can be used by the week b detection as well this is a preventive mechanism where you don't wait for the failure at t is equal to zero itself you find out the weak bits and do where possible connections and with this correction through the bits your system will be much much robust for its lifetime but this is a extremely relevant concept and is also being used and multiple places to make the system robust then coming to the use of backup latches for safety critical nodes so for say for latches there is a threat of failure due to radiation right or due to high leakage localized high leakage due to the run process variation or say any fault uh present in the latch across the system maybe so a backup latch is used for safety critical nodes when you say backup left means you were using two latch instead of one simple and then the fifth one is use of dummy bits to ensure correctness of rain data what is the use of dummy bits does anyone understand you have a word a lot on memories but do you understand what are dummy bits okay so uh basically when you read a memory or write into a memory what you do you start from the address and then clock now after that there is an internet uh decoding the roadie put the selection then sense amplifier triggering through the dummy column and then a data readout through the i o so there is a sequence of event that needs to operate in a discipline manner in time domain to ensure that the correct data is read and dummy bit when i say use of dummy blades you place one column of data additional column of bit cells for one and one for zero in order to observe at every read and read operation at every read operation whether the readout data is correct or not the dummy one that you are intending to read the cell is hard programmed as one and for dummy zero what you want to read the cell is hard program at zero so there is no question of reading one from a column which is intended for dummy zero and vice versa so this mechanism this arrangement is kept in memory just to ensure on on each and every axis of memory each and every read axis of memory to be very sure the integrity of the operation suppose there is some intrusion at some particular place by external means then the timing would be wrong for the sense amplifier triggering and the red out data would be wrong this is not a definitive check but yes every safety aspect put in place in hardware has a probabilistic coverage when we talk about placing any safety or security feature put in place in hardware we talk about probabilistic coverage fifty percent ninety percent hundred percent overall coverage so no detection is 100 foolproof now coming to the uh rom code encryption sorry uh next one is shielding of important nets prevent from external probing shielding of important nets so when a hacker is trying to read like here in the same backside images suppose you are having a programmation layer here or say data being read out here and on top of that data if you put a shield of metal then that would mask the observation of the hacker this means if you see this is the backside image and if you are reading out a data and the data is traveling in metal one then you cannot shield it so in order to shield the data you must use one level higher method that is submitted to our metal three in order to read out the data so that you can use the lowest level of metal that would be coming as a picture and the backside images usual practice is always to use the lowest level of metal in order to avoid the condition in soc where the safety is not required but one there is this is the safety of security critical application you must use district you may use this trick this trick to enhance the safety coverage of your memory in coming to rom code encryption i think encryption what is encryption is known to all of you we encrypt something because we want to not to disclose the actual thing and when the raw matrix is being programmed raw matrix is being programmed in hardware when you read out the rom data you decrypt the red out data and then use it for the system for the cpu so that is the mechanism put in place so so that even if the hacker has the red out through these backside images or even at the boundary when you are reading out during actual operations by such laser voltage provings then then also this encryption will help at hardware level to prevent user from understanding the actual content or the actual code that is required for the cpu to operate so next one will be is a monitoring of critical signals for correctness in each cycle i just explained you the dummy bits dummy bits are uh taking a monit monitoring the complete path from clock to queue similarly the individual signals like say the internal clocks or the decoded address signals other may be any other control signal when that is the sample like chip enable that can be sampled out that can be sampled out reverted back from this point at this point reverted back and latched at this here so during each and every axis of the memory just like you read out the data you sample the queue you also sample these signals what are the values suppose during an actual operation you expect your internal clock to be in the low condition and when you have taken out the external clock here and comparing the external clock the external clock is coming out to be one then you should understand that there is some problem within the functionality of the memory within the signal flow of the mem,https://www.youtube.com/watch?v=X5egItiB9xw,"Link: https://www.youtube.com/watch?v=X5egItiB9xw
Transcript: so good afternoon everyone uh let me formally welcome dr ashish uh he's been working with st microelectronics india for more than 20 years now and uh you know with the conversation that we were just having you know that we go back a long long time uh he obtained his phd from iit delhi in 2017 and before that he did his mtech and solid state technology from iit kharagpur in 2000. his major area of interest is circuit design with a larger emphasis on memory circuits and systems he has more than 17 patent current subsystems and many more already filed which will get granted over time and he also publishes uh quite politically in various international forums so today he will talk to us about uh you know safety and how you know safety is important for us for automotive applications for example and other applications and how do we make circuit and architectural changes to bring that safety into the embedded memories and therefore at the system level okay so let's welcome ashish and over to you ashish with that so uh good afternoon everybody let me introduce you with the topic the topic is circuit and architecture for safety critical embedded memories so many of you might have well understanding of sram memories and roms and maybe other memories as well and when i say about safety or security what does it mean first we will have to develop an understanding of that what we actually intend to embed in these memories as a function as a capability when we say safety and security so this is the outline of this lecture so first i will introduce you with the context and then for the need of a safe and secure memory and how we design a robust memory for low failure rate and how the data theft and static memories take place and safety and security specific safety and security circuits implementation in static memories and we will take up your questions your doubts so so this is important considering a robust operation for safety critical applications when we say safety critical applications first think about the automotive application and also you think about the banking applications your credit cards your debit cards and your online transactions everything so do you think that there is a need to have a secure or safe transaction at each and every step for both these domains when you are driving a car you need to be safe you don't expect any particular function or electrical function or mechanical function to break down uh risking your lives right are you putting you in trouble in between when you were traveling and the same is true for the banking transactions you don't want your data your passwords to be had your account to be added so these are the two major uh domains where we need to be very very sensitive for implementing security and safety this is a very contextual world where you call safe or secure now there has been efforts to address both aspects through software as well as through hardware implementation any system is basically uh comprising of an interaction of software with hardwares and on top of that a system is developed so there are many many implementations where software algorithms take care of the safety and security aspects and for those areas where a very high level of security is required you need to augment with hardware as well specific hardware implementations as well so these automotive safety integrity levels this is called acell this is a standard basically i use for standard and iso 26262 covers the safety aspects for the automotive segment so um when you are now talking about the autonomous vehicles right we all are talking about the autonomous vehicle driverless vehicle smart systems and all those things then definitely a sense of fear comes into your mind and all of you are compelled to think how this will be successful in indian context although this is being tested successfully at a global level but definitely the complexity of implementation and the risk of implementation is in everyone's mind every one of you will consider that there is no driver how the semiconductor chip or the how the ai will be able to address the uh the safety aspects like if somebody comes suddenly in between how the suddenly you can't apply the brake or in a crowded market place how the vehicle will move and all now so or if the vehicle is moving at a very high speed however this will take care of the uh surroundings when uh suddenly something comes flying or there is a pothole in the road so there are many many aspects which needs to be addressed when you are talking about autonomous vehicles so there also you need to augment the system with the multiple sensors and artificial intelligence embedded around old sensors so if you have any relevant questions please do not hesitate to stop me in between definitely at the end we'll take questions but in case something comes into your mind in between you can ask those questions so that you do not forget it later and everyone can address and come with the consensus understanding now what is acl automatic safety integrity level is basically categorizing the safety standards with respect to four considerations the particular function the probability of exposure how much it is exposed the controllability severity and and these the addition of these three the combination of these three is basically deciding with respect to the um ac standard in if case in case there is a threat of life if some particular function like the break function failure is going to be a threat of life definitely this is this should follow the highest level of safety standard that is the d this is the highest level of safety standard and a is the least one now coming to memory we could understand and appreciate the requirement for a safety function uh inclusion of the safety function in the system but when it comes to memory what role the memory plays and how this memory can be addressed or the how the safety of security functions can be incorporated in memory so all of you know that the any operation or any uh execution command that the macro controller takes that takes by reading and writing from the memories itself so in case there is a failure or there is some error in the controlling bird or the control itself then the controller might misbehave and this will result into a security or safety uh failure uh like say i would say a sudden unintended acceleration if you have not to test the paddle of your wheels accelerator and still there is a sudden acceleration that might be caused by some uh say bit failure or maybe some acr or some other failure phenomena exhibiting by the memory the failures of airbags on the impact the airbags are expected to open and save your life but in case this failure occurs so all such phenomena needs to be very very robust in order not to fail and the overall system together need to address these aspects collectively they need to be compliant enough together to address the phenomena they are required to operate and similarly the financing transactions financial transactions hacking can also be taking place excuse me my question is related to the hiking of the memory or it is robustness of the memory can you be a bit louder when we talk when we talk about the safe and secure memory does it it is related to the hiking of the memory the memory can be hanged or it is related to the robustness of the memory what is the ultimate impact when a memory is hacked the hacker can perform the intended operation that is unintended for you and if the memory is not robust enough and there is some bit failure then that also can perform some operation that is not intended for you so both are equally important and soc if a system misbehaves the underlying cause may be anything that is a safety or security compromise so both thing needs to be addressed on equal footing with equal importance and that is a very very important aspect of memory design sometimes or many times we do not focus on both the aspects and there comes the weakness or the loopholes there are the safety features or the actions can be compromised later on when we will progress in the discussion uh this thing will be more clear to you okay okay thank you sir so that's why the third line when i am saying these issues should be addressed with respect to a robust memory design and also a system in place to detect a failure in case of this happens say puffs physical unclotable locations are a feature a very important feature and that is implemented using srams in order to implement safe coding a random code generation that can be used internally within the hardware and will not be known to anybody outside the world and this code if that is hacked then this aspect of safety has no meaning right so you all of you know that sram when powered up will behave in a random manner the initialization of the israel you understand this thing yes right yeah so because when sram is powered up when the chip is uh say at uh no supply voltage is your supply voltage and you are powering it up then depending on the process mismatches that are present in this within the six transistors of the memory cell the cell is expected to uh powered up in a specific data condition either zero or one but this is perfectly random cell to cell chip to chip everywhere so this is a an example of pure random code so yes so you're saying uh like hacking while reading the memory like in the last slide you were saying yes the data is stolen while reading those are like you are saying they are probing the ports outside the memory yeah yeah i i'll come to that how that okay i think you see that and definitely that is the case uh this is done during the reading when the memory is being accessed by the cpu during that access the hacker keeps a vigil on the data path and tries to read the data what command is being sent to this cpu in and in what sequence oh yes uh say my audible hello yeah yeah your article so so let's say i have a cache hierarchy kind of a thing and you some some like hacker plans a side channel tag on it and you kind of you know uh you know i mean uh you read the hacker would try to read the return all those things so would it be kind of visible i mean it would not be in a way visible to the victim right i mean what data the hacker has read from the memory or something like that so uh what i mean there are some ways to detect those failures those steps right uh there would be some ways right in general cases in general cases i would i import what i feel is that they might not be visible to the victim right yeah you will not be knowing that's why that's why you are not supposed to protect the operation of the memory or the s soc or the complete system and you cannot this is not in your hand this is in hacker's hand to hack the data and this is in system that is operating in systems architecture's hand to prevent from such attacks you cannot take any action on that when you are a user you cannot do that prevention is not in your hand that's why these features these security features the safety features are bound to be integrated in a combination of software and hardware either hardware should detect this or software should detect this okay yes i'm thankful okay um wherever we okay fine so a robust memory with extremely low failure rate should be targeted for safety critical applications that is the inherent failure rate inherently memory how how the memory can fail inherently memory can fail due to multiple reasons i have listed few of them like say process variations that are not properly accounted for in the design soft error rate robustness with respect to single event latch up high temperature compliance that means we should be working fine at high temperature and should not uh fail functionally and robustness with with respect to the aging of the device so you understand all these five points or um should i explain all these points okay let me briefly explain yes okay so soft rate is the soft error rate is understood by all of you this is the phenomena where the bit cell flips by the radiation from where this radiation comes this radiations is present in environment all the time maybe differently from place to place environment environment but some amount of radiation is always present everywhere in the form of cascaded cosmic rays so you understand cosmic rays so the kashmiri showers are mainly responsible for these softwares and then environment and the cheap package in package also there are radioactive elements and those radioactive elements emit some radiation and those radiations pass through your memory cell and may cause a failure and then with respect to the single even latcher single latch of phenomena you must have studied in your female score session so when the chip is operating at higher voltage and also at higher temperature then particularly this phenomena occurs when there is a very high dc consumption in the chip and the chip altogether fails to operate or sometimes if the magnitude of current is not very high the electric is localized this may result into the random failures then high temperature compliance at high temperature you all don't understand that the ion of mass device decreases and this decrease of current should be well considered when you are designing a memory the chip should be validated in cad and also on silicon at high temperatures and similarly for aging you should test your chip with respect to the required timeline if you want to use a particular product for 20 years or 10 years under certain environmental conditions like 140 degree celsius or from automotive now this is 175 degree celsius then under that conditions with accelerated aging instrument methodology you need to test your semiconductor chips that yes there is not going to be any failure if that is not done then at certain point of time your semiconductor device your card or maybe your very critical biomedical applications like say pacemakers or human embedded semiconductor systems can start malfunctioning and that can be life threatening so validating your design your design with respect to aging of the device and eating is a prominent where aging when you say aging this is basically nbti if you understand nbti phenomena this is negative bias and temperature and stability and what this phenomenon does this phenomena close down the device increases the vt of the pmos primarily certainly this is also present for nmos but at less severe so when this aging phenomena is present and you have not validated with respect to aging then after certain lifetime your product will start malfunctioning within the required lifespan i think whatever i said is clear to you if you understood all these things we can go ahead if any doubt you can ask me right okay good so for any failure occurring there should be a mechanism to detect and take a preventive action and what all these preventive actions can be done those can be taken at the design state or those can be taken at when the system has failed or your the component has failed and you can take a preventive mechanism a provision to prevent the system failure like if your memory has failed your system if the system is able to detect that yes your memory has failed you should be able to or your system itself can be able to take a preventive mechanism like i would see when you uh try to login in the banking system by say your wrong password what happens this allows you five uh five attempts and after that it still locks the system that you cannot uh attempt anymore for a particular duration so this is a safety mechanism put in place by the software and similarly there can be safety mechanisms placed by the hardware as well and the hardware detects a fault that is the ram is failing and the hardware is able to detect yes that the ram has failed the data red is incorrect there is an intrusion then there can be a hardware reset the system itself can trigger a hardware reset and prohibit the further operations this can lock the device so this sort of safety mechanisms are also very important to consider for such applications so few points i have listed here use of appropriate assist circuits to ensure functionality and robustness so that with respect to environmental rift under standard operating condition you do not frequently face a safety issue a 
failure a reoccurring failures then and stable and robust process technology this is the thing to be addressed as technology as well like scr is completely dependent on the process technology the way you define the resistivity of your well the way you design the process steps of the mos transistors will also decide what would be the critical charge required for an sram cell to deflect and if that critical charge required for the stem cell to be flipped is higher definitely your memory would be robust an adequate design margin to address the design ppm the design margin you will understand that when you are designing you ensure a certain level of differential adsense amplifier that is that is the simplest and easiest example of design margin so there are multiple margins there are multiple margins to honor in the memory and if you have kept a margin keeping a view of the safety or the security aspect that may occur under certain environmental conditions then this will help for a more safer semiconductor or system design then design device aging consideration during validation validation using uh stress conditions like aging or specific high voltage spikes are applied and under that conditions in the functionality of the device is checked the redundancy redundancy and the repair capacity in memory is a very very important aspect the failure what we are going to talk about are in fact most of them are rare and when such failures occurs the memory or the system in itself should have the capability and provision to repair itself suppose you have designed a memory of say 4k words and we have you have got a redundancy of say um of 48 words or something like that then in case your memory fails then you have an option to replace those failed words or failed bits with respect to the newly available locations that may work fine and the last one but the very very important one is the transient fault detection and correction and this is the hardest one to detect and correct but there is a lot of focus in today when we are talking about say adas or automated vehicles this aspect is being addressed specifically in semiconductor design how to detect transient faults and corrections you understand what your transient faults sorry they occur for a very less amount of time and then die out well partially correct yeah they occur for a very short amount of time but if they occur very short amount uh span of time why this is difficult to put payment mechanism for such faults tanya's faults are basically false under external environment impacting a particular function of any component not in a severe manner but maybe in a softer manner and that is not going to exhibit at t is equal to 0 or even at is equal to 15 years but under slight alternation condition this will result into a failure like say if you are having um a particle is striking a particle is striking transit a transitioning node that is having lessened capacitance but that creates a path a discharge path through the driving uh nmos or the pmos then what would that result into that may not result into a full transition but that may result into a delay in the signal and that delay might exhibit itself in a failure so you should have a capability to detect such small delays that may cause catastrophic failures in your system you cannot delay permanently uh such detections or put in place a mechanism that is very very pessimistic for the design because that will affect the performance of your system so you need to maintain the performance of your system as well as you need to put in place the safety mechanism by putting a detection mechanism in place so that is the essence behind this so later on there will be couple of examples that will help you to understand more with respect to these transient faults so this slide is a very important slides for understanding how data theft is done in static memories so you see here the familiar snm cell is put here this is your sram cell very familiar 60 srm cell now if you see a laser scanning a mage of the sram cells then with respect to the data is stored in the memory cell the color of the imaging will differ so laser scanning image of the sram cell can reveal what data is stored inside the memory so this is a way when a hacker can do this and detect the store data fault injection fault injections is in the photo flash this is a device photo flash for very small amount of time very short duration and also in a very focused area when i say in a very focused area then this injection of say laser or photoelectrons can be put within a memory cell also nowadays and usually this is done to probe the data over a span of one i o if your one i o consists of say it's a mux of 16 so within expand of 16 himself if one is able to disturb the data that is being read then he is able to prove your data what is done usually in labs using these photo flash automated system an automatic mechanism is put in place where this sort of attack random attacks but systematic that means these attacks are done a millions of times whenever the data is read for millions of cycles and based on the fault injected and the data read ultimately the data content of the whole fm array is found that can be determined so there are dedicated dedicated labs and systems put in place those who want to hack the systems for major gains by hacking the banking transaction systems and all you regularly you see those servers being hacked and codes being tested so this sort of dedicated massive operations are planned or executed in order to break through into the system so maybe you might be aware only of the software attacks that are made to break into a computer or systems but these hardware attacks and the extraction of codes are and see i would say a leap ahead approach to do such activities so another slide based on that so this is deflected infrared light backside image of the microcontrollers that is seen here shown here um so with by analyzing the deflected uh backside images the rom contents are also extracted because you know that the rom is basically a programmation by either by metals metal programming programmable or by the via programmable so these informations can easily be extracted by the backside reflected infrared image now what are the safety and security implementation in static memories i would list down a few of those here so word line fault detection the first one is that is the very widely used methodology is to use the word line for detection so um this schemes aims to detect any deviations from normal word line selection like in the memory how does a memory uh operates uh let me come to this section here if you will see that uh basic uh say functional diagram for a memory this is your core region this is your control region this is a row decoder region and the red one this is the highlighted one is the one one line here this is the one bar line now when when you are accessing your memory what you are doing what you intend you in turn that only one word line should be high what will happen if two word line gets high by any fault within the memory or by any intuition outside intuition if two word lines are selected can any one of you guess what will happen if two word lines are selected at a time collecting multiple bits and will be activated at the same time in the same row in the same column see one line is selecting rows right not column like if multiple rows are selected then like in a single column multiple rows selected multiple bit cells of different you can say those are selected then their data can be uh read wrong on the bit lines why because it's okay so you can say like uh two cells i'm reading from two cells and the same column um then when their bit line will be shorted with their internal nodes so if both the cells have different data then we'll have we will not know okay like bit line console like discharge statistics in your pattern right right perfectly right very good so your data will no more be the valid this will be randomly corrupted so there should be a mechanism or there is a mechanism usually put in place to detect such issues that occurs during runtime of the memory then use of beta debates use of ecc weak big detection and replacements use of backup latches for safety critical nodes now uh one line fault detection i think this the essence what we do and why we do that is clear to you details of how we do i will come to that i think use of parity bits at this point is should be understood by you uh because you might be studying in your courses also right of course so through penalty checks you want to ensure that the word that is read that is correct or not right assuming that your parity bit is not corrected then comes the use of ecc ecc is error correction code ecc is just an extension of a variative it's the way this is implemented and ecc also takes help of the additional bits in the word in order to assess whether the red data is the correct one or not so when you write into a memory say if you have a 32-bit memory you want to use then you will have to use a seven bit period tv seven additional bits for tell for acc and uh these ecc bits while writing into the data uh c locations while writing this word you will also write these issue bits and during read you will have a recalculation from the read out data and matching with this and this will help you to find out whether the red data is correct or there is any fault this is the standard practice cc might be known to all of you and this is a very very powerful tool today to detect any fault mostly single bit faults ecc is used mostly to detect single bit forms because when you go for say multiple detecting multiple bit faults why don't we use this you understand the thing why ec is usually limited to single bit for it first of all you understand ecce listen okay then if you understand ecc then you must be knowing that ecc is usually used for detecting single bit calls or at the most two bit words not more than that where comes the limitation why can't this be used uh to detect if you are using a 32-bit memory then all the bits are faulty why can't we use to detect a 32-bit fault this is because the hardware or the complex complexity in the algorithm that will lead to explosion in area of the memory so area is in very important aspects whenever you are designing a memory and whatever features may be safety may be security or may be a low power whatever you are implementing you have to be very very much vigilant not to impact the area too much and that is the reason this is limited to one or two with call detection and weak big detection and replacement is another concept where we detect the bits that can fail marginally and we intend to replace the access to these bits before they have failed so what is the difference between redundancy and this the same set of redundancy can be used by the week b detection as well this is a preventive mechanism where you don't wait for the failure at t is equal to zero itself you find out the weak bits and do where possible connections and with this correction through the bits your system will be much much robust for its lifetime but this is a extremely relevant concept and is also being used and multiple places to make the system robust then coming to the use of backup latches for safety critical nodes so for say for latches there is a threat of failure due to radiation right or due to high leakage localized high leakage due to the run process variation or say any fault uh present in the latch across the system maybe so a backup latch is used for safety critical nodes when you say backup left means you were using two latch instead of one simple and then the fifth one is use of dummy bits to ensure correctness of rain data what is the use of dummy bits does anyone understand you have a word a lot on memories but do you understand what are dummy bits okay so uh basically when you read a memory or write into a memory what you do you start from the address and then clock now after that there is an internet uh decoding the roadie put the selection then sense amplifier triggering through the dummy column and then a data readout through the i o so there is a sequence of event that needs to operate in a discipline manner in time domain to ensure that the correct data is read and dummy bit when i say use of dummy blades you place one column of data additional column of bit cells for one and one for zero in order to observe at every read and read operation at every read operation whether the readout data is correct or not the dummy one that you are intending to read the cell is hard programmed as one and for dummy zero what you want to read the cell is hard program at zero so there is no question of reading one from a column which is intended for dummy zero and vice versa so this mechanism this arrangement is kept in memory just to ensure on on each and every axis of memory each and every read axis of memory to be very sure the integrity of the operation suppose there is some intrusion at some particular place by external means then the timing would be wrong for the sense amplifier triggering and the red out data would be wrong this is not a definitive check but yes every safety aspect put in place in hardware has a probabilistic coverage when we talk about placing any safety or security feature put in place in hardware we talk about probabilistic coverage fifty percent ninety percent hundred percent overall coverage so no detection is 100 foolproof now coming to the uh rom code encryption sorry uh next one is shielding of important nets prevent from external probing shielding of important nets so when a hacker is trying to read like here in the same backside images suppose you are having a programmation layer here or say data being read out here and on top of that data if you put a shield of metal then that would mask the observation of the hacker this means if you see this is the backside image and if you are reading out a data and the data is traveling in metal one then you cannot shield it so in order to shield the data you must use one level higher method that is submitted to our metal three in order to read out the data so that you can use the lowest level of metal that would be coming as a picture and the backside images usual practice is always to use the lowest level of metal in order to avoid the condition in soc where the safety is not required but one there is this is the safety of security critical application you must use district you may use this trick this trick to enhance the safety coverage of your memory in coming to rom code encryption i think encryption what is encryption is known to all of you we encrypt something because we want to not to disclose the actual thing and when the raw matrix is being programmed raw matrix is being programmed in hardware when you read out the rom data you decrypt the red out data and then use it for the system for the cpu so that is the mechanism put in place so so that even if the hacker has the red out through these backside images or even at the boundary when you are reading out during actual operations by such laser voltage provings then then also this encryption will help at hardware level to prevent user from understanding the actual content or the actual code that is required for the cpu to operate so next one will be is a monitoring of critical signals for correctness in each cycle i just explained you the dummy bits dummy bits are uh taking a monit monitoring the complete path from clock to queue similarly the individual signals like say the internal clocks or the decoded address signals other may be any other control signal when that is the sample like chip enable that can be sampled out that can be sampled out reverted back from this point at this point reverted back and latched at this here so during each and every axis of the memory just like you read out the data you sample the queue you also sample these signals what are the values suppose during an actual operation you expect your internal clock to be in the low condition and when you have taken out the external clock here and comparing the external clock the external clock is coming out to be one then you should understand that there is some problem within the"
1kNYgsH40Q0,the overall design flow chip design so today we intend to cover chip design flow am i right and different abstractions linked to it so how many of us remember uh what kind of stages are there in our design flow first stage was design analysis um characterization okay good i'm happy you remember quite a bit so yes the the first stage in fact was for is design analysis where there are different so we will go into each of these stages one by one and look at what each step entails okay and uh don't hesitate to stop me ask questions or add anything if you feel like okay so the first stage is design analysis where the first step is requirement analysis so what do you understand by requirement analysis what do you think is requirement analysis so customer requirement i think specifically solutions that we want in the circuit the basically demand of the market what exactly is required in the market yeah so over here what we are looking at is what is it that the uh customer would pay for is would be willing to pay for for the price point where we want to target our product so if if i want to come up with the next generation of iphone 12 or you know iphone for example now iphone 13 what would the customer be willing to pay the premium for next year so that would become my requirement and then we do the next step which is called the function functional and test specifications what would come into this according to you to test the functionality of our design in the base of requirements so what we just required a buyer design what kind of functions we require yes what kind of functionality is required for example you may say that you know when apple came up with this infrared face recognition feature at that time what functionality is required you need to understand that okay it has to be infrared and it should it should recognize the face and it should unlock the screen if the face recognition is say above or the face matches above say 80 it should also unlock the screen or ninety percent it should only also unlock the scheme and very importantly when you define the functional specifications you also define how will you test that your device is meeting those specifications in various conditions so as soon as you define the functionality how to test it is also defined simultaneously this is something which is not commonly understood and done are we able to appreciate the significance of this aspect so i'm not able to understand how this text specification can be introduced here i mean okay so uh let us take this same feature the face recognition feature that you're talking about so how would you test this camera now if i want to say that apple would have this camera in it how would you test it so most probably i would be taking some samples of pictures or photos and then seeing the quality or the how what the output is then analyzing that output so i may say that i will take 10 000 photos of one person okay and when any of those 10 000 photos is put in front of this camera system it should be able to recognize it as the right person and should unlock the screen that could be one way to test it okay okay so like uh we are specifying the specification from an overview overall from the functional perspective this is the okay i wanted how do i test that this functionality is being met okay okay i know because finally what whether some other functionality happens or not happens doesn't matter functionality that i am selling to my customers should definitely work fine and i should know how to test it this i should know early on when even when i am defining the specification okay answer the functionality you are talking about it is in terms of specification like uh it needs to have a 40 megapixel camera or should be able to detect that that in terms of yes so it is specifications of functional specifications and test specifications functional specifications would say it should be infrared it should be able to identify the person even in an ambient light of let us say a dark room and it should be able to you know differentiate between two brothers for example who look very much alive but are not twins okay so like what the kind of thing we see in the ads of basically that is yeah that is one aspect of it so i gave you an apple example under the face recognition example because that you already see in the ads and it is easy to relate to them yes but for any chip even if you're if you have to design an spga okay for even for an fpga the user would have the specification that its ddr should operate at uh two gigahertz that it should be able to support this kind of throughput it should be able to give this kind of uh uh you know dry stone mix per second whatever okay okay so that also comes here interesting okay okay i gave you a user i took the example of an apple face recognition thing i was i gave test specifications for that but when i talk of functional specs which which does not really materialize into the user or a consumer application then i will anyway have technical functional specifications there okay okay so here also the engineer will be working generating them would be working to define the specifications yes okay so we will define the specification and consultation with the customer who is going to use the product and also the test specifications in consultation with the customer department you had raised your hand uh strict to define the verification of the testing method in the beginning what if the specification changes in at a later stage then it won't be a tedious task to review everything you tell me one thing if the specification changes you anyways need to need to you know come back to the initial phase so let us say you were in this stage at this point of time the customer said no no i do not want this camera to work in infrared light i now want this camera to work at uh regular light with regular light i want a laser to be generated there so do you realize that everything would change for you also the kind of energy that your image sensors will now capture will be very different from what they would capture in an infrared light scenario yes yes so you will anyway need to come back to this stage again because the functional specifications have changed yes okay i was just concerned about the timing part yeah basically if the functional specifications are changing everything would need to be redefined okay and as as soon as you change the functional specification test specification should also be reviewed all over so my and my actually the point was that maybe we can if we are a bit mature state then we can define how to test because then we will be sure that this is like the final product text required no change can be done beyond that as a designer you may want that but as a customer would you want that suppose let us put it like this you want to go and order a double bed for your room and you want it to be succeed by six feet now would you would you give the specification to the to the carpenter right away or say that okay i wanted to be six feet by six feet but i will tell you how i will measure six feet uh after you have you know um cut the plywood no yeah i think goddamn will tell you which scale you're going to use right away so that he also uses the same scale is it not right so the test specifications have to be built alongside functional specifications there is no other way okay and this is what many times i see designers miss out on they think only in terms of functional specification they forget that test specification is equally important to be defined right there correct correct got it thank you sir to be actually making a hardware and then testing it or something else you tell me this is a this is a chip design fluna entire entire thing is a chip design flow is it not listen so in this flow we will actually you actually get silicon in your cell phones is it not like the wafer fabrication and all things are later on so are we actually making it in the initial stages and then testing it we are making the specifications specifications for example example in this what did we say we said that i will tell the carpenter i want a bed a double bed which is six feet by six feet and that i will measure six feet by using this particular scale i have not built the bed yet i have not even purchased the plywood yet but i know what i want in my bedroom that's where so test the testing means is it a simulation or something related to this no testing so for a carpenter thing you will want to actually measure physically the the dimensions of your bed now but the physical thing that you're getting is working exactly the way it was intended to be right yes so you will actually have to characterize and test the silicon wafers that are out or whatever system it is sir uh yes sir so you mean to say that we are just giving the specifications but not actually testing them like functional and test specifications we are just mentioning them what do we test yeah product design has not even started yet what do we test we are simply telling this is how we will test okay okay okay so basically this all the documentation partner uh yes this is in a way the specification the statement of work creation part this is still just documentation no design implementation yet yes okay in fact just after this step if you look the step is called partition and plan what do you think this means uh dividing the follow strategy uh divine implementation dividing the whole strategy of how to implement all the things related with it yeah so some for example if you go back to the actual space recognition example in that particular example it will mean which team will do what kind of work who will design that laser the infrared laser who will design the uh the hardware the chip who will write the software which does the recognition or which does the analysis okay who will integrate all of it and the plan as to by when will different milestones of different such partitions be completed so that i finally have my apple phone uh available in the market by thanksgiving so that people can purchase it for christmas yes sir so that is partitioning and planning all of this the design has not even started okay okay any questions still here yes sir if you talk about in memory sir when we say uh for a room that when when we say that we want to make the connections that we want to i mean diffuse the transistor in in the highest layers so basically that is i mean in that context we say that if the customer uh says that now in the data state of the making the memory at that point of time if the customer says i want this this code to be embedded and not the one that i uh gave i mean i have given to you so is that also not the functional specification that is being changed and then we are not really going to the design analysis uh once again we are just changing the connections so it depends currently like uh depends how big a change the user is asking for and and what is the stage of the design if the change is really that doesn't require any change in the design implementation you will not go back to the scratch board you know the the drawing board all over again but if the specification change is very significant then you will need to do that and you should be aware of this that you cannot really change specification after the implementation has begun or has kind of closed whatever because that means a huge turnaround time it can mean a huge turnaround time yes so usually a good amount of time is spent on this stage the design analysis stage because if this is not done correctly all the effort that goes subsequently so this effort 10 people will do but the design implementation effort for example if it's about a intel microprocessor the typical effort that goes into a microprocessor is 200 million years 300 million years so so many people working across multiple teams across the various sites uh are involved in making a full intel microprocessor and if the first phase design analysis phase is not good enough is is is kind of carelessly done then all those 2 200 manual efforts can simply go down the drain you will come up with the product which will not sell in the market so this is one of the most important parts so in this part what kind of things you get to do in india so since there are very few end-to-end product manufacturers in the country not much of this job gets done in india but in every company whether it is ti or st or samsung or micron uh all these three kinds of jobs exist they typically exist in the headquarters samsung has this kind of jobs in korea st has these kinds of jobs in italy and france ti has them in the u.s micron has them in the us so these kind of this kind of design analysis or product definition thing is is primarily in the headquarters or then somewhere very close to the customer wherever they are getting their maximum sales from they would have some some such jobs in that place also okay once the product specification animation wanted to add something audible yes you're audible so yes sir i wanted to ask if these test specifications right if you would like to test it on uh for example what we were talking about an apple air uh phase recognition system if we would like to test first that application on an fpga which is reconfigurable before making try trying to release this specifications we would want to test it on our fpga right before starting the chip um we don't know so we will come where the fpga and such kind of work would come in we can we can i will i will share about where we can do that emulation part okay so so abhini a when when the customer is defining the specification he has no clue how you would implement it he is simply telling you that i want this okay only when you enter into the design implementation phase you will look at how to validate and verify it okay fpga is largely about verifying your design is it not yes seriously you need to have a design first so a design entry has to happen before that okay yes so in the design implementation stage,https://www.youtube.com/watch?v=1kNYgsH40Q0,"Link: https://www.youtube.com/watch?v=1kNYgsH40Q0
Transcript: the overall design flow chip design so today we intend to cover chip design flow am i right and different abstractions linked to it so how many of us remember uh what kind of stages are there in our design flow first stage was design analysis um characterization okay good i'm happy you remember quite a bit so yes the the first stage in fact was for is design analysis where there are different so we will go into each of these stages one by one and look at what each step entails okay and uh don't hesitate to stop me ask questions or add anything if you feel like okay so the first stage is design analysis where the first step is requirement analysis so what do you understand by requirement analysis what do you think is requirement analysis so customer requirement i think specifically solutions that we want in the circuit the basically demand of the market what exactly is required in the market yeah so over here what we are looking at is what is it that the uh customer would pay for is would be willing to pay for for the price point where we want to target our product so if if i want to come up with the next generation of iphone 12 or you know iphone for example now iphone 13 what would the customer be willing to pay the premium for next year so that would become my requirement and then we do the next step which is called the function functional and test specifications what would come into this according to you to test the functionality of our design in the base of requirements so what we just required a buyer design what kind of functions we require yes what kind of functionality is required for example you may say that you know when apple came up with this infrared face recognition feature at that time what functionality is required you need to understand that okay it has to be infrared and it should it should recognize the face and it should unlock the screen if the face recognition is say above or the face matches above say 80 it should also unlock the screen or ninety percent it should only also unlock the scheme and very importantly when you define the functional specifications you also define how will you test that your device is meeting those specifications in various conditions so as soon as you define the functionality how to test it is also defined simultaneously this is something which is not commonly understood and done are we able to appreciate the significance of this aspect so i'm not able to understand how this text specification can be introduced here i mean okay so uh let us take this same feature the face recognition feature that you're talking about so how would you test this camera now if i want to say that apple would have this camera in it how would you test it so most probably i would be taking some samples of pictures or photos and then seeing the quality or the how what the output is then analyzing that output so i may say that i will take 10 000 photos of one person okay and when any of those 10 000 photos is put in front of this camera system it should be able to recognize it as the right person and should unlock the screen that could be one way to test it okay okay so like uh we are specifying the specification from an overview overall from the functional perspective this is the okay i wanted how do i test that this functionality is being met okay okay i know because finally what whether some other functionality happens or not happens doesn't matter functionality that i am selling to my customers should definitely work fine and i should know how to test it this i should know early on when even when i am defining the specification okay answer the functionality you are talking about it is in terms of specification like uh it needs to have a 40 megapixel camera or should be able to detect that that in terms of yes so it is specifications of functional specifications and test specifications functional specifications would say it should be infrared it should be able to identify the person even in an ambient light of let us say a dark room and it should be able to you know differentiate between two brothers for example who look very much alive but are not twins okay so like what the kind of thing we see in the ads of basically that is yeah that is one aspect of it so i gave you an apple example under the face recognition example because that you already see in the ads and it is easy to relate to them yes but for any chip even if you're if you have to design an spga okay for even for an fpga the user would have the specification that its ddr should operate at uh two gigahertz that it should be able to support this kind of throughput it should be able to give this kind of uh uh you know dry stone mix per second whatever okay okay so that also comes here interesting okay okay i gave you a user i took the example of an apple face recognition thing i was i gave test specifications for that but when i talk of functional specs which which does not really materialize into the user or a consumer application then i will anyway have technical functional specifications there okay okay so here also the engineer will be working generating them would be working to define the specifications yes okay so we will define the specification and consultation with the customer who is going to use the product and also the test specifications in consultation with the customer department you had raised your hand uh strict to define the verification of the testing method in the beginning what if the specification changes in at a later stage then it won't be a tedious task to review everything you tell me one thing if the specification changes you anyways need to need to you know come back to the initial phase so let us say you were in this stage at this point of time the customer said no no i do not want this camera to work in infrared light i now want this camera to work at uh regular light with regular light i want a laser to be generated there so do you realize that everything would change for you also the kind of energy that your image sensors will now capture will be very different from what they would capture in an infrared light scenario yes yes so you will anyway need to come back to this stage again because the functional specifications have changed yes okay i was just concerned about the timing part yeah basically if the functional specifications are changing everything would need to be redefined okay and as as soon as you change the functional specification test specification should also be reviewed all over so my and my actually the point was that maybe we can if we are a bit mature state then we can define how to test because then we will be sure that this is like the final product text required no change can be done beyond that as a designer you may want that but as a customer would you want that suppose let us put it like this you want to go and order a double bed for your room and you want it to be succeed by six feet now would you would you give the specification to the to the carpenter right away or say that okay i wanted to be six feet by six feet but i will tell you how i will measure six feet uh after you have you know um cut the plywood no yeah i think goddamn will tell you which scale you're going to use right away so that he also uses the same scale is it not right so the test specifications have to be built alongside functional specifications there is no other way okay and this is what many times i see designers miss out on they think only in terms of functional specification they forget that test specification is equally important to be defined right there correct correct got it thank you sir to be actually making a hardware and then testing it or something else you tell me this is a this is a chip design fluna entire entire thing is a chip design flow is it not listen so in this flow we will actually you actually get silicon in your cell phones is it not like the wafer fabrication and all things are later on so are we actually making it in the initial stages and then testing it we are making the specifications specifications for example example in this what did we say we said that i will tell the carpenter i want a bed a double bed which is six feet by six feet and that i will measure six feet by using this particular scale i have not built the bed yet i have not even purchased the plywood yet but i know what i want in my bedroom that's where so test the testing means is it a simulation or something related to this no testing so for a carpenter thing you will want to actually measure physically the the dimensions of your bed now but the physical thing that you're getting is working exactly the way it was intended to be right yes so you will actually have to characterize and test the silicon wafers that are out or whatever system it is sir uh yes sir so you mean to say that we are just giving the specifications but not actually testing them like functional and test specifications we are just mentioning them what do we test yeah product design has not even started yet what do we test we are simply telling this is how we will test okay okay okay so basically this all the documentation partner uh yes this is in a way the specification the statement of work creation part this is still just documentation no design implementation yet yes okay in fact just after this step if you look the step is called partition and plan what do you think this means uh dividing the follow strategy uh divine implementation dividing the whole strategy of how to implement all the things related with it yeah so some for example if you go back to the actual space recognition example in that particular example it will mean which team will do what kind of work who will design that laser the infrared laser who will design the uh the hardware the chip who will write the software which does the recognition or which does the analysis okay who will integrate all of it and the plan as to by when will different milestones of different such partitions be completed so that i finally have my apple phone uh available in the market by thanksgiving so that people can purchase it for christmas yes sir so that is partitioning and planning all of this the design has not even started okay okay any questions still here yes sir if you talk about in memory sir when we say uh for a room that when when we say that we want to make the connections that we want to i mean diffuse the transistor in in the highest layers so basically that is i mean in that context we say that if the customer uh says that now in the data state of the making the memory at that point of time if the customer says i want this this code to be embedded and not the one that i uh gave i mean i have given to you so is that also not the functional specification that is being changed and then we are not really going to the design analysis uh once again we are just changing the connections so it depends currently like uh depends how big a change the user is asking for and and what is the stage of the design if the change is really that doesn't require any change in the design implementation you will not go back to the scratch board you know the the drawing board all over again but if the specification change is very significant then you will need to do that and you should be aware of this that you cannot really change specification after the implementation has begun or has kind of closed whatever because that means a huge turnaround time it can mean a huge turnaround time yes so usually a good amount of time is spent on this stage the design analysis stage because if this is not done correctly all the effort that goes subsequently so this effort 10 people will do but the design implementation effort for example if it's about a intel microprocessor the typical effort that goes into a microprocessor is 200 million years 300 million years so so many people working across multiple teams across the various sites uh are involved in making a full intel microprocessor and if the first phase design analysis phase is not good enough is is is kind of carelessly done then all those 2 200 manual efforts can simply go down the drain you will come up with the product which will not sell in the market so this is one of the most important parts so in this part what kind of things you get to do in india so since there are very few end-to-end product manufacturers in the country not much of this job gets done in india but in every company whether it is ti or st or samsung or micron uh all these three kinds of jobs exist they typically exist in the headquarters samsung has this kind of jobs in korea st has these kinds of jobs in italy and france ti has them in the u.s micron has them in the us so these kind of this kind of design analysis or product definition thing is is primarily in the headquarters or then somewhere very close to the customer wherever they are getting their maximum sales from they would have some some such jobs in that place also okay once the product specification animation wanted to add something audible yes you're audible so yes sir i wanted to ask if these test specifications right if you would like to test it on uh for example what we were talking about an apple air uh phase recognition system if we would like to test first that application on an fpga which is reconfigurable before making try trying to release this specifications we would want to test it on our fpga right before starting the chip um we don't know so we will come where the fpga and such kind of work would come in we can we can i will i will share about where we can do that emulation part okay so so abhini a when when the customer is defining the specification he has no clue how you would implement it he is simply telling you that i want this okay only when you enter into the design implementation phase you will look at how to validate and verify it okay fpga is largely about verifying your design is it not yes seriously you need to have a design first so a design entry has to happen before that okay yes so in the design implementation stage"
OLJIYZylox0,we first do the design entry now i know that my my team is to develop that face recognition hardware okay the the the sensors will give me some data and i have to now uh design the hardware which would do the calculations to ensure that face recognition happens accurately so i do the design entry i make it an rtl or something like that after the design entry i synthesize it i say that okay i wanted i wanted a adder there i wanted a multiplier here i wanted a comparator here and so on and i synthesize it i make those connections and then i simulate it saying thereby that the adder and the multiplier and the connectivity of them is working fine it is at this stage you know when you are simulating and if the simulations come fine it is at this stage that you may also want to emulate that is where the fpga or other emulation systems would come in okay and then you enter into the stage of physical design and layout this is hardcore implementation and once that implementation is done you will simply do a design verification that whatever chip i had i have now designed i have now implemented that is in line with the design specifications that i had okay and then what we then what we would do is if we call it as a tape out but then we tape out our chip and send the design to the foundry in the foundry uh yes uh so the design verification step you have uh put it at the very end but design verification as i can remember it comes after synthesis also and like after this yeah everybody at various stages so what kind of design verification are you like me uh focusing on here and this step because yeah so design verification that i have put on this slide over here at the bottom of the design implementation stage is exhaustive it includes simulation based verification includes stages like drc lvs erc techs everything package verification everything is done in this stage only after everything is fine you send something for mass making okay answer like uh we are also including the formal verification and those kind of things we will look at that in the next slide because that is too much detail so okay so over here i've just put the entire design implementation phase into five stages so on the next slide we will look at all those uh detailed you know that these five stages are actually a mix of 20 other activities and each though each of those 20 activities is a different job profile we will look at that in the next slide yes sir rajneesh you had a question yes sir uh sir uh in this uh design implementation sir this uh uh like logic partitioning and planning is present in this physical design also this yeah yeah the floor plan floor plan placement everything we will talk about in the next slide don't worry we will go into much more detail in the next slide so these two are different now this uh design analysis partitioning and planning yes they are very different partitioning that i talked about in design analysis was which team where we'll do which kind of uh designing okay that was the overall partitioning of the project okay uh sir yeah so i don't understand what's the difference between synthesis and physical design we will see and the next slide we will see i mean um i realize this might be a little different but from uh what we studied about fpga like you when you when you're doing synthesis you're doing a mapping and routing i mean i mean all that placement and all that isn't that a part of your layout itself so we will see that in the next slide here just wait a little sure okay so keep this question alive in yourself we will see that in the next slide let me just give you a complete top level overview first then we'll go into the detail okay so once once we are sure that the chip that we have designed you know the layout that we have designed everything is really good good to go we send it to the foundry the foundry first sends it to the mask shop where masks are made and once the masks are available you start to do the wafer fabrication now depending on a technology there could be 39 masks there could be 28 masks there could be 47 masks or there would be 60 masks that that design or a wafer would need to go through to make the entire design so it would depend on technology and the choices that you've made regarding the design okay and the more the number of masks the more the time it takes in the fabrication facility because it is more number of times it has to sit into machines and run through it and also higher the risk of loss because every mass step every step additional step in the foundry means some some heal loss at every step so every extra step means some extra heavy loss that can happen yes vaishnav sir what is this mask exactly sir i mean that yeah we will come to that so mask is like something that we will use to fabricate a design okay okay sir so when we will look at the fabrication process uh in probably the next class or hopefully today i don't know you will get a view of what a mask is okay so yeah once the wafers are fabricated they are sent for testing and characterization so the first test that happens is wafer prototype test what does it mean it means that at the wafer level itself without even cutting the wafer into dice and cutting it into chips so you know how a wafer looks a silicon wafer is a for example a 300 millimeter wafer means that there is this circular silicon wafer a thin thin piece of silicon which is 300 millimeters wide so 12 inches wide the diameter is 12 inches and on this wafer there would be and on this wafer there would be these uh i think that ppt have you just say that the diameter is 12 inches yeah the base foot is 12 inches isn't that quite big i mean yes it is big on one vapor you can have thousands of dice that can be fabricated and sir what exactly a dive die is the chip that will go into your phone okay but yeah you you manufacture all of them together so many of them together so that the overall cost can be low okay so uh so basically we are we are manufacturing many diets in the same paper and then those guys can be later separated yes to decrease the manufacturing costs so we are manufacturing them in bulk yes so the first test you do is on wafer level itself that okay let me see how many dies in this particular wafer are working after that wafer prototype test you identify the good ones and only those good dies you package you don't package the bad ones after packaging you do another testing so so i mean we are testing the good ones twice effectively yes so hoga so every as i said every step that you take there could be some failures happening there so on the wafer you saw that okay out of the thousand dies 990 dies are working so you say okay i will package these 990 dice dives after packaging out of those 990 99 980 may be working so only those 980 you will then send to the customer so but why will something like that happen i mean are we using different tests in uh i mean both the levels i mean prototypes and then package okay and let us put it like this uh have you done some painting any point of time in your life yeah so the first step you do is sketch it with pencil then you start to put some colors into it yes so you suppose you have to put you have to make a rainbow so you have to put seven colors next to each other now i want uh i want only that particular painting to be shipped in which there is no overlap of any color yeah so what can happen after the first step that is the i made it with the pencil okay pencil method overlapped for possibility so it is fine there is no heat loss after the red color again there is no heat loss but as soon as i put the orange color i might end up overlapping it with red somewhere okay okay so that yeah yeah yeah so every extra step that you do there can be somebody lost yes sir so when you package what are you doing you are connecting wires from the pins of the package to the pads on your die there could be some error in that connection therefore he lost okay so you have to test after every step yeah yes we're gonna depend on that [Music] [Music] because we have to describe some pattern only so wait we'll come to mask a little later as i already mentioned we'll look at what a mask is a little later don't worry vapor prototype test is it we are just cutting each and every die and testing it separately whether uh some guys are whether the guys are working or not or is it like uh we are just testing a bit a part of some uh that before is it like in a wafer prototype test you just keep the entire wafer there you bring probes and you put put them on every die one by one okay okay and you test it now suppose you see that there is this entire row which is not working you will not cut the dies of that row into independent pieces you will just discard the entire row when you are cutting the wafer okay so yes so what do you mean by the so what do you mean by the term characterization is this characterization essentially means what is the character of this [Laughter] so characterization essentially means that okay i wanted to design a processor which would work at 1.2 gigahertz okay but i designed it for 1.2 gigahertz but due to some reasons it could work only at 1.1 gigahertz on silicon can it happen okay so i need to know i need to know at what speed it is working so that is why it is called characterization so it is the characteristic of that dye that this dye is working at 1.1 gigahertz and not 1.2 gigahertz okay so like i started with a certain kind of a goal in mind but if it is like differentiating from that i need to know that okay how much it even if it has met the goal even if it has met the objective i need to know that this is 1.2 gigahertz or 1.21 gigahertz okay okay so like finally it is completed now what is like it yeah is it finally it is completed now what is it okay look at it like this so uh childbirth huh so you do an ultra sound you do everything everything you know that the child is developing so i don't know if you have children yet but some point of time you will have probably so you know ultrasound and all those tests you see that the child is growing well but finally when the child characterization happens okay okay okay fine so that is what it is okay what is this uh you know what is how what is this dive finally it is working fine but what is it finally is it operating at 1.2 gigahertz 1.24 gigahertz or 1.16 gigahertz it is working fine what what at what frequency similarly at what power consumption at what leakage at what battery life all those things everything is characterizing that particular dye okay okay so thank you sir okay shivam you had a question yes sir sir actually i want to ask that uh whether the number of transistors that are to be manufactured on this dice is uh decided by our requirement or specifications or is there any rule that a fixed number of transistors or will be manufactured on the particular tie you tell me what should it be sir it should be according to our requirement yes enough so it can happen for example someone may say that i need 1 billion transistors to be put now the technology team may come back and say see if you put 1 billion transistors your die will become this big and the yield will be less instead we recommend that you put 500 million on this chip and add another die which is another 500 million and together you will be able to come up with a much much cheaper and more efficient product that may happen but you would want to put number of devices based on what your requirements are yes okay so there could be a technology constraint you can accommodate that that's a different thing yes yes myself so when we are saying uh that we want our goal is 1.2 gigahertz and somehow we got 1.1 gigahertz now why the customer would accept our chip now so you tell me you tell me do you purchase an intel i3 professor or not at all okay i will select cheaper yeah yeah so but uh if we want 1.2 gigahertz so we should aim a bit higher like 1.25 or 1.3 then we'll get whatever it can be done i will finally what i need to do is i need to characterize and tell this is one point one gigahertz i will select hundred dollars cheaper oh that i still need to do okay for negotiation and something that is working at 1.4 gigahertz i will tell the user oh this is very low power and i will sell it as i7 yes okay you see so i still need to know this information how i achieve what i achieve that is a different thing that is strategy designer strategy we are presently talking about what does the flow entail the fluent is identifying and sorting them so wafer test and die sort package tests and slots see these packages are operating at this frequency these packet is at this frequency and therefore i will sell them separately yes sir okay and then i finally ship it to the customer finally okay so uh after the wafer prototype test so here we have uh tested the functionality whether our die is working properly or not or for every row or column whatever we prototype test and then to paper test or would it be like uh before prototyping this and that paper test and iso so see wafer is when all the dyes are together yes packages after you have separated these dyes and packaged them into their ics so after the package test wafer test can't happen yes sir so in the last step shift production units when i say wafer test and die sort that step is not coming after packaging that that step is coming after wafer prototype test okay because at times what happens is for example that apple face recognition thing you said that laser someone would make image sensors someone would make and the computational processor someone else would make something estimate something samsung made something sony made so now you cannot package just the sensor and say okay this is the chip apple had a product in mind where all these three dies would be put together so you are sending only the wafers and dice to the customer you're not sending packages to the customer yes so at times you send wafers and dice to the customer at times you send packages whatever it is you do the testing and only after that testing you send them yes sir yes sir in the wafer prototype test we put the probe uh on the each die still when still it is part of paper we tested whether it is functionally working or not and then in the wafer test what kind of test you're doing and that what is the difference between these kind of tests right so wafer prototype test and wafer test could be similar but it the last stage involves dye sorting okay okay so like we have characterized before now we are like putting them different categories yes uh so can you elaborate on dice sorting again yeah it is that okay this guy is working at 1.2 gigahertz this diet 1.4 gigahertz i had 1.1 so sorting them into different bins and saying this one sell at 100 100 cheaper this one sent 200 costier this one sell at the target price right so i mean um all the dyes in the wafer do not need to be of the same type may not be yeah may not be okay so sir i mean do these duty steps happen in parallel design characterization and shift production units um it depends they could they may not okay depends on product uh yeah because the thing is you know you can do die sort right after the package prototype test so like no no wait wait wait wait if you already packaged it then you can't then there is no longer die sort then there is packet shot okay like packet sort involves uh what exactly same thing it is that you're shipping packages instead of dice okay so i mean then what's uh so like okay you're performing wait for prototype test and you're performing wafer tests and diastole instead of instead of that you can just do wait for prototype test and follow that up with dye soft so you can do that okay so like that additional wafer test is just like optional again it depends you know it's the wafer prototype test because of uh the so you know it depends on the fab conditions suppose you say that wafer prototype test was done at the at tsmc and wafer test and dyesort [Music] qualcomm would do at its own facility so testing has to happen twice then right right so it depends if it's happening in the same place or different if it is intel it will only happen once oh sir sorry sir my question is what so there can be variation in the thing which we are shipping we can ship the package or we can ship the wafer or we can ship the driver because as you said that at and play and different company different type of tests can happen so that means there can be different type of product which is being shipped is that correct assumption yes yes yes yes there are for example the rfid tags that you keep in your shirts those are small small chips which are which are which are sent only as dyes which are shipped only as dyes on strips of paper okay so uh all kinds of forms and features appear in these chipping parts so i see the hands of vaisnava and gadandeep also raised hello sir uh i want to ask that uh we are doing die sorting and then we are going to i mean do the package sort also so i mean it looks like that we are uh doing a die sword which might not really affect what we said because at the end if i sort the packages then i i need to uh ship those only after categorizing so yeah but if i'm shifting dice but then if i'm shipping dies only then i don't need to package them now yes in that case it would be yeah so not something that has already been packaged will not be wafer tested and die sorted it will only be packaged tested and sorted something which is being shipped as a wafer will be wafer tested and die sorted so it is about what i am going to shape yeah hello okay hello yes yes yes sir actually you were saying that uh like i3 or i7 for example if you take an intel so aren't we doing something i'm like uh we would know that uh before uh uh i mean like we are supposed to make an icon processor but we got an i3 processor uh while doing uh wafer testing it's is it something mean like something has happened and due to some malfunction we have got got an i3 processor or something like that yeah it could be that no so i i gave the names of i3 i7 and i5 but let us say that have you seen that there are products which are exactly the same specification but the frequency is lower only frequency is lower see there is a difference between ic i5 and i7 the difference is not just about speed that difference is also about hardware okay so that could be because some hardware on i5 failed and now you call it i3 okay so uh my doubt was that uh actually uh so have we done some something unintentionally or something so that uh by mistake we have got an ison processor or uh during the function no no no it was designed to be built as an i7 only therefore we designed an i7 but when i7 could not when there were some dice which would not really give that kind of functionality and we felt the customer will not purchase them at that price point we said okay we will sell them a little cheaper okay sir thank you okay so uh let's not enter into i3 i5 i7 let me say that i7 here let us say it is only i7 but there are three different frequencies of i7 itself and each of those i7s is still at a slightly different uh sale point okay sir okay thank you okay yes action sir i have a question like and last generation of intel processors something like happened in laptop that i five is performing right uh better than i seven so what kind of sorting uh yeah so that is where machine learning comes into vlsi okay so they defined some tests and they said that okay if if these parameters on the particular die are positive we will call it i5 if these additional five parameters are positive we will call it i7 okay this was based on their understanding of the design that this when these five additional parameters are also positive that is when the performance will be better so so it was not an hardware issue it was their understanding of how to sort okay uh one way so this is a bit confusing they've got i don't know what exactly happened but uh given from what he just said they confused between i5 and i7 because there was a mix-up with the specifications yes because they felt that this would be faster and it was not actually faster so so i mean uh isn't that like the job of you know your design implementation and then your design characterization i mean um if you're designing it such that okay it should be faster you know that you're designing an i7 right so if it's showing that particular speed then how can you sort it differently see i see it is not just about speed mirror like it is not just about clock frequency at which you are operating uh benchmarks actually test how well you are able to use the the access to the memory for example okay benchmarks would also relate to how easily you are able to transition from one thread to another benchmarks test a lot of things and real life use cases are also like that you're not you know just looking at clock frequency and saying my system is faster finally you go with your experience you know an apple chip you know an apple iphone chip would typically if you look at it operate at a lower frequency but has a much more fluid user experience than an intel chip based design so would you say that the fault was in the test specifications that okay it did not test all the cases it could be anywhere it could be an in their understanding it could be in the design implementation they had designed uh designed it such that that the memory would they have put in more memory and they said this will actually lead to better performance but due to more memory what happened was the wire lengths increased let us say and delay is increased so or or there was a bottleneck in terms of bandwidth due to which the information transfer that you anticipated did not really happen at the same rate right the fault could be anywhere i'm just saying that if they say that okay this was expected to be faster and it is slower it could be simply a die sort algorithm failure also okay it could simply be that but it could be anywhere else previous in the chain also uh right right okay okay so how do we yeah how do we resolve this kind of issue like um so you go back you go back review your design you debug where where did the assumptions go wrong and then you correct those assumptions redo the so you cannot really undo what has already been shipped to the customer yeah yeah but the next chip design that you're doing you have more mature assumptions now and you will therefore design it better so but the problem was with the fact that i mean one of the problems one of the possible problems that okay you couldn't identify one type from another because yeah so you were showing what you expected yeah so you will then upgrade yeah so then you will upgrade your sorting algorithms okay so the next lot that you will sort you will have a better algorithm so therefore the problem will disappear after some time okay should retrain your algorithms then,https://www.youtube.com/watch?v=OLJIYZylox0,"Link: https://www.youtube.com/watch?v=OLJIYZylox0
Transcript: we first do the design entry now i know that my my team is to develop that face recognition hardware okay the the the sensors will give me some data and i have to now uh design the hardware which would do the calculations to ensure that face recognition happens accurately so i do the design entry i make it an rtl or something like that after the design entry i synthesize it i say that okay i wanted i wanted a adder there i wanted a multiplier here i wanted a comparator here and so on and i synthesize it i make those connections and then i simulate it saying thereby that the adder and the multiplier and the connectivity of them is working fine it is at this stage you know when you are simulating and if the simulations come fine it is at this stage that you may also want to emulate that is where the fpga or other emulation systems would come in okay and then you enter into the stage of physical design and layout this is hardcore implementation and once that implementation is done you will simply do a design verification that whatever chip i had i have now designed i have now implemented that is in line with the design specifications that i had okay and then what we then what we would do is if we call it as a tape out but then we tape out our chip and send the design to the foundry in the foundry uh yes uh so the design verification step you have uh put it at the very end but design verification as i can remember it comes after synthesis also and like after this yeah everybody at various stages so what kind of design verification are you like me uh focusing on here and this step because yeah so design verification that i have put on this slide over here at the bottom of the design implementation stage is exhaustive it includes simulation based verification includes stages like drc lvs erc techs everything package verification everything is done in this stage only after everything is fine you send something for mass making okay answer like uh we are also including the formal verification and those kind of things we will look at that in the next slide because that is too much detail so okay so over here i've just put the entire design implementation phase into five stages so on the next slide we will look at all those uh detailed you know that these five stages are actually a mix of 20 other activities and each though each of those 20 activities is a different job profile we will look at that in the next slide yes sir rajneesh you had a question yes sir uh sir uh in this uh design implementation sir this uh uh like logic partitioning and planning is present in this physical design also this yeah yeah the floor plan floor plan placement everything we will talk about in the next slide don't worry we will go into much more detail in the next slide so these two are different now this uh design analysis partitioning and planning yes they are very different partitioning that i talked about in design analysis was which team where we'll do which kind of uh designing okay that was the overall partitioning of the project okay uh sir yeah so i don't understand what's the difference between synthesis and physical design we will see and the next slide we will see i mean um i realize this might be a little different but from uh what we studied about fpga like you when you when you're doing synthesis you're doing a mapping and routing i mean i mean all that placement and all that isn't that a part of your layout itself so we will see that in the next slide here just wait a little sure okay so keep this question alive in yourself we will see that in the next slide let me just give you a complete top level overview first then we'll go into the detail okay so once once we are sure that the chip that we have designed you know the layout that we have designed everything is really good good to go we send it to the foundry the foundry first sends it to the mask shop where masks are made and once the masks are available you start to do the wafer fabrication now depending on a technology there could be 39 masks there could be 28 masks there could be 47 masks or there would be 60 masks that that design or a wafer would need to go through to make the entire design so it would depend on technology and the choices that you've made regarding the design okay and the more the number of masks the more the time it takes in the fabrication facility because it is more number of times it has to sit into machines and run through it and also higher the risk of loss because every mass step every step additional step in the foundry means some some heal loss at every step so every extra step means some extra heavy loss that can happen yes vaishnav sir what is this mask exactly sir i mean that yeah we will come to that so mask is like something that we will use to fabricate a design okay okay sir so when we will look at the fabrication process uh in probably the next class or hopefully today i don't know you will get a view of what a mask is okay so yeah once the wafers are fabricated they are sent for testing and characterization so the first test that happens is wafer prototype test what does it mean it means that at the wafer level itself without even cutting the wafer into dice and cutting it into chips so you know how a wafer looks a silicon wafer is a for example a 300 millimeter wafer means that there is this circular silicon wafer a thin thin piece of silicon which is 300 millimeters wide so 12 inches wide the diameter is 12 inches and on this wafer there would be and on this wafer there would be these uh i think that ppt have you just say that the diameter is 12 inches yeah the base foot is 12 inches isn't that quite big i mean yes it is big on one vapor you can have thousands of dice that can be fabricated and sir what exactly a dive die is the chip that will go into your phone okay but yeah you you manufacture all of them together so many of them together so that the overall cost can be low okay so uh so basically we are we are manufacturing many diets in the same paper and then those guys can be later separated yes to decrease the manufacturing costs so we are manufacturing them in bulk yes so the first test you do is on wafer level itself that okay let me see how many dies in this particular wafer are working after that wafer prototype test you identify the good ones and only those good dies you package you don't package the bad ones after packaging you do another testing so so i mean we are testing the good ones twice effectively yes so hoga so every as i said every step that you take there could be some failures happening there so on the wafer you saw that okay out of the thousand dies 990 dies are working so you say okay i will package these 990 dice dives after packaging out of those 990 99 980 may be working so only those 980 you will then send to the customer so but why will something like that happen i mean are we using different tests in uh i mean both the levels i mean prototypes and then package okay and let us put it like this uh have you done some painting any point of time in your life yeah so the first step you do is sketch it with pencil then you start to put some colors into it yes so you suppose you have to put you have to make a rainbow so you have to put seven colors next to each other now i want uh i want only that particular painting to be shipped in which there is no overlap of any color yeah so what can happen after the first step that is the i made it with the pencil okay pencil method overlapped for possibility so it is fine there is no heat loss after the red color again there is no heat loss but as soon as i put the orange color i might end up overlapping it with red somewhere okay okay so that yeah yeah yeah so every extra step that you do there can be somebody lost yes sir so when you package what are you doing you are connecting wires from the pins of the package to the pads on your die there could be some error in that connection therefore he lost okay so you have to test after every step yeah yes we're gonna depend on that [Music] [Music] because we have to describe some pattern only so wait we'll come to mask a little later as i already mentioned we'll look at what a mask is a little later don't worry vapor prototype test is it we are just cutting each and every die and testing it separately whether uh some guys are whether the guys are working or not or is it like uh we are just testing a bit a part of some uh that before is it like in a wafer prototype test you just keep the entire wafer there you bring probes and you put put them on every die one by one okay okay and you test it now suppose you see that there is this entire row which is not working you will not cut the dies of that row into independent pieces you will just discard the entire row when you are cutting the wafer okay so yes so what do you mean by the so what do you mean by the term characterization is this characterization essentially means what is the character of this [Laughter] so characterization essentially means that okay i wanted to design a processor which would work at 1.2 gigahertz okay but i designed it for 1.2 gigahertz but due to some reasons it could work only at 1.1 gigahertz on silicon can it happen okay so i need to know i need to know at what speed it is working so that is why it is called characterization so it is the characteristic of that dye that this dye is working at 1.1 gigahertz and not 1.2 gigahertz okay so like i started with a certain kind of a goal in mind but if it is like differentiating from that i need to know that okay how much it even if it has met the goal even if it has met the objective i need to know that this is 1.2 gigahertz or 1.21 gigahertz okay okay so like finally it is completed now what is like it yeah is it finally it is completed now what is it okay look at it like this so uh childbirth huh so you do an ultra sound you do everything everything you know that the child is developing so i don't know if you have children yet but some point of time you will have probably so you know ultrasound and all those tests you see that the child is growing well but finally when the child characterization happens okay okay okay fine so that is what it is okay what is this uh you know what is how what is this dive finally it is working fine but what is it finally is it operating at 1.2 gigahertz 1.24 gigahertz or 1.16 gigahertz it is working fine what what at what frequency similarly at what power consumption at what leakage at what battery life all those things everything is characterizing that particular dye okay okay so thank you sir okay shivam you had a question yes sir sir actually i want to ask that uh whether the number of transistors that are to be manufactured on this dice is uh decided by our requirement or specifications or is there any rule that a fixed number of transistors or will be manufactured on the particular tie you tell me what should it be sir it should be according to our requirement yes enough so it can happen for example someone may say that i need 1 billion transistors to be put now the technology team may come back and say see if you put 1 billion transistors your die will become this big and the yield will be less instead we recommend that you put 500 million on this chip and add another die which is another 500 million and together you will be able to come up with a much much cheaper and more efficient product that may happen but you would want to put number of devices based on what your requirements are yes okay so there could be a technology constraint you can accommodate that that's a different thing yes yes myself so when we are saying uh that we want our goal is 1.2 gigahertz and somehow we got 1.1 gigahertz now why the customer would accept our chip now so you tell me you tell me do you purchase an intel i3 professor or not at all okay i will select cheaper yeah yeah so but uh if we want 1.2 gigahertz so we should aim a bit higher like 1.25 or 1.3 then we'll get whatever it can be done i will finally what i need to do is i need to characterize and tell this is one point one gigahertz i will select hundred dollars cheaper oh that i still need to do okay for negotiation and something that is working at 1.4 gigahertz i will tell the user oh this is very low power and i will sell it as i7 yes okay you see so i still need to know this information how i achieve what i achieve that is a different thing that is strategy designer strategy we are presently talking about what does the flow entail the fluent is identifying and sorting them so wafer test and die sort package tests and slots see these packages are operating at this frequency these packet is at this frequency and therefore i will sell them separately yes sir okay and then i finally ship it to the customer finally okay so uh after the wafer prototype test so here we have uh tested the functionality whether our die is working properly or not or for every row or column whatever we prototype test and then to paper test or would it be like uh before prototyping this and that paper test and iso so see wafer is when all the dyes are together yes packages after you have separated these dyes and packaged them into their ics so after the package test wafer test can't happen yes sir so in the last step shift production units when i say wafer test and die sort that step is not coming after packaging that that step is coming after wafer prototype test okay because at times what happens is for example that apple face recognition thing you said that laser someone would make image sensors someone would make and the computational processor someone else would make something estimate something samsung made something sony made so now you cannot package just the sensor and say okay this is the chip apple had a product in mind where all these three dies would be put together so you are sending only the wafers and dice to the customer you're not sending packages to the customer yes so at times you send wafers and dice to the customer at times you send packages whatever it is you do the testing and only after that testing you send them yes sir yes sir in the wafer prototype test we put the probe uh on the each die still when still it is part of paper we tested whether it is functionally working or not and then in the wafer test what kind of test you're doing and that what is the difference between these kind of tests right so wafer prototype test and wafer test could be similar but it the last stage involves dye sorting okay okay so like we have characterized before now we are like putting them different categories yes uh so can you elaborate on dice sorting again yeah it is that okay this guy is working at 1.2 gigahertz this diet 1.4 gigahertz i had 1.1 so sorting them into different bins and saying this one sell at 100 100 cheaper this one sent 200 costier this one sell at the target price right so i mean um all the dyes in the wafer do not need to be of the same type may not be yeah may not be okay so sir i mean do these duty steps happen in parallel design characterization and shift production units um it depends they could they may not okay depends on product uh yeah because the thing is you know you can do die sort right after the package prototype test so like no no wait wait wait wait if you already packaged it then you can't then there is no longer die sort then there is packet shot okay like packet sort involves uh what exactly same thing it is that you're shipping packages instead of dice okay so i mean then what's uh so like okay you're performing wait for prototype test and you're performing wafer tests and diastole instead of instead of that you can just do wait for prototype test and follow that up with dye soft so you can do that okay so like that additional wafer test is just like optional again it depends you know it's the wafer prototype test because of uh the so you know it depends on the fab conditions suppose you say that wafer prototype test was done at the at tsmc and wafer test and dyesort [Music] qualcomm would do at its own facility so testing has to happen twice then right right so it depends if it's happening in the same place or different if it is intel it will only happen once oh sir sorry sir my question is what so there can be variation in the 
thing which we are shipping we can ship the package or we can ship the wafer or we can ship the driver because as you said that at and play and different company different type of tests can happen so that means there can be different type of product which is being shipped is that correct assumption yes yes yes yes there are for example the rfid tags that you keep in your shirts those are small small chips which are which are which are sent only as dyes which are shipped only as dyes on strips of paper okay so uh all kinds of forms and features appear in these chipping parts so i see the hands of vaisnava and gadandeep also raised hello sir uh i want to ask that uh we are doing die sorting and then we are going to i mean do the package sort also so i mean it looks like that we are uh doing a die sword which might not really affect what we said because at the end if i sort the packages then i i need to uh ship those only after categorizing so yeah but if i'm shifting dice but then if i'm shipping dies only then i don't need to package them now yes in that case it would be yeah so not something that has already been packaged will not be wafer tested and die sorted it will only be packaged tested and sorted something which is being shipped as a wafer will be wafer tested and die sorted so it is about what i am going to shape yeah hello okay hello yes yes yes sir actually you were saying that uh like i3 or i7 for example if you take an intel so aren't we doing something i'm like uh we would know that uh before uh uh i mean like we are supposed to make an icon processor but we got an i3 processor uh while doing uh wafer testing it's is it something mean like something has happened and due to some malfunction we have got got an i3 processor or something like that yeah it could be that no so i i gave the names of i3 i7 and i5 but let us say that have you seen that there are products which are exactly the same specification but the frequency is lower only frequency is lower see there is a difference between ic i5 and i7 the difference is not just about speed that difference is also about hardware okay so that could be because some hardware on i5 failed and now you call it i3 okay so uh my doubt was that uh actually uh so have we done some something unintentionally or something so that uh by mistake we have got an ison processor or uh during the function no no no it was designed to be built as an i7 only therefore we designed an i7 but when i7 could not when there were some dice which would not really give that kind of functionality and we felt the customer will not purchase them at that price point we said okay we will sell them a little cheaper okay sir thank you okay so uh let's not enter into i3 i5 i7 let me say that i7 here let us say it is only i7 but there are three different frequencies of i7 itself and each of those i7s is still at a slightly different uh sale point okay sir okay thank you okay yes action sir i have a question like and last generation of intel processors something like happened in laptop that i five is performing right uh better than i seven so what kind of sorting uh yeah so that is where machine learning comes into vlsi okay so they defined some tests and they said that okay if if these parameters on the particular die are positive we will call it i5 if these additional five parameters are positive we will call it i7 okay this was based on their understanding of the design that this when these five additional parameters are also positive that is when the performance will be better so so it was not an hardware issue it was their understanding of how to sort okay uh one way so this is a bit confusing they've got i don't know what exactly happened but uh given from what he just said they confused between i5 and i7 because there was a mix-up with the specifications yes because they felt that this would be faster and it was not actually faster so so i mean uh isn't that like the job of you know your design implementation and then your design characterization i mean um if you're designing it such that okay it should be faster you know that you're designing an i7 right so if it's showing that particular speed then how can you sort it differently see i see it is not just about speed mirror like it is not just about clock frequency at which you are operating uh benchmarks actually test how well you are able to use the the access to the memory for example okay benchmarks would also relate to how easily you are able to transition from one thread to another benchmarks test a lot of things and real life use cases are also like that you're not you know just looking at clock frequency and saying my system is faster finally you go with your experience you know an apple chip you know an apple iphone chip would typically if you look at it operate at a lower frequency but has a much more fluid user experience than an intel chip based design so would you say that the fault was in the test specifications that okay it did not test all the cases it could be anywhere it could be an in their understanding it could be in the design implementation they had designed uh designed it such that that the memory would they have put in more memory and they said this will actually lead to better performance but due to more memory what happened was the wire lengths increased let us say and delay is increased so or or there was a bottleneck in terms of bandwidth due to which the information transfer that you anticipated did not really happen at the same rate right the fault could be anywhere i'm just saying that if they say that okay this was expected to be faster and it is slower it could be simply a die sort algorithm failure also okay it could simply be that but it could be anywhere else previous in the chain also uh right right okay okay so how do we yeah how do we resolve this kind of issue like um so you go back you go back review your design you debug where where did the assumptions go wrong and then you correct those assumptions redo the so you cannot really undo what has already been shipped to the customer yeah yeah but the next chip design that you're doing you have more mature assumptions now and you will therefore design it better so but the problem was with the fact that i mean one of the problems one of the possible problems that okay you couldn't identify one type from another because yeah so you were showing what you expected yeah so you will then upgrade yeah so then you will upgrade your sorting algorithms okay so the next lot that you will sort you will have a better algorithm so therefore the problem will disappear after some time okay should retrain your algorithms then"
S7091-SZPFk,give me a second i will pause the recording and i will come back again just give me a minute so once we have this you know good overview of how a chip starts from a requirement analysis to finally shipping we enter into this detail of how does the design implementation happen okay so the first stage of the design implementation is initial design entry where you say that okay i need this kind of memory i need this kind of a processor i need this kind of interfaces ddrs and so on and then you do a design entry this design entry is an rtl okay you write a verilog code and that is rtl once you've done the design entry you need to verify that this design is meeting the functionality that you wanted it to meet so do you simulate the rtl and do a quick power analysis that the power budget is also within the you know specified range after that is done you do the logic synthesis now what what do you understand about logic synthesis there was already a question earlier about logic synthesis and layout so what do you understand by logic synthesis it is mapping our uh rtl code to the gate gate level net list [Music] so it is converting an rtl verilog netlist into a gate level net list that okay you just said an adder but an adder is implemented by using these kind of ands and rs and xor gates okay so that implementation is synthesis after the logic synthesis is done you do test and clock synthesis what do you think test and clock synthesis entails uh sir so like uh when we test our code like when we're stimulating so you know you're using a clock signal that you have provided but to actually generate a clock which will run in that system you need to do a block system as well right okay i mean it should uh run at 2.5 megahertz so yeah so let us look at it like this in the logic synthesis you said you will put 1 million flip flops on your chip and for every flip flop you simply put the clock pin am i right in reality clock will be generated by some pll somewhere or you will get it from outside your chip so there is one point on the chip there you will have the clock generated and do you think that one point can drive all the one million flip flops no so we have dog buffers right i mean so you have to now arrange and organize these flip flops in a particular way that okay these ten flip flops this buffer would drive these ten flip flops another buffer would drive so this part of inserting clock buffers so that none of the clock pins or none of the clock signals nodes has a load more than let us say 100 front of arrows additionally you know all the matched clock nodes uh clock ends arrive at almost the same delay so if if there is one flip flop and another flip flop which was supposed to work simultaneously it should not happen that because i put 10 buffers in one path and five in the other path one swap operated much faster than much earlier than the other one so if they were expected to operate synchronously and simultaneously i have to put 10 buffers on both the paths so this is clock synthesis similarly as we talked about you know initial functional specification and testification we look at test synthesis that as to how will i make those scan chains how will i test the entire chip once it is fabricated so at this early stage itself when when you just add the logic synthesis stage or just right after that you start to also do the test synthesis you start to insert some test features also rather you have a question yes sir sir in this clock synthesis are you referring to the clock tree synthesis yes and so one more thing so like after the design entry you have mentioned the power analysis so but design entry is in the rtl form so we still don't have a kind of uh the components that will be involved so what kind of power analysis that they're doing here like how would we know that what kind of power can be considered let us say i i said that i will use a memory somewhere okay and i have not gated the access to the memory so memory every clock cycle memory is being accessed i know that a memory will consume more power i have models for memory also so in that case then what we see is in that case what we see is that your system will show that the power consumption is high that you need to do power gating at some places to reduce overall power consumption so you can change your rtl so that clock dating happens and memory is not accessed every cycle it is only fs when needed so but my question is like rtl at the rt level we still have we are having only a behavior model so like yeah but you okay so it is not just behavioral model so the models that you have you know the very long models that you have many times they are also associated with uh some top-level information on power consumption and timings okay okay like apart from the net list also yes okay so okay um so so it's a about you know designing a chair so uh it could be an asic it could be a assp it could be anything it could be a standard product all together a commodity product not even an asic and not even an assp it is a standard chip anything so you know the difference between asics and asses and standard yes yes i mean i i don't know what you're referring to by standard chips like for example uh atmel uh atmel 32 processor is a standard chip it is available off the shelf anyone can come to the market and purchase it stm32 is a standard chip anyone can come it is not defined or prepared for a particular application whereas for example corus is a product from st which is a specific chip for automotive industry but it is again standard it was not made specifically for bosch it was not made specifically for rolls-royce it was just made so that any user any um car manufacturer can use it okay so you're saying that uh it's like programmable it can be programmed as to the needs of the customer what about programming no no it is not just about programming it is about application for example stm32 is a standard product it could be used across any application whether you use it in a car you can use stm32 whether you use it in your alexa you can use an stm32 whether it is google home you can use stm32 any application can use stm32 even your smartwatch can use stm32 okay so any range of applications it could be automotive it could even be a satellite it could be using stm32 so it is off the shelf available standard product however when i'm talking about let us say an automotive specific product then that product is designed for a particular use inside cars only for example tire tire pressure monitoring sensor yes now tpms you will not use in your watch will you no it will only be used in automotive sector but it is not designed specifically for bosch it is a standard product so it is application specific standard product assp so but like the features are somewhat to save right i mean okay you can you can only do these amount of things in this ship i mean and those those amount of operations can be used in a car or in a watch or anywhere but it's still fixed you cannot you cannot change it you cannot like uh it's not steel programmable like fpga yeah for example uh so that is that there are multiple flavors of let us say stm32 some flavors would have one kilobyte of non-volatile memory some flavors would have 32 kilobytes some would have one megabit okay so that will limit what all you can store and what all so that would change stuff but otherwise it is stm32 to the standard product okay right okay but assp is application specific standard product now tire pressure monitoring sensor is a tire pressure monitoring sensor only any tire can use it but it is specific to tire pressure monitoring yes and then there would be specific chips for example uh there will be a chip that tesla orders which says that i want a chip for car vision so that i can go into uh self-driving cars okay i want to use this particular algorithm so that it is most efficient for my purposes now that chip is an application specific ic yes it is made specifically for one customer it is much costlier for that customer but customer may still want it for the competitive advantage yes object synthesis again logic synthesis okay i will do that yes is it a microcontroller yes stem cell it was a microcontroller yes okay so uh pressure yes logic synthesis involves uh so rtl would say that okay uh move data from resistor r1 to r2 add r1 plus r2 whatever something like this but how would you move data you need to have some buffer somewhere yes sir how do you add two numbers you need to have that propagate and generate thing coming in you will have to have something coming in to add two numbers yes sir so what would those gates be [Music] so rtl is almost like english language but finally silicon cannot understand english silicon would understand only some transistor language now okay so so we don't even go to understand language when you do logic synthesis we go to gate language so we come to arrive at a gate level net list we say that okay after this nand gate we will put an or gate and when these two nand gates outputs connect on this or gate inputs the output of this or gate is going to be a plus b that a plus b i need to now write into that so we'll convert all those melee machines and more machines and everything that is what is logic synthesis so implementing your english language or a program code into a gate level net list is it clearer yes sir so you do this logic synthesis then you do 10 synthesis once all that is done you know what kind of circuits and what is the total number of cells you need to put on your device you enter into a state which is called as float planning as to where would you put your processor where would you put your memory where would you put different parts of your chip okay i want the memory to be as close to the processor so that there is no delay in accessing the memory one could say that someone would say that i would want to put the pll on this corner of the shift so that it does not encounter any noise someone would say i want to put adc on this place so that is float planning you basically building a plan of how you would lay out your chip finally consider it like if you have to build a residential complex you need to plan where the five towers or residential towers have to be where the swimming pool has to be where the clubhouse has to be and so on so that is what is like float planning and after the while the floor planning is done you also do stuff like our estimation static timing analysis gate level synthesis and so on gate level simulation and so on so what does static timing analysis entail who will tell so this is you know that flip flops would have some setup time some hold time something so when the clock arrives the data should be set up so whether that is happening or not do you need to add some delay somewhere so it is largely timing verification timing characterization gate level simulation is once i've removed the english from a plus b and i've actually put an adder there after all that logic conversion is my net list still still operating the same way as i intended it to be okay then a structure verification is i wanted to have a scan chain built there i wanted to test different different components independently am i able to really test them then power estimation now sensitive actually you have real gates available there okay you have real gates available there you actually can estimate what kind of power consumption will happen and then you also check that okay or that there are two outputs driving one single node so or that there is some input that is floating or that there is a a load on a particular on a particular gate which it cannot even be able to hold so all these checks you do while you do these steps and as you complete these checks you also release your netlist which is now reasonably stable because it has met all these logical standards to the layout now you say ok this was where i wanted to put my tower one this was where i wanted to put my tower to now is the time to build the towers okay so now you will start to place the windows the walls and everything over there and you will and this is what you would be you this is the final shape of a residential complex and layout is essentially the final shape of your design so you start to put the layout of the and gate as to how it will appear on silicon you put the layout of the nor gate of the adder of everything of the memory so all those things you now start to put together and you now do timing driven layout optimization that okay the output of this and gate is going into this or gate so let me place this and gate and nor gate together okay so that is layout driven time timing driven layout optimizations once you have done that you again need to do static timing analysis because now where you now know the additional information of how long a wire is there between two different gates till now you only knew that this nand connects to that norm now you know that this when this man connects to that not there is also this longer wire in between them so the delays would change and you need to do a timing analysis all over again sir so i mean so the static timing analysis we did after the floor uh planning we were not we were not taking into account the routing today so you would use some model method there you would assume that okay most of the wires like you will use a statistical model based on your earlier analysis some other chips you had designed so you know that okay most of my wires were one micron in length and a few wires were 10 microns in length and very few wires were 100 microns in length so based on that you will statistically distribute those wire so this is called a wire load model you distribute those wire loads on some different places and you would do it but now you actually have the real wire length available with you okay okay so this is a more realistic analysis so you do sta all over again and you do post layout technology checks now that is drc clean as lvs clean is a uh is is every gate connected to a or every poly connected to a diode or a drain somewhere otherwise there could be uh you know antenna violations and the strip would fail after fabrication and all that stuff okay the the thing you said about if it's connected to the day in a diode was uh wasn't it a part of gate level simulation like you have diodes are not i would have no functionality per se so yeah how did we skip that in a game simulation because diode is not a gate what combinational logic does diode represent i mean it's just it just really acts as a switcher but like no you know the diodes that i am talking about here are so that due to fabrication there could be a lot of iron iron deposition on your polysilicon gates and you need to discharge them otherwise the gate breakdown will occur these are physical texts technology linked checks okay can you can you just elaborate on that for the little princess and we will look at that in more detail later but yeah so when you manufacture silicon you actually put very high energy uh you know uh how do i put it plasma onto your dies okay this can lead to a lot of charge buildup on your dice and that charge needs to be sunk into the substrate otherwise there can be dielectric breakdown somewhere because of very high voltage okay so every polysilicon gate needs to be connected to some drain or source some something like that so that that charge has a path to discharge this is not a part of logic synthesis at all rather you also wanted to ask something oh yes sir so this timing driven layout optimization are you is it a part of like the routing part like that yes placement uh place and route yes okay answer one more thing so this uh power estimation and the earlier power analysis that we've done just after design entry like uh estimation and analysis does have a different connotation or like does it have an accuracy it has a different connotation in the sense that when you did it the first time you you did not really have the exact numbers because you did not know the exact dates that would be used to implement your design you just saw that okay this processor is being accessed 2000 number of times can i reduce it somehow it was an architectural level thing so this memory is being accessed every cycle can i reduce the number of accesses to the memory okay okay okay so now you actually have the power consumption that happens in every cycle and now you're estimating it and now you can tell oh i still i i reduce it to 50 now i actually need to reduce it to 20 only okay so at the power estimation we are having the specific amount of power consumed every cycle like yeah because synthesis has happened now i know every device yes sir and so one more thing so that uh you have mentioned this uh clock synthesis before the flow planning generally enough flow we generally see that rocket and then the placement and uh uh planning for planning and the placement then we do the kind of this clock three synthesis but here you have put before you see synthesis synthesis uh would happen uh alongside floor planning actually so that is where the link is so test and clock synthesis leads to two things floor planning and this but you see that is a horizontal connector it could actually be happening in parallel also they feed into each other okay okay so can i just briefly explain this how these interconnections are made up between the different boxes you have made actually it's the beginning of it yeah so the ones for example static timing analysis gate level synthesis etcetera they're all running in parallel they do not so while sta has something to do with floor planning and other stuff gate level simulations has nothing to do with it so in the sta box i also show an entry of float planning but i do not show an entry of float planning into gate level sentences for example okay the output of sta goes for timing assertion it also goes for sds and rc and cap estimation and that information also come back to sda so that is also shown as an input there and an output there so uh if you look at if you look at these ones these are reverse loops that okay if after sta i realize that something is not working it means i will go back to this state i will redo the timing driven layout optimization okay if i notice that so when i release the netlist from here i also release timing assertions so that they can be used for timing driven layout optimization i release timing assertions to layout also so these are these are not just one way at least these ones over here they may not necessarily be one way routes there could be also both ways okay timing sessions are basically uh the adjustment of the timing we are doing after the sda so likewise if some gate is failing or not yes you may say that this this device is so far away from there that i need to put in some extra buffers in the other path okay or bring these two devices closer so that is the layout different timing optimization so yes action so so power estimation is done but before timing optimization as you can see in this alongside so you know sta is happening alongside sta and power estimation are happening in the parallel plane uh so sir i want to know that power in load and idle power also matters yes so so after uh like i can see that before releasing the phone found it there's no again power testing or something like when every optimization is done every kind of optimization there's no again power test or something yeah so what happens is uh you know when you actually go into chip designing you will notice that if you've done the you know gating and everything properly over here and you've done verification at gate level simulations and power estimation then after the layout not not really much would change buyers would change they will reflect into sta so you know as soon as you do this sdf and rf you again come back to this level so you do sta again you may you may want to do some other text of this place again that can happen but because there is some extra wire somewhere because of that power is not going to change from 1 milliwatt to 2 milliwatts it may go from 1 milliwatt to 1.01 milliwatts okay sir okay because some you had used some wire load model even initially and it's a fair you know based on a based on earlier products only it's not a random thing picked up from somewhere so many ics are have been designed till date that we have a fair amount of an idea that an ic of this complexity would use this kind of a wire load distribution so power estimation does not really change much after this stage okay sir because you already have the post layout library characterized now okay so what is a wireless model a wire load model okay so when i say that there are these many and gates and these many nand gates on a chip they need to be connected is it not should they be wires in between them these wires will lead to loading of your gates so what length of wire to assume between or what length of wire to assume at the output of a given given gate that is probabilistically set left corner so after you have finally designed your entire chip you will do a post layout extraction so you will see now finally what are my capacitances at different places and with those load capacitances now is my sta is my timing still correct or not if it is not you will go back to the sts stage and you will do a layout riddle and optimization all over again so there will be eco of some parts of your chip eco means engineering change order so some things you will need to change so that your delays and everything are still in that okay answer the block which represents a test structure verification is that connected to bfd and such things yes yes rather if you had a question your hand is raised uh yes sir so this uh can you just say there was a static time and recent timing assertion that so what's the difference here oh so static timing analysis said that okay before the layout i assume that there is some kind of a wire load on on between the two no in the between the two gates and i would say that this is what my uh timing is because i assumed some load now there could be some race conditions where the slack is very less so you will tell that oh i do not really have margins here so please do not increase the tap of this wire more than that so what do you what does that mean for the layout it means that these two cells have to be placed close together they cannot be kept far away okay so it's it's kind of a directive for the optimization that do this keeping this in mind yes there are timing assertions yes okay okay mother you have a question uh yes sir what's the difference between gate level simulation and test structure verification so gate level simulation would typically test only the functional modes okay test structure verification would typically test only the test modes i didn't get it so what's the difference what are the test modes and i mean uh let us look at it like this when i want to do a face recognition on an apple chip that is a function i will test that face recognition and i will say this is working fine or not however for for that particular chip i need to keep a memory which is let us say one kilo bit by uh you know one kilo words and 32 bits each word 1k cross 32 memory i need to pick during a functional mode i may not actually access every memory cell every memory location with both kind of data zero and one let us say so but this was just the test program that you wrote in reality when the customer face would actually come then the any bit can be zero and any bit can be one so for every memory you have to test every bit for both zero and one your test cases may not have everything when you when you're designing test cases only for the functional mode so you design a separate bist you add a built-in self-test into the overall system which would access the memory for every location and write zero and one on every location so that everything is tested now gate level simulation you don't run the best but in test structure verification you will test the best so now you're not changing the wireless model you're actually extracting the wire loads and putting that into the net list yes i'm changing the netlist from the no no again there is no model now now this is the real thing that you're putting back in there model was an estimate model was an extrapolation now this is the real thing you're putting real capacitance you're putting there okay yes between uh yeah sir so what you said about test structure verification you're testing every single possibility so is that um isn't that kind of expensive i mean you're testing it so you tell me if you have entered into a car you enter into a car which was tested only for good road conditions would you write so i mean you have to make test conditions which you know will accommodate to every type of yeah you know exactly so that is what test structure verification is but otherwise a gate level simulation is okay my car is starting fine it is receiving inputs from all the different sensors it is working fine that is gate level simulation uh so so for example when you're writing a computer code and you're testing it right so you will might have like a million different test cases but to accommodate each each function i mean you only you we need a limited number of test cases which test all the different possibilities so a test is a very very significant cost we will come to it we'll come to it later in this uh in the next section next lecture but test is a very significant cost you actually have to test it very exhaustively so if you are so even the gate level simulation you're testing for those test specifications you have given and then in test structure verification you are testing each possibility so what's the point of the previous step uh the point of the previous step is okay i just said that for memory you have a best there okay now i tested the memory with the best i know memory is functioning fine similarly i test the processor with its logic best all that logic is working fine do i not need to also test that the interface of memory and logic is working fine yeah yeah yes sir yeah so that is what is the purpose of gate level simulation that the functionality that you wanted you are getting that then s structure is each each component that you have put in itself is robust okay so gate level simulation is for the functionality and then test structure verification is you're going to find details that okay every single component is individually working fine yes okay okay so i have three people raising their hand mother divine so the question was once again related to test structure verification uh so in gates uh gate level simulation we know that uh our circuit has this particular function so with destructive verification we are basically pushing it to its limits and finding out if there is any error uh yes and no so in a gate level simulation i am connecting the processor and the memory and the all the different slaves of the processor and testing that everything as a system is working fine in test structure verification i am putting the best into question and saying that is my memory work only my memory working fine completely or not is my set of bank of flip flops working fine completely or not given whatever input set [Music] i want to build a car so at one point of time i tested that the car starts and it runs well okay and at another point of time i tested just the engine separately that it is giving me the horsepower that i require another test i'm testing only the tires that they are giving me the kind of uh grip that i require so one thing was system level testing the other thing is doing tests specific to the engine so that i am sure that engine will work even at minus 40 degree celsius and even at once 125 degree celsius uh separate modules are being tested yes so one thing is more about module level testing and ensuring that every module is well tested okay it also has some system level tests but gate level simulation is more about functional testing okay that all the required functionality is in there it's built in there so once you have that once you do then finally you do the atpg automatic test pattern generation and you release the stuff to the foundry but okay all my tests all my timings everything is closed my power is within the budget everything is fine please fabricate it okay and i tell you each block over here is a kind of an independent job in industry each of these blocks is an independent job now it may happen that there is a team that does all these five things so there are people who are doing all these five things that in one project or another so they get to get exposed to all these five things but uh it could also be in a particular case that one person is doing only this or this sti karaoke post layout stf that is the only thing he is doing that can also happen so each one each one of these is a specialized domain so orange yellow and green could be different teams or they could be actually independent jobs each block would be an independent job profile okay so i think we should stop here we will go to the abstraction levels in the next class okay any any pending questions that you forgot to ask so i have one so this after uh the yellow row uh so mostly still we i have not gone to the physical level we are still at the logical level yeah so but yes sir so but like in this after the starting time analysis you have connected it to the sdf rc and cap so what is that so sdf rc and cap are inputs from after the layout has been made back into static timing analysis okay so it's going the other way around not yet so anything else so what kind of checks are done during pre-layout technology during pre-layout technology tech street layout technology takes as i mentioned that okay uh even at the gate level net list my the load of any one of my gates is not greater than 220 fahrenheit that is kind of a pre-layout you don't even need to know the layout update you know that every gate has some input or capacitance so depending on what the fan out that you have connected you can estimate the overall load on any particular gate so these are like free layout technology checks quick estimates because if you need to do some buffering you do it right away so that the netlist already has it and then you release it to the layout okay,https://www.youtube.com/watch?v=S7091-SZPFk,"Link: https://www.youtube.com/watch?v=S7091-SZPFk
Transcript: give me a second i will pause the recording and i will come back again just give me a minute so once we have this you know good overview of how a chip starts from a requirement analysis to finally shipping we enter into this detail of how does the design implementation happen okay so the first stage of the design implementation is initial design entry where you say that okay i need this kind of memory i need this kind of a processor i need this kind of interfaces ddrs and so on and then you do a design entry this design entry is an rtl okay you write a verilog code and that is rtl once you've done the design entry you need to verify that this design is meeting the functionality that you wanted it to meet so do you simulate the rtl and do a quick power analysis that the power budget is also within the you know specified range after that is done you do the logic synthesis now what what do you understand about logic synthesis there was already a question earlier about logic synthesis and layout so what do you understand by logic synthesis it is mapping our uh rtl code to the gate gate level net list [Music] so it is converting an rtl verilog netlist into a gate level net list that okay you just said an adder but an adder is implemented by using these kind of ands and rs and xor gates okay so that implementation is synthesis after the logic synthesis is done you do test and clock synthesis what do you think test and clock synthesis entails uh sir so like uh when we test our code like when we're stimulating so you know you're using a clock signal that you have provided but to actually generate a clock which will run in that system you need to do a block system as well right okay i mean it should uh run at 2.5 megahertz so yeah so let us look at it like this in the logic synthesis you said you will put 1 million flip flops on your chip and for every flip flop you simply put the clock pin am i right in reality clock will be generated by some pll somewhere or you will get it from outside your chip so there is one point on the chip there you will have the clock generated and do you think that one point can drive all the one million flip flops no so we have dog buffers right i mean so you have to now arrange and organize these flip flops in a particular way that okay these ten flip flops this buffer would drive these ten flip flops another buffer would drive so this part of inserting clock buffers so that none of the clock pins or none of the clock signals nodes has a load more than let us say 100 front of arrows additionally you know all the matched clock nodes uh clock ends arrive at almost the same delay so if if there is one flip flop and another flip flop which was supposed to work simultaneously it should not happen that because i put 10 buffers in one path and five in the other path one swap operated much faster than much earlier than the other one so if they were expected to operate synchronously and simultaneously i have to put 10 buffers on both the paths so this is clock synthesis similarly as we talked about you know initial functional specification and testification we look at test synthesis that as to how will i make those scan chains how will i test the entire chip once it is fabricated so at this early stage itself when when you just add the logic synthesis stage or just right after that you start to also do the test synthesis you start to insert some test features also rather you have a question yes sir sir in this clock synthesis are you referring to the clock tree synthesis yes and so one more thing so like after the design entry you have mentioned the power analysis so but design entry is in the rtl form so we still don't have a kind of uh the components that will be involved so what kind of power analysis that they're doing here like how would we know that what kind of power can be considered let us say i i said that i will use a memory somewhere okay and i have not gated the access to the memory so memory every clock cycle memory is being accessed i know that a memory will consume more power i have models for memory also so in that case then what we see is in that case what we see is that your system will show that the power consumption is high that you need to do power gating at some places to reduce overall power consumption so you can change your rtl so that clock dating happens and memory is not accessed every cycle it is only fs when needed so but my question is like rtl at the rt level we still have we are having only a behavior model so like yeah but you okay so it is not just behavioral model so the models that you have you know the very long models that you have many times they are also associated with uh some top-level information on power consumption and timings okay okay like apart from the net list also yes okay so okay um so so it's a about you know designing a chair so uh it could be an asic it could be a assp it could be anything it could be a standard product all together a commodity product not even an asic and not even an assp it is a standard chip anything so you know the difference between asics and asses and standard yes yes i mean i i don't know what you're referring to by standard chips like for example uh atmel uh atmel 32 processor is a standard chip it is available off the shelf anyone can come to the market and purchase it stm32 is a standard chip anyone can come it is not defined or prepared for a particular application whereas for example corus is a product from st which is a specific chip for automotive industry but it is again standard it was not made specifically for bosch it was not made specifically for rolls-royce it was just made so that any user any um car manufacturer can use it okay so you're saying that uh it's like programmable it can be programmed as to the needs of the customer what about programming no no it is not just about programming it is about application for example stm32 is a standard product it could be used across any application whether you use it in a car you can use stm32 whether you use it in your alexa you can use an stm32 whether it is google home you can use stm32 any application can use stm32 even your smartwatch can use stm32 okay so any range of applications it could be automotive it could even be a satellite it could be using stm32 so it is off the shelf available standard product however when i'm talking about let us say an automotive specific product then that product is designed for a particular use inside cars only for example tire tire pressure monitoring sensor yes now tpms you will not use in your watch will you no it will only be used in automotive sector but it is not designed specifically for bosch it is a standard product so it is application specific standard product assp so but like the features are somewhat to save right i mean okay you can you can only do these amount of things in this ship i mean and those those amount of operations can be used in a car or in a watch or anywhere but it's still fixed you cannot you cannot change it you cannot like uh it's not steel programmable like fpga yeah for example uh so that is that there are multiple flavors of let us say stm32 some flavors would have one kilobyte of non-volatile memory some flavors would have 32 kilobytes some would have one megabit okay so that will limit what all you can store and what all so that would change stuff but otherwise it is stm32 to the standard product okay right okay but assp is application specific standard product now tire pressure monitoring sensor is a tire pressure monitoring sensor only any tire can use it but it is specific to tire pressure monitoring yes and then there would be specific chips for example uh there will be a chip that tesla orders which says that i want a chip for car vision so that i can go into uh self-driving cars okay i want to use this particular algorithm so that it is most efficient for my purposes now that chip is an application specific ic yes it is made specifically for one customer it is much costlier for that customer but customer may still want it for the competitive advantage yes object synthesis again logic synthesis okay i will do that yes is it a microcontroller yes stem cell it was a microcontroller yes okay so uh pressure yes logic synthesis involves uh so rtl would say that okay uh move data from resistor r1 to r2 add r1 plus r2 whatever something like this but how would you move data you need to have some buffer somewhere yes sir how do you add two numbers you need to have that propagate and generate thing coming in you will have to have something coming in to add two numbers yes sir so what would those gates be [Music] so rtl is almost like english language but finally silicon cannot understand english silicon would understand only some transistor language now okay so so we don't even go to understand language when you do logic synthesis we go to gate language so we come to arrive at a gate level net list we say that okay after this nand gate we will put an or gate and when these two nand gates outputs connect on this or gate inputs the output of this or gate is going to be a plus b that a plus b i need to now write into that so we'll convert all those melee machines and more machines and everything that is what is logic synthesis so implementing your english language or a program code into a gate level net list is it clearer yes sir so you do this logic synthesis then you do 10 synthesis once all that is done you know what kind of circuits and what is the total number of cells you need to put on your device you enter into a state which is called as float planning as to where would you put your processor where would you put your memory where would you put different parts of your chip okay i want the memory to be as close to the processor so that there is no delay in accessing the memory one could say that someone would say that i would want to put the pll on this corner of the shift so that it does not encounter any noise someone would say i want to put adc on this place so that is float planning you basically building a plan of how you would lay out your chip finally consider it like if you have to build a residential complex you need to plan where the five towers or residential towers have to be where the swimming pool has to be where the clubhouse has to be and so on so that is what is like float planning and after the while the floor planning is done you also do stuff like our estimation static timing analysis gate level synthesis and so on gate level simulation and so on so what does static timing analysis entail who will tell so this is you know that flip flops would have some setup time some hold time something so when the clock arrives the data should be set up so whether that is happening or not do you need to add some delay somewhere so it is largely timing verification timing characterization gate level simulation is once i've removed the english from a plus b and i've actually put an adder there after all that logic conversion is my net list still still operating the same way as i intended it to be okay then a structure verification is i wanted to have a scan chain built there i wanted to test different different components independently am i able to really test them then power estimation now sensitive actually you have real gates available there okay you have real gates available there you actually can estimate what kind of power consumption will happen and then you also check that okay or that there are two outputs driving one single node so or that there is some input that is floating or that there is a a load on a particular on a particular gate which it cannot even be able to hold so all these checks you do while you do these steps and as you complete these checks you also release your netlist which is now reasonably stable because it has met all these logical standards to the layout now you say ok this was where i wanted to put my tower one this was where i wanted to put my tower to now is the time to build the towers okay so now you will start to place the windows the walls and everything over there and you will and this is what you would be you this is the final shape of a residential complex and layout is essentially the final shape of your design so you start to put the layout of the and gate as to how it will appear on silicon you put the layout of the nor gate of the adder of everything of the memory so all those things you now start to put together and you now do timing driven layout optimization that okay the output of this and gate is going into this or gate so let me place this and gate and nor gate together okay so that is layout driven time timing driven layout optimizations once you have done that you again need to do static timing analysis because now where you now know the additional information of how long a wire is there between two different gates till now you only knew that this nand connects to that norm now you know that this when this man connects to that not there is also this longer wire in between them so the delays would change and you need to do a timing analysis all over again sir so i mean so the static timing analysis we did after the floor uh planning we were not we were not taking into account the routing today so you would use some model method there you would assume that okay most of the wires like you will use a statistical model based on your earlier analysis some other chips you had designed so you know that okay most of my wires were one micron in length and a few wires were 10 microns in length and very few wires were 100 microns in length so based on that you will statistically distribute those wire so this is called a wire load model you distribute those wire loads on some different places and you would do it but now you actually have the real wire length available with you okay okay so this is a more realistic analysis so you do sta all over again and you do post layout technology checks now that is drc clean as lvs clean is a uh is is every gate connected to a or every poly connected to a diode or a drain somewhere otherwise there could be uh you know antenna violations and the strip would fail after fabrication and all that stuff okay the the thing you said about if it's connected to the day in a diode was uh wasn't it a part of gate level simulation like you have diodes are not i would have no functionality per se so yeah how did we skip that in a game simulation because diode is not a gate what combinational logic does diode represent i mean it's just it just really acts as a switcher but like no you know the diodes that i am talking about here are so that due to fabrication there could be a lot of iron iron deposition on your polysilicon gates and you need to discharge them otherwise the gate breakdown will occur these are physical texts technology linked checks okay can you can you just elaborate on that for the little princess and we will look at that in more detail later but yeah so when you manufacture silicon you actually put very high energy uh you know uh how do i put it plasma onto your dies okay this can lead to a lot of charge buildup on your dice and that charge needs to be sunk into the substrate otherwise there can be dielectric breakdown somewhere because of very high voltage okay so every polysilicon gate needs to be connected to some drain or source some something like that so that that charge has a path to discharge this is not a part of logic synthesis at all rather you also wanted to ask something oh yes sir so this timing driven layout optimization are you is it a part of like the routing part like that yes placement uh place and route yes okay answer one more thing so this uh power estimation and the earlier power analysis that we've done just after design entry like uh estimation and analysis does have a different connotation or like does it have an accuracy it has a different connotation in the sense that when you did it the first time you you did not really have the exact numbers because you did not know the exact dates that would be used to implement your design you just saw that okay this processor is being accessed 2000 number of times can i reduce it somehow it was an architectural level thing so this memory is being accessed every cycle 
can i reduce the number of accesses to the memory okay okay okay so now you actually have the power consumption that happens in every cycle and now you're estimating it and now you can tell oh i still i i reduce it to 50 now i actually need to reduce it to 20 only okay so at the power estimation we are having the specific amount of power consumed every cycle like yeah because synthesis has happened now i know every device yes sir and so one more thing so that uh you have mentioned this uh clock synthesis before the flow planning generally enough flow we generally see that rocket and then the placement and uh uh planning for planning and the placement then we do the kind of this clock three synthesis but here you have put before you see synthesis synthesis uh would happen uh alongside floor planning actually so that is where the link is so test and clock synthesis leads to two things floor planning and this but you see that is a horizontal connector it could actually be happening in parallel also they feed into each other okay okay so can i just briefly explain this how these interconnections are made up between the different boxes you have made actually it's the beginning of it yeah so the ones for example static timing analysis gate level synthesis etcetera they're all running in parallel they do not so while sta has something to do with floor planning and other stuff gate level simulations has nothing to do with it so in the sta box i also show an entry of float planning but i do not show an entry of float planning into gate level sentences for example okay the output of sta goes for timing assertion it also goes for sds and rc and cap estimation and that information also come back to sda so that is also shown as an input there and an output there so uh if you look at if you look at these ones these are reverse loops that okay if after sta i realize that something is not working it means i will go back to this state i will redo the timing driven layout optimization okay if i notice that so when i release the netlist from here i also release timing assertions so that they can be used for timing driven layout optimization i release timing assertions to layout also so these are these are not just one way at least these ones over here they may not necessarily be one way routes there could be also both ways okay timing sessions are basically uh the adjustment of the timing we are doing after the sda so likewise if some gate is failing or not yes you may say that this this device is so far away from there that i need to put in some extra buffers in the other path okay or bring these two devices closer so that is the layout different timing optimization so yes action so so power estimation is done but before timing optimization as you can see in this alongside so you know sta is happening alongside sta and power estimation are happening in the parallel plane uh so sir i want to know that power in load and idle power also matters yes so so after uh like i can see that before releasing the phone found it there's no again power testing or something like when every optimization is done every kind of optimization there's no again power test or something yeah so what happens is uh you know when you actually go into chip designing you will notice that if you've done the you know gating and everything properly over here and you've done verification at gate level simulations and power estimation then after the layout not not really much would change buyers would change they will reflect into sta so you know as soon as you do this sdf and rf you again come back to this level so you do sta again you may you may want to do some other text of this place again that can happen but because there is some extra wire somewhere because of that power is not going to change from 1 milliwatt to 2 milliwatts it may go from 1 milliwatt to 1.01 milliwatts okay sir okay because some you had used some wire load model even initially and it's a fair you know based on a based on earlier products only it's not a random thing picked up from somewhere so many ics are have been designed till date that we have a fair amount of an idea that an ic of this complexity would use this kind of a wire load distribution so power estimation does not really change much after this stage okay sir because you already have the post layout library characterized now okay so what is a wireless model a wire load model okay so when i say that there are these many and gates and these many nand gates on a chip they need to be connected is it not should they be wires in between them these wires will lead to loading of your gates so what length of wire to assume between or what length of wire to assume at the output of a given given gate that is probabilistically set left corner so after you have finally designed your entire chip you will do a post layout extraction so you will see now finally what are my capacitances at different places and with those load capacitances now is my sta is my timing still correct or not if it is not you will go back to the sts stage and you will do a layout riddle and optimization all over again so there will be eco of some parts of your chip eco means engineering change order so some things you will need to change so that your delays and everything are still in that okay answer the block which represents a test structure verification is that connected to bfd and such things yes yes rather if you had a question your hand is raised uh yes sir so this uh can you just say there was a static time and recent timing assertion that so what's the difference here oh so static timing analysis said that okay before the layout i assume that there is some kind of a wire load on on between the two no in the between the two gates and i would say that this is what my uh timing is because i assumed some load now there could be some race conditions where the slack is very less so you will tell that oh i do not really have margins here so please do not increase the tap of this wire more than that so what do you what does that mean for the layout it means that these two cells have to be placed close together they cannot be kept far away okay so it's it's kind of a directive for the optimization that do this keeping this in mind yes there are timing assertions yes okay okay mother you have a question uh yes sir what's the difference between gate level simulation and test structure verification so gate level simulation would typically test only the functional modes okay test structure verification would typically test only the test modes i didn't get it so what's the difference what are the test modes and i mean uh let us look at it like this when i want to do a face recognition on an apple chip that is a function i will test that face recognition and i will say this is working fine or not however for for that particular chip i need to keep a memory which is let us say one kilo bit by uh you know one kilo words and 32 bits each word 1k cross 32 memory i need to pick during a functional mode i may not actually access every memory cell every memory location with both kind of data zero and one let us say so but this was just the test program that you wrote in reality when the customer face would actually come then the any bit can be zero and any bit can be one so for every memory you have to test every bit for both zero and one your test cases may not have everything when you when you're designing test cases only for the functional mode so you design a separate bist you add a built-in self-test into the overall system which would access the memory for every location and write zero and one on every location so that everything is tested now gate level simulation you don't run the best but in test structure verification you will test the best so now you're not changing the wireless model you're actually extracting the wire loads and putting that into the net list yes i'm changing the netlist from the no no again there is no model now now this is the real thing that you're putting back in there model was an estimate model was an extrapolation now this is the real thing you're putting real capacitance you're putting there okay yes between uh yeah sir so what you said about test structure verification you're testing every single possibility so is that um isn't that kind of expensive i mean you're testing it so you tell me if you have entered into a car you enter into a car which was tested only for good road conditions would you write so i mean you have to make test conditions which you know will accommodate to every type of yeah you know exactly so that is what test structure verification is but otherwise a gate level simulation is okay my car is starting fine it is receiving inputs from all the different sensors it is working fine that is gate level simulation uh so so for example when you're writing a computer code and you're testing it right so you will might have like a million different test cases but to accommodate each each function i mean you only you we need a limited number of test cases which test all the different possibilities so a test is a very very significant cost we will come to it we'll come to it later in this uh in the next section next lecture but test is a very significant cost you actually have to test it very exhaustively so if you are so even the gate level simulation you're testing for those test specifications you have given and then in test structure verification you are testing each possibility so what's the point of the previous step uh the point of the previous step is okay i just said that for memory you have a best there okay now i tested the memory with the best i know memory is functioning fine similarly i test the processor with its logic best all that logic is working fine do i not need to also test that the interface of memory and logic is working fine yeah yeah yes sir yeah so that is what is the purpose of gate level simulation that the functionality that you wanted you are getting that then s structure is each each component that you have put in itself is robust okay so gate level simulation is for the functionality and then test structure verification is you're going to find details that okay every single component is individually working fine yes okay okay so i have three people raising their hand mother divine so the question was once again related to test structure verification uh so in gates uh gate level simulation we know that uh our circuit has this particular function so with destructive verification we are basically pushing it to its limits and finding out if there is any error uh yes and no so in a gate level simulation i am connecting the processor and the memory and the all the different slaves of the processor and testing that everything as a system is working fine in test structure verification i am putting the best into question and saying that is my memory work only my memory working fine completely or not is my set of bank of flip flops working fine completely or not given whatever input set [Music] i want to build a car so at one point of time i tested that the car starts and it runs well okay and at another point of time i tested just the engine separately that it is giving me the horsepower that i require another test i'm testing only the tires that they are giving me the kind of uh grip that i require so one thing was system level testing the other thing is doing tests specific to the engine so that i am sure that engine will work even at minus 40 degree celsius and even at once 125 degree celsius uh separate modules are being tested yes so one thing is more about module level testing and ensuring that every module is well tested okay it also has some system level tests but gate level simulation is more about functional testing okay that all the required functionality is in there it's built in there so once you have that once you do then finally you do the atpg automatic test pattern generation and you release the stuff to the foundry but okay all my tests all my timings everything is closed my power is within the budget everything is fine please fabricate it okay and i tell you each block over here is a kind of an independent job in industry each of these blocks is an independent job now it may happen that there is a team that does all these five things so there are people who are doing all these five things that in one project or another so they get to get exposed to all these five things but uh it could also be in a particular case that one person is doing only this or this sti karaoke post layout stf that is the only thing he is doing that can also happen so each one each one of these is a specialized domain so orange yellow and green could be different teams or they could be actually independent jobs each block would be an independent job profile okay so i think we should stop here we will go to the abstraction levels in the next class okay any any pending questions that you forgot to ask so i have one so this after uh the yellow row uh so mostly still we i have not gone to the physical level we are still at the logical level yeah so but yes sir so but like in this after the starting time analysis you have connected it to the sdf rc and cap so what is that so sdf rc and cap are inputs from after the layout has been made back into static timing analysis okay so it's going the other way around not yet so anything else so what kind of checks are done during pre-layout technology during pre-layout technology tech street layout technology takes as i mentioned that okay uh even at the gate level net list my the load of any one of my gates is not greater than 220 fahrenheit that is kind of a pre-layout you don't even need to know the layout update you know that every gate has some input or capacitance so depending on what the fan out that you have connected you can estimate the overall load on any particular gate so these are like free layout technology checks quick estimates because if you need to do some buffering you do it right away so that the netlist already has it and then you release it to the layout okay"
rq15h18pxbk,so we come back to the course so what were we doing in the last class what did we do look at the trip design flow with logarithmic design flow from requirement analysis to shipping to the customer and we looked at various stages of the design implementation phase where we saw that things have to be analyzed as they have to be uh simulated verified many times before you know even the layouts are made and after the layouts are made they are again verified again simulated and show that all the timing sign offs are fine and then we tape it out so this much we had done in the last class today we will start to look at a different abstraction of uh design flow where we are not really talking about uh entire chip we're talking more of more of it in terms of libraries this could be talked up talked about also in terms of chip but uh i'm i'm talking it in terms of libraries because while we are still having the specification phase here while we still have the behavioral understanding phase here and an rtl kind of a phase here what we also are saying is that we will go to circuit and layout stage okay so in terms of design level the language that is used for specification is common english behavioral description is typically a verilog code which is an executable program rtl is a sequential machine and a machine representation of the design that you are looking at you synthesize the rtl and you come to the stage of logic gates and those logic gates are actually implemented by using transistors and these transistors are actually implemented on silicon in the form of a layout which appears to be sets of rectangles overlapping you know one over another so that you can create transistors so in this particular course we will actually go from logic down to layout stage okay so what are the units in which we talk of when we talk of uh any level of abstraction so when when you are at the level of behavioral understanding or rtl you talk of it in terms of throughput and number of clock cycles taken when you go to logic you talk of how many inputs that is literals and uh logic depth okay how many number of stages are we talking about when you come to circuits you measure its efficacy in terms of speed in terms of nanoseconds power in terms of microwatts leakage in terms of microamperes or amperes and so on okay and layout you measure in terms of area in terms of microns or micron square yes uh so in the starting we said that we are now moving to a library view in the library design flow yeah yes so what exactly uh how is this like what do you mean by library here exactly okay libraries uh so okay you you know programming something you know so what is math.h so it's a header file that contain p processor it's already available to you you do not need to create it every time you write a c program do you no sir yeah so a library is something like that see when you're going for a soft design see last time there was a question key will we make so many millions of transistors by hand remember last time there was a question so no you don't really need to do that what is done is a library is created which is a collection of uh different views of different gates a different logic different implementations okay and then that is used by uh by the chip designer when they are designing the chips if we come back to the same example as we had about a residential complex then we said that floor planning is like defining which place would have which tower you remember that example that we discussed in the last class when we were talking about chip design flow yes sir where there would be a swimming pool and everything now let's say we're talking about building a tower so i'm talking about building a microprocessor microprocessor is one component that goes on that particular chip so this tower is one one such component that goes into this residential complex now come to think of this builder will he build will he start to make everything like from bricks onwards uh on the site or will he procure bricks from outside and simply start building the building so that is something like what we are talking about uh that for a standard for a sock designer uh for a system level designer he need not worry about how the bricks are built so we will give them gates and we will give them a library of gates so you will have bricks you will have windows you will have glass panes you will have those all these could be prefabricated and you can simply put them into your building as the structure builds up you know in the same manner we will already give you and gates nand gates a range of and or invert or r and invert gates adders multipliers and a whole range of such material which you can directly use as soon as you start your soc design so as an soc designer you need not worry about uh how how many layers i have put there or nothing you simply use these gates you're not really worried about exact layout of the transistors you're more worried about the logic part and the logic depth and so on okay okay so these are these dot dot lift files that the fast dot live or the slow dot left that we use to while doing kind of doing the love by converting from rtl to netlist no so dot lip files are simply characterization of these gates that we have designed the library that we have designed okay dot lib file is simply a characterization we'll just come to that don't worry in the next slide we will look at that also but uh library library is a collection so uh i would say look at it like a constellation of various cells our zodiac is a collection of twelve constellations from these two pisces okay similarly a library would be a collection of various functionalities which is which is available in one group each of these constellations each of these say aries or pisces will have their own set of stars and will and and can have their own impact on human behavior you know that is what astrology is all about whether you believe it or not that's good so i believe there is someone who believes in it and this is what they are saying so each of these libraries each of these cells whether it is an and cell or an and cell or a adder or whatever they have their own behavior they have their own characteristics so that characteristic and that behavior is encapsulated or described in the dot lip files rather yes sir okay but that that dot lift file is not the library the library is that zodiac which includes all the 12 uh stuffs okay okay so it's uh the dotted file is basically a subset of that yes okay small subset okay okay okay okay anything else so one more thing so in this uh can you also throw some light on this design time and the logic depth at the behavior and the logic level uh so if you do the computer architecture course you will get that idea don't worry okay okay so so logic depth is how many status in one particular pipeline stage how many how many stages of logic go in every pipeline stage design time is about how quickly you can design something or what time does it take to execute the program on your you know the number of clock cycles and all that so that that is that is in computer architecture course that you will get the handle on okay okay okay can i lower your hand raga sir sure uh what would decide behavior i'm sorry moan i miss what exactly is throughput throughput means how many how many instructions you can execute per cycle or per second again computer architecture this is the higher so in this course dvd courses is let us say here onwards and what you're talking about over here is ca what we did in the last class was covered in well well the entire flow would be covered in the vdf course is that okay doughnut if you have a question yes sir behavioral it is high level synthesis so behave that is uh just that instead of writing your behavioral code in very long you've written that in c or c plus plus and then from c to c plus plus you go towards the rtl phase by using high level synthesis flow okay yes okay so we move forward if you've not yet started dvd actually we're just talking about what is around dvd but it's important because you should know where we are it's important to have the overall context would be automated like you have a circuit design and a floor plan can it be automated so floor plan uh at the rt at the stock level is already automated uh when we talk of uh when we talk of floor plan or layout design at standard cell level you can automate it but it can lead to area loss because automation can lead to some loss of area and therefore we would want to avoid that area is so i have not yet used this thing over here in this class but in vlsi area is gold so we don't want to lose gold so typically we would design layouts by hands in this course definitely you will design them by hand but yes you can automate them but those libraries are not usually dense enough at least the automation has not reach that level of ns that they can match human design but with more and more constricting drc's coming into picture probably we will get very good layouts even by automation akash you have a question yes sir actually in the refresher module we have studied very long in which we have implemented this like behavior level uh suppose uh we have implemented full adder using behavior level then converted into in this synthesizable level so how could we relate this very log to computer architecture so uh verilog is you just look are looking at an adder part of it so you are not able to relate it but when you look at a processor a processor would have adder it would have a lot of other combinational blocks it would have a complete alu in itself is it not yes so that also you would write in the behavioral description and that is what you will cover in ca i am not saying that ca is going to teach you very log what i am saying is the concept of throughput and design time or function unit and clock cycles is being covered in the ca course that is where you talk about sequential machines and executable programs and so on verilog doesn't mean uh you're always just behavioral or whether it doesn't mean that it is being taught in c no ca will not teach you very long okay okay see a very long you have to learn yourself you have a question uh yes sir so what do you mean but i mean i don't understand why layout is in a lower level than circuit i mean uh what so what here what are we what do we exactly mean by layout because uh i'm sorry as we go lower and lower we are coming very close to silicon technology okay so circuit is a schematic that you have in p spice even if you're not done you know virtuoso schematic you would have done piece 5 schematics earlier i think all of you have already used virtuoso by now am i right yeah so that is just a schematic uh you you what do you do in a schematic you simply create a rectangle or a symbol like this and say this is a pmos but if you cannot draw this on silicon and say for silicon you need to have a layout view where this would be the polysilicon gate and one of this will be source the other part will be drained right okay so this is much closer to silicon this you can actually implement on silicon this you cannot so by layout we mean the actual implementation on hardware no my layout we mean a set of tad layers which if you convert them into masks you can implement this particular functionality that you have specified on the silicon onto hardware so there is an entire fabrication process that is that has to happen after that also right right okay so yeah layout is basic so we can implement those circuits uh with the help of masks on those silicon vehicles yes we will fabricate not implement we'll fabricate fabricate is the correct product right uh and one more question when we when we say function units we mean something like at the abstraction level of say an adder or something like that and then logic is basically a disorder gate and the and gate you use yeah so when you're talking about function unit you may talk about uh 1000 max multiply and accumulate msc units yeah yeah good good okay so shakti is asking should we do verification after each step of design abstraction yes whenever you're doing a handoff to a different team you have to verify your stuff it may actually be a different team working on the on the different abstraction so before you hand off from your team to the other team you have to verify there is no two ways about it is that okay yes sir yes sir ranjit here so i have a doubt sir when we look at the top level specification and we look at the design we follow this top top-down approach we first look at the specification design the behavior and model and synthesize to rtl and so on but when we look at the prerequisites for each and every design abstraction suppose we we take the case of a circuit so for that uh the layout is prerequisite or if we take a logic design then layout is not a prerequisite you design a circuit and after you ensure that the circuit is fine then you go to the layout phase so suppose if we take the abstraction of logic suppose if we want to uh design a nand gate then we need the uh transistors so this is this way like this would be we will come to that detailed level of description in the next slide would you want to wait till then uh yes sir i can wait from logic to layout you're coming in the next slide yeah yeah thank you sir,https://www.youtube.com/watch?v=rq15h18pxbk,"Link: https://www.youtube.com/watch?v=rq15h18pxbk
Transcript: so we come back to the course so what were we doing in the last class what did we do look at the trip design flow with logarithmic design flow from requirement analysis to shipping to the customer and we looked at various stages of the design implementation phase where we saw that things have to be analyzed as they have to be uh simulated verified many times before you know even the layouts are made and after the layouts are made they are again verified again simulated and show that all the timing sign offs are fine and then we tape it out so this much we had done in the last class today we will start to look at a different abstraction of uh design flow where we are not really talking about uh entire chip we're talking more of more of it in terms of libraries this could be talked up talked about also in terms of chip but uh i'm i'm talking it in terms of libraries because while we are still having the specification phase here while we still have the behavioral understanding phase here and an rtl kind of a phase here what we also are saying is that we will go to circuit and layout stage okay so in terms of design level the language that is used for specification is common english behavioral description is typically a verilog code which is an executable program rtl is a sequential machine and a machine representation of the design that you are looking at you synthesize the rtl and you come to the stage of logic gates and those logic gates are actually implemented by using transistors and these transistors are actually implemented on silicon in the form of a layout which appears to be sets of rectangles overlapping you know one over another so that you can create transistors so in this particular course we will actually go from logic down to layout stage okay so what are the units in which we talk of when we talk of uh any level of abstraction so when when you are at the level of behavioral understanding or rtl you talk of it in terms of throughput and number of clock cycles taken when you go to logic you talk of how many inputs that is literals and uh logic depth okay how many number of stages are we talking about when you come to circuits you measure its efficacy in terms of speed in terms of nanoseconds power in terms of microwatts leakage in terms of microamperes or amperes and so on okay and layout you measure in terms of area in terms of microns or micron square yes uh so in the starting we said that we are now moving to a library view in the library design flow yeah yes so what exactly uh how is this like what do you mean by library here exactly okay libraries uh so okay you you know programming something you know so what is math.h so it's a header file that contain p processor it's already available to you you do not need to create it every time you write a c program do you no sir yeah so a library is something like that see when you're going for a soft design see last time there was a question key will we make so many millions of transistors by hand remember last time there was a question so no you don't really need to do that what is done is a library is created which is a collection of uh different views of different gates a different logic different implementations okay and then that is used by uh by the chip designer when they are designing the chips if we come back to the same example as we had about a residential complex then we said that floor planning is like defining which place would have which tower you remember that example that we discussed in the last class when we were talking about chip design flow yes sir where there would be a swimming pool and everything now let's say we're talking about building a tower so i'm talking about building a microprocessor microprocessor is one component that goes on that particular chip so this tower is one one such component that goes into this residential complex now come to think of this builder will he build will he start to make everything like from bricks onwards uh on the site or will he procure bricks from outside and simply start building the building so that is something like what we are talking about uh that for a standard for a sock designer uh for a system level designer he need not worry about how the bricks are built so we will give them gates and we will give them a library of gates so you will have bricks you will have windows you will have glass panes you will have those all these could be prefabricated and you can simply put them into your building as the structure builds up you know in the same manner we will already give you and gates nand gates a range of and or invert or r and invert gates adders multipliers and a whole range of such material which you can directly use as soon as you start your soc design so as an soc designer you need not worry about uh how how many layers i have put there or nothing you simply use these gates you're not really worried about exact layout of the transistors you're more worried about the logic part and the logic depth and so on okay okay so these are these dot dot lift files that the fast dot live or the slow dot left that we use to while doing kind of doing the love by converting from rtl to netlist no so dot lip files are simply characterization of these gates that we have designed the library that we have designed okay dot lib file is simply a characterization we'll just come to that don't worry in the next slide we will look at that also but uh library library is a collection so uh i would say look at it like a constellation of various cells our zodiac is a collection of twelve constellations from these two pisces okay similarly a library would be a collection of various functionalities which is which is available in one group each of these constellations each of these say aries or pisces will have their own set of stars and will and and can have their own impact on human behavior you know that is what astrology is all about whether you believe it or not that's good so i believe there is someone who believes in it and this is what they are saying so each of these libraries each of these cells whether it is an and cell or an and cell or a adder or whatever they have their own behavior they have their own characteristics so that characteristic and that behavior is encapsulated or described in the dot lip files rather yes sir okay but that that dot lift file is not the library the library is that zodiac which includes all the 12 uh stuffs okay okay so it's uh the dotted file is basically a subset of that yes okay small subset okay okay okay okay anything else so one more thing so in this uh can you also throw some light on this design time and the logic depth at the behavior and the logic level uh so if you do the computer architecture course you will get that idea don't worry okay okay so so logic depth is how many status in one particular pipeline stage how many how many stages of logic go in every pipeline stage design time is about how quickly you can design something or what time does it take to execute the program on your you know the number of clock cycles and all that so that that is that is in computer architecture course that you will get the handle on okay okay okay can i lower your hand raga sir sure uh what would decide behavior i'm sorry moan i miss what exactly is throughput throughput means how many how many instructions you can execute per cycle or per second again computer architecture this is the higher so in this course dvd courses is let us say here onwards and what you're talking about over here is ca what we did in the last class was covered in well well the entire flow would be covered in the vdf course is that okay doughnut if you have a question yes sir behavioral it is high level synthesis so behave that is uh just that instead of writing your behavioral code in very long you've written that in c or c plus plus and then from c to c plus plus you go towards the rtl phase by using high level synthesis flow okay yes okay so we move forward if you've not yet started dvd actually we're just talking about what is around dvd but it's important because you should know where we are it's important to have the overall context would be automated like you have a circuit design and a floor plan can it be automated so floor plan uh at the rt at the stock level is already automated uh when we talk of uh when we talk of floor plan or layout design at standard cell level you can automate it but it can lead to area loss because automation can lead to some loss of area and therefore we would want to avoid that area is so i have not yet used this thing over here in this class but in vlsi area is gold so we don't want to lose gold so typically we would design layouts by hands in this course definitely you will design them by hand but yes you can automate them but those libraries are not usually dense enough at least the automation has not reach that level of ns that they can match human design but with more and more constricting drc's coming into picture probably we will get very good layouts even by automation akash you have a question yes sir actually in the refresher module we have studied very long in which we have implemented this like behavior level uh suppose uh we have implemented full adder using behavior level then converted into in this synthesizable level so how could we relate this very log to computer architecture so uh verilog is you just look are looking at an adder part of it so you are not able to relate it but when you look at a processor a processor would have adder it would have a lot of other combinational blocks it would have a complete alu in itself is it not yes so that also you would write in the behavioral description and that is what you will cover in ca i am not saying that ca is going to teach you very log what i am saying is the concept of throughput and design time or function unit and clock cycles is being covered in the ca course that is where you talk about sequential machines and executable programs and so on verilog doesn't mean uh you're always just behavioral or whether it doesn't mean that it is being taught in c no ca will not teach you very long okay okay see a very long you have to learn yourself you have a question uh yes sir so what do you mean but i mean i don't understand why layout is in a lower level than circuit i mean uh what so what here what are we what do we exactly mean by layout because uh i'm sorry as we go lower and lower we are coming very close to silicon technology okay so circuit is a schematic that you have in p spice even if you're not done you know virtuoso schematic you would have done piece 5 schematics earlier i think all of you have already used virtuoso by now am i right yeah so that is just a schematic uh you you what do you do in a schematic you simply create a rectangle or a symbol like this and say this is a pmos but if you cannot draw this on silicon and say for silicon you need to have a layout view where this would be the polysilicon gate and one of this will be source the other part will be drained right okay so this is much closer to silicon this you can actually implement on silicon this you cannot so by layout we mean the actual implementation on hardware no my layout we mean a set of tad layers which if you convert them into masks you can implement this particular functionality that you have specified on the silicon onto hardware so there is an entire fabrication process that is that has to happen after that also right right okay so yeah layout is basic so we can implement those circuits uh with the help of masks on those silicon vehicles yes we will fabricate not implement we'll fabricate fabricate is the correct product right uh and one more question when we when we say function units we mean something like at the abstraction level of say an adder or something like that and then logic is basically a disorder gate and the and gate you use yeah so when you're talking about function unit you may talk about uh 1000 max multiply and accumulate msc units yeah yeah good good okay so shakti is asking should we do verification after each step of design abstraction yes whenever you're doing a handoff to a different team you have to verify your stuff it may actually be a different team working on the on the different abstraction so before you hand off from your team to the other team you have to verify there is no two ways about it is that okay yes sir yes sir ranjit here so i have a doubt sir when we look at the top level specification and we look at the design we follow this top top-down approach we first look at the specification design the behavior and model and synthesize to rtl and so on but when we look at the prerequisites for each and every design abstraction suppose we we take the case of a circuit so for that uh the layout is prerequisite or if we take a logic design then layout is not a prerequisite you design a circuit and after you ensure that the circuit is fine then you go to the layout phase so suppose if we take the abstraction of logic suppose if we want to uh design a nand gate then we need the uh transistors so this is this way like this would be we will come to that detailed level of description in the next slide would you want to wait till then uh yes sir i can wait from logic to layout you're coming in the next slide yeah yeah thank you sir"
A1aWZcz1Krk,to your tape out so the first thing you do is you do a schematic capture because you have an idea that i want to design a nand gate so you say a nand gate i will want to make like this a b a b and these are p masses this you must say is y okay so this is the schematic after you've made the schematic in the schematic capture you will analyze this how will you analyze this you will give different stimuli to a and b and you will see if your output is coming uh correctly or not that is simulation after you have verified that the schematic is working fine you know at least on the schematic level i am getting the the functionality that i wanted the kind of delays that i was targeting i am able to achieve them then you go to the layout you implement this in the form of a layout okay so you will design a few p masses you will design nmoses you will connect them so don't worry you will do all of this i will make you do all of this but yeah okay [Music] so this is the layout once you've made the layout you see that are all the design rule checks now what do you understand by design rules jack anyone uh so this talks about the set of rules that has to be followed in designing a particular layout yeah so look at it like this uh i ask you to draw two parallel lines on a sheet of paper as close to each other as possible without them even touching ever so you do realize that there is some the second line that i draw it went it went a little wavy because i was worried that it should not touch the first line so you do realize that if you have a kind of instrumentation i i did not use a scale but if i use a ruler i can probably draw them much a little bit still closer but then you know if the tip of my pencil is not sharp i will draw them a little farther away so there are so many instrumentation reasons because of which i cannot draw these two lines closer than a minimum spacing because if i try to do that then somewhere there is a possibility they will short with each other are you able to see this so this minimum spacing that we have to keep between any two rectangles that we just made here is called design rules check now these are design rules and we should not be violating any of these design rules otherwise when we fabricate on silicon there could be a loss of functionality somewhere so as you make the layout you also simultaneously do the design rules deck drc we call it drc okay then we do what is called as layout versus schematic check what is layout versus schematic check this check means that see i had this circuit in my mind and uh i am trying to implement a this circuit in a in a layout so i said this is ground this is vdd but it could happen that i have made some connection wrong somewhere so to verify that this layout actually represents the same the schematic that i had intended to draw to implement is called as layout versus schematic text okay so what did we do when we were going down from schematic to layout we would we did a verification what was the verification that i should run my simulation and see that my schematic is operating as it is expected to be and then once we have done the layout we again do a verification that this layout is in the same as representing the same functionality as the schematic wanted to so verification is not just done downwards it is also done backwards this you noticed even in the chip implementation flow last time where we said that once we have the post layout stuff we go back to the uh to the sts data and see that even after the post layout things are still fine you remember that so we do lots of two and four runs to ensure that things are as they were expected to be and this layout versus schematic is one such back and forth run is that okay any questions vaishnav you have a question yes sir so uh sir while uh while we are doing layout uh i mean like uh we can drag it in uh into anywhere like uh giving some space some area or more area so how do we area it's not what i meant exactly uh so uh i mean like we we can do we can do whatever we want uh avoiding the errors right said i'm like there are many possibilities that we come to a conclusion uh so my doubt is that uh how can we say that our model is much efficient so minimum area uh okay so i mean like yes sir would there be any kind of uh uh i mean like any kind of option that we can check our area in the in the uh so no no no that is not available you just draw and then the competition will tell that your area is good or bad suppose you join intel and you draw something or let us say you join synopsis and you make a layout then arm is also working on the same technology or st is also working on the same technology they will also be making their layouts yes some customers will come back to you and tell you your area is bad you don't want to use your library you will go with arm so it's it's like a already too late it's already too late when you get this information the customers are already lost okay so don't wait for that benchmark always strive to make a very dense layout as dense as possible okay yes sir thank you yeah you can lower your hand yeah so once the layout versus schematic thing is done then we do a what is called as a parasitic extraction see till the time we were in the schematic phase did you even talk about the capacitance of this wire a and how this wire a capacitance is coupling with the output no you could make something but usually you would not do you simply say a is an input and y is the output but over here when you make this layout you see that there is an input a coming over here there would be some metal over here which is we're running very close to my output so there is bound to be some capacitance i need to extract that capacitance and see its impact on my results so that is the next step after the lvs is done we go to the step of parasitic extraction so all the parasitic resistances and capacitances can be extracted and okay in this course we will not look into these two aspects okay but we will after parasitic extraction go to post layout circuit analysis those two aspects are valid when we are talking about circuits like ios where package you know what kind of package is being used also comes into picture and uh ios being analog in in their characteristic uh the substrate coupling extractor also becomes big in this course since we are going to work on digital circuits so substrate noise and package model thing do not really bother us in this course okay these are separate independent job profiles the package model extraction and and verification this is a separate job profile in itself we will not be covering it in this course and once you've done the post layout circuit analysis you know check that the delays are in line with my specification even after these extra parasitics have come into picture that is when we say that my circuit is complete i can go ahead for a tape out okay there's a question yes yes sir what do we exactly mean by substrate so substrate coupling is uh let us say i have a processor over here on one side and there's a let us say this is a picture i have a processor over here and let us say there is a pll over here somewhere now since this is the same chip they are sharing the same substrate now if the processor is operating at let us say 2 gigahertz there will be some currents which will flow into the substrate those currents have to be sunk somewhere there is a very high probability that the noise injected by this processor will impact the functionality of this ell so when you are designing that pll you have to see that there is no substrate noise or even if there is a presence of substrate noise your circuit should work well even after that right so it's like you know source to body capacitance and so we're taking account for that uh yes because social body junction capacitance will always exist junctions would toggle so there would be some current in the source and that can lead to noise for the other circuits which could be sensitive to that noise in this course since we are looking at digital circuits only such noise is not really bothersome for us right okay and how do we how do we solve these problems okay so we use uh we use uh things like guard rings so guard rings are uh so if let us say this is your nand gate let us say this is an analog circuit so what i will do is around this analog circuit i will make a ring a ring or substrate connection okay so if there is any noise coming from anywhere else because this ring has all bdd substrate connections and ground substrate connections in it this ring will sync that current it will not let that current spoil the behavior of the transistors enclosed within it okay okay okay there is another technique which we call as deep and well or triple well technology will not look into that just yet but there are many methods as at a designer level if you want to do something you can work with either triple uh triple wells or with guard rings guard rings are more appropriate when you do not want to lose area you know when it is when the circuit when these circuits have to be placed really close together then guard rings are denser right okay but it wasn't the problem you know that uh the current was flowing into the substrate so like uh yeah so how it so the god if the guard ring is also a substrate yeah yeah but it is giving it a power supply now the ring is fully connected to vdds or gnds or whatever is a substrate supply very richly connected so no noise from the analog circuit can go to the digital side nor from the digital circuit come to the analog side because there is such huge sync such good connectivity to substrate power in this gathering yeah okay so we move forward any other questions oh one more you know when we are in the drc uh step we can check the minimum drift and area of the we could check the minimum width and area of the poly and all other things so by that can we not make the area of the layout minimum yes that is the minimum that is the way see uh vaishnava was saying that you have such a big field draw your devices anywhere why will you anyone ever face an error i said yes you will never face an error but then you will lose area so you design minimum area at minimum drc and go ahead okay yes sir so if we get to know about this parasitic capacitances then how will it affect our circuit and how we'll get rid of them oh you tell me if there is an rc in a in a circuit what happens it's extra delay yes so that is how it will affect the circuit your targeted timing but there is a capacitance there so the timing changes to 550 picoseconds yes sir and then how how will resolve this issue we will increase the width of the devices so that this extra capacitance can also be you know handled okay okay thank you yeah and then it was in this is that is that what happens yes so in the post layout circuit analysis all the resistances and capacitances that are parasitically present in your net list would be embedded into the design and then you simulate again so your design would actually have this capacitance there it will have a capacitance from b to output it will have a capacitance from b to this internal node you will have a capacitance from a to this internal node and so on so post layout netlist will have all the capacitances in picture and then we will simulate it it will also have some resistance between ground and and you know your nmos there okay yes there we are good afternoon sir uh basically i want to know what we are exactly doing parasitic extraction i don't get it so do you realize that when you will make the wires to make these connections between a and the gates of the two transistors and so on these wires will have some some capacitance of theirs yeah these wires are metal plates so when there are some capacitance there would you not want to see the impact of that capacitance on circuit behavior so the first step to see their impact on circuit behavior is to measure or estimate the value of this capacitance yeah that is what parasitic extraction step does okay so uh will it create any issue or not type no we do not even know that parasitic extraction step only estimates the various capacitances whether it is creating an issue or not we check that in the post layout circuit analysis okay so so yes yes so the temperature factor is also uh checked in post checks yes has to be um because estimating temperature cannot be is it possible by looking at the previous models so you can say that my circuit has a functional specification to operate fine between 125 degree celsius and minus 40 degree celsius okay so you have the specification you you've taken that specification range okay sir sir am i audible yes akash as you mentioned already so vaishnav already had his hand raised if it's not linked to what akshay just so as you have mentioned we considered the effect of passive capacity extraction in the post layout circuit analysis so after considering if we see that there is some effect then we again go to previous step and consider this effect before typing it out yes then we go back to the circuit state schematic stage we say that i want to increase the size of this particular nmos because the output capacitance is very large the nmr size that i have put yet will not be able to drive sufficient current and give me the timing that i am looking for so i increase the size in the schematic i then change the layout i then change the i then again do drc lvs again extract and then resimulate entire loop has to be done again sir uh yes sir so sir uh when we get to know about the parasitic extraction uh then are we uh connecting these capacitors manually by ourselves in layout again or would there be any kind of option for us to check this parasitic extraction after lvs see in the layout you made those wires already so those parasitics are already there you don't need to do anything else they're already there they're parasitic they're not to be designed they're parasitics they just appear are there parasites parasites okay so uh then uh why don't these uh and i mean like show up in design role check and layout for this schematic uh i mean like uh during those even these parenthesis uh parasitics are present right sir yeah so i mean like the outputs which we get are included with these parasitic extractions or or i mean like are they excluded with this parasitic extension so output of what output of design rule check yes sir no design rule check is a different tool altogether you do design rules check with calibre uh and you do parasitic extraction with a different tool let us say rc extract okay okay sir so after layout uh now if we check the output i'm like in any output for example you have done a cmos inverter over in our refresher so uh after layout uh i mean like if we uh if we take the output so the output would be with respect to paracetamol the output we get would be including the parasitic extractions or unlike the capacitance included it will include if you have done the extraction and embedded the capacitances into your netlist if you're doing the post layout circuit analysis it will include you made the layout left it there and then you're redoing the simulation of the schematic again then no change so sir then i mean we have already got our output so then why are we doing this parasitic extraction again sir uh i'm let we already know uh unlike uh at which time our circuit is getting um work and at which time it's getting turned off so first tell me one thing tell me one thing in the first schematic that you made are you sure how much is the wire capacitance uh no sir i'm not sure but otherwise you cannot put that capacitance or even if you have put that capacitance could be wrong uh but the output which we get would be included of this capacitance that i mean to be able to get that output you have to do a parasitic extraction so how will you estimate the capacitance the layout is simply rectangles yes sir the layout is simply rectangle rectangles don't tell you anything yes sir but output which we get at layout is simply rectangles no it has some rectangles and layout assembly rectangles for supposing we we give this a four called easy wave and we we get to know this way uh waveform analysis so you will go through the entire flow again don't worry so you will see that drc is a separate step and parasitic extraction is a separate step if you do not do parasitic extraction and only do let us say until lvs okay then you will not be able to add these extra capacitances in your net list you will never be able to see the impact of those capacitances on your circuit behavior okay we just want to know the effect of this specifically on the circuit yes okay okay i'm like now i understand i was thinking only about that i was only concerned about the output but not about this exact index effect of key capacity look at it like this without these capacitances the delay could be 500 pico seconds and that could be well within your specification as soon as these capacitances come you need to increase the your delay increases to 550 picoseconds which could be out of your specification so what do you do akash is asking this in the chat window also what do you do i said you increase the size of your nmos and your pmos so that it can now sync more current when you increase the size of your nmos and pmos what does it do it increases the drive capability of these devices so they can now sync or provide more current so that extra current can discharge this extra capacitor also within the stipulated time that is why you will still you will come back within the specifications okay does that solve your,https://www.youtube.com/watch?v=A1aWZcz1Krk,"Link: https://www.youtube.com/watch?v=A1aWZcz1Krk
Transcript: to your tape out so the first thing you do is you do a schematic capture because you have an idea that i want to design a nand gate so you say a nand gate i will want to make like this a b a b and these are p masses this you must say is y okay so this is the schematic after you've made the schematic in the schematic capture you will analyze this how will you analyze this you will give different stimuli to a and b and you will see if your output is coming uh correctly or not that is simulation after you have verified that the schematic is working fine you know at least on the schematic level i am getting the the functionality that i wanted the kind of delays that i was targeting i am able to achieve them then you go to the layout you implement this in the form of a layout okay so you will design a few p masses you will design nmoses you will connect them so don't worry you will do all of this i will make you do all of this but yeah okay [Music] so this is the layout once you've made the layout you see that are all the design rule checks now what do you understand by design rules jack anyone uh so this talks about the set of rules that has to be followed in designing a particular layout yeah so look at it like this uh i ask you to draw two parallel lines on a sheet of paper as close to each other as possible without them even touching ever so you do realize that there is some the second line that i draw it went it went a little wavy because i was worried that it should not touch the first line so you do realize that if you have a kind of instrumentation i i did not use a scale but if i use a ruler i can probably draw them much a little bit still closer but then you know if the tip of my pencil is not sharp i will draw them a little farther away so there are so many instrumentation reasons because of which i cannot draw these two lines closer than a minimum spacing because if i try to do that then somewhere there is a possibility they will short with each other are you able to see this so this minimum spacing that we have to keep between any two rectangles that we just made here is called design rules check now these are design rules and we should not be violating any of these design rules otherwise when we fabricate on silicon there could be a loss of functionality somewhere so as you make the layout you also simultaneously do the design rules deck drc we call it drc okay then we do what is called as layout versus schematic check what is layout versus schematic check this check means that see i had this circuit in my mind and uh i am trying to implement a this circuit in a in a layout so i said this is ground this is vdd but it could happen that i have made some connection wrong somewhere so to verify that this layout actually represents the same the schematic that i had intended to draw to implement is called as layout versus schematic text okay so what did we do when we were going down from schematic to layout we would we did a verification what was the verification that i should run my simulation and see that my schematic is operating as it is expected to be and then once we have done the layout we again do a verification that this layout is in the same as representing the same functionality as the schematic wanted to so verification is not just done downwards it is also done backwards this you noticed even in the chip implementation flow last time where we said that once we have the post layout stuff we go back to the uh to the sts data and see that even after the post layout things are still fine you remember that so we do lots of two and four runs to ensure that things are as they were expected to be and this layout versus schematic is one such back and forth run is that okay any questions vaishnav you have a question yes sir so uh sir while uh while we are doing layout uh i mean like uh we can drag it in uh into anywhere like uh giving some space some area or more area so how do we area it's not what i meant exactly uh so uh i mean like we we can do we can do whatever we want uh avoiding the errors right said i'm like there are many possibilities that we come to a conclusion uh so my doubt is that uh how can we say that our model is much efficient so minimum area uh okay so i mean like yes sir would there be any kind of uh uh i mean like any kind of option that we can check our area in the in the uh so no no no that is not available you just draw and then the competition will tell that your area is good or bad suppose you join intel and you draw something or let us say you join synopsis and you make a layout then arm is also working on the same technology or st is also working on the same technology they will also be making their layouts yes some customers will come back to you and tell you your area is bad you don't want to use your library you will go with arm so it's it's like a already too late it's already too late when you get this information the customers are already lost okay so don't wait for that benchmark always strive to make a very dense layout as dense as possible okay yes sir thank you yeah you can lower your hand yeah so once the layout versus schematic thing is done then we do a what is called as a parasitic extraction see till the time we were in the schematic phase did you even talk about the capacitance of this wire a and how this wire a capacitance is coupling with the output no you could make something but usually you would not do you simply say a is an input and y is the output but over here when you make this layout you see that there is an input a coming over here there would be some metal over here which is we're running very close to my output so there is bound to be some capacitance i need to extract that capacitance and see its impact on my results so that is the next step after the lvs is done we go to the step of parasitic extraction so all the parasitic resistances and capacitances can be extracted and okay in this course we will not look into these two aspects okay but we will after parasitic extraction go to post layout circuit analysis those two aspects are valid when we are talking about circuits like ios where package you know what kind of package is being used also comes into picture and uh ios being analog in in their characteristic uh the substrate coupling extractor also becomes big in this course since we are going to work on digital circuits so substrate noise and package model thing do not really bother us in this course okay these are separate independent job profiles the package model extraction and and verification this is a separate job profile in itself we will not be covering it in this course and once you've done the post layout circuit analysis you know check that the delays are in line with my specification even after these extra parasitics have come into picture that is when we say that my circuit is complete i can go ahead for a tape out okay there's a question yes yes sir what do we exactly mean by substrate so substrate coupling is uh let us say i have a processor over here on one side and there's a let us say this is a picture i have a processor over here and let us say there is a pll over here somewhere now since this is the same chip they are sharing the same substrate now if the processor is operating at let us say 2 gigahertz there will be some currents which will flow into the substrate those currents have to be sunk somewhere there is a very high probability that the noise injected by this processor will impact the functionality of this ell so when you are designing that pll you have to see that there is no substrate noise or even if there is a presence of substrate noise your circuit should work well even after that right so it's like you know source to body capacitance and so we're taking account for that uh yes because social body junction capacitance will always exist junctions would toggle so there would be some current in the source and that can lead to noise for the other circuits which could be sensitive to that noise in this course since we are looking at digital circuits only such noise is not really bothersome for us right okay and how do we how do we solve these problems okay so we use uh we use uh things like guard rings so guard rings are uh so if let us say this is your nand gate let us say this is an analog circuit so what i will do is around this analog circuit i will make a ring a ring or substrate connection okay so if there is any noise coming from anywhere else because this ring has all bdd substrate connections and ground substrate connections in it this ring will sync that current it will not let that current spoil the behavior of the transistors enclosed within it okay okay okay there is another technique which we call as deep and well or triple well technology will not look into that just yet but there are many methods as at a designer level if you want to do something you can work with either triple uh triple wells or with guard rings guard rings are more appropriate when you do not want to lose area you know when it is when the circuit when these circuits have to be placed really close together then guard rings are denser right okay but it wasn't the problem you know that uh the current was flowing into the substrate so like uh yeah so how it so the god if the guard ring is also a substrate yeah yeah but it is giving it a power supply now the ring is fully connected to vdds or gnds or whatever is a substrate supply very richly connected so no noise from the analog circuit can go to the digital side nor from the digital circuit come to the analog side because there is such huge sync such good connectivity to substrate power in this gathering yeah okay so we move forward any other questions oh one more you know when we are in the drc uh step we can check the minimum drift and area of the we could check the minimum width and area of the poly and all other things so by that can we not make the area of the layout minimum yes that is the minimum that is the way see uh vaishnava was saying that you have such a big field draw your devices anywhere why will you anyone ever face an error i said yes you will never face an error but then you will lose area so you design minimum area at minimum drc and go ahead okay yes sir so if we get to know about this parasitic capacitances then how will it affect our circuit and how we'll get rid of them oh you tell me if there is an rc in a in a circuit what happens it's extra delay yes so that is how it will affect the circuit your targeted timing but there is a capacitance there so the timing changes to 550 picoseconds yes sir and then how how will resolve this issue we will increase the width of the devices so that this extra capacitance can also be you know handled okay okay thank you yeah and then it was in this is that is that what happens yes so in the post layout circuit analysis all the resistances and capacitances that are parasitically present in your net list would be embedded into the design and then you simulate again so your design would actually have this capacitance there it will have a capacitance from b to output it will have a capacitance from b to this internal node you will have a capacitance from a to this internal node and so on so post layout netlist will have all the capacitances in picture and then we will simulate it it will also have some resistance between ground and and you know your nmos there okay yes there we are good afternoon sir uh basically i want to know what we are exactly doing parasitic extraction i don't get it so do you realize that when you will make the wires to make these connections between a and the gates of the two transistors and so on these wires will have some some capacitance of theirs yeah these wires are metal plates so when there are some capacitance there would you not want to see the impact of that capacitance on circuit behavior so the first step to see their impact on circuit behavior is to measure or estimate the value of this capacitance yeah that is what parasitic extraction step does okay so uh will it create any issue or not type no we do not even know that parasitic extraction step only estimates the various capacitances whether it is creating an issue or not we check that in the post layout circuit analysis okay so so yes yes so the temperature factor is also uh checked in post checks yes has to be um because estimating temperature cannot be is it possible by looking at the previous models so you can say that my circuit has a functional specification to operate fine between 125 degree celsius and minus 40 degree celsius okay so you have the specification you you've taken that specification range okay sir sir am i audible yes akash as you mentioned already so vaishnav already had his hand raised if it's not linked to what akshay just so as you have mentioned we considered the effect of passive capacity extraction in the post layout circuit analysis so after considering if we see that there is some effect then we again go to previous step and consider this effect before typing it out yes then we go back to the circuit state schematic stage we say that i want to increase the size of this particular nmos because the output capacitance is very large the nmr size that i have put yet will not be able to drive sufficient current and give me the timing that i am looking for so i increase the size in the schematic i then change the layout i then change the i then again do drc lvs again extract and then resimulate entire loop has to be done again sir uh yes sir so sir uh when we get to know about the parasitic extraction uh then are we uh connecting these capacitors manually by ourselves in layout again or would there be any kind of option for us to check this parasitic extraction after lvs see in the layout you made those wires already so those parasitics are already there you don't need to do anything else they're already there they're parasitic they're not to be designed they're parasitics they just appear are there parasites parasites okay so uh then uh why don't these uh and i mean like show up in design role check and layout for this schematic uh i mean like uh during those even these parenthesis uh parasitics are present right sir yeah so i mean like the outputs which we get are included with these parasitic extractions or or i mean like are they excluded with this parasitic extension so output of what output of design rule check yes sir no design rule check is a different tool altogether you do design rules check with calibre uh and you do parasitic extraction with a different tool let us say rc extract okay okay sir so after layout uh now if we check the output i'm like in any output for example you have done a cmos inverter over in our refresher so uh after layout uh i mean like if we uh if we take the output so the output would be with respect to paracetamol the output we get would be including the parasitic extractions or unlike the capacitance included it will include if you have done the extraction and embedded the capacitances into your netlist if you're doing the post layout circuit analysis it will include you made the layout left it there and then you're redoing the simulation of the schematic again then no change so sir then i mean we have already got our output so then why are we doing this parasitic extraction again sir uh i'm let we already know uh unlike uh at which time our circuit is getting um work and at which time it's getting turned off so first tell me one thing tell me one thing in the first schematic that you made are you sure how much is the wire capacitance uh no sir i'm not sure but otherwise you cannot put that capacitance or even if you have put that capacitance could be wrong uh but the output which we get would be included of this capacitance that i mean to be able to get that output you have to do a parasitic extraction so how will you estimate the capacitance the layout is simply rectangles yes sir the layout is simply rectangle rectangles don't tell you anything yes sir but output which we get at layout is simply rectangles no it has some rectangles and layout assembly rectangles for supposing we we give this a four called easy wave and we we get to know this way uh waveform analysis so you will go through the entire 
flow again don't worry so you will see that drc is a separate step and parasitic extraction is a separate step if you do not do parasitic extraction and only do let us say until lvs okay then you will not be able to add these extra capacitances in your net list you will never be able to see the impact of those capacitances on your circuit behavior okay we just want to know the effect of this specifically on the circuit yes okay okay i'm like now i understand i was thinking only about that i was only concerned about the output but not about this exact index effect of key capacity look at it like this without these capacitances the delay could be 500 pico seconds and that could be well within your specification as soon as these capacitances come you need to increase the your delay increases to 550 picoseconds which could be out of your specification so what do you do akash is asking this in the chat window also what do you do i said you increase the size of your nmos and your pmos so that it can now sync more current when you increase the size of your nmos and pmos what does it do it increases the drive capability of these devices so they can now sync or provide more current so that extra current can discharge this extra capacitor also within the stipulated time that is why you will still you will come back within the specifications okay does that solve your"
4o7Z_aS-cXQ,to understand it now yes serious okay vashna you want to lower your hand do you have some more question sorry sir hello okay so while we do this you should also be aware that before you do any circuit analysis there is something else that has already gone in the background so in the background someone has designed a process created devices on that process and given you the models models of transistors capacitors and resistors so that you can actually directly simulate and do circuit analysis over here is that okay and the process design itself uh so some of you if you will do the course on nanoelectronics or if you get to work with dr sneh you will see that you will work on these card tools like silvaco okay and you will actually you know make these source and drain regions and see the potential in that source and drain region and you will see how your device will finally behave so even before the so even before the process is designed you have you do these silvaco or tcat simulations to see how would you want you know what to expect when you have one particular kind of doping and stuff like that so through silvaco you can actually have a real physics-based simulation and come up with the transistor characteristics you can make a model out of it and say that will this meet my my performance specification of this at the stock level quick analysis you know back of the null up analysis you can do and only then you say okay let me go and design this thing on a silicon okay so the entire you may say the entire vlsi design flow someone or the other in our faculty team will take you through one course or another or if not a course you can take an independent project or something to learn about all these various aspects of vlsi design flow overall chip design whether it's library design or soc design or ip design anything so a wide range of people in our in our faculty would be able to take you through all these courses okay so this is a overview of vlsi vrsi work that we do uh the kind of jobs that we have and so on here you have a question yes sir what do we mean by process exactly process is the technology part the doping you know the doping that you need to do uh what is the depth of doping whether it has to be an implant or which way you do the doping and all that stuff that is the process uh okay okay so what are we doing in the previous slide i was not able to understand that what part yeah this part i mean uh someone has designed this uh this mosfet for this capacitors and resistance and what are we doing with this i'm not able to connect it in your circuit you wanted to put a pmos there no yes sir so someone has designed it yes okay okay okay okay someone had to design those p mosses also they didn't come out of thin air so yes so in the process do you mean that the 65 nanometer process or this 45 okay answer and what we are making from those process like the pmos and was that is the device level yeah right okay so also like for example sir uh what somewhere i actually uh read that uh for example 65 nanometer process there could be different versions of it like with denser version so what where would that be coming in those three levels like for example i'm devising a device and uh yeah it would come here it would come here it would say that okay now physically the length has to be reduced because i want to make a shrink version i want to make a denser version okay okay so but like there also like there is also like a fast and the slow of for a particular that is because of variation that we will see okay that is a lot of variation okay okay [Music] okay this is,https://www.youtube.com/watch?v=4o7Z_aS-cXQ,"Link: https://www.youtube.com/watch?v=4o7Z_aS-cXQ
Transcript: to understand it now yes serious okay vashna you want to lower your hand do you have some more question sorry sir hello okay so while we do this you should also be aware that before you do any circuit analysis there is something else that has already gone in the background so in the background someone has designed a process created devices on that process and given you the models models of transistors capacitors and resistors so that you can actually directly simulate and do circuit analysis over here is that okay and the process design itself uh so some of you if you will do the course on nanoelectronics or if you get to work with dr sneh you will see that you will work on these card tools like silvaco okay and you will actually you know make these source and drain regions and see the potential in that source and drain region and you will see how your device will finally behave so even before the so even before the process is designed you have you do these silvaco or tcat simulations to see how would you want you know what to expect when you have one particular kind of doping and stuff like that so through silvaco you can actually have a real physics-based simulation and come up with the transistor characteristics you can make a model out of it and say that will this meet my my performance specification of this at the stock level quick analysis you know back of the null up analysis you can do and only then you say okay let me go and design this thing on a silicon okay so the entire you may say the entire vlsi design flow someone or the other in our faculty team will take you through one course or another or if not a course you can take an independent project or something to learn about all these various aspects of vlsi design flow overall chip design whether it's library design or soc design or ip design anything so a wide range of people in our in our faculty would be able to take you through all these courses okay so this is a overview of vlsi vrsi work that we do uh the kind of jobs that we have and so on here you have a question yes sir what do we mean by process exactly process is the technology part the doping you know the doping that you need to do uh what is the depth of doping whether it has to be an implant or which way you do the doping and all that stuff that is the process uh okay okay so what are we doing in the previous slide i was not able to understand that what part yeah this part i mean uh someone has designed this uh this mosfet for this capacitors and resistance and what are we doing with this i'm not able to connect it in your circuit you wanted to put a pmos there no yes sir so someone has designed it yes okay okay okay okay someone had to design those p mosses also they didn't come out of thin air so yes so in the process do you mean that the 65 nanometer process or this 45 okay answer and what we are making from those process like the pmos and was that is the device level yeah right okay so also like for example sir uh what somewhere i actually uh read that uh for example 65 nanometer process there could be different versions of it like with denser version so what where would that be coming in those three levels like for example i'm devising a device and uh yeah it would come here it would come here it would say that okay now physically the length has to be reduced because i want to make a shrink version i want to make a denser version okay okay so but like there also like there is also like a fast and the slow of for a particular that is because of variation that we will see okay that is a lot of variation okay okay [Music] okay this is"
9EqPTLhEWlY,uh both for b-tech students and m tech students now how many of you have heard about what is called as moore's law who can tell me about moore's law so it tells us about the number of uh transistors the the increment in the number of transistors for three years or something i forgot the exact figure per decade and so it says the number of transistors we will get in certain rupees or dollars will get doubled okay very nice so we're already talking business now money now huh vishal you're saying something yes sir i was i was saying like uh he also said like the transistor or the speed of the computers that we see they will dump the speed will double in every every 18 months which is basically if we increase the transistors you know just synonymous okay at a device level the size of the transfer is getting reduced okay so also the speed and the capability over computers will increase in every couple of years and we will pay less for them also okay so we're talking about money what we are going to pay and everything now this is coming from your side not from my side okay great what else other views on moore's law so is it a law so it's just an observation which we are looking so what was it who was more gordon so what what more observed was and that was way back so moore's law says that [Music] every 18 months the number of transistors you can pack per square centimeter will double what did that mean that means that if i have this particular area in which i have to design my chip my functionality then every 18 months this area can shrink so i have some additional bandwidth to add more circuits there what does that mean that means that i can integrate more functionality onto the same die what does that also mean it also means that if i had do not want to add any more functionality i can reduce the die size and my price would reduce or if i add more functionality then at the same price i am now getting more functionality so i am getting more value either case whether my price reduced or more integration happened moore's law said that user value would increase are you able to see this hello yes sir yeah yeah it's clear okay so then this moore's law just said this much then you guys added other stuff and you assume that also to be moore's law was a law or there was something called dennard scaling that was proposed by dennard who said that uh you can reduce the size of gate and when you reduce the size of gate you should you know also reduce the depth of the source and drain and you should reduce the size of the gate oxide thickness of the gate oxide and he gives these rules to say that if you do all this if you do all this then what happens then you're scaling keyboard say because you're reducing the size so you are coming into the small region the price would reduce but also the performance would improve okay so that is denard scaling that with every shrink in technology so when linked with moore's law it may mean to say that not only will your devices become cheaper they will also perform faster okay and then there is another rule pollux rule which said that as you integrate more and more stuff on your diet okay the performance would improve why would the performance improve because now you do not need to go off check so when you have to access a memory the memory is now already on check you don't need to spend delays of going through an i o and then onto a pcb and then on to another i o and then the memory so your overall delays would decrease when you integrate more and more stuff onto the same die so pollack's rule states that when you integrate more the performance would improve so these three gentlemen paula don and dennard and more they kind of established that there is a virtuous cycle that operates in semiconductor manufacturing due to which you know electronics has really changed the face or the way we are living today so uh you know uh when the first time cell phones came in india which was i think 1994 or something like that the phone was this this big heavy like a brick and every call would cost something like 120 rupees per minute today your phones are tiny teeny tiny even if they're not teeny tiny they're not so because of your choice because you wanted a bigger screen otherwise the capability to have very small feature phones is right there feature phones are very very small when you don't have that bigger screen so uh today uh the call rate for example you know you have unlimited calling for 199 rupees for the entire month forget about per minute call rates just talking about a few paisa where i understand the value of money has only degraded so what was 125 rupees in 1994 today it would be worth something like a thousand rupees or more so instead of paying thousand rupees for a call today you are paying only a few pair per call and that is largely because of this this virtuous loop that has saturn and that has changed the very lift today this is the main reason why vlsi is so hot is it will it continue to remain hot we don't know but yeah it is hot today sir yes so i have a thing to asking they're not scaling sir dennard skilling is saying that when we reduce the features the size of the features of a particular device the performance increases and we also see in con in addition to that that the price is also decreasing is he trying to say that scaling means that you are now making the same die in a smaller area so the price is naturally reducing so but like the similar kind of thing moves i said that you are more simply said the number of transistors per centimeter square very double so he also said about price yes we both talked about price in a way okay so more doesn't didn't specifically told about the sizes of the devices no okay basically like i said you will be able to pack more devices per unit square okay not basically even more he gave the rules he gave the rules on how to be able to pack those devices there so can you just repeat that so he gave the rules by which you could enable that okay so you have to reduce that channel length or the great length okay okay so class modes was simply an observation it was not even a law you call it a law it was simply an observation okay okay so what did moore see moore saw that you know the relative manufacturing cost per component was something like this in 1962 then it reduced in 65 then it reduced in 70 and he saw that the number of components were increasing this was his only observation and based on that observation over time what was seen was that actually the number of devices were doubling so this is a logarithmic line okay so if it appears to be linear over here it means actually things are doubling it's a exponential growth and this is what was evident therefore people thought it is a law it actually is not a law it is it was simply an observation okay and because it was not a law actually we noticed that as we come to let us say so this is i'm not sure if you're able to read this clearly this is 90 nanometer this is 65 nanometer this is 40 nanometer 28 nanometer 20 nanometer and 14 nanometer so we see that until 28 nanometer cost is reducing but then the cost is no longer reducing so in a way something about moore's law has given in why why do you think this has happened due to the power dissipation i mean like this was even mentioned in cmos class so as we pack them together the amount of power dissipated gets increased and by then we have to i mean let we have to compensate this cost to reduce that power if that's if that's right i'm not sure about that but i think that is one aspect but no that's not the real reason this is possible manufacturing cost yeah this is only about manufacturing cost why is it breaking why is it increasing now so i think it's something to do with mark's mask sizing and uh i mean because as you said the cost of technology and um and lithography basically when we reduce that to reduce the sizes even more due to that technology the price increase yeah maybe maybe the mask needing more number of masks or better masks or very fine masks something like that so you're kind of there the overall manufacturing ecosystem is not able to handle finer geometries than 28 nanometers so what happens the total number of masks increase and in fact that is the reason you know uh even uh the international semiconductor association it gave a road map you know of technology shrink like this it said in 2013 that by 2025 you will be at seven seven nanometer node or something like this but in its 2015 report it said no that's that doesn't seem to be possible we'll probably saturate at 10 nanometers because they observed that the scaling or the rules that we wanted to apply are no longer possible okay but then what is this all this talk about seven finfets and five sunsets you must have heard about these technologies if at all people are still talking about these technologies so the fact of the matter is in seventh and fifth technology seven nanometers in fact technology there is no dimension which is equal to seven nanometers no physical dimension equal to that it used to be the case until let us say 32 nanometer or even 45 nanometers that do baby nether at 45 nanometer there it used to be the case that what you draw would actually be the dimension on silicon also okay but in seventh in fact for example there's no physical dimension which is equivalent to 7 nanometers it is called 7th and fit only because it is able to give that 15 to 20 performance gain from the previous designs which we used to call it 10 nanometers 10 nanometers has no physical dimension of 10 nanometers in it and it was called 10 nanometers simply because it gave those kind of gains as you would expect from a technology shrink through various other means by using different materials or whatever but it gave you those kind of gains and therefore you call it 10 nanometers input okay but physically there was nothing 10 nanometer in that technology also so what has happened the reality is that the cost of masks has increased very steeply as you come to finer geometries so what does that do that increases the cost of manufacturing significantly why does this mask set cost increase because you're trying to draw features which are let's say 28 nanometer apart by using a light you know with the wavelength of 193 nanometers because of this you have to do a lot of optics and you need to make additional masks so that diffraction patterns interference and all those are taken care of you need to do a lot of resolution enhancement so that you're able to draw a feature of 28 nanometer with a wavelength of light of 193 nanometer there okay and how to uh how to take care of it excuse me sir yes uh so isn't the cost also increasing because as we reduce the size then the defects also increase so the overall average usable actually the chips that are actually usable and correctly functioning they also decrease like we get 15 percent yield or 30 percent yield at the end so that is also increasing this is that the case really for example if i have this one big wafer let me make a few dies out of it able to see this yes yeah we will see this in a little more detail later when we talk about evie but since you already mentioned it so let me just cover it now so let's say this is the wafer i say there were four defects okay one two three and four these four defects will lead to loss of four dice total number of dies are 1 2 3 3 and 12 and 16. so 4 out of 16 dies are defective e loss is 25 huh now let me say i i reduce the chip size to half now how many dice do i have you see i have six six and then eight then again eight possibly this set of dice would start to work i don't know we could add them or six plus let us 24 30 30 plus 3 33 out of 33 dies now four are failing what is the yield loss 12 percent so when you reduce the die area you actually improve yield for the same defectivity that is one more reason why we say that area is gold in vlsi yes so what isn't uh the number of chips database that are defective also depending on the density because if the transistors are sort of big and sparse then if if you have ensured that your drcs are all clean then you're not expecting an error anyways is it not so what about just particles so dust particles so are independent of what technology or how dense your layout is now dust particles are them are the characteristic of your clean room yes but they don't transfer technology technology if there are four dust particles they remain to be four dust particles only so but the probability that they will actually damage a design will increase if the transistors are placed too close together yeah so essentially what happens is as you scale in technology mother you also change the specifications of your clean room instead of a class 10 clean room you will go to class 1 clean room okay so you spend more in the clean room maintaining a clean room but you would not really want those kind of defects to impact your yields there are other very other detractors anyways but at least dust is not something that you will let to distract your yield excuse me sir yes sir i think what he was trying to say and maybe i have the same doubt sir if we start to reduce the size of our steps or our components then the things that can cause defects are going to increase for example for a large component a dust particle might not be as problematic as for something which is comparable to the size of dust so i think what he was trying to say is we have we're going to have more number of problems as we start to reduce the size of the components and we need to tackle those problems because of which our cost will increase yeah but uh maintaining a clean room uh which is of a higher quality does not increase the cost in the same ratio as the mask set cost that you are seeing here how much yeah and okay so i understand i know that is some logistics yes some costume three is one person two percent not like this so we are just i know we are we are at the end of the time allocated for the class is it okay if we continue for another three four minutes we will just close this section then this is okay so how to reduce this cost mask set cost one way to reduce this mass set cost is by using what is called as photo uh extreme ultraviolet light for photolithography so all these you know uh 1900 i said 1900 dual patterning 1900i second generation dual patterning all these use 193 nanometer light okay what we are saying is that please go to euv uv the wavelength of light is 13 nanometer as soon as you do that the number of masks that you will need will reduce and therefore as you also increase the capability of your euv machines that is they are able to give more power and therefore expose more number of dice per unit unit time you will reduce the cost further so there are but you know there is only one company in the world that makes these euv machines asml and whatever is the semiconductor cycle asml stock price always rises rises and rises you know why because it is the only one no one has yet mastered the same technology the way asml has mastered it so we see that 7th in fact has been made has been enabled largely because euv has come into picture and litho litho costs have been pushed back towards the normal range they're not no longer increasing at the same rate okay but euv is being used only for uh you know a few layers and let us say 15 or 16 and fit but in many layers than when you're talking about seven sensitive technology okay and then another way that the semiconductor industry has found their way uh around more is you know more is like saying that okay go from 130 to 90 to 165 to 45 and so on this is baseline cmos for processing technologies but we realize that because electronics is touching different facets of life we also need analog circuits which would not scale we need high voltage circuits for example those and cars you know car batteries they will not they cannot scale so we are also adding additional content onto our technology so that electronics continues to add more value to users independent of whether the scaling happens miniaturize miniaturization happens or not okay this direction of movement is called more than more this is essentially diversifying so you have image sensors you have capacitive sensors you have all these piezoelectric sensors everything is trying to getting embedded onto the die into the same die integrated into the same die and uh you now adding more dies onto the same package so system and package and so on so overall you are able to add higher value to the users there okay so that is the primary reason why vrsi is hot,https://www.youtube.com/watch?v=9EqPTLhEWlY,"Link: https://www.youtube.com/watch?v=9EqPTLhEWlY
Transcript: uh both for b-tech students and m tech students now how many of you have heard about what is called as moore's law who can tell me about moore's law so it tells us about the number of uh transistors the the increment in the number of transistors for three years or something i forgot the exact figure per decade and so it says the number of transistors we will get in certain rupees or dollars will get doubled okay very nice so we're already talking business now money now huh vishal you're saying something yes sir i was i was saying like uh he also said like the transistor or the speed of the computers that we see they will dump the speed will double in every every 18 months which is basically if we increase the transistors you know just synonymous okay at a device level the size of the transfer is getting reduced okay so also the speed and the capability over computers will increase in every couple of years and we will pay less for them also okay so we're talking about money what we are going to pay and everything now this is coming from your side not from my side okay great what else other views on moore's law so is it a law so it's just an observation which we are looking so what was it who was more gordon so what what more observed was and that was way back so moore's law says that [Music] every 18 months the number of transistors you can pack per square centimeter will double what did that mean that means that if i have this particular area in which i have to design my chip my functionality then every 18 months this area can shrink so i have some additional bandwidth to add more circuits there what does that mean that means that i can integrate more functionality onto the same die what does that also mean it also means that if i had do not want to add any more functionality i can reduce the die size and my price would reduce or if i add more functionality then at the same price i am now getting more functionality so i am getting more value either case whether my price reduced or more integration happened moore's law said that user value would increase are you able to see this hello yes sir yeah yeah it's clear okay so then this moore's law just said this much then you guys added other stuff and you assume that also to be moore's law was a law or there was something called dennard scaling that was proposed by dennard who said that uh you can reduce the size of gate and when you reduce the size of gate you should you know also reduce the depth of the source and drain and you should reduce the size of the gate oxide thickness of the gate oxide and he gives these rules to say that if you do all this if you do all this then what happens then you're scaling keyboard say because you're reducing the size so you are coming into the small region the price would reduce but also the performance would improve okay so that is denard scaling that with every shrink in technology so when linked with moore's law it may mean to say that not only will your devices become cheaper they will also perform faster okay and then there is another rule pollux rule which said that as you integrate more and more stuff on your diet okay the performance would improve why would the performance improve because now you do not need to go off check so when you have to access a memory the memory is now already on check you don't need to spend delays of going through an i o and then onto a pcb and then on to another i o and then the memory so your overall delays would decrease when you integrate more and more stuff onto the same die so pollack's rule states that when you integrate more the performance would improve so these three gentlemen paula don and dennard and more they kind of established that there is a virtuous cycle that operates in semiconductor manufacturing due to which you know electronics has really changed the face or the way we are living today so uh you know uh when the first time cell phones came in india which was i think 1994 or something like that the phone was this this big heavy like a brick and every call would cost something like 120 rupees per minute today your phones are tiny teeny tiny even if they're not teeny tiny they're not so because of your choice because you wanted a bigger screen otherwise the capability to have very small feature phones is right there feature phones are very very small when you don't have that bigger screen so uh today uh the call rate for example you know you have unlimited calling for 199 rupees for the entire month forget about per minute call rates just talking about a few paisa where i understand the value of money has only degraded so what was 125 rupees in 1994 today it would be worth something like a thousand rupees or more so instead of paying thousand rupees for a call today you are paying only a few pair per call and that is largely because of this this virtuous loop that has saturn and that has changed the very lift today this is the main reason why vlsi is so hot is it will it continue to remain hot we don't know but yeah it is hot today sir yes so i have a thing to asking they're not scaling sir dennard skilling is saying that when we reduce the features the size of the features of a particular device the performance increases and we also see in con in addition to that that the price is also decreasing is he trying to say that scaling means that you are now making the same die in a smaller area so the price is naturally reducing so but like the similar kind of thing moves i said that you are more simply said the number of transistors per centimeter square very double so he also said about price yes we both talked about price in a way okay so more doesn't didn't specifically told about the sizes of the devices no okay basically like i said you will be able to pack more devices per unit square okay not basically even more he gave the rules he gave the rules on how to be able to pack those devices there so can you just repeat that so he gave the rules by which you could enable that okay so you have to reduce that channel length or the great length okay okay so class modes was simply an observation it was not even a law you call it a law it was simply an observation okay okay so what did moore see moore saw that you know the relative manufacturing cost per component was something like this in 1962 then it reduced in 65 then it reduced in 70 and he saw that the number of components were increasing this was his only observation and based on that observation over time what was seen was that actually the number of devices were doubling so this is a logarithmic line okay so if it appears to be linear over here it means actually things are doubling it's a exponential growth and this is what was evident therefore people thought it is a law it actually is not a law it is it was simply an observation okay and because it was not a law actually we noticed that as we come to let us say so this is i'm not sure if you're able to read this clearly this is 90 nanometer this is 65 nanometer this is 40 nanometer 28 nanometer 20 nanometer and 14 nanometer so we see that until 28 nanometer cost is reducing but then the cost is no longer reducing so in a way something about moore's law has given in why why do you think this has happened due to the power dissipation i mean like this was even mentioned in cmos class so as we pack them together the amount of power dissipated gets increased and by then we have to i mean let we have to compensate this cost to reduce that power if that's if that's right i'm not sure about that but i think that is one aspect but no that's not the real reason this is possible manufacturing cost yeah this is only about manufacturing cost why is it breaking why is it increasing now so i think it's something to do with mark's mask sizing and uh i mean because as you said the cost of technology and um and lithography basically when we reduce that to reduce the sizes even more due to that technology the price increase yeah maybe maybe the mask needing more number of masks or better masks or very fine masks something like that so you're kind of there the overall manufacturing ecosystem is not able to handle finer geometries than 28 nanometers so what happens the total number of masks increase and in fact that is the reason you know uh even uh the international semiconductor association it gave a road map you know of technology shrink like this it said in 2013 that by 2025 you will be at seven seven nanometer node or something like this but in its 2015 report it said no that's that doesn't seem to be possible we'll probably saturate at 10 nanometers because they observed that the scaling or the rules that we wanted to apply are no longer possible okay but then what is this all this talk about seven finfets and five sunsets you must have heard about these technologies if at all people are still talking about these technologies so the fact of the matter is in seventh and fifth technology seven nanometers in fact technology there is no dimension which is equal to seven nanometers no physical dimension equal to that it used to be the case until let us say 32 nanometer or even 45 nanometers that do baby nether at 45 nanometer there it used to be the case that what you draw would actually be the dimension on silicon also okay but in seventh in fact for example there's no physical dimension which is equivalent to 7 nanometers it is called 7th and fit only because it is able to give that 15 to 20 performance gain from the previous designs which we used to call it 10 nanometers 10 nanometers has no physical dimension of 10 nanometers in it and it was called 10 nanometers simply because it gave those kind of gains as you would expect from a technology shrink through various other means by using different materials or whatever but it gave you those kind of gains and therefore you call it 10 nanometers input okay but physically there was nothing 10 nanometer in that technology also so what has happened the reality is that the cost of masks has increased very steeply as you come to finer geometries so what does that do that increases the cost of manufacturing significantly why does this mask set cost increase because you're trying to draw features which are let's say 28 nanometer apart by using a light you know with the wavelength of 193 nanometers because of this you have to do a lot of optics and you need to make additional masks so that diffraction patterns interference and all those are taken care of you need to do a lot of resolution enhancement so that you're able to draw a feature of 28 nanometer with a wavelength of light of 193 nanometer there okay and how to uh how to take care of it excuse me sir yes uh so isn't the cost also increasing because as we reduce the size then the defects also increase so the overall average usable actually the chips that are actually usable and correctly functioning they also decrease like we get 15 percent yield or 30 percent yield at the end so that is also increasing this is that the case really for example if i have this one big wafer let me make a few dies out of it able to see this yes yeah we will see this in a little more detail later when we talk about evie but since you already mentioned it so let me just cover it now so let's say this is the wafer i say there were four defects okay one two three and four these four defects will lead to loss of four dice total number of dies are 1 2 3 3 and 12 and 16. so 4 out of 16 dies are defective e loss is 25 huh now let me say i i reduce the chip size to half now how many dice do i have you see i have six six and then eight then again eight possibly this set of dice would start to work i don't know we could add them or six plus let us 24 30 30 plus 3 33 out of 33 dies now four are failing what is the yield loss 12 percent so when you reduce the die area you actually improve yield for the same defectivity that is one more reason why we say that area is gold in vlsi yes so what isn't uh the number of chips database that are defective also depending on the density because if the transistors are sort of big and sparse then if if you have ensured that your drcs are all clean then you're not expecting an error anyways is it not so what about just particles so dust particles so are independent of what technology or how dense your layout is now dust particles are them are the characteristic of your clean room yes but they don't transfer technology technology if there are four dust particles they remain to be four dust particles only so but the probability that they will actually damage a design will increase if the transistors are placed too close together yeah so essentially what happens is as you scale in technology mother you also change the specifications of your clean room instead of a class 10 clean room you will go to class 1 clean room okay so you spend more in the clean room maintaining a clean room but you would not really want those kind of defects to impact your yields there are other very other detractors anyways but at least dust is not something that you will let to distract your yield excuse me sir yes sir i think what he was trying to say and maybe i have the same doubt sir if we start to reduce the size of our steps or our components then the things that can cause defects are going to increase for example for a large component a dust particle might not be as problematic as for something which is comparable to the size of dust so i think what he was trying to say is we have we're going to have more number of problems as we start to reduce the size of the components and we need to tackle those problems because of which our cost will increase yeah but uh maintaining a clean room uh which is of a higher quality does not increase the cost in the same ratio as the mask set cost that you are seeing here how much yeah and okay so i understand i know that is some logistics yes some costume three is one person two percent not like this so we are just i know we are we are at the end of the time allocated for the class is it okay if we continue for another three four minutes we will just close this section then this is okay so how to reduce this cost mask set cost one way to reduce this mass set cost is by using what is called as photo uh extreme ultraviolet light for photolithography so all these you know uh 1900 i said 1900 dual patterning 1900i second generation dual patterning all these use 193 nanometer light okay what we are saying is that please go to euv uv the wavelength of light is 13 nanometer as soon as you do that the number of masks that you will need will reduce and therefore as you also increase the capability of your euv machines that is they are able to give more power and therefore expose more number of dice per unit unit time you will reduce the cost further so there are but you know there is only one company in the world that makes these euv machines asml and whatever is the semiconductor cycle asml stock price always rises rises and rises you know why because it is the only one no one has yet mastered the same technology the way asml has mastered it so we see that 7th in fact has been made has been enabled largely because euv has come into picture and litho litho costs have been pushed back towards the normal range they're not no longer increasing at the same rate okay but euv is being used only for uh you know a few layers and let us say 15 or 16 and fit but in many layers than when you're talking about seven sensitive technology okay and then another way that the semiconductor industry has found their way uh around more is you know more is like saying that okay go from 130 to 90 to 165 to 45 and so on this is baseline cmos for processing technologies but we realize that because electronics is touching different facets of life we also need analog circuits which would not scale we need high voltage circuits for example those and cars you know car batteries they will not they cannot scale so we are also adding additional content onto our technology so that electronics continues to add more value to users independent of whether the scaling happens miniaturize miniaturization happens or not okay this direction of movement is called more than more this is essentially diversifying so you have image sensors you have 
capacitive sensors you have all these piezoelectric sensors everything is trying to getting embedded onto the die into the same die integrated into the same die and uh you now adding more dies onto the same package so system and package and so on so overall you are able to add higher value to the users there okay so that is the primary reason why vrsi is hot"
1CjvgmPJq1I,so uh why is silicon any ideas so because we first of all we get the in the particular band gap we get the right cap bind gap thing and it's a group for uh we have the four valence electrons and we cannot have carbon because that becomes too tightly bonded so here we get the kind of properties that at a temperature higher than zero kelvin we get the semiconductor properties so and it's also really easily available sand it's there so that is also there okay other ideas small leakage current and high temperature applications uh the virus small leakage current and high temperature applications and high temperature applications they will be better with germanium actually but small leakage current is more in germany okay they're abundantly available silicon and it can be partially dropped or negative so that it can be partially dropped or negatively doped so that we can get an extensive entrance sorry we i'm like we can get a posture on it it's an extrinsic i'm like if you do that with something it's an extrinsic so yeah that's it okay it's closely available right cpu available okay somewhere also something uh it is non-toxic it is non-toxic it is non-toxic okay compared to other groups okay comfortable with the wide range of temperature wide range of temperature okay can be purified in comparison to germanium germanium okay but what about silicon carbide why not silicon carbide silicon carbide can handle much more power voltage [Music] [Music] okay so all of us know so many properties of silicon why are these properties of silicon so evident there what is it that gives silicon its properties like that uh the atomic structure of silicon crystalline structure the crystalline structure of silicon yes great so uh when we talk of crystalline structure what is the crystal so uh basically we can say that repetitive arrangement of atoms when the atoms of a material are arranged in a repetitive manner for a very long distance we call it as a crystal otherwise there will be some arrangement of atoms which could change every every now and then so we call it polycrystalline or amorphous but whenever when there is a systematic arrangement of atoms for a long range we call that as crystalline in fact in one crystal it is only one arrangement of atoms as soon as that arrangement of atom changes we call it as a second crystal so the most common crystalline structure that we know of is you know simple cubic so repetitive arrangement of atoms and there are different kinds of ones uh simple cubic body centered face centered we'll just look at them and then we understand that as you change the type of crystal structure the various features like density physical properties chemical properties and even electrical properties of materials change diamond has very different chemical properties and electrical properties than graphite both are pure carbon and that difference is largely because of different structure of the crystal am i right different arrangement of atoms in the two materials and the properties are entirely different even though the chemical component which composition is same so crystalline structure has or the crystal structure has significant bearing on say physical and electrical properties and that is what we are interested in as of now okay so this is face centered cubic structure where you have the atoms at the boundary of or at the edges at the vertices of the cuboid but you also have atoms at the faces okay this is face centered cubic and this is diamond cubic so what has happened over here in a diamond cubic structure what you've done is in addition to these atoms at the center of the faces you also add atoms in four of the internal eight uh short cubes small cubes so you have atoms inside uh different uh small cubes you know in total there will be eight small cubes inside out of those eight small cubes there are atoms in four of them and they are organized like this i believe all of you must have studied this in your semiconductor physics in 11th and 12th if not later anyone who has not studied it please put a minus one in your chat window i believe all of us must have seen this in our 11th 12th or even later than that okay so this is diamond cubic structure and let us look at a short animation of how this diamond cubic structure looks like from from different perspectives okay so this isn't you know we're just rotating a diamond cubic crystal and you notice that when i try to see at different angles i would see different density and uh and therefore different physical properties will appear so what all will change let us say i want to send an electron from one side to the other and there is this large density of atoms there electron will experience lots of resistance to pass whereas when you have that hexagonal view there like this one you will see that electrons will pass easily so the direction in which i am trying to move my current the electrical properties will also vary the physical properties will also vary depending on what is happening okay so what is happening is that in different planes in different planes there is a different density of atoms and even different topology of atoms therefore they have different electrical properties and therefore it is very important that when we design or when we fabricate any device we should fabricate it very carefully in the desired plane are you able to see this challenge so we we can easily make silicon crystal so have you done some experiments with crystallizing say alum or sugar or something in your school school times make a solution of sugar and crystallize it you done such kind of experiments in school days yes sir huh so can you ascertain that this is the plane in which all the crystals are formed when you do a regular such experiment are you able to ascertain that no no so what we are saying is that when we want to make silicon crystals for fabrication purpose uh because the properties of the crystal electrical properties of the crystal are different across different planes and i have all my models and all my process assumptions based on one kind of plane so i rather would have my electrons flowing in that direction are you able to see this point that the crystalline plane has to be the the plane in which you will fabricate your devices has to be carefully chosen so the crystal has to be carefully manufactured it cannot be just like the home experiments on crystallizing of sugar that you did are you able to see this any questions around this topic sir yes nish uh sir uh so you are saying that uh in that previous 3d diagram of diamond uh say foreign so yes if you change the direction of electron flow it will see different kind of resistivity okay there has to be some more you know process that should go in is it not is crystallizing or using even though sand is abundantly available you cannot make a silicon wafer at home just like you could make a sugar crystal at home you cannot do the same for silicon wafers is this finger is this thing clear yes so then we because if this thing is clear we can then move to the next step of how this wafer is fabricated so uh the complexity of vlsi design or vsf fabrication starts from the very base of how to manufacture this crystal which has the same direction and the same plane as we wanted to be okay so uh what is done is we use a silicon crystal and we dip it in molten silicon and this silicon crystal that we have we put it so carefully into our uh uh into our uh instrument so that it when it goes the dips into the molten crystal it then starts to crystallize you know it solidifies according to the crystals orientation so the orientation of my seed crystal is carefully chosen and determined and only then you dip it into there okay and then you slowly pull out this crystal from from this molten mass and the speed with which you pull it out so you rotate it and you pull it out the speed with which you pull it out will define the width of this in got so this is called as in got okay and based on this you will be able to make 6 inches 8 inches or 12 inch wafers 12 inch wafer is this big diametrically okay so i can actually literally hide my face behind the 12 inch even 8 inch wafer it can fairly hide my face don't probably not my hair but a 12 inch will hide everything of my face and here okay so this this big wafers uh coming out of it and can you imagine the weight of this whole ingot as it would pull it out and a 12 inch wafer you know so it's huge so this process is called so so we did this this is a this is a of vacant phrase so to choose falci process okay so uh this is how ingots are made once the ingots are made do you see that this ingot has a lot of these uh you know contours on its surface are you able to see this so what this means is that the sim card cannot be used directly to make wafers because then some wafers will be 12 inch uh 12 inch wide or 12 inch diameter some would be 12.1 others would be 12.2 and so on but all your machines are designed for a see we need nanometer level accuracy in our machines so the machines are designed such that they 112 inch wafer so you cannot really handle 12.1 inch also and 12.2 inch also and then say oh i will give you the accuracy of nanometers when i expose the or when i make your wafers or when i make your silicon dies so here it says the process has to be you know some something needs to be done so that each wafer is exactly okay so since i forget the formula sorry because we just put in one crystal and as we are pulling it out from that molten material the silicon atoms would align to align to the existing crystalline structure so there would there would be just one crystal there i don't get it yeah so then this is not an ic of course you will need to probably read a little more of it off the course but yeah this is the way you tip a crystal there and all now because this is the property of the material that atoms will bond with other atoms in the orientation of the existing crystal okay yeah okay and then when you slowly pull it out those atoms are now a part of that earlier crystal so they become a bigger crystal okay and then as you pull it out it becomes a still bigger crystal a still bigger question and until you reach that width until you reach that width of let us say 12.5 inches you you just pull it out very very slowly you slowly you know you you pull it out and then you say that okay now at a stable speed i will pull it out so that all the crystals are at that 12 inch approximately 12 12.5 inch wide uh wafer there okay so for dedicated machine that it is like forming okay if you want to relate to that i will not but yeah it's okay whatever helps you on your understanding rather uh sir like for example you said that we are not only interested in manufacturing the silicon crystal but a particular orientation so so like we put the crystal in a particular orientation and we pulled it out so but still for example we are getting the whole crystal and if you are getting the crystal all the particular orientations are still possible so we need to then have to be in direction also okay this is the from where can i get the orientation like because i cannot access that so when you are seeding at that point of time the orientation is established with the help of a microscope so but still i'm getting the crystal right so in crystal every orientation is possible yeah yeah that is okay if you make if you have a crystal with this kind of a plane then it will it will grow like this only whichever plane you choose that is how it will grow that is the property of a crystal okay so i have chosen the plane also okay this is the plane okay yeah okay sir ingot is something that holds the silicon crystals and what is that huge mass of uh silicon circular mass of silicon which through which you will slice and get the crystals okay sir okay that is what we are on and looking at going to look at in this slide so you first get that n got and then you slice it to make crystals or to make wafers these wafers then you grind so that they are all circular because you we just saw that they may not be all circular at all times so then the grinding is done so that you get circular wafers of exactly 12 inch diameter or or eight inch diameter or six inch diameter whichever your machining is ready for okay and then because you slice these crystals so you've tried to cut let us say slices of cucumber or tomato at home for making salad yes sir can you always cut them in the same of the same width no sir so it can happen that some wafers are thicker some are not as thick but again realize that our machining is such that it can it has to make things which are accurate to the level of nanometers so you cannot really have different thickness of wafers otherwise the light that will fall from the top will not fall at the side right angle okay sir uh this is the reason why amalek will get the wafer in a circular shape i'm like we are dipping it out and the way it spreads it will be a circle i'm like one of the person so we this this was a question in the last class i have to why don't you make it square now if i have to make it square i have to cut some part of the circular wafer which actually leads to more loss of you know if in a circular wafer you will probably be able to get more dice than a square which has a smaller size than it so in lapping in the second step that you do wrapping you actually make the thickness of the wafers exactly let us say five millimeter or uh two millimeters or whatever is the agreed specification for that particular wafer okay then you do the polishing because all this grinding and lapping there could be some broken bonds on the on the and dislocations that you may have introduced on the surface of the wafer so do the polishing and then you dope it the the substrate is typically p type doped and uh and you then create a flat so you dope the you do you dope uh boron into it let us say so it is p type and uh then what you do the circular wafer you create a flat over here a little flat when you have an n type then you also create a secondary flap so this flap would be let us say uh four centimeters this flat would be something like two centimeter i don't know the exact numbers you can find out on the internet if you are interested but in an entire wafer you will have two flats in a p-type wafer you have one plant okay in advanced technologies or today you do not even talk of flat you talk of what is called as a notch and uh that notch defines that this like this is the notch so if my current flows in this particular direction i will be using one one one kind of direction so the notch not only defines uh that this is an n type or a p type but it also tells where is the one one one plane or one one zero direction so to say in that particular wafer because the current flow uh the electrical properties in different directions are different so we also need to tell the user that this is where this is how you should fabricate it this is how you should place the wafer in your fabrication machinery okay any questions still here so uh in the in god which we are making will it have like uniform diameter throughout no that is why we need to do grinding ah okay sir so like how can we know like what is the diameter of the ingot that is formed and can we know it before uh creating the angle yeah like you know the cooling rate you you can control the temperature of your furnace you can do everything so that you can estimate you know this this is a physical model you can which actually can be easily made and it is existing so the speed at which you are pulling the wafer out and everything and the site can easily be used to decide the size of the ingot okay it's a physical process the purely physical process will characterize physical process oh sir you said that when we were pulling out the in god we were pulling out in the direction uh which was corresponding to the orientation which we wanted right so like now what exactly we are doing this is flat because because we know that okay like this is the orientation i got so that is the plane we are saying this is the plane but in a plane also for example if we look at the plane a face centered cubic plane so if i go in this direction there will be one kind of resistance if i go in this direction there will be another kind of resistance are you able to see this yes sir so i need to tell which direction to go because that is where all my models and all my everything is designed for okay okay so at the ingot level i have only got the plane orientation but now the direction you get lanes now this is only a big plane that you know now you need to know the direction also so that you can actually then fabricate your gates in the right orient right direction within that plane yes okay okay so okay okay you also wanted to ask something deepak suddenly yes sir so sir we are making this notch so some amount of silicon would be wasted right yeah we make that is why we don't know we now don't make a flat you make a notch notch is a small thing flat would have really taken a lot of silicon off but notch is a small thing we don't want to wear silicon wafer area can't you make a mark or something why cut silicon so this notch is also very small if you make a mark you will have to physically you know visually see it and align it a notch is easy because mechanically you can just lock your wafers into the notch when you are transferring wafers from one machine to another a physical asymmetry is always easier to handle in the manufacturing processes than a planar visual asymmetry because then you will need to have cameras and lasers and do everything to align the wafer every time with a notch you just need to get the wafer in and you know the notch is already established and fixed in there so the wafer is properly aligned right so when we are talking about the orientation of a crystal like the crystal is a spherical kind we look at crystalline structures in cuboid from cubic and uh space center we are talking about their orientations and okay okay is everyone comfortable with hindi language is asking something in hindi is everyone comfortable with that anyone who does not understand hindi in this class can you put a plus one in the chat window oh so everyone is comfortable with hindi oh there is deja who is not okay so no issues so actually uh uh currently we have designed a vapor so uh we have prepared a substrate now okay so we have doped and we have built up right now uh what we will do we just build upgrades our source and drain forward uh that the thing is completely perpendicular to the surface so now the current would flow from the top of the gate or from the top of the source of transistor exactly the current flow uh inside the substrate would completely uh would be decided by this uh flat what we are preparing what or it could random direction randomly so if you know that this is the 1 1 direction and you want to orient or you want to have the current flow in in a particular direction you can make uh devices like that such that uh the current will flow in your desired direction you know one direction this is the so you've given you've been given a reference now see consider it like this uh you go to a uh amusement park and you get a map on how to navigate in this amusement park what is the most important thing that you need to look at where are you you are here that that mark okay i am here now in this context i can go left right wherever but that you are here is most important is it not yes so this knot is the you are here mark okay okay yes you said when we are saying that i want to i want to make the current run in only single direction so does that mean i cannot make a mosfet on layout which is in another orientation if i rotate it by 90 so if you do then there could be some consequences which may not be acceptable to you you will see we will just have a look at what happens when you rotate the wafer there's a slide on that don't worry,https://www.youtube.com/watch?v=1CjvgmPJq1I,"Link: https://www.youtube.com/watch?v=1CjvgmPJq1I
Transcript: so uh why is silicon any ideas so because we first of all we get the in the particular band gap we get the right cap bind gap thing and it's a group for uh we have the four valence electrons and we cannot have carbon because that becomes too tightly bonded so here we get the kind of properties that at a temperature higher than zero kelvin we get the semiconductor properties so and it's also really easily available sand it's there so that is also there okay other ideas small leakage current and high temperature applications uh the virus small leakage current and high temperature applications and high temperature applications they will be better with germanium actually but small leakage current is more in germany okay they're abundantly available silicon and it can be partially dropped or negative so that it can be partially dropped or negatively doped so that we can get an extensive entrance sorry we i'm like we can get a posture on it it's an extrinsic i'm like if you do that with something it's an extrinsic so yeah that's it okay it's closely available right cpu available okay somewhere also something uh it is non-toxic it is non-toxic it is non-toxic okay compared to other groups okay comfortable with the wide range of temperature wide range of temperature okay can be purified in comparison to germanium germanium okay but what about silicon carbide why not silicon carbide silicon carbide can handle much more power voltage [Music] [Music] okay so all of us know so many properties of silicon why are these properties of silicon so evident there what is it that gives silicon its properties like that uh the atomic structure of silicon crystalline structure the crystalline structure of silicon yes great so uh when we talk of crystalline structure what is the crystal so uh basically we can say that repetitive arrangement of atoms when the atoms of a material are arranged in a repetitive manner for a very long distance we call it as a crystal otherwise there will be some arrangement of atoms which could change every every now and then so we call it polycrystalline or amorphous but whenever when there is a systematic arrangement of atoms for a long range we call that as crystalline in fact in one crystal it is only one arrangement of atoms as soon as that arrangement of atom changes we call it as a second crystal so the most common crystalline structure that we know of is you know simple cubic so repetitive arrangement of atoms and there are different kinds of ones uh simple cubic body centered face centered we'll just look at them and then we understand that as you change the type of crystal structure the various features like density physical properties chemical properties and even electrical properties of materials change diamond has very different chemical properties and electrical properties than graphite both are pure carbon and that difference is largely because of different structure of the crystal am i right different arrangement of atoms in the two materials and the properties are entirely different even though the chemical component which composition is same so crystalline structure has or the crystal structure has significant bearing on say physical and electrical properties and that is what we are interested in as of now okay so this is face centered cubic structure where you have the atoms at the boundary of or at the edges at the vertices of the cuboid but you also have atoms at the faces okay this is face centered cubic and this is diamond cubic so what has happened over here in a diamond cubic structure what you've done is in addition to these atoms at the center of the faces you also add atoms in four of the internal eight uh short cubes small cubes so you have atoms inside uh different uh small cubes you know in total there will be eight small cubes inside out of those eight small cubes there are atoms in four of them and they are organized like this i believe all of you must have studied this in your semiconductor physics in 11th and 12th if not later anyone who has not studied it please put a minus one in your chat window i believe all of us must have seen this in our 11th 12th or even later than that okay so this is diamond cubic structure and let us look at a short animation of how this diamond cubic structure looks like from from different perspectives okay so this isn't you know we're just rotating a diamond cubic crystal and you notice that when i try to see at different angles i would see different density and uh and therefore different physical properties will appear so what all will change let us say i want to send an electron from one side to the other and there is this large density of atoms there electron will experience lots of resistance to pass whereas when you have that hexagonal view there like this one you will see that electrons will pass easily so the direction in which i am trying to move my current the electrical properties will also vary the physical properties will also vary depending on what is happening okay so what is happening is that in different planes in different planes there is a different density of atoms and even different topology of atoms therefore they have different electrical properties and therefore it is very important that when we design or when we fabricate any device we should fabricate it very carefully in the desired plane are you able to see this challenge so we we can easily make silicon crystal so have you done some experiments with crystallizing say alum or sugar or something in your school school times make a solution of sugar and crystallize it you done such kind of experiments in school days yes sir huh so can you ascertain that this is the plane in which all the crystals are formed when you do a regular such experiment are you able to ascertain that no no so what we are saying is that when we want to make silicon crystals for fabrication purpose uh because the properties of the crystal electrical properties of the crystal are different across different planes and i have all my models and all my process assumptions based on one kind of plane so i rather would have my electrons flowing in that direction are you able to see this point that the crystalline plane has to be the the plane in which you will fabricate your devices has to be carefully chosen so the crystal has to be carefully manufactured it cannot be just like the home experiments on crystallizing of sugar that you did are you able to see this any questions around this topic sir yes nish uh sir uh so you are saying that uh in that previous 3d diagram of diamond uh say foreign so yes if you change the direction of electron flow it will see different kind of resistivity okay there has to be some more you know process that should go in is it not is crystallizing or using even though sand is abundantly available you cannot make a silicon wafer at home just like you could make a sugar crystal at home you cannot do the same for silicon wafers is this finger is this thing clear yes so then we because if this thing is clear we can then move to the next step of how this wafer is fabricated so uh the complexity of vlsi design or vsf fabrication starts from the very base of how to manufacture this crystal which has the same direction and the same plane as we wanted to be okay so uh what is done is we use a silicon crystal and we dip it in molten silicon and this silicon crystal that we have we put it so carefully into our uh uh into our uh instrument so that it when it goes the dips into the molten crystal it then starts to crystallize you know it solidifies according to the crystals orientation so the orientation of my seed crystal is carefully chosen and determined and only then you dip it into there okay and then you slowly pull out this crystal from from this molten mass and the speed with which you pull it out so you rotate it and you pull it out the speed with which you pull it out will define the width of this in got so this is called as in got okay and based on this you will be able to make 6 inches 8 inches or 12 inch wafers 12 inch wafer is this big diametrically okay so i can actually literally hide my face behind the 12 inch even 8 inch wafer it can fairly hide my face don't probably not my hair but a 12 inch will hide everything of my face and here okay so this this big wafers uh coming out of it and can you imagine the weight of this whole ingot as it would pull it out and a 12 inch wafer you know so it's huge so this process is called so so we did this this is a this is a of vacant phrase so to choose falci process okay so uh this is how ingots are made once the ingots are made do you see that this ingot has a lot of these uh you know contours on its surface are you able to see this so what this means is that the sim card cannot be used directly to make wafers because then some wafers will be 12 inch uh 12 inch wide or 12 inch diameter some would be 12.1 others would be 12.2 and so on but all your machines are designed for a see we need nanometer level accuracy in our machines so the machines are designed such that they 112 inch wafer so you cannot really handle 12.1 inch also and 12.2 inch also and then say oh i will give you the accuracy of nanometers when i expose the or when i make your wafers or when i make your silicon dies so here it says the process has to be you know some something needs to be done so that each wafer is exactly okay so since i forget the formula sorry because we just put in one crystal and as we are pulling it out from that molten material the silicon atoms would align to align to the existing crystalline structure so there would there would be just one crystal there i don't get it yeah so then this is not an ic of course you will need to probably read a little more of it off the course but yeah this is the way you tip a crystal there and all now because this is the property of the material that atoms will bond with other atoms in the orientation of the existing crystal okay yeah okay and then when you slowly pull it out those atoms are now a part of that earlier crystal so they become a bigger crystal okay and then as you pull it out it becomes a still bigger crystal a still bigger question and until you reach that width until you reach that width of let us say 12.5 inches you you just pull it out very very slowly you slowly you know you you pull it out and then you say that okay now at a stable speed i will pull it out so that all the crystals are at that 12 inch approximately 12 12.5 inch wide uh wafer there okay so for dedicated machine that it is like forming okay if you want to relate to that i will not but yeah it's okay whatever helps you on your understanding rather uh sir like for example you said that we are not only interested in manufacturing the silicon crystal but a particular orientation so so like we put the crystal in a particular orientation and we pulled it out so but still for example we are getting the whole crystal and if you are getting the crystal all the particular orientations are still possible so we need to then have to be in direction also okay this is the from where can i get the orientation like because i cannot access that so when you are seeding at that point of time the orientation is established with the help of a microscope so but still i'm getting the crystal right so in crystal every orientation is possible yeah yeah that is okay if you make if you have a crystal with this kind of a plane then it will it will grow like this only whichever plane you choose that is how it will grow that is the property of a crystal okay so i have chosen the plane also okay this is the plane okay yeah okay sir ingot is something that holds the silicon crystals and what is that huge mass of uh silicon circular mass of silicon which through which you will slice and get the crystals okay sir okay that is what we are on and looking at going to look at in this slide so you first get that n got and then you slice it to make crystals or to make wafers these wafers then you grind so that they are all circular because you we just saw that they may not be all circular at all times so then the grinding is done so that you get circular wafers of exactly 12 inch diameter or or eight inch diameter or six inch diameter whichever your machining is ready for okay and then because you slice these crystals so you've tried to cut let us say slices of cucumber or tomato at home for making salad yes sir can you always cut them in the same of the same width no sir so it can happen that some wafers are thicker some are not as thick but again realize that our machining is such that it can it has to make things which are accurate to the level of nanometers so you cannot really have different thickness of wafers otherwise the light that will fall from the top will not fall at the side right angle okay sir uh this is the reason why amalek will get the wafer in a circular shape i'm like we are dipping it out and the way it spreads it will be a circle i'm like one of the person so we this this was a question in the last class i have to why don't you make it square now if i have to make it square i have to cut some part of the circular wafer which actually leads to more loss of you know if in a circular wafer you will probably be able to get more dice than a square which has a smaller size than it so in lapping in the second step that you do wrapping you actually make the thickness of the wafers exactly let us say five millimeter or uh two millimeters or whatever is the agreed specification for that particular wafer okay then you do the polishing because all this grinding and lapping there could be some broken bonds on the on the and dislocations that you may have introduced on the surface of the wafer so do the polishing and then you dope it the the substrate is typically p type doped and uh and you then create a flat so you dope the you do you dope uh boron into it let us say so it is p type and uh then what you do the circular wafer you create a flat over here a little flat when you have an n type then you also create a secondary flap so this flap would be let us say uh four centimeters this flat would be something like two centimeter i don't know the exact numbers you can find out on the internet if you are interested but in an entire wafer you will have two flats in a p-type wafer you have one plant okay in advanced technologies or today you do not even talk of flat you talk of what is called as a notch and uh that notch defines that this like this is the notch so if my current flows in this particular direction i will be using one one one kind of direction so the notch not only defines uh that this is an n type or a p type but it also tells where is the one one one plane or one one zero direction so to say in that particular wafer because the current flow uh the electrical properties in different directions are different so we also need to tell the user that this is where this is how you should fabricate it this is how you should place the wafer in your fabrication machinery okay any questions still here so uh in the in god which we are making will it have like uniform diameter throughout no that is why we need to do grinding ah okay sir so like how can we know like what is the diameter of the ingot that is formed and can we know it before uh creating the angle yeah like you know the cooling rate you you can control the temperature of your furnace you can do everything so that you can estimate you know this this is a physical model you can which actually can be easily made and it is existing so the speed at which you are pulling the wafer out and everything and the site can easily be used to decide the size of the ingot okay it's a physical process the purely physical process will characterize physical process oh sir you said that when we were pulling out the in god we were pulling out in the direction uh which was corresponding to the orientation which we wanted right so like now what exactly we are doing this is flat because because we know that okay like this is the orientation i got so that is the plane we are saying this is the plane but in a plane also for example if we look at the plane a face centered cubic plane so if i go in this direction there will be one kind of resistance if i 
go in this direction there will be another kind of resistance are you able to see this yes sir so i need to tell which direction to go because that is where all my models and all my everything is designed for okay okay so at the ingot level i have only got the plane orientation but now the direction you get lanes now this is only a big plane that you know now you need to know the direction also so that you can actually then fabricate your gates in the right orient right direction within that plane yes okay okay so okay okay you also wanted to ask something deepak suddenly yes sir so sir we are making this notch so some amount of silicon would be wasted right yeah we make that is why we don't know we now don't make a flat you make a notch notch is a small thing flat would have really taken a lot of silicon off but notch is a small thing we don't want to wear silicon wafer area can't you make a mark or something why cut silicon so this notch is also very small if you make a mark you will have to physically you know visually see it and align it a notch is easy because mechanically you can just lock your wafers into the notch when you are transferring wafers from one machine to another a physical asymmetry is always easier to handle in the manufacturing processes than a planar visual asymmetry because then you will need to have cameras and lasers and do everything to align the wafer every time with a notch you just need to get the wafer in and you know the notch is already established and fixed in there so the wafer is properly aligned right so when we are talking about the orientation of a crystal like the crystal is a spherical kind we look at crystalline structures in cuboid from cubic and uh space center we are talking about their orientations and okay okay is everyone comfortable with hindi language is asking something in hindi is everyone comfortable with that anyone who does not understand hindi in this class can you put a plus one in the chat window oh so everyone is comfortable with hindi oh there is deja who is not okay so no issues so actually uh uh currently we have designed a vapor so uh we have prepared a substrate now okay so we have doped and we have built up right now uh what we will do we just build upgrades our source and drain forward uh that the thing is completely perpendicular to the surface so now the current would flow from the top of the gate or from the top of the source of transistor exactly the current flow uh inside the substrate would completely uh would be decided by this uh flat what we are preparing what or it could random direction randomly so if you know that this is the 1 1 direction and you want to orient or you want to have the current flow in in a particular direction you can make uh devices like that such that uh the current will flow in your desired direction you know one direction this is the so you've given you've been given a reference now see consider it like this uh you go to a uh amusement park and you get a map on how to navigate in this amusement park what is the most important thing that you need to look at where are you you are here that that mark okay i am here now in this context i can go left right wherever but that you are here is most important is it not yes so this knot is the you are here mark okay okay yes you said when we are saying that i want to i want to make the current run in only single direction so does that mean i cannot make a mosfet on layout which is in another orientation if i rotate it by 90 so if you do then there could be some consequences which may not be acceptable to you you will see we will just have a look at what happens when you rotate the wafer there's a slide on that don't worry"
jh6qhtM88KM,so this is the next slide so if you rotate the wafer what happens so until I would say uh 2002 2004 2006 so this is this is February 20 2006 look at this huh so until this time uh Wafers were made in this kind of a format one one zero so it says that your current would flow in one one zero Direction okay but uh Thomas Scott Nikki hmm proposed in 2006. to rotate the substrate such that current would flow in one zero zero Direction now why was this required or and what how did it help so the fact is that in Silicon there are uh two kinds of holes some are light holes so light holes means that the gradation of change of your electric electrostatic field is is sharp and some are heavy holes so if you look into this direction or you know this this hole if you look into this plane this hole would be a heavy hole so in the standard Wafers there were light holes and also heavy holes because uh there was a direction of movement which considered this bad slope and also the so this was symmetrical it's escalated whole whole Mobility was not changing but for this the whole Mobility was changing if you would move in One Direction or the other but when you rotated the wafer what happened when you rotated the wave so you came to this you came to this part of the wafer where this extra lobe was not not a part of your current flow and therefore rotated Wafers also had light holes only so overall mobility of the of the holes improved what does improved whole whole mobility mean that now to get the same current I can have a smaller device so the p2n ratio which was traditionally kept to be something like uh between 2.5 and 3 from this technology onwards which was I think 65 or yeah 65 onwards whole Mobility was significantly improved and you could have P by and ratio closer to two whole Mobility was still worse than electron Mobility but it significantly improved just because you rotated the wafer okay and there was actually no change in electron Mobility because for electrons whether the Wafers are rotated or not the effective weight was same so vulnerability to improved electromobility remains same no degradation on the electron mobility and you've got a win-win kind of a solution you could say more area okay sir that is the importance of understanding what the notch means and how to use the notch yes slither because of the mobility the effective mass is changing or because of the effective mass of Mobility because of the effective Mass Mobility is changing okay okay Mobility is a behavior which depends on the mass a heavier substance would move slower yes sir understood yeah okay so once the wafer is ready you know that I have to use rotated substrate and everything then you go into the manufacturing phase and interestingly in Silicon manufacturing there are a few steps which are just repeated over and over again these are implantation oxidation and deposition so implantation is in fact a front-end process and deposition is then subsequently a backend process so what are we saying that you will make layers of so this is my silicon wafer let us say yeah so you will first implant something onto it after you've implanted you will make a layer of oxide okay then you will deposit something on it which which you would call as a photoresist and then you will remove this photoresist in a patterned manner okay so you will remove it from here let us say so over here you have created a window such that this oxide becomes now visible to incident light so when the light will come it will now be able to fall here but not fall here okay stuff like that so pattern removal and then again implementation implantation or patent removal or oxidation or the position of some of these steps would come you just repeat these over and over again and you're finally able to build your silicon die consider it like this if I have to make a 20 storage building what do I need to do let us let us assume that you have come to the ground level now so what do I need to do I need to make pillars I need to make the walls I need to make the roof for the next level I again need to grow the pillars more I need to make the balls I need to make the roof or whatever pillars roof wall pillars roof wall filler's roof wall and I can go to as many stories as I want to in a similar manner the Silicon manufacturing process also use this the same steps to overall build the wafer over and over again to make multiple layers of metals and so on ticket so this is a primer and this is an example in fact Let us look at an example over here we had a silicon substrate we drew oxide on it or we deposited oxide on it then we deposited photoresist on it then we expose this photoresist they expose this photoresist to a glass mask so you see over here there is a black black line there so light will not pass but over here the glass is transparent so light would pass and this part of the photoresist would get exposed to this light now this photoresist it why is it called a photoresist because it is sensitive to photons it is sensitive to light its chemical properties would change when light falls on it so then you clean this wafer which was already exposed with a acid let us say hydrofluoric acid address and this this part which was exposed that would go away now what you do after this part goes away now what you do you etch h means you remove whatever is available uh visible from the top now so this photoresist is hardened it cannot be etched but the remaining oxide which you had deposited in this phase it will be etched so now you have this kind of a structure in there what will you do now you will remove the photoresist and you will let us say implant boron what would happen Boron would not go beneath this oxide layer but over here you will form a p plus region huh are you able to see this then when you need to make the next layer all that you need to do is again deposit oxide so your gain deposit oxide you again put a photoresist you again expose now a different part and uh so after that after you expose that part then something can be deposited over here in this region okay we will look at it in a little more we will exemplify it a little more in a few minutes but what is essentially happening is that you have a light source and a condenser so we are talking about Optics now so condenser would what does our collimator do condenser do it makes all the rays of light parallel so what happens then this is this is exposed to a mask where there are Parts which are blacked out so that light cannot pass through it and then after the mask there is a projection lens which will again refocus these parallel lights into converging lights and you will be able to expose underlying silicon wafer so this is Wafer already written there you will expose the underlying silicon wafer with light okay so as I mentioned 190c nanometer light has been used for all these technos even in someone people even tried 16 nanometer with 193 nanometer light it does not very so there is lots of diffraction lots of things that come into picture but people have even manufactured 16 nanometer chips with uh 192 nanometer light so what they need to do is to manage the diffraction path they need to say that okay uh if you want to make this kind of a poly you make slits in The Mask you make dummy Pollies around it for this distance so that after diffraction I am able to achieve this poly shape accurately so there are rules that are design rules that are added to be able to enable use of 196 nanometers even at Advanced Technologies There Are Rules which say that two polies uh if they are this close let us say then they will be made on two masks so this will be mask a and this will be mask B so this is called dual patterning why two masks because they cannot really be drawn this close with the 192 nanometer light there there will be diffraction and the one of the gates would die out so you say okay I will first expose a and the next step I will expose B so they are not actually made together they are made just this one first at a time and this one at the other time so there will be another B here so in in between B's there is more spacing and then between A's there is more spacing and they are very complex design rules to manage A and B independently so this is called colored layout so a is one color and b is another color you seriously yes so is there something special with 193 nanometer light that we are using just to manufacture even smaller yeah this is arden-based laser okay so and that was the so how how do you get this wavelength of light how do you get any light source if we studied that in physics Optics 11 12 also how do you get a light source what happens electrons jump from one level to another yeah electrons go to the outer level outer orbital and they fall to an inner orbital and as they fall they release energy because in an orbital has lower energy and that energy comes out as light so you cannot say that I will get 193 nanometer light and now tomorrow I will want 188 nanometer light no it doesn't happen like that the you know you have to find a material which will which will be able to give you that light and we're not talking about lasers what does a laser mean that this just one wavelength of light so typically when you look at your tube light it would generate wavelengths in different in the entire visible spectrum is it not all the wavelengths of light in the visible spectrum it will generate but the laser pointer that you have it will only generate infrared or red or some particular wavelength of light so you're talking about lasers of different uh wavelengths three materials to be able to generate that is it not yes so but we can use other techniques like we may be doing by some means we can do fabrication inside a medium that is optically denser so wavelength so that is what we so that is already done we use immersional lipography you asked me about how does 193 figure it 193 figures and because the material which is used to generate that laser is generating 193 nanometers finding a different material as a material scientist work and it is ongoing at a very very high Pace that is how you finally arrived at UV euv machines also that we were talking about in the last class because we could find the different materials but generating this light is here is also difficult yes more importantly you need a laser uh so just the save length of light no other wavelength then you need to ensure that whatever the slide source is it can generate light for longer durations of time so that this light carries some energy with it and is able to expose and is able to work on the photoresist you need some energy to also be a part of it does that wavelength and two and two photons is not sufficient you need a sufficient number of photons to be there to be able to react with the photoresis there you need some wattage then it should be sustainable it should be able to work for 24 hours a day 365 365 days a year because otherwise uh your production will have to stop every now and then you see there are so many constraints yes sir thank you okay Faisal you had a question in this 193 nanometer technology if we need a and b 193 nanometer lights We Want A and B to be closed so that is why we are using two Mass because it cannot be possible with with this 193 the fraction will the fraction will not let it happen that is why we were saying with 13 nanometer we can have uh A and B closer on the same on the same mask and that is how the number yes and that is why we reduce the mass cost yeah okay okay so what is this term colored layout you have used color layout means that uh see otherwise poly is just poly for example you just make all the polys same way color layout means that now there are two colors in the layout poly also is of two colors so have you seen a layout in your refresher course yes sir so you see a red color could be used for poly green for active and so on yes sir so all poly was red only you know yes sir in in 16th and fat or in Advanced Technologies you will see poly is also in two colors red and yellow let us say but it is in two colors because they are coming from different Mass here yes okay because if you want to manufacture them in different marks and so this is because we're doing because we have to be we want to uh counter the effects of diffraction right yes because we want to use this cheaper source of light 190 nanometer light still as long as possible euv is costlier okay answer what was the concept of dummy poly that how is different from this one because uh in both we are manufacturing for in one we are making more masks in dual partnering but in dummy poly what you're doing dummy poly is for example I just wanted to make a okay I just wanted to make an a this is simply not possible to make an a which is let us say 16 nanometer wide so what you do is you also there is no sufficient energy in the light it's because the wavelength of light is 193 nanometer in a slit of 60 nanometer nothing will come true so what you do is you also make slits here so that the light diffracted from here will also reach here and expose the photoresis down here so this is called as dummy poly okay so we are basically doing some technique within the same mask itself yeah this is all objects okay okay but here in dummy here because of dummy poly we're not increasing any Mass cost right no no yes what is happening is that you may actually end up so the next poly could only be here now okay okay we are basically exploiting the diffraction part of it yes okay okay so I think till now you've already understood that vlsi is not just an Electronics job you have chemical Engineers material scientists physicists Optical Engineers Quantum physicists and everyone involved in making Electronics possible is this evident to you now yes yes there's not designers like you and me who have made vlsi hot it is someone else yes sir and Sir why did you said that the deposition was a back-end process that will be no so we will come to that okay then if you had a question yes sir uh when we talk that we are shrinking the technology so mask also gets smaller Mars would be uh mask size would depend on how big your die is if your die has become smaller then yes if your diet remains same then no listen eventually then we will I mean we will also be using these techniques for making masks so mask for a mask so mask see masks so you can actually use uh use uh plasma etching to make the mask kind of microscopic etching you can do to make the mask that is still possible only what really make every feature by hand mask you can make actually make every feature by hand yes sir okay that is why Mass making cost is very high in Advanced Technologies because features have to be more handcrafted than stuff like that okay so this is what I was talking about that as you go to Advanced Technologies mask costs are increasing okay and this despite we are going to 193 I I stands for immersion immersion means that you use uh use a liquid in the machine so that light passes through a liquid and overall numerical aperture changes and all the Optics comes in okay and because the you know Mass costs are so high it is extremely important it is extremely extremely important that whenever you put any design on Silicon it should be first time right you cannot have reruns on Silicon see software jobs are much easier you make a bug even then you know you've shipped the product to the customer and you will say oh there is an update on the air update update your phone fine a soft server can be corrected like that Hardware work once it is there then you have to go through the entire process of Hardware designing over and over again and the next product will come out only after six to seven months at the earliest so you cannot afford to have any bugs or errors left in your design when you sign it off okay so a quick review or a quick view of how fabrication happens so this is this is something that uh I myself also did in in my master's program because my University had a Fab a small Fab fabrication facility there but these photos are from a course from University of Maryland so you can check that out online but yeah so what what you do is you you make a field log site and then by exposing a light to a mask you after etching get something like this okay then as a Next Step you say that you would want to deposit poly silicon so you grow gate oxide and then you deposit polish silicon and you etch out polysilicon from areas there you do not want the gate so polysilicon and oxide are edged out from all this region and you get what you call as a polygate are you able to realize this is something like a polygate that you would have seen then you start to so this is how the images would the the microscopic images look like and you see this is the depth of the oxide that you had drawn that you had manufactured that you had grown and uh the polygate is there then you do the doping of the source and the drain which which results in this n plus and uh regions being designed and then you deposit metal once you deposit the metals what do you do um sorry not metal this is a oxide again in which you will then create these slits in these slips you will then make a contact on the silicon source and drain region you see these contacts appear like this this is the contact on the poly region the gate region these are the contacts on the source and drain and uh once you've made these contacts you deposit a metal and you remove the metal from the parts where you did not want the connection so this is how your die looks like now okay and I think this is uh the one that we worked on was something like 0.5 Micron Technology or something like that and you see this kind the you wanted you made a contact and you wanted to make a wire over it but you see what has happened such a large part of the contact there is no metal so if there is no metal it means silicon is contacted with metal through a lesser surface area so the real resistance of this contact will be higher than the resistance that you would you had wanted it to be are you able to see this you wanted this resistance this contact to be this big but in reality the contacted area is only this so the current flow is now happening through you know through a lesser area than earlier so the resistance of this contact will be higher than what you had intended it to be and this is just 0.5 Micron Technology today we are talking about five nanometer 1.5 now you see this is such inaccuracy so five nanometer code just to get five nanometer working the kind of precision you require in the machines is tremendous it's a lot of hard work to to ensure a working guide here okay a huge advancement in technology has enabled where we are today okay so now we just saw how the first metal is drawn so what is happening there are oxidation status where you make the gate dielectric you make intermittent dielectric and you also use oxide as mask for example when we had to deposit the metal we used oxide as the mask is it not wherever the metal uh wherever the oxide was not there metal wood could go down and contact with the source and drain region so oxidation is used for different purposes to deposit stuff we deposited the gate in the example we also deposited aluminum or the interconnects pattern removal means etching an implant implantation is dopants to modify the electrical you know doping the source and drain region so you see these steps were repeat were done over and over again some were done twice some are done once to be able to make the transistor that we just saw and when you do it over and over again when you do it over and over again you start to get what is called as uh multiple metal layers so not just one layer of metal but second third fourth so in a typical uh uh so even in the DK that you may have used during a fresher program you would have noticed you could go up to metal sticks metal seven and so on so those metals were just extra stories that were built over the basic metal structure there okay so we are in the slide which is called dual damaging process have any one of you heard about dual dimension yes sir what is dual damaging so basically you want to reduce a process step when we want to make a VR so we do the etching twice and make a via that is of metal itself we do not deposit anything else okay mother you wanted to ask something yes so how do we con so we can control the area and the shape of these of everything by using the mask but how do we control the height like the deposition height of let's say the metal oxide that we were depositing how do we control that type you deposit it for a longer duration of time okay so duration okay so longer duration means uh higher bigger yeah you could do that or you could uh let us say later on you do CMP which is called chemo mechanical polishing so even if you look at the previous slides you know uh what we were showing was that uh see what happens do you think this this oxide was always this thick was it always this this thick only no when you had fabricated the oxide it would have been slightly wavy you polished it so that is called CMP chemo mechanical planarization so use chemicals and you use mechanical scrubbing to polish planarize the surface so when you do this you can actually plannerize it a little more and have lesser thickness there is it not yes sir so you could change the duration to increase or decrease the thickness and then CMP is the process through which you can finally arrive at the exact thickness that you needed okay so so while doing a metal one deposition you said that we can use the oxide as a mask so but exactly we're not using oxide as mass because where to H in the oxide that for that also you'll be using some other kind of yeah so I think the oxide there was a different mask but for depositing the metal oxide is the mass is it not okay okay okay fine fine so answer one more thing so in a previous slide uh you said that uh there was a point mentioned that using diffraction to enhance the resolution that wasn't clear to me so Productions you will see that in diffraction and when when when a large wavelength of light passes through a slit which has lesser width lesser uh you know a width which is a slit which is smaller than the wavelength of light like the facts yes sir yes sir yeah multiple slits placed to each other and placed close to each other light from the adjacent slits will also come below this first letter yes sir yes sir in so the kind of energy that comes below the first one would be significant enough now to be able to cause the etching whereas the common light falling below slit two and would be lesser than that okay so we're talking about the interference interference and the fractions we're talking about hardcore Optics there okay okay sorry okay okay so for others if it is really going over your head don't worry this is not a course on Optics this is not a course on fabrication also this is just an introduction to fabrication that we want that I want you to have so that you can then choose your coursework appropriately or you get to you know if someone is asking you a question on vlsi in in our interview you know have a well-rounded view of everything even if you have not done that exact course you have better understanding of the overall ecosystem there okay that is why I'm just covering it so don't need to worry too much about it mother you have a question okay so as within the said so that dual Dimension process is used to reduce a process step uh it may not be as intuitive to all of you on yet but let me explain it to you see in a typical manufacturing process what you do is you if you look at the this side first what you do is you you know make an oxide you put a when deposit a photo resist you do whatever you expose light you then etch when you etch you are able to make these holes in your system so that these holes will now allow or deposit metal layers and whatever you can so you would do this step for making a contact you will do this step for making a via so a contact is from Silicon to metal one okay and a via is from any other metal metal one select a five pack to the next metal layer metal two select a six packs okay so contact is made out of tungsten Vias initially let us say until 130 nanometer technology also vrs are made out of tungsten y tungsten we will just come to that but till that time we also made out of tungsten after 130 nanometer and wires at that time were made out of aluminum in in more Advanced Technologies wires are today made out of copper so why do we need to shift to Copper from aluminum this is the physical property of copper versus aluminum inductility ductility that purpose you can make much thinner wires and as you go to more advanced symmetry you wanted thinner wires additionally copper is less resistive than aluminum if you are making a thin wire its resistance would increase but by going to Copper you could reduce the resistivity also,https://www.youtube.com/watch?v=jh6qhtM88KM,"Link: https://www.youtube.com/watch?v=jh6qhtM88KM
Transcript: so this is the next slide so if you rotate the wafer what happens so until I would say uh 2002 2004 2006 so this is this is February 20 2006 look at this huh so until this time uh Wafers were made in this kind of a format one one zero so it says that your current would flow in one one zero Direction okay but uh Thomas Scott Nikki hmm proposed in 2006. to rotate the substrate such that current would flow in one zero zero Direction now why was this required or and what how did it help so the fact is that in Silicon there are uh two kinds of holes some are light holes so light holes means that the gradation of change of your electric electrostatic field is is sharp and some are heavy holes so if you look into this direction or you know this this hole if you look into this plane this hole would be a heavy hole so in the standard Wafers there were light holes and also heavy holes because uh there was a direction of movement which considered this bad slope and also the so this was symmetrical it's escalated whole whole Mobility was not changing but for this the whole Mobility was changing if you would move in One Direction or the other but when you rotated the wafer what happened when you rotated the wave so you came to this you came to this part of the wafer where this extra lobe was not not a part of your current flow and therefore rotated Wafers also had light holes only so overall mobility of the of the holes improved what does improved whole whole mobility mean that now to get the same current I can have a smaller device so the p2n ratio which was traditionally kept to be something like uh between 2.5 and 3 from this technology onwards which was I think 65 or yeah 65 onwards whole Mobility was significantly improved and you could have P by and ratio closer to two whole Mobility was still worse than electron Mobility but it significantly improved just because you rotated the wafer okay and there was actually no change in electron Mobility because for electrons whether the Wafers are rotated or not the effective weight was same so vulnerability to improved electromobility remains same no degradation on the electron mobility and you've got a win-win kind of a solution you could say more area okay sir that is the importance of understanding what the notch means and how to use the notch yes slither because of the mobility the effective mass is changing or because of the effective mass of Mobility because of the effective Mass Mobility is changing okay okay Mobility is a behavior which depends on the mass a heavier substance would move slower yes sir understood yeah okay so once the wafer is ready you know that I have to use rotated substrate and everything then you go into the manufacturing phase and interestingly in Silicon manufacturing there are a few steps which are just repeated over and over again these are implantation oxidation and deposition so implantation is in fact a front-end process and deposition is then subsequently a backend process so what are we saying that you will make layers of so this is my silicon wafer let us say yeah so you will first implant something onto it after you've implanted you will make a layer of oxide okay then you will deposit something on it which which you would call as a photoresist and then you will remove this photoresist in a patterned manner okay so you will remove it from here let us say so over here you have created a window such that this oxide becomes now visible to incident light so when the light will come it will now be able to fall here but not fall here okay stuff like that so pattern removal and then again implementation implantation or patent removal or oxidation or the position of some of these steps would come you just repeat these over and over again and you're finally able to build your silicon die consider it like this if I have to make a 20 storage building what do I need to do let us let us assume that you have come to the ground level now so what do I need to do I need to make pillars I need to make the walls I need to make the roof for the next level I again need to grow the pillars more I need to make the balls I need to make the roof or whatever pillars roof wall pillars roof wall filler's roof wall and I can go to as many stories as I want to in a similar manner the Silicon manufacturing process also use this the same steps to overall build the wafer over and over again to make multiple layers of metals and so on ticket so this is a primer and this is an example in fact Let us look at an example over here we had a silicon substrate we drew oxide on it or we deposited oxide on it then we deposited photoresist on it then we expose this photoresist they expose this photoresist to a glass mask so you see over here there is a black black line there so light will not pass but over here the glass is transparent so light would pass and this part of the photoresist would get exposed to this light now this photoresist it why is it called a photoresist because it is sensitive to photons it is sensitive to light its chemical properties would change when light falls on it so then you clean this wafer which was already exposed with a acid let us say hydrofluoric acid address and this this part which was exposed that would go away now what you do after this part goes away now what you do you etch h means you remove whatever is available uh visible from the top now so this photoresist is hardened it cannot be etched but the remaining oxide which you had deposited in this phase it will be etched so now you have this kind of a structure in there what will you do now you will remove the photoresist and you will let us say implant boron what would happen Boron would not go beneath this oxide layer but over here you will form a p plus region huh are you able to see this then when you need to make the next layer all that you need to do is again deposit oxide so your gain deposit oxide you again put a photoresist you again expose now a different part and uh so after that after you expose that part then something can be deposited over here in this region okay we will look at it in a little more we will exemplify it a little more in a few minutes but what is essentially happening is that you have a light source and a condenser so we are talking about Optics now so condenser would what does our collimator do condenser do it makes all the rays of light parallel so what happens then this is this is exposed to a mask where there are Parts which are blacked out so that light cannot pass through it and then after the mask there is a projection lens which will again refocus these parallel lights into converging lights and you will be able to expose underlying silicon wafer so this is Wafer already written there you will expose the underlying silicon wafer with light okay so as I mentioned 190c nanometer light has been used for all these technos even in someone people even tried 16 nanometer with 193 nanometer light it does not very so there is lots of diffraction lots of things that come into picture but people have even manufactured 16 nanometer chips with uh 192 nanometer light so what they need to do is to manage the diffraction path they need to say that okay uh if you want to make this kind of a poly you make slits in The Mask you make dummy Pollies around it for this distance so that after diffraction I am able to achieve this poly shape accurately so there are rules that are design rules that are added to be able to enable use of 196 nanometers even at Advanced Technologies There Are Rules which say that two polies uh if they are this close let us say then they will be made on two masks so this will be mask a and this will be mask B so this is called dual patterning why two masks because they cannot really be drawn this close with the 192 nanometer light there there will be diffraction and the one of the gates would die out so you say okay I will first expose a and the next step I will expose B so they are not actually made together they are made just this one first at a time and this one at the other time so there will be another B here so in in between B's there is more spacing and then between A's there is more spacing and they are very complex design rules to manage A and B independently so this is called colored layout so a is one color and b is another color you seriously yes so is there something special with 193 nanometer light that we are using just to manufacture even smaller yeah this is arden-based laser okay so and that was the so how how do you get this wavelength of light how do you get any light source if we studied that in physics Optics 11 12 also how do you get a light source what happens electrons jump from one level to another yeah electrons go to the outer level outer orbital and they fall to an inner orbital and as they fall they release energy because in an orbital has lower energy and that energy comes out as light so you cannot say that I will get 193 nanometer light and now tomorrow I will want 188 nanometer light no it doesn't happen like that the you know you have to find a material which will which will be able to give you that light and we're not talking about lasers what does a laser mean that this just one wavelength of light so typically when you look at your tube light it would generate wavelengths in different in the entire visible spectrum is it not all the wavelengths of light in the visible spectrum it will generate but the laser pointer that you have it will only generate infrared or red or some particular wavelength of light so you're talking about lasers of different uh wavelengths three materials to be able to generate that is it not yes so but we can use other techniques like we may be doing by some means we can do fabrication inside a medium that is optically denser so wavelength so that is what we so that is already done we use immersional lipography you asked me about how does 193 figure it 193 figures and because the material which is used to generate that laser is generating 193 nanometers finding a different material as a material scientist work and it is ongoing at a very very high Pace that is how you finally arrived at UV euv machines also that we were talking about in the last class because we could find the different materials but generating this light is here is also difficult yes more importantly you need a laser uh so just the save length of light no other wavelength then you need to ensure that whatever the slide source is it can generate light for longer durations of time so that this light carries some energy with it and is able to expose and is able to work on the photoresist you need some energy to also be a part of it does that wavelength and two and two photons is not sufficient you need a sufficient number of photons to be there to be able to react with the photoresis there you need some wattage then it should be sustainable it should be able to work for 24 hours a day 365 365 days a year because otherwise uh your production will have to stop every now and then you see there are so many constraints yes sir thank you okay Faisal you had a question in this 193 nanometer technology if we need a and b 193 nanometer lights We Want A and B to be closed so that is why we are using two Mass because it cannot be possible with with this 193 the fraction will the fraction will not let it happen that is why we were saying with 13 nanometer we can have uh A and B closer on the same on the same mask and that is how the number yes and that is why we reduce the mass cost yeah okay okay so what is this term colored layout you have used color layout means that uh see otherwise poly is just poly for example you just make all the polys same way color layout means that now there are two colors in the layout poly also is of two colors so have you seen a layout in your refresher course yes sir so you see a red color could be used for poly green for active and so on yes sir so all poly was red only you know yes sir in in 16th and fat or in Advanced Technologies you will see poly is also in two colors red and yellow let us say but it is in two colors because they are coming from different Mass here yes okay because if you want to manufacture them in different marks and so this is because we're doing because we have to be we want to uh counter the effects of diffraction right yes because we want to use this cheaper source of light 190 nanometer light still as long as possible euv is costlier okay answer what was the concept of dummy poly that how is different from this one because uh in both we are manufacturing for in one we are making more masks in dual partnering but in dummy poly what you're doing dummy poly is for example I just wanted to make a okay I just wanted to make an a this is simply not possible to make an a which is let us say 16 nanometer wide so what you do is you also there is no sufficient energy in the light it's because the wavelength of light is 193 nanometer in a slit of 60 nanometer nothing will come true so what you do is you also make slits here so that the light diffracted from here will also reach here and expose the photoresis down here so this is called as dummy poly okay so we are basically doing some technique within the same mask itself yeah this is all objects okay okay but here in dummy here because of dummy poly we're not increasing any Mass cost right no no yes what is happening is that you may actually end up so the next poly could only be here now okay okay we are basically exploiting the diffraction part of it yes okay okay so I think till now you've already understood that vlsi is not just an Electronics job you have chemical Engineers material scientists physicists Optical Engineers Quantum physicists and everyone involved in making Electronics possible is this evident to you now yes yes there's not designers like you and me who have made vlsi hot it is someone else yes sir and Sir why did you said that the deposition was a back-end process that will be no so we will come to that okay then if you had a question yes sir uh when we talk that we are shrinking the technology so mask also gets smaller Mars would be uh mask size would depend on how big your die is if your die has become smaller then yes if your diet remains same then no listen eventually then we will I mean we will also be using these techniques for making masks so mask for a mask so mask see masks so you can actually use uh use uh plasma etching to make the mask kind of microscopic etching you can do to make the mask that is still possible only what really make every feature by hand mask you can make actually make every feature by hand yes sir okay that is why Mass making cost is very high in Advanced Technologies because features have to be more handcrafted than stuff like that okay so this is what I was talking about that as you go to Advanced Technologies mask costs are increasing okay and this despite we are going to 193 I I stands for immersion immersion means that you use uh use a liquid in the machine so that light passes through a liquid and overall numerical aperture changes and all the Optics comes in okay and because the you know Mass costs are so high it is extremely important it is extremely extremely important that whenever you put any design on Silicon it should be first time right you cannot have reruns on Silicon see software jobs are much easier you make a bug even then you know you've shipped the product to the customer and you will say oh there is an update on the air update update your phone fine a soft server can be corrected like that Hardware work once it is there then you have to go through the entire process of Hardware designing over and over again and the next product will come out only after six to seven months at the earliest so you cannot afford to have any bugs or errors left in your design when you sign it off okay so a quick review or a quick view of how fabrication happens so this is this is something that uh I myself also did in in my master's program because my University had a Fab a small Fab fabrication facility there but these photos are from a course from University of Maryland so you can check that out online but yeah so what what you do is you you make a field log site and then by exposing a light to a mask you after 
etching get something like this okay then as a Next Step you say that you would want to deposit poly silicon so you grow gate oxide and then you deposit polish silicon and you etch out polysilicon from areas there you do not want the gate so polysilicon and oxide are edged out from all this region and you get what you call as a polygate are you able to realize this is something like a polygate that you would have seen then you start to so this is how the images would the the microscopic images look like and you see this is the depth of the oxide that you had drawn that you had manufactured that you had grown and uh the polygate is there then you do the doping of the source and the drain which which results in this n plus and uh regions being designed and then you deposit metal once you deposit the metals what do you do um sorry not metal this is a oxide again in which you will then create these slits in these slips you will then make a contact on the silicon source and drain region you see these contacts appear like this this is the contact on the poly region the gate region these are the contacts on the source and drain and uh once you've made these contacts you deposit a metal and you remove the metal from the parts where you did not want the connection so this is how your die looks like now okay and I think this is uh the one that we worked on was something like 0.5 Micron Technology or something like that and you see this kind the you wanted you made a contact and you wanted to make a wire over it but you see what has happened such a large part of the contact there is no metal so if there is no metal it means silicon is contacted with metal through a lesser surface area so the real resistance of this contact will be higher than the resistance that you would you had wanted it to be are you able to see this you wanted this resistance this contact to be this big but in reality the contacted area is only this so the current flow is now happening through you know through a lesser area than earlier so the resistance of this contact will be higher than what you had intended it to be and this is just 0.5 Micron Technology today we are talking about five nanometer 1.5 now you see this is such inaccuracy so five nanometer code just to get five nanometer working the kind of precision you require in the machines is tremendous it's a lot of hard work to to ensure a working guide here okay a huge advancement in technology has enabled where we are today okay so now we just saw how the first metal is drawn so what is happening there are oxidation status where you make the gate dielectric you make intermittent dielectric and you also use oxide as mask for example when we had to deposit the metal we used oxide as the mask is it not wherever the metal uh wherever the oxide was not there metal wood could go down and contact with the source and drain region so oxidation is used for different purposes to deposit stuff we deposited the gate in the example we also deposited aluminum or the interconnects pattern removal means etching an implant implantation is dopants to modify the electrical you know doping the source and drain region so you see these steps were repeat were done over and over again some were done twice some are done once to be able to make the transistor that we just saw and when you do it over and over again when you do it over and over again you start to get what is called as uh multiple metal layers so not just one layer of metal but second third fourth so in a typical uh uh so even in the DK that you may have used during a fresher program you would have noticed you could go up to metal sticks metal seven and so on so those metals were just extra stories that were built over the basic metal structure there okay so we are in the slide which is called dual damaging process have any one of you heard about dual dimension yes sir what is dual damaging so basically you want to reduce a process step when we want to make a VR so we do the etching twice and make a via that is of metal itself we do not deposit anything else okay mother you wanted to ask something yes so how do we con so we can control the area and the shape of these of everything by using the mask but how do we control the height like the deposition height of let's say the metal oxide that we were depositing how do we control that type you deposit it for a longer duration of time okay so duration okay so longer duration means uh higher bigger yeah you could do that or you could uh let us say later on you do CMP which is called chemo mechanical polishing so even if you look at the previous slides you know uh what we were showing was that uh see what happens do you think this this oxide was always this thick was it always this this thick only no when you had fabricated the oxide it would have been slightly wavy you polished it so that is called CMP chemo mechanical planarization so use chemicals and you use mechanical scrubbing to polish planarize the surface so when you do this you can actually plannerize it a little more and have lesser thickness there is it not yes sir so you could change the duration to increase or decrease the thickness and then CMP is the process through which you can finally arrive at the exact thickness that you needed okay so so while doing a metal one deposition you said that we can use the oxide as a mask so but exactly we're not using oxide as mass because where to H in the oxide that for that also you'll be using some other kind of yeah so I think the oxide there was a different mask but for depositing the metal oxide is the mass is it not okay okay okay fine fine so answer one more thing so in a previous slide uh you said that uh there was a point mentioned that using diffraction to enhance the resolution that wasn't clear to me so Productions you will see that in diffraction and when when when a large wavelength of light passes through a slit which has lesser width lesser uh you know a width which is a slit which is smaller than the wavelength of light like the facts yes sir yes sir yeah multiple slits placed to each other and placed close to each other light from the adjacent slits will also come below this first letter yes sir yes sir in so the kind of energy that comes below the first one would be significant enough now to be able to cause the etching whereas the common light falling below slit two and would be lesser than that okay so we're talking about the interference interference and the fractions we're talking about hardcore Optics there okay okay sorry okay okay so for others if it is really going over your head don't worry this is not a course on Optics this is not a course on fabrication also this is just an introduction to fabrication that we want that I want you to have so that you can then choose your coursework appropriately or you get to you know if someone is asking you a question on vlsi in in our interview you know have a well-rounded view of everything even if you have not done that exact course you have better understanding of the overall ecosystem there okay that is why I'm just covering it so don't need to worry too much about it mother you have a question okay so as within the said so that dual Dimension process is used to reduce a process step uh it may not be as intuitive to all of you on yet but let me explain it to you see in a typical manufacturing process what you do is you if you look at the this side first what you do is you you know make an oxide you put a when deposit a photo resist you do whatever you expose light you then etch when you etch you are able to make these holes in your system so that these holes will now allow or deposit metal layers and whatever you can so you would do this step for making a contact you will do this step for making a via so a contact is from Silicon to metal one okay and a via is from any other metal metal one select a five pack to the next metal layer metal two select a six packs okay so contact is made out of tungsten Vias initially let us say until 130 nanometer technology also vrs are made out of tungsten y tungsten we will just come to that but till that time we also made out of tungsten after 130 nanometer and wires at that time were made out of aluminum in in more Advanced Technologies wires are today made out of copper so why do we need to shift to Copper from aluminum this is the physical property of copper versus aluminum inductility ductility that purpose you can make much thinner wires and as you go to more advanced symmetry you wanted thinner wires additionally copper is less resistive than aluminum if you are making a thin wire its resistance would increase but by going to Copper you could reduce the resistivity also"
1VGPTGZ8e_Q,it is more ductile why were we not using copper even earlier why were we using aluminum earlier why we wanted thick wires with this so you could always make thick wires with copper also there would be still lesser resistance did not have the technology copper wire all your house fittings are also copper wire so maybe the it the copper interacts with the kind of may lead to some kind of effect that we wouldn't we won't be wanting or it could it is doing something to the process to the whatever we are trying to manufacture not getting the product right maybe that could be the thing some kind of undesired effects may be coming to play maybe okay should they be sorry using copper introduces more contact resistances in the active regions more resistance oh copper to lessen the aluminium uh sorry show some effects with the oxide layer as well so it gets diffused or conditions and that's why we use tungsten okay so what happens is copper copper gold and silver when they interact with silicon they create energy states inside the band gap deep inside the band gap see why is silicon a very good semiconductor because it has a band gap of 1.12 electron volts all of you remember this 1.12 electron volts so this band gap what does it ensure that the electrons over here here have to dump have to be given of energy of at least one dot to 1.12 volts so that they will start to conduct so this is the switching for behavior of a mosfet or any device also that you apply some voltage so that electron you kind of surmount this band gap and stuff and electrons go from here to here you need that kind of voltage and that is where it is a semiconductor now what copper gold and silver do is they make intermediate energy states in the middle of this band gap so now an electron can easily jump from here to here and then with the same energy kind of stuff move from here to here so now instead of 1.12 you require a voltage of only let us say 0.57 to conduct so your semiconductor no longer is as good as it was earlier okay so that is why copper usage was avoided in the semiconductor manufacturing process for a very very long time until we were hit with the volca of copper okay so everywhere there is copper today but the contacts still remain to be tungsten why because you do not want copper to come in contact with silicon at all so in fact in fabs the copper part of the fab is physically handed 200 meter 300 meters far away from the front and part of the fab where contacts are made so you make you do processing on wafers until contact level over here and then you physically shift the wafers to the other side there are there is a different clean room all together which you will need to go to and then you will do the processing of metal one and upwards okay so contacts continue to be tungsten vrs have moved from uh tungsten to copper because with copper you could do a different thing with copper what you could do was you could make two tiers of etching so up you see first year of etching para and then what you did you deposited the resist on it again and you made another exposure and with that after that exposure you made the second level of etching done so now when you deposit copper over here you will make a vr and also the metal in one step so this saves cost this is called as dual dynasty process which was enabled by copper and the major you know it really changed the way we handle handle devices because as soon as dual damaging process was enabled defectivity reduced significantly and you could go to many more number of metal layers so until there was aluminum you could only think of four or five metal layers but today you can very easily think of even 11 12 metal layers every extra meter layer is extra cost but at least if you want you can get them because of the dual dimension process okay so yes so how uh so before the 130 nanometer we were using aluminium for wires but for veya we are we are using different kind of things function okay for via viewing test and then aluminium but now we are using for via and wire copper yes so but then how it is reducing the defectivity i mean you just mentioned okay so you tell me one thing i make one step and i let us say i have to make a how do we put it i have to you'll be okay we just saw an example now we made contacts and then we deposited metal over it what happened there was more defectivity because there were two different steps is it not yeah yes sir yes so if i were to if i were to make the contacts and uh metals in one step it will automatically always fill the contacts for lena okay okay so basically we are we are reducing the cost the defectivity due to misalignments okay okay we are doing the deposition only once yeah okay it is flowing okay fine sir so overall cost of your chip would reduce yeah okay so okay so dual dimension process enabled that uh what we really need to realize is that with copper because we just understood that copper can diffuse into silicon and can lead to uh interstitials those intermediate states and completely spoil the functioning of your of your device so for copper you need to be extremely careful and you need to put a barrier around copper copper wires so that this copper doesn't diffuse out of the wire region otherwise copper will very easily diffuse into the oxide and from oxide it will very easily go into the substrate also so you need to make this barrier now when you were at 65 nanometers what happened you made a barrier which was uh say five nanometers thick and you were still fine but as you go to a finer geometry what happens now the barrier rate has not changed but your wire width has reduced so the effective resistance increases significantly so we are continuously looking for as we go to advanced technologies we are continuously looking for advanced barrier materials also okay let's say this was a pvd couple form cathode plasma deposition and this is atomic layer deposition you actually deposit this atom by atom so we are going to advance technology so that this barrier thickness we can reduce somehow so using copper has improved yield has improved stuff but it has also led to more complexity in manufacturing processes we will look into this aspect a little in in more detail later also okay so what do we do see we are almost done with the class time but there are three or four more slides should i continue or do we want me to stop and then continue in the next class so is it okay face stop right now it's already too much not that actually it's friday and if i miss the namaz then i have to go 10 to 11 kilometers then that's why okay okay so would you be okay by watching the recording or if others are okay can we just continue for five more minutes and then you can watch the last five minutes of recording later is that okay okay yeah that will be okay it was recording so we will be sharing anyways you okay okay if there is some question you can ask me in the office okay okay thank you thank you sir others are you okay with another five minutes of the class yes sir yes because then that will we will complete the fabrication part and we will move to the devices in the next class it will make it you know a consistent thing then okay and uh if you're tired and you want to leave you can you can watch the recording the file last five minutes later also okay so uh we said that fabrication is a piece of art you know you see that we wanted to fabricate a wire like this but we ended up fabricating something else we also did an experiment that if i want to did we do that experiment okay let us do it now uh you have a pen and a paper with you you write your name exactly the same way 10 times you write your name 10 times trying to make it make each each version a replica of the earlier ones please please do that write your name 10 times once you are done put a plus one in the chart window you know why i'm asking you to write your name because your name is the most you know wonderful sound to your ears you hear it the most so this is the most beautiful sound for you i want you to write your name 10 times trying to match the earlier versions and then tell me all the 10 words exactly the same or not were they the same are all the ten versions no sir no sir what happened there were some variations that came up i just asked you to write your name ten times how many transistors do you want to make on every die million billions billions of transistors and you're talking of a machine to manufacture millions of transistors exactly the same way can it ever happen no sir no there will be what is called as variations so as we go to advanced technologies this variability starts to bother us come to think of it like that in 65 nanometer technology the gate oxide thickness is only 12 angstroms which is only two to three molecules of silicon dioxide add one more molecule and what has happened the gate of right thickness has changed by 25 to 30 percent let us look at the gate length let us say i etched the end the length a little more so but instead of uh uh 65 60 nanometers i ended up manufacturing 65 uh 55 what happens performance improves a bit eight percent performance change leakage goes by more than thirty percent sixty sixty kilo i ended up making fifty five now let us say this five nanometer error i make in a 22 nanometer technology with 18 nanometer gate length what happens now so over here what was the error okay the error was less than 10 what would be the error over here if i make a 5 nanometer error it will be almost 30 are you able to see this so small errors which were handleable or manageable with some margins and earlier technologies are today come completely unacceptable so when we go to advanced technologies not only do we need to work on wavelength of light and this and that you also need to work a lot on instrumentation so that your instruments are very very accurate so scaling is not just about you and me and electronics engineers any longer it is all about a lot of technology people making it work for us are you able to see this any questions okay so in this slide what is this uh high kid electric thing which i mentioned and we'll come to that later high k dielectric so uh what happens is an advanced technologies uh so already see the gate oxide was 12 angstroms two to three molecules of silicon dioxide when you scale you need to go to an effective oxide thickness of eight angstroms yes sir so that is just one to two atoms one to two molecules you see the variability would increase so much so what was done was instead of silicon dioxide as the gate dielectric we used high k materials as gate dielectric so that physical thickness of the oxide would be something of the order of 20 angstroms but in terms of silicon dioxide the effective thickness would be in the ratio of the high k so effectively gate oxide thickness is eight eight angstroms but physical gate of site sickness because of a high k dielectric is 20 angstroms so variability reduces okay so now we are playing with the chemical properties of that yes okay materials okay so we mentioned about clean rooms there are huge range of you know different standards of clean rooms and uh you see there was a class hundred thousand clean room earlier we felt it was good enough we came to class one and we realized the clean room capability is no longer good enough so we had to define a completely different standard an iso standard where further advanced clean rooms have a name which the earlier terminology did not even have okay and these clean rooms are are really like sacred places if you want to enter into a clean room you have to wear extra layers of of clothing over your regular clothing that's a you know you see all these that doctors have been wearing in this cove with times so the technology engineers we have two such kits every time they enter into a clean room a very high pressure is maintained inside the clean room so that even if you open the door because of high pressure the air would come out of the clean room and not enter so no dust can enter into the clean room from outside so high pressure is maintained yellow light is used so that even by accident you do not expose any photoresist or anything and as i already mentioned as a plate in clean room for implant at wafer level and deposition of copper so clean rooms uh are something that are again you know completely logistics management of a vlsi facility is a completely different beast so my attempt over here is just to share with you so many people ensure that you and i are able to design what we are designing well okay uh this is so whatever we design we have to test and uh only good stuff only good wafers and good dies need to be shipped to customers so there are a range of tests that every dye needs to go through and you know a test equipment just one machine could be one million dollars today machines are actually much costlier even five million dollars and 10 million dollars machines are there because you have to test so many devices you have to operate them at a higher frequency so machines have also become costlier and realize that the over of the overall cost of test a huge 57 percent of the cost even at this time was depreciation cost so there is a huge research effort that we as designers are also taking up to reduce the test the cost of test so in even in my group you're working quite extensively on reducing the cost of test for okay for sams in my group but yeah across the board people are working on on methods to reduce the cost of tests,https://www.youtube.com/watch?v=1VGPTGZ8e_Q,"Link: https://www.youtube.com/watch?v=1VGPTGZ8e_Q
Transcript: it is more ductile why were we not using copper even earlier why were we using aluminum earlier why we wanted thick wires with this so you could always make thick wires with copper also there would be still lesser resistance did not have the technology copper wire all your house fittings are also copper wire so maybe the it the copper interacts with the kind of may lead to some kind of effect that we wouldn't we won't be wanting or it could it is doing something to the process to the whatever we are trying to manufacture not getting the product right maybe that could be the thing some kind of undesired effects may be coming to play maybe okay should they be sorry using copper introduces more contact resistances in the active regions more resistance oh copper to lessen the aluminium uh sorry show some effects with the oxide layer as well so it gets diffused or conditions and that's why we use tungsten okay so what happens is copper copper gold and silver when they interact with silicon they create energy states inside the band gap deep inside the band gap see why is silicon a very good semiconductor because it has a band gap of 1.12 electron volts all of you remember this 1.12 electron volts so this band gap what does it ensure that the electrons over here here have to dump have to be given of energy of at least one dot to 1.12 volts so that they will start to conduct so this is the switching for behavior of a mosfet or any device also that you apply some voltage so that electron you kind of surmount this band gap and stuff and electrons go from here to here you need that kind of voltage and that is where it is a semiconductor now what copper gold and silver do is they make intermediate energy states in the middle of this band gap so now an electron can easily jump from here to here and then with the same energy kind of stuff move from here to here so now instead of 1.12 you require a voltage of only let us say 0.57 to conduct so your semiconductor no longer is as good as it was earlier okay so that is why copper usage was avoided in the semiconductor manufacturing process for a very very long time until we were hit with the volca of copper okay so everywhere there is copper today but the contacts still remain to be tungsten why because you do not want copper to come in contact with silicon at all so in fact in fabs the copper part of the fab is physically handed 200 meter 300 meters far away from the front and part of the fab where contacts are made so you make you do processing on wafers until contact level over here and then you physically shift the wafers to the other side there are there is a different clean room all together which you will need to go to and then you will do the processing of metal one and upwards okay so contacts continue to be tungsten vrs have moved from uh tungsten to copper because with copper you could do a different thing with copper what you could do was you could make two tiers of etching so up you see first year of etching para and then what you did you deposited the resist on it again and you made another exposure and with that after that exposure you made the second level of etching done so now when you deposit copper over here you will make a vr and also the metal in one step so this saves cost this is called as dual dynasty process which was enabled by copper and the major you know it really changed the way we handle handle devices because as soon as dual damaging process was enabled defectivity reduced significantly and you could go to many more number of metal layers so until there was aluminum you could only think of four or five metal layers but today you can very easily think of even 11 12 metal layers every extra meter layer is extra cost but at least if you want you can get them because of the dual dimension process okay so yes so how uh so before the 130 nanometer we were using aluminium for wires but for veya we are we are using different kind of things function okay for via viewing test and then aluminium but now we are using for via and wire copper yes so but then how it is reducing the defectivity i mean you just mentioned okay so you tell me one thing i make one step and i let us say i have to make a how do we put it i have to you'll be okay we just saw an example now we made contacts and then we deposited metal over it what happened there was more defectivity because there were two different steps is it not yeah yes sir yes so if i were to if i were to make the contacts and uh metals in one step it will automatically always fill the contacts for lena okay okay so basically we are we are reducing the cost the defectivity due to misalignments okay okay we are doing the deposition only once yeah okay it is flowing okay fine sir so overall cost of your chip would reduce yeah okay so okay so dual dimension process enabled that uh what we really need to realize is that with copper because we just understood that copper can diffuse into silicon and can lead to uh interstitials those intermediate states and completely spoil the functioning of your of your device so for copper you need to be extremely careful and you need to put a barrier around copper copper wires so that this copper doesn't diffuse out of the wire region otherwise copper will very easily diffuse into the oxide and from oxide it will very easily go into the substrate also so you need to make this barrier now when you were at 65 nanometers what happened you made a barrier which was uh say five nanometers thick and you were still fine but as you go to a finer geometry what happens now the barrier rate has not changed but your wire width has reduced so the effective resistance increases significantly so we are continuously looking for as we go to advanced technologies we are continuously looking for advanced barrier materials also okay let's say this was a pvd couple form cathode plasma deposition and this is atomic layer deposition you actually deposit this atom by atom so we are going to advance technology so that this barrier thickness we can reduce somehow so using copper has improved yield has improved stuff but it has also led to more complexity in manufacturing processes we will look into this aspect a little in in more detail later also okay so what do we do see we are almost done with the class time but there are three or four more slides should i continue or do we want me to stop and then continue in the next class so is it okay face stop right now it's already too much not that actually it's friday and if i miss the namaz then i have to go 10 to 11 kilometers then that's why okay okay so would you be okay by watching the recording or if others are okay can we just continue for five more minutes and then you can watch the last five minutes of recording later is that okay okay yeah that will be okay it was recording so we will be sharing anyways you okay okay if there is some question you can ask me in the office okay okay thank you thank you sir others are you okay with another five minutes of the class yes sir yes because then that will we will complete the fabrication part and we will move to the devices in the next class it will make it you know a consistent thing then okay and uh if you're tired and you want to leave you can you can watch the recording the file last five minutes later also okay so uh we said that fabrication is a piece of art you know you see that we wanted to fabricate a wire like this but we ended up fabricating something else we also did an experiment that if i want to did we do that experiment okay let us do it now uh you have a pen and a paper with you you write your name exactly the same way 10 times you write your name 10 times trying to make it make each each version a replica of the earlier ones please please do that write your name 10 times once you are done put a plus one in the chart window you know why i'm asking you to write your name because your name is the most you know wonderful sound to your ears you hear it the most so this is the most beautiful sound for you i want you to write your name 10 times trying to match the earlier versions and then tell me all the 10 words exactly the same or not were they the same are all the ten versions no sir no sir what happened there were some variations that came up i just asked you to write your name ten times how many transistors do you want to make on every die million billions billions of transistors and you're talking of a machine to manufacture millions of transistors exactly the same way can it ever happen no sir no there will be what is called as variations so as we go to advanced technologies this variability starts to bother us come to think of it like that in 65 nanometer technology the gate oxide thickness is only 12 angstroms which is only two to three molecules of silicon dioxide add one more molecule and what has happened the gate of right thickness has changed by 25 to 30 percent let us look at the gate length let us say i etched the end the length a little more so but instead of uh uh 65 60 nanometers i ended up manufacturing 65 uh 55 what happens performance improves a bit eight percent performance change leakage goes by more than thirty percent sixty sixty kilo i ended up making fifty five now let us say this five nanometer error i make in a 22 nanometer technology with 18 nanometer gate length what happens now so over here what was the error okay the error was less than 10 what would be the error over here if i make a 5 nanometer error it will be almost 30 are you able to see this so small errors which were handleable or manageable with some margins and earlier technologies are today come completely unacceptable so when we go to advanced technologies not only do we need to work on wavelength of light and this and that you also need to work a lot on instrumentation so that your instruments are very very accurate so scaling is not just about you and me and electronics engineers any longer it is all about a lot of technology people making it work for us are you able to see this any questions okay so in this slide what is this uh high kid electric thing which i mentioned and we'll come to that later high k dielectric so uh what happens is an advanced technologies uh so already see the gate oxide was 12 angstroms two to three molecules of silicon dioxide when you scale you need to go to an effective oxide thickness of eight angstroms yes sir so that is just one to two atoms one to two molecules you see the variability would increase so much so what was done was instead of silicon dioxide as the gate dielectric we used high k materials as gate dielectric so that physical thickness of the oxide would be something of the order of 20 angstroms but in terms of silicon dioxide the effective thickness would be in the ratio of the high k so effectively gate oxide thickness is eight eight angstroms but physical gate of site sickness because of a high k dielectric is 20 angstroms so variability reduces okay so now we are playing with the chemical properties of that yes okay materials okay so we mentioned about clean rooms there are huge range of you know different standards of clean rooms and uh you see there was a class hundred thousand clean room earlier we felt it was good enough we came to class one and we realized the clean room capability is no longer good enough so we had to define a completely different standard an iso standard where further advanced clean rooms have a name which the earlier terminology did not even have okay and these clean rooms are are really like sacred places if you want to enter into a clean room you have to wear extra layers of of clothing over your regular clothing that's a you know you see all these that doctors have been wearing in this cove with times so the technology engineers we have two such kits every time they enter into a clean room a very high pressure is maintained inside the clean room so that even if you open the door because of high pressure the air would come out of the clean room and not enter so no dust can enter into the clean room from outside so high pressure is maintained yellow light is used so that even by accident you do not expose any photoresist or anything and as i already mentioned as a plate in clean room for implant at wafer level and deposition of copper so clean rooms uh are something that are again you know completely logistics management of a vlsi facility is a completely different beast so my attempt over here is just to share with you so many people ensure that you and i are able to design what we are designing well okay uh this is so whatever we design we have to test and uh only good stuff only good wafers and good dies need to be shipped to customers so there are a range of tests that every dye needs to go through and you know a test equipment just one machine could be one million dollars today machines are actually much costlier even five million dollars and 10 million dollars machines are there because you have to test so many devices you have to operate them at a higher frequency so machines have also become costlier and realize that the over of the overall cost of test a huge 57 percent of the cost even at this time was depreciation cost so there is a huge research effort that we as designers are also taking up to reduce the test the cost of test so in even in my group you're working quite extensively on reducing the cost of test for okay for sams in my group but yeah across the board people are working on on methods to reduce the cost of tests"
w2JBCrDmuno,there is a huge research effort going on packaging because not just about uh you know it is not just about power power dissipation or stuff like that uh packaging when we talk about more than more and having a major and processor and memory in the same die so packaging is also becoming more complex there's a lot of research happening on packaging also and recently because we want more speeds that the typical inductive effects of the uh package start the figure in so just you know exposing you to different research areas as well with blsi and you know uh this is how the power the power generation on our chips has increased okay but this is how the air cooling capability is so air cooling capability has will remain largely constant is it not air can cool only this much can dissipate remove only this much of heat from a given area in a given amount of time after that you start to use fans and all that um but in reality today even in your mobile phone so if you look at qualcomm's latest chips specifications you will see mobile phone application processors also use what is called as liquid cooling so that you can just you can remove heat much faster and your chip can function at the required performance level okay so I think yeah this kind of brings me to the end of this session I know I had to choose the last few slides but frankly there was not much to know about or talk about except I wanted you to be introduced to these all these domains and challenges and dlsr Manufacturing processes also if you have any if you have any questions please shoot yes Mother so why are there only a handful of companies the world that looks at because just because it is so complex and so costly now only until you have very Deep Pockets you cannot afford to put that kind of money in there now so what stops the company like Reliance or Tata to make a fabrication facility indigenous fabrication facility oh indigenous fabrication facility in India so many many things you know uh first is that to be able to have a so first thing you realize is that Fab is costly such complex equipment such things need to be there so making a Fab setting a Fab is a very costly process are you able to understand this yes sir so then once you have a Fab made you would want to utilize a 24 course seven 365 days a week a year yes sir do you know one single Fab consumes what kind of water and electricity so it requires hundreds of megawatts of electricity just to run one trap India is yet not an electricity energy Surplus country we have we have regular power Cuts in summers where we say that uh uh okay industry will pay this higher price and there will also be power cuts that industry has to face because the residential consumers should get the power I and you should sit in AC so industries use their generators to generate their power they are given park at load shedding okay so uh one aspect availability of abundance of water second aspect we don't have we don't have water supply in our cities even Delhi there are areas where there is no no regular water supply we are the capital city here so there are many many reasons where our infrastructure is lacking okay so it is not just setting for so in India it is not just about establishing the facilities now also ensuring that you have the electricity made available to you you have water made available to you so the overall cost of establishing a Fab increases much more in India and as soon as that happens the products that you will make will be costlier than products that are made in tsmc or in a Samsung tab in Korea so why would anyone come to you so even if you make a Fab you will not be able to sell to anyone so if we use the same technology your cellular technology that is being used for teams tsmc or Samsung Japan company so in tsmc and Samsung these met electricity and water applied by the government over here this thing has to be ensured by the manufacturer himself because Supply heini I have to set up my captive power plants to be able to do this so that is extra cost in making the fabinal okay so it's a it should be uh combined effort by government as well as private sector yes it's all about economics so government is saying we are giving you those so much subsidy but the government is not realizing that the economics of a Fab is much much bigger than just setting up that habit is about ensuring that there is uninterrupted power supply uh that the labor is you know the labor laws are such that you're able to use the Fab uh 24 7 365 days a year and so on so there are many constraints because of which even though people have shown intent so as of now Tata group has shown and tend to participate in a semiconductor Saab but till now all these attempts have resulted out because it was a very costly Affair it's a very very high risk and the Indian government is not willing to take up the bill of that risk and why should it because if the profits come they will go to the private party then why should the loss come to the government the government is right and that's on towns but then should the government expand the semiconductor complex for example that we have in Mohali which is a government sub so these are you have you know tough questions to answer but yeah some answers would come from the bare economics of it that economics do not allow it to be done in India yet and you know uh also look at it like this you invest itna billion dollars to make a Fab how many jobs do you create for the government of India if they would invest that kind of money in the education sector or in uh in you know uh medium and Small industry sector they will be able to create much much more jobs so both sorry Dimensions it's not a simple answer so if you said designing and verification part is done in India a lot but eventually the fabrication is done outside so yes and because designing and verification does not require that kind of an infrastructure no it requires machines CPUs you can purchase even there there are lots of constraints you go to any of these companies and you talk to the finance people the asset managers they will just pull their hair something that you know uskandarvi government has such constraints today that uh even that is a difficult thing to do but okay because of people like you who are good who will turn out to be good designers companies still want to set up shop in India okay otherwise yeah sir I have seen uh course like post silicon validation Engineers what do they do I do not know what do they do how do they participate in this flow post siliconers after silicon is ready so what do you need to do you need to test to the new test so testing can be done you just bring a testing machine to India and you bring the Wafers and you can test here I know so testing is done in India more than that you can test and then you can debug okay by using stuff like best by using stuff like scan chains built-in self characterizers you can identify where the failure is and then you can help make the next version of the design better so that is post post silicon validation so I thought the these all uh distance can change were uh already tested while we were designing and performing every verification yeah but that is still pretty silicon now silicon suppose silicon validation is that okay I wanted this functionality so let us say like this uh I make a setup box chip yeah I get the Silicon now I have to ensure that the Silicon is able to run the entire suit of programs whether it is Netflix or whether it is uh ZTV or whether it is a simple cable TV relay whether it is an app or whether it is a simple cable TV relay and it should be secure there are so many functionalities linked to silica to this piece of silicon that I have just fabricated is it not that needs to be validated you do not even need a tester to do that you you use the tester you got the product out now that you have the product in hand which is seemingly all correct we need to validate that all the functionality that I wanted it to have does it have it yes sir is my software properly correlated with the hardware that I have manufactured yet so all that is part of poor silicon validation got it okay,https://www.youtube.com/watch?v=w2JBCrDmuno,"Link: https://www.youtube.com/watch?v=w2JBCrDmuno
Transcript: there is a huge research effort going on packaging because not just about uh you know it is not just about power power dissipation or stuff like that uh packaging when we talk about more than more and having a major and processor and memory in the same die so packaging is also becoming more complex there's a lot of research happening on packaging also and recently because we want more speeds that the typical inductive effects of the uh package start the figure in so just you know exposing you to different research areas as well with blsi and you know uh this is how the power the power generation on our chips has increased okay but this is how the air cooling capability is so air cooling capability has will remain largely constant is it not air can cool only this much can dissipate remove only this much of heat from a given area in a given amount of time after that you start to use fans and all that um but in reality today even in your mobile phone so if you look at qualcomm's latest chips specifications you will see mobile phone application processors also use what is called as liquid cooling so that you can just you can remove heat much faster and your chip can function at the required performance level okay so I think yeah this kind of brings me to the end of this session I know I had to choose the last few slides but frankly there was not much to know about or talk about except I wanted you to be introduced to these all these domains and challenges and dlsr Manufacturing processes also if you have any if you have any questions please shoot yes Mother so why are there only a handful of companies the world that looks at because just because it is so complex and so costly now only until you have very Deep Pockets you cannot afford to put that kind of money in there now so what stops the company like Reliance or Tata to make a fabrication facility indigenous fabrication facility oh indigenous fabrication facility in India so many many things you know uh first is that to be able to have a so first thing you realize is that Fab is costly such complex equipment such things need to be there so making a Fab setting a Fab is a very costly process are you able to understand this yes sir so then once you have a Fab made you would want to utilize a 24 course seven 365 days a week a year yes sir do you know one single Fab consumes what kind of water and electricity so it requires hundreds of megawatts of electricity just to run one trap India is yet not an electricity energy Surplus country we have we have regular power Cuts in summers where we say that uh uh okay industry will pay this higher price and there will also be power cuts that industry has to face because the residential consumers should get the power I and you should sit in AC so industries use their generators to generate their power they are given park at load shedding okay so uh one aspect availability of abundance of water second aspect we don't have we don't have water supply in our cities even Delhi there are areas where there is no no regular water supply we are the capital city here so there are many many reasons where our infrastructure is lacking okay so it is not just setting for so in India it is not just about establishing the facilities now also ensuring that you have the electricity made available to you you have water made available to you so the overall cost of establishing a Fab increases much more in India and as soon as that happens the products that you will make will be costlier than products that are made in tsmc or in a Samsung tab in Korea so why would anyone come to you so even if you make a Fab you will not be able to sell to anyone so if we use the same technology your cellular technology that is being used for teams tsmc or Samsung Japan company so in tsmc and Samsung these met electricity and water applied by the government over here this thing has to be ensured by the manufacturer himself because Supply heini I have to set up my captive power plants to be able to do this so that is extra cost in making the fabinal okay so it's a it should be uh combined effort by government as well as private sector yes it's all about economics so government is saying we are giving you those so much subsidy but the government is not realizing that the economics of a Fab is much much bigger than just setting up that habit is about ensuring that there is uninterrupted power supply uh that the labor is you know the labor laws are such that you're able to use the Fab uh 24 7 365 days a year and so on so there are many constraints because of which even though people have shown intent so as of now Tata group has shown and tend to participate in a semiconductor Saab but till now all these attempts have resulted out because it was a very costly Affair it's a very very high risk and the Indian government is not willing to take up the bill of that risk and why should it because if the profits come they will go to the private party then why should the loss come to the government the government is right and that's on towns but then should the government expand the semiconductor complex for example that we have in Mohali which is a government sub so these are you have you know tough questions to answer but yeah some answers would come from the bare economics of it that economics do not allow it to be done in India yet and you know uh also look at it like this you invest itna billion dollars to make a Fab how many jobs do you create for the government of India if they would invest that kind of money in the education sector or in uh in you know uh medium and Small industry sector they will be able to create much much more jobs so both sorry Dimensions it's not a simple answer so if you said designing and verification part is done in India a lot but eventually the fabrication is done outside so yes and because designing and verification does not require that kind of an infrastructure no it requires machines CPUs you can purchase even there there are lots of constraints you go to any of these companies and you talk to the finance people the asset managers they will just pull their hair something that you know uskandarvi government has such constraints today that uh even that is a difficult thing to do but okay because of people like you who are good who will turn out to be good designers companies still want to set up shop in India okay otherwise yeah sir I have seen uh course like post silicon validation Engineers what do they do I do not know what do they do how do they participate in this flow post siliconers after silicon is ready so what do you need to do you need to test to the new test so testing can be done you just bring a testing machine to India and you bring the Wafers and you can test here I know so testing is done in India more than that you can test and then you can debug okay by using stuff like best by using stuff like scan chains built-in self characterizers you can identify where the failure is and then you can help make the next version of the design better so that is post post silicon validation so I thought the these all uh distance can change were uh already tested while we were designing and performing every verification yeah but that is still pretty silicon now silicon suppose silicon validation is that okay I wanted this functionality so let us say like this uh I make a setup box chip yeah I get the Silicon now I have to ensure that the Silicon is able to run the entire suit of programs whether it is Netflix or whether it is uh ZTV or whether it is a simple cable TV relay whether it is an app or whether it is a simple cable TV relay and it should be secure there are so many functionalities linked to silica to this piece of silicon that I have just fabricated is it not that needs to be validated you do not even need a tester to do that you you use the tester you got the product out now that you have the product in hand which is seemingly all correct we need to validate that all the functionality that I wanted it to have does it have it yes sir is my software properly correlated with the hardware that I have manufactured yet so all that is part of poor silicon validation got it okay"
SMA5k1yLOKs,okay so that was primarily the first introduction to vlsi section that we actually covered uh till the last class uh today we will move into vlsi devices okay so when i say the rsi devices what do you understand by vlsi devices the transistors okay just transistors capacitors and all those things for the mixed signal design yes not just transistors any actually we will start with mass capacitance over here okay so what is the mos capacitance what does mos stand for metal oxide semiconductor so what we are essentially saying three layers like is layer is method second outside and third is something yeah what we are saying is there is a metal there is a semiconductor and in between them there is an oxide so metal is simply a conducting plate a semiconductor is semiconducting but semiconducting means it can conduct so it is it means that there is a dielectric oxide between two conducting plates and that clearly means it's a capacitance so mass by the name itself represents the capacitance so metal the metal gate silicon dioxide and then the body and this becomes the mos capacitor when you put in the source and drain region you call it a mos transistor but we will initially start our analysis of from the mos capacitor we will move to mos transistors in the next step is that okay so uh when i say that this is metal oxide and silicon they're connected with each other what happens at these connections at this interface or at this interface any ideas you can read the question i am saying that when we bring metal oxide and semiconductor together you know we brought them they brought them together we brought them in contact with each other so when they come in contact with each other what happens at the interface so basically three of these materials have different uh electron affinities so uh when we bring them together so basically there has to be some rearrangement of charges that that has to happen there for this device on the material that we are overall creating to be stable to have a uniform potential across if we are not applying any potential so basically the band bending happens here energy so all of you understand what is electron affinity but then we use the term electron affinity there what is electron affinity [Music] outer motion yes the energy required for an electron to escape from any material that is called electron affinity so i would not say valence band because for example metals also have electron affinity so they don't have a valence band though but electron affinity essentially means the energy it takes to for an electron to escape from that particular material so every material has some electron affinity uh do you remember this much so so don't we call that a work function the yeah work function and that is also referred to as electron affinity okay okay yes there we are even fermi energy don't worry oh yeah yes actually in my pre-tech i have started affinity and what function is different terms like affinity uh like affinity is from uh like one is from five level and one is to take an electron from conduction like we have uh we have done as a work function is sum of affinity plus one more time like in the predictive study in this manner okay um let me check that and let me correct that for you like i will come back on this point a little later but uh do you understand that there would be some energy that every electron like that electrons in any material would require to move to the vacuum to escape from the from the substance yes sir so the vacuum level or universe level let us say is constant and energy required by different devices by different materials would be different so if it comes to plotting those materials so if let us say this is a vacuum level one material could be here another could be here another could be here can that happen yes sir and then when we bring these materials together what needs to match so first so okay again i'm slightly confused we're talking about all this electron affinity fermi level everything uh i do understand that some of you have like some of you did mention to me that in the last semester you did not cover semiconductor devices or mosfets in much detail so are these things coming like clear to you also because you studied them in your class 11 12 or in another course or is it all going over your head if you don't see that i think you understand this much just yeah sorry uh yeah so like um we understand this much it's just that we didn't cover all the frequency responses and the other various types of capacitance capacitances in a cmos um like what i mean in the mosfet so like uh yeah that's so so that pattern i have covered because that is what i intend to cover today right so we didn't cover device physics yeah so see i don't want to enter into too much of device physics also because there is a separate course solid state devices for that this course is not that but i i do want you to understand that there will be there are bands and there is band bending and there is a complete uh you know language two semiconductor devices so this jargon is not entirely clear this is not entirely it's not entirely clear it's not entirely clear so most of the jargon you will get clarified when you do the ssd codes and but i i want you to realize that there is some jargon around like that is that much clearer yes sir so there will be when you go when you go and do the ssd course you will talk about band diagrams and band bending and and all that stuff uh so if you are interested in device physics that is where that that is one course that you should definitely do in this course we are more into circuits but to understand circuits and their operation it is important to know that there is a physics behind it i don't want to go into too much of physics here but i want you to realize that there is a physical basis to whatever we are going to talk about from now on is that much clearer yes sir you have,https://www.youtube.com/watch?v=SMA5k1yLOKs,"Link: https://www.youtube.com/watch?v=SMA5k1yLOKs
Transcript: okay so that was primarily the first introduction to vlsi section that we actually covered uh till the last class uh today we will move into vlsi devices okay so when i say the rsi devices what do you understand by vlsi devices the transistors okay just transistors capacitors and all those things for the mixed signal design yes not just transistors any actually we will start with mass capacitance over here okay so what is the mos capacitance what does mos stand for metal oxide semiconductor so what we are essentially saying three layers like is layer is method second outside and third is something yeah what we are saying is there is a metal there is a semiconductor and in between them there is an oxide so metal is simply a conducting plate a semiconductor is semiconducting but semiconducting means it can conduct so it is it means that there is a dielectric oxide between two conducting plates and that clearly means it's a capacitance so mass by the name itself represents the capacitance so metal the metal gate silicon dioxide and then the body and this becomes the mos capacitor when you put in the source and drain region you call it a mos transistor but we will initially start our analysis of from the mos capacitor we will move to mos transistors in the next step is that okay so uh when i say that this is metal oxide and silicon they're connected with each other what happens at these connections at this interface or at this interface any ideas you can read the question i am saying that when we bring metal oxide and semiconductor together you know we brought them they brought them together we brought them in contact with each other so when they come in contact with each other what happens at the interface so basically three of these materials have different uh electron affinities so uh when we bring them together so basically there has to be some rearrangement of charges that that has to happen there for this device on the material that we are overall creating to be stable to have a uniform potential across if we are not applying any potential so basically the band bending happens here energy so all of you understand what is electron affinity but then we use the term electron affinity there what is electron affinity [Music] outer motion yes the energy required for an electron to escape from any material that is called electron affinity so i would not say valence band because for example metals also have electron affinity so they don't have a valence band though but electron affinity essentially means the energy it takes to for an electron to escape from that particular material so every material has some electron affinity uh do you remember this much so so don't we call that a work function the yeah work function and that is also referred to as electron affinity okay okay yes there we are even fermi energy don't worry oh yeah yes actually in my pre-tech i have started affinity and what function is different terms like affinity uh like affinity is from uh like one is from five level and one is to take an electron from conduction like we have uh we have done as a work function is sum of affinity plus one more time like in the predictive study in this manner okay um let me check that and let me correct that for you like i will come back on this point a little later but uh do you understand that there would be some energy that every electron like that electrons in any material would require to move to the vacuum to escape from the from the substance yes sir so the vacuum level or universe level let us say is constant and energy required by different devices by different materials would be different so if it comes to plotting those materials so if let us say this is a vacuum level one material could be here another could be here another could be here can that happen yes sir and then when we bring these materials together what needs to match so first so okay again i'm slightly confused we're talking about all this electron affinity fermi level everything uh i do understand that some of you have like some of you did mention to me that in the last semester you did not cover semiconductor devices or mosfets in much detail so are these things coming like clear to you also because you studied them in your class 11 12 or in another course or is it all going over your head if you don't see that i think you understand this much just yeah sorry uh yeah so like um we understand this much it's just that we didn't cover all the frequency responses and the other various types of capacitance capacitances in a cmos um like what i mean in the mosfet so like uh yeah that's so so that pattern i have covered because that is what i intend to cover today right so we didn't cover device physics yeah so see i don't want to enter into too much of device physics also because there is a separate course solid state devices for that this course is not that but i i do want you to understand that there will be there are bands and there is band bending and there is a complete uh you know language two semiconductor devices so this jargon is not entirely clear this is not entirely it's not entirely clear it's not entirely clear so most of the jargon you will get clarified when you do the ssd codes and but i i want you to realize that there is some jargon around like that is that much clearer yes sir so there will be when you go when you go and do the ssd course you will talk about band diagrams and band bending and and all that stuff uh so if you are interested in device physics that is where that that is one course that you should definitely do in this course we are more into circuits but to understand circuits and their operation it is important to know that there is a physics behind it i don't want to go into too much of physics here but i want you to realize that there is a physical basis to whatever we are going to talk about from now on is that much clearer yes sir you have"
cXY4b9XCUgM,foreign capacitances and mosfets earlier so that makes my job easier I can move I can actually move a little faster I will not go into too much of detail there then because I just wanted to have you have you get a glimpse of it and if you already have some Glimpse then I can be fast so what we are saying is that when these three materials come together they form a they form a capacitor between them but this capacitor is not like a capacitor between two metals see when you have two metal con two conducting layers there are some different characteristics that this capacitor would have in comparison to a metal oxide or metal dielectric metal capacitor and the reason for that is that uh there are these uh bands and that there are these energy levels that you're talking about and when we bring these semiconductors in contact with the oxide and we say that there is this Fermi level which needs to be matched across the entire material uh then it requires some band bending to happen we will just look at what band bending also means so uh over here what I have done is I've put a n Plus polysilicon a p silicon body and siot that is your silicon dioxide and when I bring these three materials together see n Plus n plus polysilicon means n plus means that there is so much doping that the Fermi level and the conduction band are kind of overlapping that is the kind of doping we have there okay sir could you elaborate on what family Fermi level is okay so Fermi level is a is a notional term it's actually it is a term which states that uh around 50 percent of the you know the probability of finding electrons in a particular material is is plotted and then it is said that uh there are 50 percent of electrons above the Fermi level and fifty percent of electrons below the Fermi level okay so Fermi level is such that uh okay the level itself it describes the energy of the electrons right yes it is about some energy of electrons but for example look at the Silicon silicon part of it the Silicon body part of it um over here the family level is in the band Gap what does that mean okay okay level actually there is no electron there over here look at it in the oxide region again the Fermi level is in the band app what that means is in within the uh oxide you're not expecting any electrons there Fermi level is just that probability what is the probability yeah so for me was a scientist who gave these this for me direct statistics okay to to uh describe the distribution of electrons in a semiconductor okay okay and uh so that is classical physics um in an Advanced Technologies are are today we also use quantum Quantum devices and quantum physics into it so some of these things may hold true some of these things may not fall true but Fermi level you say is a notional level at which the probability of finding an electron is 50 percent so what what is the meaning of primary level lying inside a band Gap it simply means when when this line is closer to the valence band it means that is a p-type doped substance so the probability of finding electrons in the balance band is higher when it is closer to the conduction band it means it's the n-type doc substance or probability of finding an electron in the valence band is higher and when it is in the center that is along with the intrinsic level so intrinsic level is in the center of the band Gap sure it means that uh the material is not doped okay okay so Fermi level has no physical significance it has only a notional thing created to improve our understanding and to do some analysis of the system physically it represents no energy level is that clear yes sir okay so what happens is that when I bring these three materials next to each other then uh the Fermi level has to be aligned because in this region we say that the probability of finding an electron above the Fermi level is 50 percent and below it is also 50 percent now we also understand that silicon say polysilicon over here and sio2 have a Affinity difference of 3.1 electron volts okay and over here also there is a gap of 3.1 electron volts because this side is also silicon but because the Fermi level is stable so at at an infinite depth we would we would get the same uh Fermi level as the doping or the Fermi level at the same level as a doping but close to this oxide boundary what happens is there starts to be some collection of charge or removal of charge so that I can get this 3.1 electron volt dap between oxide and the conduction band of the semiconductor this is called as band bending and this is what changes the behavior of a mass capacitor from a regular capacitor that you would otherwise see in your Labs you may have already seen in your earlier labs and the the capacitors the metal capacitors are stuff like that that you would otherwise use Mass capacitors behave would behave differently from them is this part clear that at least this much that most most capacitors will not be like any other capacitor they will behave differently this part here yeah so okay so as well you have a question so can you please explain that again uh I was not able to understand like flaw like from this when you have said 3.1 electron volts in the gate side and 3.1 in the silicon and that is what is bending like can you please explain that role part again Okay so let us say the three materials are separately placed as of now let us say okay uh yeah let us say three materials are separately are placed separately as of now and uh when they are separate separated when they are separate we realize that conduction band of polysilicon conduction band of silicon and conduction band of the dielectric they will have a gap of 3.1 electron volt between them is it clear till here yes sir now because of the doping Fermi level of this was here um level was at the EC that is how we had doped because you wanted it to be like a metal yes metal means a sea of electrons lots of electrons there so you dope it very heavily so heavily that it was almost like EC and efr coinciding you will always have electrons in the conduction and that is when it becomes a metal otherwise it will not be a metal yes sir so you dope it very heavily so the Fermi level and this match now you bring these two materials together what happens as soon as these materials start to touch each other a requirement section that Fermi levels have to be matched okay so Fermi levels have to be matched what does this mean it means that this material there will be some voltage generated internally so that Fermi level will match all of this will go up all of this will go up so that the Fermi level matches and your valence band is here and conduction band is up there but there is also this free condition but there is also this precondition that spacing between these two will be 3.1 volts so what happens if this went up by let us say x volts a data X you know extra question part will appear across the dielectric dielectric can always have a voltage drop across it see Metals cannot have voltage drop across them do you understand this if there is any voltage drop across a metal electrons will flow and kind of mitigate that voltage drop but dielectrics and semiconductors can have some voltage drop across them because they don't allow flow of electrons easily yes so the dielectric over here will bend and this is a semiconductor so a semiconductor can also bend a bit so the semiconductor also backs combined this bending plus this bending we would get we would get this movement of the Fermi level from uh wherever it was to the metal Fermi level okay okay so bending that happened here the line is not coming yeah so the bending that happened across the oxide and the bending that happened across the uh uh semiconductor side I'd add the addition of that will be equal to EC minus EF on the semiconductor side yes sir okay okay and it is because of this band bending that your device that your capacitance Behavior do you understand this is the capacitor but this capacitor Behavior will be different from a regular metal oxide metal capacitor okay so okay okay and it is much more clear yes thank you great rajnish you have a question yeah sir uh sir as you said that uh between the uh the conduction bands of the uh poly and the sio2 uh the energy gap must be 3.1 electron sir uh so a and in this side between the uh this substrate and the Silicon oxide uh uh do uh it is a starting behaving like n type that's why we have to maintain 3.1 electron over here also no no no 3.1 electron voltage required because that is the barrier for any electron to move from Silicon to silicon dioxide okay so for any electron to move from Silicon to silicon dioxide you would need 3.1 electron volts so you cannot change that happens okay and there is no bending on the metal side because metal is a sea of electrons yes yes thank you okay I have to add some more things like if someone asks why band binding is happening so we have to save for matching the Fermi level band bending is happening is that right so when you explain the way like I explained it to you when when things are in contact with each other their family levels have to match okay but there is a physical uh barrier also which exists there's this electrical barrier which cannot be changed so this 3.1 electron volt also has to be maintained okay so for the because of these Spirits because of these two things that band bending happens okay okay thank you sir okay not just one of them both of them are involved yes sir okay that's nice so can I ask yes so uh as I understand the gate and the Silicon body there are different materials so but why we're meeting the 3.1 electron volt for both both of them because we use poly silicon for the gate now polysilicon is polycrystalline silicon okay so that's why it's three point one same thing okay yes so uh okay and it's a very good question rather because we need to understand that in Advanced Technologies we're using metal gates so what happens when I use a metal gate this 3.1 electron volt is not necessary now I can have a different uh I can have a different uh pinning point so till the time we were using polysilicon Gates there was a constraint on what the VT of different devices can be because you can only dope as much and this is only bending that you can bring about okay whereas uh once we start to use metal gates and hierarchy dielectrics uh what happens is that I have more flexibility by changing the material of the gate to change my VT of the pmos and the nmos independently okay so this is something that you should remember this would come in handy in some interview sometime you had a question yes sir sir talking about this silicon body where the bending is actually happening at the interface of the oxide and the Silicon bodies and there I can see that Fermi level has moved towards more towards the conduction band so can I say that electron concentration has also changed it is more towards uh interface rather than the bulk yes uh interface Matlab sorry uh interface okay so what we say is that at the surface of uh the device at the surface of or at the interface of silicon dioxide and uh uh p-type silicon body there is a higher density of electrons than in the remaining part of the body that is what you can say yes okay so ah we have to be very exact in the way we speak things over here because a slip of one word or another can can completely change the meaning sir sir in case of n silicon body uh this uh EVS of the Silicon oxide and uh this substrate have to be uh difference must be constant now yeah so it is a so if we had a n-type silicon body the band bending would be in a different direction then okay uh yes sorry yes sir actually I was confused like uh like I think poorly Krishna should be the like good materials and get as a that's good great material because like like poly silicone and silicone will have very less work function difference so it will keep the threshold voltage low actually as per my knowledge as as much I know can you please explain that so uh we we used polysilicon as the date material because it was very easy and cheap to manufacture using Metals makes the process much more complex and polysilicon and plus policy again and P plus policy can also helps in controlling the VT the band bending initially so that also helps so sir like can you please tell like other advantages of using matter so like so let us say let us say neither SSD is the right course to discuss this in detail because then we are talking about design of the devices I want to talk about the fact that capacitance in a mosfet will behave differently from the capacitance a regular capacitance that you have known till now we are digressing too much but yeah if you want we can discuss it in the office that's not a problem thank you sir okay David uses so along the width of the uh sio2 we see that EC and EV is kind of rising linearly so why is that happening because uh yeah sio2 what happens is there is no electron that can happen and between in nsio2 am I right yes sir it's a dielectric so what happens uh since there is no charge um the entire voltage drop across the or the voltage drop across this silicon dioxide thickness is distributed equitably across the entire back side in Silicon there will be some charges that will still be there fore you have a bend a kind of a curve there because some potential drop happens there so so can we say that the extent of the band bending would depend upon the thickness of the silicon dioxide as well because if we increase this means from the diagram if we increase the silicon dioxide width it will it would rise more linearly thus resisting more voltage drop and no no no so what happens is the slope of this will change the the distribution of band bending across silicon dioxide and the p-type Silicon is is actually a function of the dielectric constants of silicon and silicon dioxide not a function of thickness so the drop across silicon dioxide will be in the ratio of the dielectric constants of silicon dioxide and silicon okay then the slope will be lesser okay if it is thinner the slope will be much deeper and that can lead to tunneling we will look at that later in the past so in one more small questions sorry if we replace the dielectric materials uh by let's say that is having a say higher dielectric value so then the band bending would decrease the type of band bending would also change yes because it is a function of dielectric constant very good this is a very good introduction very good and that's why you told us state that for reducing variability we are using uh thicker dielectric and replacing them with uh no the reason of using hierarchy dialectics was not to be able to do this this is the additional benefit see it's a very costly Affair to use high k dielectrics for silicon dioxide you simply growth oxide that's it to deposit a high K die electrode electric you actually have to do atomic level layer deposition it's a slow process it takes time and it's complex you have you have to talk about rare earth materials and uh rare earth metals and you know 99.9 percent of rare earth metals are sourced from China so it's a it's a big risk the whole electronic industry electronic industry actually uh pivots around geopolitics of China okay so uh we don't want to use high K dialectics just for the fun of it so high grade dialectics were introduced because if you would not use that then uh the silicon dioxide would need to be drawn so thin like you would just need say five angstroms of silicon dioxide that uh huge current would flow from through the gate leakage okay tunneling across the gate so many things would happen so you could not afford that so if you want to scale you you cannot go to that thin a physical that's in physical dialectic there so you go to High K dielectric so that the physical thickness is more okay so it also reduces variability because the physical thickness physical Dimension has increased so variability also reduces naturally yes you understood yes okay yes yeah so aniraj if you have if you have no more question you can lower your hand it makes it easier for me raghav so in this silicon body uh when we are measuring this uh work first 3.1 electrons we are referring to the very at the interface level from the interface why is that actually I'm not able to get because it is summoned from the interface only that an electron can jump across the barrier to be able to jump from say silicon into silicon dioxide so silicon dioxide has this conduction band this is the conduction band of silicon dioxide up there this one what is happening my PowerPoint me seems to have got stuck not able to move into bar point so I may need to restart that but yeah uh the top point you know the top line which has a slant over there this represents uh silicon the conduction band of silicon dioxide so if an electron has to move from Silicon to the conduction band of silicon dioxide it has to have that kind of 3.1 electron volts with it that movement will happen only when the when the two substances are touching each other it cannot happen at some other places so but that's that's that is the moment that is that we don't want right so that will not happen what about whether you want it or not the fact is that if the electron at the interface gets 3.1 electron volts it will jump into the conduction band of the dielectric that's a fact whether you want it or not doesn't matter okay so we are bending 3.1 is a physical phenomena which has to be intact Even in our model so band diagram is a model of this in this silicon oxide and metal is it not it is simply a model of what we are talking about the model has to reflect what is physically the constraint so physically there is a constraint that could jump from Silicon to silicon dioxide you need 3.1 electron volts that is where the model is made like this okay okay so yeah rajneesh so uh why we have a grounded VG here in this oh we just wanted to study something we grounded it so in reality you will have many things coming on the gate this is just one analysis we are doing no no other reason so on varying we did so all things will change yeah yeah yeah that is how you will turn the transistor on and turn it off now by changing the gate voltage I mean that's it we're not at the transistor yet but yes this is just one terminal of the capacitance so capacitance one terminal cannot need not necessarily be fixed both terminals can change you just put it to Brown so this band diagram will change yes yes yes yes okay sir uh you were actually talking about the relationship between these band diagram and vth right sir uh could you I'm like say that once there's nothing like threshold voltage for a moss capacitor you are saying something about a vth previously sir I mean yeah I was talking about that for uh for uh transistors that if the the band bending over here determines what is the threshold voltage that you would require we'll come to that in a little while we'll come to that when we will touch about the mosfets thank you okay or even earlier than that actually so those whose questions are answered please lower your hands uh yeah you said that because of this band bending the mosfet doesn't behave like regular capacitors right so uh how so how are we saying that exactly so uh see for a regular metal metal oxide metal capacitor uh the oxide thickness or the dielectric thickness remains constant is it not yeah yeah over here what is happening over here you realize that if I want to change the charges so so whatever you whatever voltages you apply on the two sides charges will change across the fixed thickness of the capacitor yeah but in a mosfet uh in a mosfet name Moss capacitor you see that there is some band bending happening okay if you add more charges somewhere the bending would change right right so you wanted some charges some charts charge distribution to appear but due to band bending that charge distribution is different from that so what does the uh level of the conduction band of your uh silicon dioxide has do anything with the capacitance because it defines where the electrons would come and settle right right so that is where see capacitance is about two plates and putting charges on those two plates so on the Silicon side how will the charges be placed and where they will be placed that will depend on the bands over there now okay okay yeah because bands Define where the charges can come and where they simply cannot come right and therefore band bending would mean that and variable band mending would mean that the capacitance would vary okay Priyanka so like in this at interface we have to maintain 3.1 electron mole uh like electron affinity so by in not in uh body like when we go from a file from the interface why this bending doesn't happen there like there also we have to maintain a 3.1 electron world no an electron from one one micron depths inside the semiconductor cannot simply jump into the dioxide now yeah to be able to move into the dioxide the electron has to first come close to the surface only then it will jump so this 3.1 is required only at the surface now look at the metal side on the metal side three point one electron voltage constant that is throughout the metal side this is 3.1 electron volts why so because in metals you cannot have any bending so it is all constant but in a semiconductor since you can't have bending uh the capacitance also varies and uh 3.1 electron volt or the you know Fermi level uh or basically at some depth the original nature of the semiconductor would appear and not the band bended one is that clear yes,https://www.youtube.com/watch?v=cXY4b9XCUgM,"Link: https://www.youtube.com/watch?v=cXY4b9XCUgM
Transcript: foreign capacitances and mosfets earlier so that makes my job easier I can move I can actually move a little faster I will not go into too much of detail there then because I just wanted to have you have you get a glimpse of it and if you already have some Glimpse then I can be fast so what we are saying is that when these three materials come together they form a they form a capacitor between them but this capacitor is not like a capacitor between two metals see when you have two metal con two conducting layers there are some different characteristics that this capacitor would have in comparison to a metal oxide or metal dielectric metal capacitor and the reason for that is that uh there are these uh bands and that there are these energy levels that you're talking about and when we bring these semiconductors in contact with the oxide and we say that there is this Fermi level which needs to be matched across the entire material uh then it requires some band bending to happen we will just look at what band bending also means so uh over here what I have done is I've put a n Plus polysilicon a p silicon body and siot that is your silicon dioxide and when I bring these three materials together see n Plus n plus polysilicon means n plus means that there is so much doping that the Fermi level and the conduction band are kind of overlapping that is the kind of doping we have there okay sir could you elaborate on what family Fermi level is okay so Fermi level is a is a notional term it's actually it is a term which states that uh around 50 percent of the you know the probability of finding electrons in a particular material is is plotted and then it is said that uh there are 50 percent of electrons above the Fermi level and fifty percent of electrons below the Fermi level okay so Fermi level is such that uh okay the level itself it describes the energy of the electrons right yes it is about some energy of electrons but for example look at the Silicon silicon part of it the Silicon body part of it um over here the family level is in the band Gap what does that mean okay okay level actually there is no electron there over here look at it in the oxide region again the Fermi level is in the band app what that means is in within the uh oxide you're not expecting any electrons there Fermi level is just that probability what is the probability yeah so for me was a scientist who gave these this for me direct statistics okay to to uh describe the distribution of electrons in a semiconductor okay okay and uh so that is classical physics um in an Advanced Technologies are are today we also use quantum Quantum devices and quantum physics into it so some of these things may hold true some of these things may not fall true but Fermi level you say is a notional level at which the probability of finding an electron is 50 percent so what what is the meaning of primary level lying inside a band Gap it simply means when when this line is closer to the valence band it means that is a p-type doped substance so the probability of finding electrons in the balance band is higher when it is closer to the conduction band it means it's the n-type doc substance or probability of finding an electron in the valence band is higher and when it is in the center that is along with the intrinsic level so intrinsic level is in the center of the band Gap sure it means that uh the material is not doped okay okay so Fermi level has no physical significance it has only a notional thing created to improve our understanding and to do some analysis of the system physically it represents no energy level is that clear yes sir okay so what happens is that when I bring these three materials next to each other then uh the Fermi level has to be aligned because in this region we say that the probability of finding an electron above the Fermi level is 50 percent and below it is also 50 percent now we also understand that silicon say polysilicon over here and sio2 have a Affinity difference of 3.1 electron volts okay and over here also there is a gap of 3.1 electron volts because this side is also silicon but because the Fermi level is stable so at at an infinite depth we would we would get the same uh Fermi level as the doping or the Fermi level at the same level as a doping but close to this oxide boundary what happens is there starts to be some collection of charge or removal of charge so that I can get this 3.1 electron volt dap between oxide and the conduction band of the semiconductor this is called as band bending and this is what changes the behavior of a mass capacitor from a regular capacitor that you would otherwise see in your Labs you may have already seen in your earlier labs and the the capacitors the metal capacitors are stuff like that that you would otherwise use Mass capacitors behave would behave differently from them is this part clear that at least this much that most most capacitors will not be like any other capacitor they will behave differently this part here yeah so okay so as well you have a question so can you please explain that again uh I was not able to understand like flaw like from this when you have said 3.1 electron volts in the gate side and 3.1 in the silicon and that is what is bending like can you please explain that role part again Okay so let us say the three materials are separately placed as of now let us say okay uh yeah let us say three materials are separately are placed separately as of now and uh when they are separate separated when they are separate we realize that conduction band of polysilicon conduction band of silicon and conduction band of the dielectric they will have a gap of 3.1 electron volt between them is it clear till here yes sir now because of the doping Fermi level of this was here um level was at the EC that is how we had doped because you wanted it to be like a metal yes metal means a sea of electrons lots of electrons there so you dope it very heavily so heavily that it was almost like EC and efr coinciding you will always have electrons in the conduction and that is when it becomes a metal otherwise it will not be a metal yes sir so you dope it very heavily so the Fermi level and this match now you bring these two materials together what happens as soon as these materials start to touch each other a requirement section that Fermi levels have to be matched okay so Fermi levels have to be matched what does this mean it means that this material there will be some voltage generated internally so that Fermi level will match all of this will go up all of this will go up so that the Fermi level matches and your valence band is here and conduction band is up there but there is also this free condition but there is also this precondition that spacing between these two will be 3.1 volts so what happens if this went up by let us say x volts a data X you know extra question part will appear across the dielectric dielectric can always have a voltage drop across it see Metals cannot have voltage drop across them do you understand this if there is any voltage drop across a metal electrons will flow and kind of mitigate that voltage drop but dielectrics and semiconductors can have some voltage drop across them because they don't allow flow of electrons easily yes so the dielectric over here will bend and this is a semiconductor so a semiconductor can also bend a bit so the semiconductor also backs combined this bending plus this bending we would get we would get this movement of the Fermi level from uh wherever it was to the metal Fermi level okay okay so bending that happened here the line is not coming yeah so the bending that happened across the oxide and the bending that happened across the uh uh semiconductor side I'd add the addition of that will be equal to EC minus EF on the semiconductor side yes sir okay okay and it is because of this band bending that your device that your capacitance Behavior do you understand this is the capacitor but this capacitor Behavior will be different from a regular metal oxide metal capacitor okay so okay okay and it is much more clear yes thank you great rajnish you have a question yeah sir uh sir as you said that uh between the uh the conduction bands of the uh poly and the sio2 uh the energy gap must be 3.1 electron sir uh so a and in this side between the uh this substrate and the Silicon oxide uh uh do uh it is a starting behaving like n type that's why we have to maintain 3.1 electron over here also no no no 3.1 electron voltage required because that is the barrier for any electron to move from Silicon to silicon dioxide okay so for any electron to move from Silicon to silicon dioxide you would need 3.1 electron volts so you cannot change that happens okay and there is no bending on the metal side because metal is a sea of electrons yes yes thank you okay I have to add some more things like if someone asks why band binding is happening so we have to save for matching the Fermi level band bending is happening is that right so when you explain the way like I explained it to you when when things are in contact with each other their family levels have to match okay but there is a physical uh barrier also which exists there's this electrical barrier which cannot be changed so this 3.1 electron volt also has to be maintained okay so for the because of these Spirits because of these two things that band bending happens okay okay thank you sir okay not just one of them both of them are involved yes sir okay that's nice so can I ask yes so uh as I understand the gate and the Silicon body there are different materials so but why we're meeting the 3.1 electron volt for both both of them because we use poly silicon for the gate now polysilicon is polycrystalline silicon okay so that's why it's three point one same thing okay yes so uh okay and it's a very good question rather because we need to understand that in Advanced Technologies we're using metal gates so what happens when I use a metal gate this 3.1 electron volt is not necessary now I can have a different uh I can have a different uh pinning point so till the time we were using polysilicon Gates there was a constraint on what the VT of different devices can be because you can only dope as much and this is only bending that you can bring about okay whereas uh once we start to use metal gates and hierarchy dielectrics uh what happens is that I have more flexibility by changing the material of the gate to change my VT of the pmos and the nmos independently okay so this is something that you should remember this would come in handy in some interview sometime you had a question yes sir sir talking about this silicon body where the bending is actually happening at the interface of the oxide and the Silicon bodies and there I can see that Fermi level has moved towards more towards the conduction band so can I say that electron concentration has also changed it is more towards uh interface rather than the bulk yes uh interface Matlab sorry uh interface okay so what we say is that at the surface of uh the device at the surface of or at the interface of silicon dioxide and uh uh p-type silicon body there is a higher density of electrons than in the remaining part of the body that is what you can say yes okay so ah we have to be very exact in the way we speak things over here because a slip of one word or another can can completely change the meaning sir sir in case of n silicon body uh this uh EVS of the Silicon oxide and uh this substrate have to be uh difference must be constant now yeah so it is a so if we had a n-type silicon body the band bending would be in a different direction then okay uh yes sorry yes sir actually I was confused like uh like I think poorly Krishna should be the like good materials and get as a that's good great material because like like poly silicone and silicone will have very less work function difference so it will keep the threshold voltage low actually as per my knowledge as as much I know can you please explain that so uh we we used polysilicon as the date material because it was very easy and cheap to manufacture using Metals makes the process much more complex and polysilicon and plus policy again and P plus policy can also helps in controlling the VT the band bending initially so that also helps so sir like can you please tell like other advantages of using matter so like so let us say let us say neither SSD is the right course to discuss this in detail because then we are talking about design of the devices I want to talk about the fact that capacitance in a mosfet will behave differently from the capacitance a regular capacitance that you have known till now we are digressing too much but yeah if you want we can discuss it in the office that's not a problem thank you sir okay David uses so along the width of the uh sio2 we see that EC and EV is kind of rising linearly so why is that happening because uh yeah sio2 what happens is there is no electron that can happen and between in nsio2 am I right yes sir it's a dielectric so what happens uh since there is no charge um the entire voltage drop across the or the voltage drop across this silicon dioxide thickness is distributed equitably across the entire back side in Silicon there will be some charges that will still be there fore you have a bend a kind of a curve there because some potential drop happens there so so can we say that the extent of the band bending would depend upon the thickness of the silicon dioxide as well because if we increase this means from the diagram if we increase the silicon dioxide width it will it would rise more linearly thus resisting more voltage drop and no no no so what happens is the slope of this will change the the distribution of band bending across silicon dioxide and the p-type Silicon is is actually a function of the dielectric constants of silicon and silicon dioxide not a function of thickness so the drop across silicon dioxide will be in the ratio of the dielectric constants of silicon dioxide and silicon okay then the slope will be lesser okay if it is thinner the slope will be much deeper and that can lead to tunneling we will look at that later in the past so in one more small questions sorry if we replace the dielectric materials uh by let's say that is having a say higher dielectric value so then the band bending would decrease the type of band bending would also change yes because it is a function of dielectric constant very good this is a very good introduction very good and that's why you told us state that for reducing variability we are using uh thicker dielectric and replacing them with uh no the reason of using hierarchy dialectics was not to be able to do this this is the additional benefit see it's a very costly Affair to use high k dielectrics for silicon dioxide you simply growth oxide that's it to deposit a high K die electrode electric you actually have to do atomic level layer deposition it's a slow process it takes time and it's complex you have you have to talk about rare earth materials and uh rare earth metals and you know 99.9 percent of rare earth metals are sourced from China so it's a it's a big risk the whole electronic industry electronic industry actually uh pivots around geopolitics of China okay so uh we don't want to use high K dialectics just for the fun of it so high grade dialectics were introduced because if you would not use that then uh the silicon dioxide would need to be drawn so thin like you would just need say five angstroms of silicon dioxide that uh huge current would flow from through the gate leakage okay tunneling across the gate so many things would happen so you could not afford that so if you want to scale you you cannot go to that thin a physical that's in physical dialectic there so you go to High K dielectric so that the physical thickness is more okay so it also reduces variability because the physical thickness physical Dimension has increased so variability also reduces naturally yes you understood yes okay yes yeah so aniraj if you have if you have no more question you can lower your hand it makes it easier for me raghav so in this silicon body uh when we are measuring this uh work first 3.1 electrons we are referring to the very at the interface level from the interface why is 
that actually I'm not able to get because it is summoned from the interface only that an electron can jump across the barrier to be able to jump from say silicon into silicon dioxide so silicon dioxide has this conduction band this is the conduction band of silicon dioxide up there this one what is happening my PowerPoint me seems to have got stuck not able to move into bar point so I may need to restart that but yeah uh the top point you know the top line which has a slant over there this represents uh silicon the conduction band of silicon dioxide so if an electron has to move from Silicon to the conduction band of silicon dioxide it has to have that kind of 3.1 electron volts with it that movement will happen only when the when the two substances are touching each other it cannot happen at some other places so but that's that's that is the moment that is that we don't want right so that will not happen what about whether you want it or not the fact is that if the electron at the interface gets 3.1 electron volts it will jump into the conduction band of the dielectric that's a fact whether you want it or not doesn't matter okay so we are bending 3.1 is a physical phenomena which has to be intact Even in our model so band diagram is a model of this in this silicon oxide and metal is it not it is simply a model of what we are talking about the model has to reflect what is physically the constraint so physically there is a constraint that could jump from Silicon to silicon dioxide you need 3.1 electron volts that is where the model is made like this okay okay so yeah rajneesh so uh why we have a grounded VG here in this oh we just wanted to study something we grounded it so in reality you will have many things coming on the gate this is just one analysis we are doing no no other reason so on varying we did so all things will change yeah yeah yeah that is how you will turn the transistor on and turn it off now by changing the gate voltage I mean that's it we're not at the transistor yet but yes this is just one terminal of the capacitance so capacitance one terminal cannot need not necessarily be fixed both terminals can change you just put it to Brown so this band diagram will change yes yes yes yes okay sir uh you were actually talking about the relationship between these band diagram and vth right sir uh could you I'm like say that once there's nothing like threshold voltage for a moss capacitor you are saying something about a vth previously sir I mean yeah I was talking about that for uh for uh transistors that if the the band bending over here determines what is the threshold voltage that you would require we'll come to that in a little while we'll come to that when we will touch about the mosfets thank you okay or even earlier than that actually so those whose questions are answered please lower your hands uh yeah you said that because of this band bending the mosfet doesn't behave like regular capacitors right so uh how so how are we saying that exactly so uh see for a regular metal metal oxide metal capacitor uh the oxide thickness or the dielectric thickness remains constant is it not yeah yeah over here what is happening over here you realize that if I want to change the charges so so whatever you whatever voltages you apply on the two sides charges will change across the fixed thickness of the capacitor yeah but in a mosfet uh in a mosfet name Moss capacitor you see that there is some band bending happening okay if you add more charges somewhere the bending would change right right so you wanted some charges some charts charge distribution to appear but due to band bending that charge distribution is different from that so what does the uh level of the conduction band of your uh silicon dioxide has do anything with the capacitance because it defines where the electrons would come and settle right right so that is where see capacitance is about two plates and putting charges on those two plates so on the Silicon side how will the charges be placed and where they will be placed that will depend on the bands over there now okay okay yeah because bands Define where the charges can come and where they simply cannot come right and therefore band bending would mean that and variable band mending would mean that the capacitance would vary okay Priyanka so like in this at interface we have to maintain 3.1 electron mole uh like electron affinity so by in not in uh body like when we go from a file from the interface why this bending doesn't happen there like there also we have to maintain a 3.1 electron world no an electron from one one micron depths inside the semiconductor cannot simply jump into the dioxide now yeah to be able to move into the dioxide the electron has to first come close to the surface only then it will jump so this 3.1 is required only at the surface now look at the metal side on the metal side three point one electron voltage constant that is throughout the metal side this is 3.1 electron volts why so because in metals you cannot have any bending so it is all constant but in a semiconductor since you can't have bending uh the capacitance also varies and uh 3.1 electron volt or the you know Fermi level uh or basically at some depth the original nature of the semiconductor would appear and not the band bended one is that clear yes"
CMe2mvwtX2M,so i will need to stop the recording over here for a minute uh because my okay so uh we just earlier talked about the fact here you have a question your hand is raised oh no sorry sir so uh we were just talking about the fact that due to band bending in the semiconductor region the mosfet capacitor would behave different the mos capacitor would behave differently than a metal capacitor a metal oxide metal capacitor so to be able to characterize this what we do is we apply a voltage between substrate and the gate and we say that we will vary this voltage v and we want to observe the you know the change in charge and the change in capacitance or the flow of current that is happening to measure the capacitance there okay and you see what happens over time when i apply a negative voltage on the gate what would happen when i apply a negative voltage on the gate though this is a p times substrate more holes would accumulate at the surface of silicon are you able to see this yes yes sir huh yes so this part is called accumulation now when i say that i reduce that negative voltage i bring the voltage closer to zero then what happens then we we looked at uh this band bending diagram and this voltage at both the nodes was zero so uh i would have this kind of a band bending happening there so if you look at it carefully what we are talking about it is that at the surface of of the silicon over here my es is kind of coinciding with the fermi level so what i would say is that there is some so when it is at the fermi level what does that mean that the silicon behavior in this region would be something like intrinsic silicon are you able to see this so if e s is equal to e i we call it as intrinsic silicon that nothing is doped there is no doping am i right yes over here if you look at it carefully uh see e i would be something like this over here in the center of ef and ec ef and economy easy and easy so yeah it's the band of silicon right no ei is the intrinsic energy level which is in the center of easy and easy intrinsic energy okay ei the red one that i am showing that's called ei okay okay so over here we see that e i and e f are almost coinciding due to band bending so i have intrinsic silicon so i would say things are almost depleted there okay and what happens is that in this region node if i if i change the voltage by a small value of few millivolts here and there there will be no charge change over here at the surface the charge would change at the boundary of this depletion layer there will be slightly extra bending or slightly lesser bending okay because at the surface it is almost intrinsic now any change any more charge or any less charge the change would happen at the boundary of the depletion rate uh so so just just to like clarify so uh can you go back to the previous slide this one uh uh no no okay i meant that uh yeah this one so here near the surface of i mean near the boundary of um your your silicon and your silicon dioxide your intrinsic energy level is coinciding with the fermi level so there it behaves like intrinsic silicon so there's not much accumulation over there but uh when you go away from the boundary it uh it approaches the conduction uh yeah you start to get more charges so so that there it behaves more like an n-type that's b-type over here it's e-type yeah but sir if it's uh if your intrinsic level is closer to the conduction band the intrinsic level is always in the center okay so when the band's been intrinsic level also is shown to be bending it is also a notional level right so um yeah so there if it's like regular p-type then why do we see a depletion region over there depletion means there are no uh like if you need charges more charges there are not many charges available here because it's almost intrinsic oh okay okay so like relatively it's uh relative and compared to the other one it's like end time even though it's just intrinsic silicon yeah okay right okay so what happens because there are no charges in this region any charges you need you will get them from the remaining depth of the silicon okay so any change in charge density would happen at the boundary of my bending so my effective ox dielectric thickness see when we say that my dielectric there are these two metal one metal two and there is this dielectric in between we say that the capacitance is equal to epsilon uh by a let us say okay epsilon into uh like epsilon a by d ox i know as t ox reduces your capacitance increases okay so what are we saying over here we are saying that my t-ox we are saying that this is my capacitor because i change a small voltage over here there is a small change in capacitance right after t ox but in silicon we are saying that that change in charge happens at t ox plus w d so what happens the denominator becomes t ox plus wd what does that mean that my capacitance would reduce right right okay okay now effectively a capacitor with with in series with another yeah i know then uh if i do still more apply still more voltage over there then there will be still more band bending still more band bending would mean let us say this and this would mean that i had a p-type but in this region i have an n-type material now because my fermi level is very close to the conduction band because of so high band bending okay so this is called as inversion layer and now if i want to change any charge there is so many so many charged particles available over here all that movement of charge can happen from the inversion layer itself so again my oxide thickness comes out to be t-ox okay so when you increase the voltage over here like this you see that initially the capacitance is high why is it high it is high because the change in charge is happening across the oxide only this is the accumulation region after some time we see that oh this capacitance starts to decrease why does it start to decrease because this depletion layer starts to get formed and this depletion layer means there are no float no available charges there so that the any change in charge would happen at the boundary of the depletion layer but all of a sudden what happens an inversion layer is formed and additional change of charge happens at the surface of or at the interface of silicon and silicon dioxide again so this is the low frequency transfer characteristic or characteristic of the mass capacitor now why did i say low frequency so maybe because at low frequency only that interface would be changing at higher frequencies so it will remain at low frequency what happens is at low frequency what happens is my let us say this is the band bending thing happening there so at low frequencies what happens is i have sufficient time to move electrons from here to substrate sufficient time to do that and therefore any change in electron density would happen at this interface at very high frequency what happens is uh if i'm moving very very very very fast so what happens is electron starts to go out but it has not even crossed the depletion region when the polarity has changed so the electrons of this region remain here only so where does any change in electrons happen it happens at the depletion width boundary again and therefore at very high frequencies the mass capacitance will behave as a very less capacitance sir yes sir could you explain this inversion layer again sir inversion layer what do you understand by inversion layer till now sir uh i'm like what i understood is that uh there is a another layer which is being formed in between like depletion and this layer so see we had a p-type silicon am i right yes sir now due to band bending the surface of the silicon has more density of electrons now yes so that at the surface it has now become n-type okay sir yes sir yes that is why it is called inversion because the polarity of the material we had we had physically of p-type material but at the surface we now have a n-type material okay that is why it is called inversion layer uh sir i mean even in depletion region also we we do have this electrons right sir first suppose uh no you do not have that kind of a density of electrons as you would have in an n type material depletion region actually has all is kind of depleted of any moving moving carriers that is why it is called depletion region okay i'm like due to this high voltage or something we are getting free electrons in that region yes okay sir thank you sir because so much band bending has happened electrons can very easily come there here rajneesh [Music] so ei is always designed or always shown as bit as the center of band gap it is a constant value e i is a notional number or a notional energy level where no electron can exist can sit there but it is shown as the center of the band gap it is an energy level which is equidistant from the valence band and the conduction band both ef on the other hand is derived from fermi direct statistics which says that probability of electrons above this is 50 and below this is also 50 percent ef is also a national energy level yes it is also a notional energy level however es will be different uh years will be closer to the conduction band in n-type material and valence band in p-type material e i will always be equidistant from both okay yes fashionable sir uh yes sir actually when this inversion layer form sir uh are the depletion electrons even present so i mean like below them depletion has no moving carriers yes sir i'm i was asking only about the layers here not the electrons or the carriers is that present over there depletion layer is always there there are there are some there are silicon atoms there yes sir i mean so there is there is a flood of electrons also there therefore we call it electro uh inversion layer so where are these electrons actually moving from sorry i mean like our voltage is being given between the gate and the body to be precise uh right sir so uh where are these electrons exactly moving sir so if the depletion region is in between uh gate and body and over there if the oh over that if the inversion line is being formed then uh i don't see any uh charge transfer or something or the current transfer between the gate and the body the gate and the body do not have any charge transfer capacitor does not allow charge to move from gate to the from one terminal to the other it cannot happen can it there is a silicon dioxide barrier in between nothing would ever move from gate to the body okay that is why we have silicon dioxide is it not that is the meaning of a capacitor but the two plates are not physically connected but they are influencing each of those behavior so what is happening i change something on the gate the behavior on the silicon side changes that is what a capacitance is okay sir we are only talking about the capacitance value that's it uh not about any uh current flow or something yeah thank you sir so so this high frequency model so i couldn't get it so this yeah so the high frequency model rather is about uh the fact that see it takes some picoseconds even if it is picoseconds for an electron to move out from the inversion layer to the substrate to the body henna now if i'm operating at a small signal level which is say 20 gigahertz how much time do i have just a few picoseconds the electron may not be able to physically move out from the inversion layer to the body but some voltage change is happening so some charge change is happening somewhere it cannot happen if it is not happening in the inversion layer it can only happen at the boundary of the depletion layer so like when i've crossed the vt voltage i have my inversion layer form so now i can see a effective capacitance thickness of t-ox now if i increase beyond vt now but still i will have that inversion layer right so so i mean i can understand that why that uh like i should go up like that because uh even if i'm fasting changing and changing very fast even the very frequency is very fast but still that inversion there exists so the t-ox is constant so what additional charge what is the capacitance we discussed that a little while back the capacitance is about or the thickness of oxide or whatever we talk about is about there is one plate there is another plate i change something here something changes on this plate that is the effect of spacing between the two plates is it not now there is this television layer here fine but nothing is changing there because there is no time for it to change only change is happening here only at the edge of the depletion boundary so this is my effective capacitance okay so inversion inversion liquid capacitance will be there but additional to that at the depletion end also no inver at very high frequency inversion layer does not have any influence on capacitance because it cannot change any charges the charges in the inversion layer cannot change yes in response to the change in gate voltage okay answer but still why it is getting constant then after that at the high frequency model shouldn't be some kind of depletion depletion width cannot grow beyond a particular maximum level any further voltage you apply there will be more charges in the in the inversion layer depletion widths cannot go beyond that okay so after the high frequency model the change the the changes in charge the delta q is happening at the very uh at the wd max depletion rate okay okay so it becomes this inversion becomes a constant basically okay sir yes i'm sorry so yeah i had this uh i had a question regarding depletion there only so like uh when we are going from um you know your depletion region to your inversion region so like it's accumulation of like effectively free electrons is just happening on the boundary right but as it happens so somewhere between the inversion layer to your body there has to be a depletion there right so the depletion layer so the depletion layer would always be there but at low frequency the charges in the electro and the inversion layer can change okay therefore the effective capacitance that you see increases because the t-ox changes or the effective distance between the two plates their charges are changing reduces right right okay sir yes sir uh my doubt was the same i'm like that this is an addition to the previous question asked by me so sir can i think that this inversion layer which is formed i ca can i think that as a metal layer and the capacitance which we are uh mentioning in this at the inversion point is the capacitance between the gate and the inversion layer yes yes right sir so and uh one more thing sir uh so what about the i'm like yeah this question was asked by maher even so what about the capacitance between the inversion layer and the body they are connected any charge can flow from an inversion layer to the body so how can there be a capacitance between them but but there would be a depletion region in between them right sir uh and depletion region doesn't mean charges cannot flow from there depletion region only means there are no charges available there oh so uh uh even uh there's no capacitance between them yeah okay sir oh thank you okay uh theta in that case we can call it as a depletion there i'm sorry depletion we can call it as a depletion capacitance uh we have a metal oxide and there is a channel and below that there is a uh depletion also we can call this we can call this as our uh depletion and the channel and the substrate has a depletion capacitance yeah so you see we are calling it depletion capacitance over here absolutely right okay so after forming the channel also uh we can say that the gate and gate oxide and channel has one capacitance and the channel depletion region under substrate as another capacitance so they are in the series no sir yeah yeah but the change in charge is happening over here at low frequency change in charge happens over here at high frequency change in charge happens over here so at low frequency the capacitance is large at high frequency capacitance goes down oh sorry even in the low frequency also the depletion region will be let there be a capacitance what would you observe at the gate you change something at what place will you see the change in charge that defines the thickness that you need to consider when you measure capacitance okay okay so i've got it but okay physically those exist doesn't matter okay but that doesn't come into the electrical plane so it doesn't matter it doesn't change anything for you yes okay yeah i think you can cover only till here today but anything else um sir uh question on this slide only so you have written uh on the upper part that mos transistor cv at any frequency so basically it won't have this high frequency effect if i have a transistor yes so that is evident in the previous slide so if there is an if there is a source or drain region over here the electrons will simply change from here to here they don't have to travel the width of the depletion layer okay so one more question yeah stuff about the depletion uh i mean if i want to understand that then can we say that uh okay when the depletion is happening so at the at the time when that band bending happens so basically the holes move away from the interface that we were saying surface of that and then the ions are only there so they cannot uh conduct right so yeah okay that is what depletion layer is okay okay if the graph cylinder graph slide the water squashy static cv washi static cv quasi static cv means that this is dynamic in nature in the sense that it appears as a constant cv like a constant cv curve but what happens is that there is a constant change or flow of electrons between source drain and this inversion layer or stuff like that so it's quasi-static it's not as soon as you will change the charge as soon as you will remove the voltages uh there is no capacitance there again see a metal oxide metal this capacitance is always there whether there is a charge when you whether you apply a voltage there or not yes but in a mosfet the capacitance and its value is quasi-static it depends on the region of operation so it is not a static cv it is quasi static it changes with the region of operation yeah okay so sir yes so uh the question gandhi asked at any f can you please elaborate uh i couldn't get it when he asked that at any f at any frequency in the top part for mosfet for mosfet the charges can come from the source and drain region the distance between source gain region and that of the body is very different so in mosfet even at high frequencies you will see a higher capacitance after inversion layer is pumped because inversion layer still continues to change in terms of amount of charge okay however in a mos capacitor that doesn't happen okay so that any phosphorous mosfet business okay okay see that you have a question your hand is raised okay so if there are no more questions we will close it here yes sir depletion reason starts from the flat band voltage and go up to the threshold voltage according to this figure yes so in the fragment voltage there is no band bending occurs after that in the flat band voltage there is no band bending because everything is flat yeah yeah yeah then the band bending stretch so after that bend bending uh start again in the reverse direction of accumulation yeah okay okay okay uh sir hello just to confirm that in when we are talking about the frequency we are ensuring that the basic offset of vt is there and about that only the frequency of the signal above that is guaranteed yeah we're talking about small signal models over here okay okay davidjit sir just one question sir how the band bending determines uh my uh vt of the device would be okay so let us say the intrinsic band bending is 500 millivolts okay so if 500 millivolts so in at 0 volts if i say i have already reached uh let us look at it like this at 0 volts there is some band bending that is already happening to create the inversion layer i need to apply some more voltage and i will get it now if my curve was such that flat band happened till here and then band bending happened like this then the vt would come here somewhere here okay so the more the band bending that already happens because of my uh gate dielectric interface whatever okay the more band mending that already happens the lesser the vp would be sure because i need lesser bending for bringing in the inversion layer okay so from this what you have told can you come can we say that if there is more band bending then we'll be for will be at resting stage will be further we will be further away from the vt so for those type of devices which would be less no no no if band banding is more already it means a inversion layer is easy to form so vt is going to be less yes so vt is going to be less sub threshold okay yes okay anything else okay so thank you guys we will start with mos transistors next class uh and then we will move to other devices okay thank you one servant yes sir uh in david's question uh sir he told that vt is less than how we told that it is in the it is the it is in the sub threshold i'm sorry sir uh sir you don't know that in that the more the backbending the bt gets lesser so how we determine that it is in the sub regulator oh that's because at lower vt when you have less vt then the sub threshold currents are higher that's the only thing don't worry about it we will talk about the current if you've studied current equations of mosfets earlier you will see that okay so thank you guys all the best see you on friday then thank you sir,https://www.youtube.com/watch?v=CMe2mvwtX2M,"Link: https://www.youtube.com/watch?v=CMe2mvwtX2M
Transcript: so i will need to stop the recording over here for a minute uh because my okay so uh we just earlier talked about the fact here you have a question your hand is raised oh no sorry sir so uh we were just talking about the fact that due to band bending in the semiconductor region the mosfet capacitor would behave different the mos capacitor would behave differently than a metal capacitor a metal oxide metal capacitor so to be able to characterize this what we do is we apply a voltage between substrate and the gate and we say that we will vary this voltage v and we want to observe the you know the change in charge and the change in capacitance or the flow of current that is happening to measure the capacitance there okay and you see what happens over time when i apply a negative voltage on the gate what would happen when i apply a negative voltage on the gate though this is a p times substrate more holes would accumulate at the surface of silicon are you able to see this yes yes sir huh yes so this part is called accumulation now when i say that i reduce that negative voltage i bring the voltage closer to zero then what happens then we we looked at uh this band bending diagram and this voltage at both the nodes was zero so uh i would have this kind of a band bending happening there so if you look at it carefully what we are talking about it is that at the surface of of the silicon over here my es is kind of coinciding with the fermi level so what i would say is that there is some so when it is at the fermi level what does that mean that the silicon behavior in this region would be something like intrinsic silicon are you able to see this so if e s is equal to e i we call it as intrinsic silicon that nothing is doped there is no doping am i right yes over here if you look at it carefully uh see e i would be something like this over here in the center of ef and ec ef and economy easy and easy so yeah it's the band of silicon right no ei is the intrinsic energy level which is in the center of easy and easy intrinsic energy okay ei the red one that i am showing that's called ei okay okay so over here we see that e i and e f are almost coinciding due to band bending so i have intrinsic silicon so i would say things are almost depleted there okay and what happens is that in this region node if i if i change the voltage by a small value of few millivolts here and there there will be no charge change over here at the surface the charge would change at the boundary of this depletion layer there will be slightly extra bending or slightly lesser bending okay because at the surface it is almost intrinsic now any change any more charge or any less charge the change would happen at the boundary of the depletion rate uh so so just just to like clarify so uh can you go back to the previous slide this one uh uh no no okay i meant that uh yeah this one so here near the surface of i mean near the boundary of um your your silicon and your silicon dioxide your intrinsic energy level is coinciding with the fermi level so there it behaves like intrinsic silicon so there's not much accumulation over there but uh when you go away from the boundary it uh it approaches the conduction uh yeah you start to get more charges so so that there it behaves more like an n-type that's b-type over here it's e-type yeah but sir if it's uh if your intrinsic level is closer to the conduction band the intrinsic level is always in the center okay so when the band's been intrinsic level also is shown to be bending it is also a notional level right so um yeah so there if it's like regular p-type then why do we see a depletion region over there depletion means there are no uh like if you need charges more charges there are not many charges available here because it's almost intrinsic oh okay okay so like relatively it's uh relative and compared to the other one it's like end time even though it's just intrinsic silicon yeah okay right okay so what happens because there are no charges in this region any charges you need you will get them from the remaining depth of the silicon okay so any change in charge density would happen at the boundary of my bending so my effective ox dielectric thickness see when we say that my dielectric there are these two metal one metal two and there is this dielectric in between we say that the capacitance is equal to epsilon uh by a let us say okay epsilon into uh like epsilon a by d ox i know as t ox reduces your capacitance increases okay so what are we saying over here we are saying that my t-ox we are saying that this is my capacitor because i change a small voltage over here there is a small change in capacitance right after t ox but in silicon we are saying that that change in charge happens at t ox plus w d so what happens the denominator becomes t ox plus wd what does that mean that my capacitance would reduce right right okay okay now effectively a capacitor with with in series with another yeah i know then uh if i do still more apply still more voltage over there then there will be still more band bending still more band bending would mean let us say this and this would mean that i had a p-type but in this region i have an n-type material now because my fermi level is very close to the conduction band because of so high band bending okay so this is called as inversion layer and now if i want to change any charge there is so many so many charged particles available over here all that movement of charge can happen from the inversion layer itself so again my oxide thickness comes out to be t-ox okay so when you increase the voltage over here like this you see that initially the capacitance is high why is it high it is high because the change in charge is happening across the oxide only this is the accumulation region after some time we see that oh this capacitance starts to decrease why does it start to decrease because this depletion layer starts to get formed and this depletion layer means there are no float no available charges there so that the any change in charge would happen at the boundary of the depletion layer but all of a sudden what happens an inversion layer is formed and additional change of charge happens at the surface of or at the interface of silicon and silicon dioxide again so this is the low frequency transfer characteristic or characteristic of the mass capacitor now why did i say low frequency so maybe because at low frequency only that interface would be changing at higher frequencies so it will remain at low frequency what happens is at low frequency what happens is my let us say this is the band bending thing happening there so at low frequencies what happens is i have sufficient time to move electrons from here to substrate sufficient time to do that and therefore any change in electron density would happen at this interface at very high frequency what happens is uh if i'm moving very very very very fast so what happens is electron starts to go out but it has not even crossed the depletion region when the polarity has changed so the electrons of this region remain here only so where does any change in electrons happen it happens at the depletion width boundary again and therefore at very high frequencies the mass capacitance will behave as a very less capacitance sir yes sir could you explain this inversion layer again sir inversion layer what do you understand by inversion layer till now sir uh i'm like what i understood is that uh there is a another layer which is being formed in between like depletion and this layer so see we had a p-type silicon am i right yes sir now due to band bending the surface of the silicon has more density of electrons now yes so that at the surface it has now become n-type okay sir yes sir yes that is why it is called inversion because the polarity of the material we had we had physically of p-type material but at the surface we now have a n-type material okay that is why it is called inversion layer uh sir i mean even in depletion region also we we do have this electrons right sir first suppose uh no you do not have that kind of a density of electrons as you would have in an n type material depletion region actually has all is kind of depleted of any moving moving carriers that is why it is called depletion region okay i'm like due to this high voltage or something we are getting free electrons in that region yes okay sir thank you sir because so much band bending has happened electrons can very easily come there here rajneesh [Music] so ei is always designed or always shown as bit as the center of band gap it is a constant value e i is a notional number or a notional energy level where no electron can exist can sit there but it is shown as the center of the band gap it is an energy level which is equidistant from the valence band and the conduction band both ef on the other hand is derived from fermi direct statistics which says that probability of electrons above this is 50 and below this is also 50 percent ef is also a national energy level yes it is also a notional energy level however es will be different uh years will be closer to the conduction band in n-type material and valence band in p-type material e i will always be equidistant from both okay yes fashionable sir uh yes sir actually when this inversion layer form sir uh are the depletion electrons even present so i mean like below them depletion has no moving carriers yes sir i'm i was asking only about the layers here not the electrons or the carriers is that present over there depletion layer is always there there are there are some there are silicon atoms there yes sir i mean so there is there is a flood of electrons also there therefore we call it electro uh inversion layer so where are these electrons actually moving from sorry i mean like our voltage is being given between the gate and the body to be precise uh right sir so uh where are these electrons exactly moving sir so if the depletion region is in between uh gate and body and over there if the oh over that if the inversion line is being formed then uh i don't see any uh charge transfer or something or the current transfer between the gate and the body the gate and the body do not have any charge transfer capacitor does not allow charge to move from gate to the from one terminal to the other it cannot happen can it there is a silicon dioxide barrier in between nothing would ever move from gate to the body okay that is why we have silicon dioxide is it not that is the meaning of a capacitor but the two plates are not physically connected but they are influencing each of those behavior so what is happening i change something on the gate the behavior on the silicon side changes that is what a capacitance is okay sir we are only talking about the capacitance value that's it uh not about any uh current flow or something yeah thank you sir so so this high frequency model so i couldn't get it so this yeah so the high frequency model rather is about uh the fact that see it takes some picoseconds even if it is picoseconds for an electron to move out from the inversion layer to the substrate to the body henna now if i'm operating at a small signal level which is say 20 gigahertz how much time do i have just a few picoseconds the electron may not be able to physically move out from the inversion layer to the body but some voltage change is happening so some charge change is happening somewhere it cannot happen if it is not happening in the inversion layer it can only happen at the boundary of the depletion layer so like when i've crossed the vt voltage i have my inversion layer form so now i can see a effective capacitance thickness of t-ox now if i increase beyond vt now but still i will have that inversion layer right so so i mean i can understand that why that uh like i should go up like that because uh even if i'm fasting changing and changing very fast even the very frequency is very fast but still that inversion there exists so the t-ox is constant so what additional charge what is the capacitance we discussed that a little while back the capacitance is about or the thickness of oxide or whatever we talk about is about there is one plate there is another plate i change something here something changes on this plate that is the effect of spacing between the two plates is it not now there is this television layer here fine but nothing is changing there because there is no time for it to change only change is happening here only at the edge of the depletion boundary so this is my effective capacitance okay so inversion inversion liquid capacitance will be there but additional to that at the depletion end also no inver at very high frequency inversion layer does not have any influence on capacitance because it cannot change any charges the charges in the inversion layer cannot change yes in response to the change in gate voltage okay answer but still why it is getting constant then after that at the high frequency model shouldn't be some kind of depletion depletion width cannot grow beyond a particular maximum level any further voltage you apply there will be more charges in the in the inversion layer depletion widths cannot go beyond that okay so after the high frequency model the change the the changes in charge the delta q is happening at the very uh at the wd max depletion rate okay okay so it becomes this inversion becomes a constant basically okay sir yes i'm sorry so yeah i had this uh i had a question regarding depletion there only so like uh when we are going from um you know your depletion region to your inversion region so like it's accumulation of like effectively free electrons is just happening on the boundary right but as it happens so somewhere between the inversion layer to your body there has to be a depletion there right so the depletion layer so the depletion layer would always be there but at low frequency the charges in the electro and the inversion layer can change okay therefore the effective capacitance that you see increases because the t-ox changes or the effective distance between the two plates their charges are changing reduces right right okay sir yes sir uh my doubt was the same i'm like that this is an addition to the previous question asked by me so sir can i think that this inversion layer which is formed i ca can i think that as a metal layer and the capacitance which we are uh mentioning in this at the inversion point is the capacitance between the gate and the inversion layer yes yes right sir so and uh one more thing sir uh so what about the i'm like yeah this question was asked by maher even so what about the capacitance between the inversion layer and the body they are connected any charge can flow from an inversion layer to the body so how can there be a capacitance between them but but there would be a depletion region in between them right sir uh and depletion region doesn't mean charges cannot flow from there depletion region only means there are no charges available there oh so uh uh even uh there's no capacitance between them yeah okay sir oh thank you okay uh theta in that case we can call it as a depletion there i'm sorry depletion we can call it as a depletion capacitance uh we have a metal oxide and there is a channel and below that there is a uh depletion also we can call this we can call this as our uh depletion and the channel and the substrate has a depletion capacitance yeah so you see we are calling it depletion capacitance over here absolutely right okay so after forming the channel also uh we can say that the gate and gate oxide and channel has one capacitance and the channel depletion region under substrate as another capacitance so they are in the series no sir yeah yeah but the change in charge is happening over here at low frequency change in charge happens over here at high frequency change in charge happens over here so at low frequency the capacitance is large at high frequency capacitance goes down oh sorry even in the low frequency also the depletion region will be let there be a capacitance what would you observe at the gate you change something at what place will you see the change in charge that defines the thickness that you need to consider when you measure capacitance okay okay so i've got it but okay 
physically those exist doesn't matter okay but that doesn't come into the electrical plane so it doesn't matter it doesn't change anything for you yes okay yeah i think you can cover only till here today but anything else um sir uh question on this slide only so you have written uh on the upper part that mos transistor cv at any frequency so basically it won't have this high frequency effect if i have a transistor yes so that is evident in the previous slide so if there is an if there is a source or drain region over here the electrons will simply change from here to here they don't have to travel the width of the depletion layer okay so one more question yeah stuff about the depletion uh i mean if i want to understand that then can we say that uh okay when the depletion is happening so at the at the time when that band bending happens so basically the holes move away from the interface that we were saying surface of that and then the ions are only there so they cannot uh conduct right so yeah okay that is what depletion layer is okay okay if the graph cylinder graph slide the water squashy static cv washi static cv quasi static cv means that this is dynamic in nature in the sense that it appears as a constant cv like a constant cv curve but what happens is that there is a constant change or flow of electrons between source drain and this inversion layer or stuff like that so it's quasi-static it's not as soon as you will change the charge as soon as you will remove the voltages uh there is no capacitance there again see a metal oxide metal this capacitance is always there whether there is a charge when you whether you apply a voltage there or not yes but in a mosfet the capacitance and its value is quasi-static it depends on the region of operation so it is not a static cv it is quasi static it changes with the region of operation yeah okay so sir yes so uh the question gandhi asked at any f can you please elaborate uh i couldn't get it when he asked that at any f at any frequency in the top part for mosfet for mosfet the charges can come from the source and drain region the distance between source gain region and that of the body is very different so in mosfet even at high frequencies you will see a higher capacitance after inversion layer is pumped because inversion layer still continues to change in terms of amount of charge okay however in a mos capacitor that doesn't happen okay so that any phosphorous mosfet business okay okay see that you have a question your hand is raised okay so if there are no more questions we will close it here yes sir depletion reason starts from the flat band voltage and go up to the threshold voltage according to this figure yes so in the fragment voltage there is no band bending occurs after that in the flat band voltage there is no band bending because everything is flat yeah yeah yeah then the band bending stretch so after that bend bending uh start again in the reverse direction of accumulation yeah okay okay okay uh sir hello just to confirm that in when we are talking about the frequency we are ensuring that the basic offset of vt is there and about that only the frequency of the signal above that is guaranteed yeah we're talking about small signal models over here okay okay davidjit sir just one question sir how the band bending determines uh my uh vt of the device would be okay so let us say the intrinsic band bending is 500 millivolts okay so if 500 millivolts so in at 0 volts if i say i have already reached uh let us look at it like this at 0 volts there is some band bending that is already happening to create the inversion layer i need to apply some more voltage and i will get it now if my curve was such that flat band happened till here and then band bending happened like this then the vt would come here somewhere here okay so the more the band bending that already happens because of my uh gate dielectric interface whatever okay the more band mending that already happens the lesser the vp would be sure because i need lesser bending for bringing in the inversion layer okay so from this what you have told can you come can we say that if there is more band bending then we'll be for will be at resting stage will be further we will be further away from the vt so for those type of devices which would be less no no no if band banding is more already it means a inversion layer is easy to form so vt is going to be less yes so vt is going to be less sub threshold okay yes okay anything else okay so thank you guys we will start with mos transistors next class uh and then we will move to other devices okay thank you one servant yes sir uh in david's question uh sir he told that vt is less than how we told that it is in the it is the it is in the sub threshold i'm sorry sir uh sir you don't know that in that the more the backbending the bt gets lesser so how we determine that it is in the sub regulator oh that's because at lower vt when you have less vt then the sub threshold currents are higher that's the only thing don't worry about it we will talk about the current if you've studied current equations of mosfets earlier you will see that okay so thank you guys all the best see you on friday then thank you sir"
AiH62PY8_-U,okay then so today what we are going to cover is mos transistors okay so this is a mosfet what do different parts of this region represent can anyone tell me like however again i still want to hear it from you so source and drain and channel and gate and substrate is there right good so we understand that one of this is source this we call as drain this is the gate region which we say is made of polysilicon this you can call as gate oxide this blackened region is channel where we say that the inversion layer already exists the channel has already been formed and this is isolation so this is also silicon dioxide okay so so that is because of field oxide right yes that isolation has free oxide yes yes there was a question another question no sir i was asking the same isolation yeah so it was field offside and uh it is called isolation these days because it is no longer grown in the way the field oxide was grown it is today uh you know there is a trench that is uh that is etched out in the silicon and the new deposit oxide so it is called shallow trench implant but yes that is oxide that that separates two adjacent transistors source and drain regions from each other okay so given that so what we just now showed was that there is uh uh same voltage at source and drain if we apply a different voltage at source and then what happens the start starts to move and you also experience what is called as pinch off you see the channel has become tapered uh oh my ppt has stopped operating again okay let me pause the recording once you should not feel sorry for asking to restart the recording yeah so when we apply a differential voltage between the source and the drain then what happens current starts to flow and we see that this channel is no longer flat we see that this channel starts to taper and we see a pinch off happening here okay so you remember all of this this this you must have all done in your earlier course on the electron yes great so pinch off happens and what does cinch off do pinch off says that oh now since pinch-off has happened the change in current that would flow would be less so in fact we call it as saturation that level after this even if you increase vds any further there will be no change in current ids at the same gate source voltage okay and these are the equations that we remember from earlier sessions earlier classes on mosfet behavior all of you remember these so rattanimana i don't need to memorize them but you remember that these equations were there in the linear region current would would vary like this so as increase the w the current would increase if you increase the length the current would reduce mobility being higher for the nmosses and mosses have larger current than pmosses so all these concepts you remember am i right for saturation we are dependent on v g s minus v t the whole square and in an ideal mosfet there is there is very limited change in in current after saturation has set in and which is due to channel length modulation clears uh yeah sir it's like kind of basic but i have always wondered how we arrived at the first equation for the linear region so this whole thing that okay you uh you take the v overdrive and then subtract i mean and you subtract vds by two from that i mean uh how do we get that so again uh here these are models we observed silicon we observed the behavior of on silicon and we modeled it and we found that this is the correct model okay then we justified it okay this is happening because of this this physical phenomena happening there but you will realize it is all models you see the current and you will model it and then you will look for ways to justify it in fact so many phenomena that you will see in advanced technologies they were discovered because the model changed okay okay that's purely experimental yeah it starts with experimental then you justify it with physics okay so is my gate overdrive gate over type a dependent schema that you understand yes sir vdsp dependent square that also you understand yeah yeah so that is what is most important to capture okay this is a square dependence cubic dependence uh three times you know uh which kind of dependence it is that that is largely curve fitting happening there okay intuitively you need to understand okay this is this is dependent on vgs minus vt now square linear all those things you also need to understand but they're all models based on what we studied in the experiment what we found in the experiments okay for example in the linear region you would say that my mosfet characteristics are like this okay so as vgs changes in this region my uh resistance changes uh linearly whereas uh in the saturation region uh the current value that i will get will depend on something so you have to have pictures so these are all models that have been made based on what we observed on silicon and that has been then justified physically much more of it you will get in ssd course okay okay but we remember these two curves and we remember these uh equations before you have a question yes sir sir can we say that uh charges are also get saturated due to uh saturation of current at fields of point i'm sorry uh charging can also be uh saturated at due to saturation of current at pins of point charges can be saturated charges uh serpents are fine okay a [Music] [Music] but okay if you want to say it like that you can but i would say that because of pinch-off there is no further increase in current okay so who's pointing for like uh electrons depletion region yeah so okay this is very interesting so tell me one thing when we say that when we say that this is uh this is this triangle there so what is this triangle is it like what is the depth of this inversion layer we made this triangle over here so what is what does this triangle represent what is the depth of inversion layer [Music] yes actually the triangle over there now it basically depends on the vds equal to vgs minus vth types or i'm like at every point over there uh where the pinch-off happens uh from there uh i'm like vds equal to vgs minus vts then the pinch-off starts to happen as as its entering point of saturation so if we consider each point in that channel uh then the voltage gets decreased i mean like uh vds voltage gets decreased that's the reason why we get to a triangle over there okay so what is the depth of the inversion layer depth of the inversion i'm like initially the inversion inversion layer which was formed before the saturation uh i think that's the same same length over near the source if i am not wrong and these ones are i think we have to integrate it if i'm not wrong uh or something uh depending on the conditions uh it was mentioned as such in the rasabi books that's so this is a concentration yes right this just the concentration so the width is almost zero so this representation is the concentration of charges in the channel so inversion layer is only at the surface this triangle that we represent is the charge density in the inversion layer do not consider this as a physical depth inversion layer is always always always at the surface remember the band bending band bending at the surface this is where you know ei so you have a band bending operator this is the place where your inversion layer exists it has no depth the depth that is shown here that appears to be depth that is just the graph of charge density of electrons and what is the probability of finding electrons in this region so you see that pinch-off happens matlab now electrons have got so much energy they don't stop you cannot find them they just rushed into the drain region you can't even locate them in this region it's not fast for move circuit and therefore when you increase the voltage what happens only more electrons move faster and faster and faster so pinch off becomes steeper and steeper okay okay so yes so i couldn't get the like there's no depth so i i mean inversion layer needs to have will have some like it has no technique it is at the surface there is the surface all the electrons are on the surface all the transistor behavior that you are looking at is at the surface at the surface of silicon at the interface of oxide and silicon no depth a nanometer of depth that's it you won't you don't call it depth because it's not depth it's there at the surface okay okay so only like it's like a sheet of like electrons yes it's a sheet of electrons there that's the inversion layer okay okay sir yes so uh what is i'm like what do you mean by the charge density exactly sir i mean like there are no charges below the inversion layer or is it something different so what do you understand by the term electron density electron is i'm like charge per unit area if i'm not wrong yeah so that that is the kind of electrons you will have at the surface in that sheet that we talked about there are so many electrons that you could locate in that sheet but after the pinch-off happens after the pinch-off happens what happens now electrons have just moved out into the drain region yes sir i mean i do understand that but my doubt was that literally there are the electrons over here right there there are electrons creating this triangle kind of thing uh no there is no depth of this triangle this is charge density that is what i am trying to clarify okay okay okay so now i notice there is no physical triangle there that is what i want to clarify okay okay thank you sir okay uh sir just to clarify this concept i mean so as we are increasing the drain voltage i mean beyond the saturation region then it's uh the depletion layer between the drain and the um and the substrate is just increasing and that's why we don't you know it it sort of remains the secretion region was always there the entire region is depletion region yeah but it starts increasing right no depletion region once it reaches wd max and inversion layer has formed depletion region will not increase so but uh then you have channel with modulation i mean that's where it's dependent or videos because your effective uh train to source length is decreasing your channel length is equation okay so that that is when you say that okay now this region also became depletion or this region also became depletion so the depletion region beneath this d would increase this is not transistor action now this is parasitic you may say okay i'm not so sure how this is working so when you apply some voltage so this is n plus and this is p yeah see avid and most capacitors we were looking at only this part even this was not there is that clear yeah are you with me till here yeah now we've added source and drain regions so what happened there was a depletion region over here which was formed because of the gate but now because of this n plus and p region and this n plus and p region there is a depletion layer that is formed on this region also all right okay so now when you increase vb what happens this depletion region increases yeah okay so what happens your t has channel length modulation okay it is not this wd max the gate control wd max cannot change okay okay okay so is this concept clear that inversion layer is just on the surface of silicon and that it's it's just a sheet of electrons and what we represent as a triangle over here is electron density at given x so sir can i say that and the sheet of sheet of electrons the the distribution of electrons is not homogeneous it's like different that's why we are getting this uh kind of triangle okay yes because the electrons as they come close to the drain they just rush out so you there is no sheet there you can't see them it doesn't they don't appear like a sheet that's the one but that's what the model says again this is modeling up electrons to suction yeah yes yes this is modeling but even then what is important to realize is all this is happening at the surface okay yes sir yes yeah that's yeah uh sorry after finch there will be no right uh at the train yet uh there will be sheet will be cut right like so there are electrons there but they are moving so far that they don't appear as sheet now they just get absorbed into the drain they are going very fast through the depletion layer or there will be at the surface at the surface also there will be depletion uh depletion layer will be there yeah but yeah that is a diffusion all that part is depletion yes okay so this is,https://www.youtube.com/watch?v=AiH62PY8_-U,"Link: https://www.youtube.com/watch?v=AiH62PY8_-U
Transcript: okay then so today what we are going to cover is mos transistors okay so this is a mosfet what do different parts of this region represent can anyone tell me like however again i still want to hear it from you so source and drain and channel and gate and substrate is there right good so we understand that one of this is source this we call as drain this is the gate region which we say is made of polysilicon this you can call as gate oxide this blackened region is channel where we say that the inversion layer already exists the channel has already been formed and this is isolation so this is also silicon dioxide okay so so that is because of field oxide right yes that isolation has free oxide yes yes there was a question another question no sir i was asking the same isolation yeah so it was field offside and uh it is called isolation these days because it is no longer grown in the way the field oxide was grown it is today uh you know there is a trench that is uh that is etched out in the silicon and the new deposit oxide so it is called shallow trench implant but yes that is oxide that that separates two adjacent transistors source and drain regions from each other okay so given that so what we just now showed was that there is uh uh same voltage at source and drain if we apply a different voltage at source and then what happens the start starts to move and you also experience what is called as pinch off you see the channel has become tapered uh oh my ppt has stopped operating again okay let me pause the recording once you should not feel sorry for asking to restart the recording yeah so when we apply a differential voltage between the source and the drain then what happens current starts to flow and we see that this channel is no longer flat we see that this channel starts to taper and we see a pinch off happening here okay so you remember all of this this this you must have all done in your earlier course on the electron yes great so pinch off happens and what does cinch off do pinch off says that oh now since pinch-off has happened the change in current that would flow would be less so in fact we call it as saturation that level after this even if you increase vds any further there will be no change in current ids at the same gate source voltage okay and these are the equations that we remember from earlier sessions earlier classes on mosfet behavior all of you remember these so rattanimana i don't need to memorize them but you remember that these equations were there in the linear region current would would vary like this so as increase the w the current would increase if you increase the length the current would reduce mobility being higher for the nmosses and mosses have larger current than pmosses so all these concepts you remember am i right for saturation we are dependent on v g s minus v t the whole square and in an ideal mosfet there is there is very limited change in in current after saturation has set in and which is due to channel length modulation clears uh yeah sir it's like kind of basic but i have always wondered how we arrived at the first equation for the linear region so this whole thing that okay you uh you take the v overdrive and then subtract i mean and you subtract vds by two from that i mean uh how do we get that so again uh here these are models we observed silicon we observed the behavior of on silicon and we modeled it and we found that this is the correct model okay then we justified it okay this is happening because of this this physical phenomena happening there but you will realize it is all models you see the current and you will model it and then you will look for ways to justify it in fact so many phenomena that you will see in advanced technologies they were discovered because the model changed okay okay that's purely experimental yeah it starts with experimental then you justify it with physics okay so is my gate overdrive gate over type a dependent schema that you understand yes sir vdsp dependent square that also you understand yeah yeah so that is what is most important to capture okay this is a square dependence cubic dependence uh three times you know uh which kind of dependence it is that that is largely curve fitting happening there okay intuitively you need to understand okay this is this is dependent on vgs minus vt now square linear all those things you also need to understand but they're all models based on what we studied in the experiment what we found in the experiments okay for example in the linear region you would say that my mosfet characteristics are like this okay so as vgs changes in this region my uh resistance changes uh linearly whereas uh in the saturation region uh the current value that i will get will depend on something so you have to have pictures so these are all models that have been made based on what we observed on silicon and that has been then justified physically much more of it you will get in ssd course okay okay but we remember these two curves and we remember these uh equations before you have a question yes sir sir can we say that uh charges are also get saturated due to uh saturation of current at fields of point i'm sorry uh charging can also be uh saturated at due to saturation of current at pins of point charges can be saturated charges uh serpents are fine okay a [Music] [Music] but okay if you want to say it like that you can but i would say that because of pinch-off there is no further increase in current okay so who's pointing for like uh electrons depletion region yeah so okay this is very interesting so tell me one thing when we say that when we say that this is uh this is this triangle there so what is this triangle is it like what is the depth of this inversion layer we made this triangle over here so what is what does this triangle represent what is the depth of inversion layer [Music] yes actually the triangle over there now it basically depends on the vds equal to vgs minus vth types or i'm like at every point over there uh where the pinch-off happens uh from there uh i'm like vds equal to vgs minus vts then the pinch-off starts to happen as as its entering point of saturation so if we consider each point in that channel uh then the voltage gets decreased i mean like uh vds voltage gets decreased that's the reason why we get to a triangle over there okay so what is the depth of the inversion layer depth of the inversion i'm like initially the inversion inversion layer which was formed before the saturation uh i think that's the same same length over near the source if i am not wrong and these ones are i think we have to integrate it if i'm not wrong uh or something uh depending on the conditions uh it was mentioned as such in the rasabi books that's so this is a concentration yes right this just the concentration so the width is almost zero so this representation is the concentration of charges in the channel so inversion layer is only at the surface this triangle that we represent is the charge density in the inversion layer do not consider this as a physical depth inversion layer is always always always at the surface remember the band bending band bending at the surface this is where you know ei so you have a band bending operator this is the place where your inversion layer exists it has no depth the depth that is shown here that appears to be depth that is just the graph of charge density of electrons and what is the probability of finding electrons in this region so you see that pinch-off happens matlab now electrons have got so much energy they don't stop you cannot find them they just rushed into the drain region you can't even locate them in this region it's not fast for move circuit and therefore when you increase the voltage what happens only more electrons move faster and faster and faster so pinch off becomes steeper and steeper okay okay so yes so i couldn't get the like there's no depth so i i mean inversion layer needs to have will have some like it has no technique it is at the surface there is the surface all the electrons are on the surface all the transistor behavior that you are looking at is at the surface at the surface of silicon at the interface of oxide and silicon no depth a nanometer of depth that's it you won't you don't call it depth because it's not depth it's there at the surface okay okay so only like it's like a sheet of like electrons yes it's a sheet of electrons there that's the inversion layer okay okay sir yes so uh what is i'm like what do you mean by the charge density exactly sir i mean like there are no charges below the inversion layer or is it something different so what do you understand by the term electron density electron is i'm like charge per unit area if i'm not wrong yeah so that that is the kind of electrons you will have at the surface in that sheet that we talked about there are so many electrons that you could locate in that sheet but after the pinch-off happens after the pinch-off happens what happens now electrons have just moved out into the drain region yes sir i mean i do understand that but my doubt was that literally there are the electrons over here right there there are electrons creating this triangle kind of thing uh no there is no depth of this triangle this is charge density that is what i am trying to clarify okay okay okay so now i notice there is no physical triangle there that is what i want to clarify okay okay thank you sir okay uh sir just to clarify this concept i mean so as we are increasing the drain voltage i mean beyond the saturation region then it's uh the depletion layer between the drain and the um and the substrate is just increasing and that's why we don't you know it it sort of remains the secretion region was always there the entire region is depletion region yeah but it starts increasing right no depletion region once it reaches wd max and inversion layer has formed depletion region will not increase so but uh then you have channel with modulation i mean that's where it's dependent or videos because your effective uh train to source length is decreasing your channel length is equation okay so that that is when you say that okay now this region also became depletion or this region also became depletion so the depletion region beneath this d would increase this is not transistor action now this is parasitic you may say okay i'm not so sure how this is working so when you apply some voltage so this is n plus and this is p yeah see avid and most capacitors we were looking at only this part even this was not there is that clear yeah are you with me till here yeah now we've added source and drain regions so what happened there was a depletion region over here which was formed because of the gate but now because of this n plus and p region and this n plus and p region there is a depletion layer that is formed on this region also all right okay so now when you increase vb what happens this depletion region increases yeah okay so what happens your t has channel length modulation okay it is not this wd max the gate control wd max cannot change okay okay okay so is this concept clear that inversion layer is just on the surface of silicon and that it's it's just a sheet of electrons and what we represent as a triangle over here is electron density at given x so sir can i say that and the sheet of sheet of electrons the the distribution of electrons is not homogeneous it's like different that's why we are getting this uh kind of triangle okay yes because the electrons as they come close to the drain they just rush out so you there is no sheet there you can't see them it doesn't they don't appear like a sheet that's the one but that's what the model says again this is modeling up electrons to suction yeah yes yes this is modeling but even then what is important to realize is all this is happening at the surface okay yes sir yes yeah that's yeah uh sorry after finch there will be no right uh at the train yet uh there will be sheet will be cut right like so there are electrons there but they are moving so far that they don't appear as sheet now they just get absorbed into the drain they are going very fast through the depletion layer or there will be at the surface at the surface also there will be depletion uh depletion layer will be there yeah but yeah that is a diffusion all that part is depletion yes okay so this is"
JTafhAtqi6w,okay so what also happens is in silicon so till the time we apply or we have limited electric fields in the channel region let us go back to the previous slide so till the time we have limited electric fields in this channel region what happens as you apply more voltage on drain electric field increases so as you increase the voltage on drain the velocity of electrons over here increases so pinch-off happens because the electrons move very very fast so you're not even able to observe them over here so the velocity of electrons increases but there comes a point in time where there can be no further increase in velocity why because then these electrons start to collide with the nuclei of uh you know the atoms over there or there are obstacles that they start to hit them and therefore the overall speed kind of saturates okay that is called as velocity saturation and how does that affect or why is it important for us how does that affect us it affects us because if we have a long channel device then what we would observe is that there is a increase in current until vgs minus vt the entire gate overdrive region whereas in very small devices what we observe is that the saturation starts to happen earlier this is because of velocity saturation okay so when we scaled you know when we came to advanced technologies and short channel effects started to appear we started to observe oh yeah our old model had said we should get this kind of current we are getting only this kind of current what is happening then the concept of velocity saturation was devised created and we said that in short channel devices instead of that vgs minus vt we would say current saturates at what is called as vdd sat sir yes sir uh can't we say that because the channel length is slow that's the reason why we have vgs minus vts low or is it due to velocity i'm like okay let me let me ask it against what is electric field what is electric field let us look at that again coming back to the very basic question there yes a rate of change of potential so delta v by l yeah yes sir yes sir as i go to a short channel device what happens l reduces yes for the same delta v what happens due to this increase in electric field we observe that velocity saturation has happened now electrons cannot really go to the same speed as they were in the lower electric field okay okay so basically it even depends i'm like it it's interlinked towards the length even uh i mean it is linked to length so that is where long channel and short channel devices are being talked about okay thank you okay uh sir can i repeat again why do we have um why do we achieve saturation i mean earlier in short channel devices okay is it is it evident that the electric fields will be higher in short channel devices yeah yeah okay so we will achieve higher electric fields in short channel devices earlier right now at high electric field what happens but sir um wouldn't the high electric field be you know dependent on at the width of the debris i mean depletion region instead of the actual uh the channel length okay so now over here we are talking about transversal effects electric field the electric field between source and drain okay source right we're not talking so sorry this is a little confusing but there are there's a vertical electric field and there's a transversal electric field flow of charge from source to drain happens because of transversal electric field okay yeah that is what saturates and that is what increases so much because length has reduced that we observe velocity saturation of the electrons there okay okay all right got it okay what's up here just took somebody for one thing the short channel means like 65 nanometer 14 nanometer that kind of thing right yeah it could also mean 130 nanometer it could also mean 180 nanometers yeah yeah okay okay so short channel depends so uh if you were to you know enter into ssd course you will see that short channel uh depends on doping and the doping profile and so many things so when the region of uh you know when when this region this region that we're talking about okay when this region no longer remains as rectangular as we want it to be we say short channel effects will start to appear okay so there is a relationship between the length of the device and the depth of this depletion region when the depth of the decreation region uh increases too much in comparison to the length we say short channel effects will appear so this can happen at any length it depends on various things but in terms of technology short channel effects becomes significantly more prominent at advanced technology notes because then you cannot even change the doping see over here in older technologies you could increase the substrate doping a bit so that the depletion width remains less but in advanced technologies it's already so high that you cannot increase it any further and you go to various different kinds of implants retrograde implant halo implants super halo implants and so on so that is where ssd my java they will get much more information about this in this course let us simply understand it as that uh in when short channel effects figure in transversal electric field becomes very very high and in that uh at that time velocity saturation happens and you see that current doesn't grow as we wanted it to okay yeah sure so yes when electric field is increasing does it mean that so velocity saturation is happening because there is more collision yes the speed has become so high that every now the collisions the collision rate increases so much that velocity cannot really increase beyond that so we have reached that electric field at which saturation happens saturation happens saturation happens at a particular electric field because now this electric field will not increase the velocity and in short channel devices you reach that electric field much faster much earlier but isn't the rate of collision dependent on density of other atoms that are present in so why it's just mine yes sir i know so it is dependent on that let us okay so i have an electron moving from here to that base okay averagely there are 10 000 electrons that are moving of those 10 000 electrons every second or every microsecond every nanosecond whatever we call it every picosecond 20 electrons will hit some atom okay so that when they hit they come to a halt so you say they have got decelerated so velocity does not increase or there is a rate of change of velocity and that is time now at very high electric fields electrons so many electrons are moving so fast and they are so like the the number of collisions because the electrons are moving very very fast increases so much that overall deceleration increases significantly number of electrons hitting atoms increases significantly and therefore velocity cannot increase any further it is not saying that velocity would reduce but any further increase in velocity is offset by the increase in number of uh collisions okay so okay saturated no further increase because any further increases also means increases in further collisions okay anymore it has been controlled by the collision it is limited by the not controlled yeah uh devotee rajesh you have questions yes sir so in one of the previous slide we observed that as soon as a pinch-off is occurring so the current is getting uh saturated it is not increasing but uh in in uh just the previous slide we also observed that you in the short channel devices uh as soon as it is reaching a certain vd after that saturation is occurring so what will happen if it means vd is less than here vgs minus vt so what will happen when it reaches vgs minus vt means what will happen to the pinch of means so it will happen yeah yeah okay so pinch off will now uh occur in vgs minus vt only for so again you know that is where i have been insisting that we've been trying to model what is uh observed on silicon through these equations okay so if we say that now saturation is happening at vdsat and you want to use that simple model of pinch-off only then you would come arrive at a conclusion that pinch-off happens at vdsat yes sir okay yes but no one talks about pinch off when you talk about wedishat but if you want to use that model then that is what will appear to be the case yes sir okay thank you sir in that velocity saturation graphs previous two slides please do you want to see that slide yes in this sir this is uh easy uh that is the critical pillar sir in case of both long channel and short channel this mu will be same so uh will this ec be different for when there is long channel in short channel that is no this is the behavior of silicon okay irrespective of long channel and short channel this will all this thing will be same everything this is the behavior of silicon this has nothing to do with the channel length so in silicon if there are two points two electrodes you apply anywhere you apply when the electric field goes beyond 1.5 there will be no further change in voltage uh electron velocity this is the behavior of silicon okay so uh i read in a book that there was written that in the long channel model carrier mobility is independent of of applied fields but uh nothing was written when the channel becomes shorter when you bias see that what happens again again i would come back with the same thing see what we are what what everyone is doing is we are modeling what we are observing on silicon into equations okay so the one way to model it is by using say vdsat yes another person would say that oh what i will do is i will still call pinch off at vgs minus vt what i will do is i will start to change mobility from here okay i will call it as musat a new short channel whatever okay we are changing new so it is about models a more accurate model would say vdsat but if that book that you read tells you that mobility is dependent on short channel or long channel that is not actually correct physically mobility doesn't change with channel length mobility is the behavior of silicon yes but that book says i will want to model it with mobility let it not run it is a way of modelling okay and reality mobility cannot change yes the behavior of silicon is it not yes it will be same for you yeah so if someone is saying that there is an inaccuracy there but we can't even say it is wrong because that is the way they modeled it that is the way they modeled this curve but is there different ways of modeling that's it okay okay yes so you see these two curves look so similar in a short channel long channel yeah sir in transition when we talk about the saturation resistor is that due to that when radius it becomes equals to overdrive voltage or it is due to that velocity saturation so uh in short channel devices it is because of velocity saturation in long channel devices we say that pinch-off happens and that is why saturation happens okay thank you okay yeah so uh you know we look at these two curves you know they look so similar but now look at the y-axis scale yeah yes look at the y-axis over here it's gone up till 6 and over here it is at 2.5 this is what velocity saturation has done because current could not even grow to that level of pinch-off voltage are you able to see this yes so look at it over here i would say that saturation happens at almost vds of 1 volts over here the saturation is coming at 1.5 so this extra current that was appearing because of increased electric field and therefore increased electron velocity that has not happened okay so similarly in short channel and long channel devices the way it would reflect an igs vds igs id vgs curve is that you will see that long channel device this quad this is quadratic behavior through and through whereas in short channel devices it's quadratic behavior earlier but then it tends to be linear okay so when you have short channel devices your models also become more complex okay and emos is similar you just change the you know you you just change the voltages to be negative so it would appear like this the the flow of current is the flow of charges is from uh drain to source now and and so on okay so pmos exactly the same thing same thing applies just realize it's a dual it's the opposite of what we talked about in the nmos and what is what happens you're talking of linear and quadratic in the super threshold region what happens in the subthreshold region so you have a question yes sir about that shorthand and all can we say that uh first driving same amount of current i need a wider short channel device and i can use a less less width of long channel device to drive the same current yeah to have the same,https://www.youtube.com/watch?v=JTafhAtqi6w,"Link: https://www.youtube.com/watch?v=JTafhAtqi6w
Transcript: okay so what also happens is in silicon so till the time we apply or we have limited electric fields in the channel region let us go back to the previous slide so till the time we have limited electric fields in this channel region what happens as you apply more voltage on drain electric field increases so as you increase the voltage on drain the velocity of electrons over here increases so pinch-off happens because the electrons move very very fast so you're not even able to observe them over here so the velocity of electrons increases but there comes a point in time where there can be no further increase in velocity why because then these electrons start to collide with the nuclei of uh you know the atoms over there or there are obstacles that they start to hit them and therefore the overall speed kind of saturates okay that is called as velocity saturation and how does that affect or why is it important for us how does that affect us it affects us because if we have a long channel device then what we would observe is that there is a increase in current until vgs minus vt the entire gate overdrive region whereas in very small devices what we observe is that the saturation starts to happen earlier this is because of velocity saturation okay so when we scaled you know when we came to advanced technologies and short channel effects started to appear we started to observe oh yeah our old model had said we should get this kind of current we are getting only this kind of current what is happening then the concept of velocity saturation was devised created and we said that in short channel devices instead of that vgs minus vt we would say current saturates at what is called as vdd sat sir yes sir uh can't we say that because the channel length is slow that's the reason why we have vgs minus vts low or is it due to velocity i'm like okay let me let me ask it against what is electric field what is electric field let us look at that again coming back to the very basic question there yes a rate of change of potential so delta v by l yeah yes sir yes sir as i go to a short channel device what happens l reduces yes for the same delta v what happens due to this increase in electric field we observe that velocity saturation has happened now electrons cannot really go to the same speed as they were in the lower electric field okay okay so basically it even depends i'm like it it's interlinked towards the length even uh i mean it is linked to length so that is where long channel and short channel devices are being talked about okay thank you okay uh sir can i repeat again why do we have um why do we achieve saturation i mean earlier in short channel devices okay is it is it evident that the electric fields will be higher in short channel devices yeah yeah okay so we will achieve higher electric fields in short channel devices earlier right now at high electric field what happens but sir um wouldn't the high electric field be you know dependent on at the width of the debris i mean depletion region instead of the actual uh the channel length okay so now over here we are talking about transversal effects electric field the electric field between source and drain okay source right we're not talking so sorry this is a little confusing but there are there's a vertical electric field and there's a transversal electric field flow of charge from source to drain happens because of transversal electric field okay yeah that is what saturates and that is what increases so much because length has reduced that we observe velocity saturation of the electrons there okay okay all right got it okay what's up here just took somebody for one thing the short channel means like 65 nanometer 14 nanometer that kind of thing right yeah it could also mean 130 nanometer it could also mean 180 nanometers yeah yeah okay okay so short channel depends so uh if you were to you know enter into ssd course you will see that short channel uh depends on doping and the doping profile and so many things so when the region of uh you know when when this region this region that we're talking about okay when this region no longer remains as rectangular as we want it to be we say short channel effects will start to appear okay so there is a relationship between the length of the device and the depth of this depletion region when the depth of the decreation region uh increases too much in comparison to the length we say short channel effects will appear so this can happen at any length it depends on various things but in terms of technology short channel effects becomes significantly more prominent at advanced technology notes because then you cannot even change the doping see over here in older technologies you could increase the substrate doping a bit so that the depletion width remains less but in advanced technologies it's already so high that you cannot increase it any further and you go to various different kinds of implants retrograde implant halo implants super halo implants and so on so that is where ssd my java they will get much more information about this in this course let us simply understand it as that uh in when short channel effects figure in transversal electric field becomes very very high and in that uh at that time velocity saturation happens and you see that current doesn't grow as we wanted it to okay yeah sure so yes when electric field is increasing does it mean that so velocity saturation is happening because there is more collision yes the speed has become so high that every now the collisions the collision rate increases so much that velocity cannot really increase beyond that so we have reached that electric field at which saturation happens saturation happens saturation happens at a particular electric field because now this electric field will not increase the velocity and in short channel devices you reach that electric field much faster much earlier but isn't the rate of collision dependent on density of other atoms that are present in so why it's just mine yes sir i know so it is dependent on that let us okay so i have an electron moving from here to that base okay averagely there are 10 000 electrons that are moving of those 10 000 electrons every second or every microsecond every nanosecond whatever we call it every picosecond 20 electrons will hit some atom okay so that when they hit they come to a halt so you say they have got decelerated so velocity does not increase or there is a rate of change of velocity and that is time now at very high electric fields electrons so many electrons are moving so fast and they are so like the the number of collisions because the electrons are moving very very fast increases so much that overall deceleration increases significantly number of electrons hitting atoms increases significantly and therefore velocity cannot increase any further it is not saying that velocity would reduce but any further increase in velocity is offset by the increase in number of uh collisions okay so okay saturated no further increase because any further increases also means increases in further collisions okay anymore it has been controlled by the collision it is limited by the not controlled yeah uh devotee rajesh you have questions yes sir so in one of the previous slide we observed that as soon as a pinch-off is occurring so the current is getting uh saturated it is not increasing but uh in in uh just the previous slide we also observed that you in the short channel devices uh as soon as it is reaching a certain vd after that saturation is occurring so what will happen if it means vd is less than here vgs minus vt so what will happen when it reaches vgs minus vt means what will happen to the pinch of means so it will happen yeah yeah okay so pinch off will now uh occur in vgs minus vt only for so again you know that is where i have been insisting that we've been trying to model what is uh observed on silicon through these equations okay so if we say that now saturation is happening at vdsat and you want to use that simple model of pinch-off only then you would come arrive at a conclusion that pinch-off happens at vdsat yes sir okay yes but no one talks about pinch off when you talk about wedishat but if you want to use that model then that is what will appear to be the case yes sir okay thank you sir in that velocity saturation graphs previous two slides please do you want to see that slide yes in this sir this is uh easy uh that is the critical pillar sir in case of both long channel and short channel this mu will be same so uh will this ec be different for when there is long channel in short channel that is no this is the behavior of silicon okay irrespective of long channel and short channel this will all this thing will be same everything this is the behavior of silicon this has nothing to do with the channel length so in silicon if there are two points two electrodes you apply anywhere you apply when the electric field goes beyond 1.5 there will be no further change in voltage uh electron velocity this is the behavior of silicon okay so uh i read in a book that there was written that in the long channel model carrier mobility is independent of of applied fields but uh nothing was written when the channel becomes shorter when you bias see that what happens again again i would come back with the same thing see what we are what what everyone is doing is we are modeling what we are observing on silicon into equations okay so the one way to model it is by using say vdsat yes another person would say that oh what i will do is i will still call pinch off at vgs minus vt what i will do is i will start to change mobility from here okay i will call it as musat a new short channel whatever okay we are changing new so it is about models a more accurate model would say vdsat but if that book that you read tells you that mobility is dependent on short channel or long channel that is not actually correct physically mobility doesn't change with channel length mobility is the behavior of silicon yes but that book says i will want to model it with mobility let it not run it is a way of modelling okay and reality mobility cannot change yes the behavior of silicon is it not yes it will be same for you yeah so if someone is saying that there is an inaccuracy there but we can't even say it is wrong because that is the way they modeled it that is the way they modeled this curve but is there different ways of modeling that's it okay okay yes so you see these two curves look so similar in a short channel long channel yeah sir in transition when we talk about the saturation resistor is that due to that when radius it becomes equals to overdrive voltage or it is due to that velocity saturation so uh in short channel devices it is because of velocity saturation in long channel devices we say that pinch-off happens and that is why saturation happens okay thank you okay yeah so uh you know we look at these two curves you know they look so similar but now look at the y-axis scale yeah yes look at the y-axis over here it's gone up till 6 and over here it is at 2.5 this is what velocity saturation has done because current could not even grow to that level of pinch-off voltage are you able to see this yes so look at it over here i would say that saturation happens at almost vds of 1 volts over here the saturation is coming at 1.5 so this extra current that was appearing because of increased electric field and therefore increased electron velocity that has not happened okay so similarly in short channel and long channel devices the way it would reflect an igs vds igs id vgs curve is that you will see that long channel device this quad this is quadratic behavior through and through whereas in short channel devices it's quadratic behavior earlier but then it tends to be linear okay so when you have short channel devices your models also become more complex okay and emos is similar you just change the you know you you just change the voltages to be negative so it would appear like this the the flow of current is the flow of charges is from uh drain to source now and and so on okay so pmos exactly the same thing same thing applies just realize it's a dual it's the opposite of what we talked about in the nmos and what is what happens you're talking of linear and quadratic in the super threshold region what happens in the subthreshold region so you have a question yes sir about that shorthand and all can we say that uh first driving same amount of current i need a wider short channel device and i can use a less less width of long channel device to drive the same current yeah to have the same"
49fHN0JaBEU,current you will now need a larger device yes so what happens in the substantial region so sub-threshold region also there is some current flowing is it not yes sub threshold region also there is some current flowing super threshold region that is above vt we saw that okay it remains quadratic for some time then it goes linear what happens in the sub threshold region the subthreshold region the current changes exponentially you remember this equation the diode current and the slope the slope that we have in this region is called as sub threshold slope this s sir hello yes sir uh i mean like in uh during this condition sir if bgs is uh less than vt then there would be a depletion region right there won't be any kind of inversion layers such that id flows i'm that that's a doubt sir so you tell me can can there be no flow of current in our depletion region uh regarding to the equations and considering the equations i think there shouldn't be any kind of no no forget about equations again sorry so you should not learn it backwards okay so sir my doubt is that let us say there is a pn junction okay let us say there's a pn junction and you're applying two different voltages on the other side between gate and body or uh waves are exactly p and junction you tell me in a mosfet player as a pn junction sir actually if you talk about the current then uh current flow then we should talk about the source and source inversion layer and the drain right so when you made the source you will form a depletion region yes sir yes sir when you make a drain you will form a depletion region yes that is what we saw in the previous slide also now that these new new depletion regions start to appear as arsenal you made those sources yes sir so whenever there is this pn junction so these are pn junctions is it not yes but they won't be evident as bodies at low voltage i'm like they are reversed by asked to be precise yeah but is there no reverse bias current they're always reverse biased yes do not we do not ever want to have those pn junctions powered by us yes sir okay yes but there is a reverse bias current okay okay sir i do understand that's it but what is this exactly current flow between source and drain or source sorry drain and body it could be both over here we are talking about sub threshold current means start flow from source to drain okay sir okay but in reality leakage will happen everywhere okay so because this slide is on sub threshold conduction over here we are talking about current that charge that would flow from source to the drain okay i know that there is there is a depletion rate in a pn junction on the source there is also a pn junction on the drain and there is a depletion region in between them yes sir so that depletion region is all connected so if some electrons enter into this depletion region they will be at once pulled towards the drain is it not yes sir that might happen i'm like the minority charge so that is what the sub threshold conduction is about that even when you are not at vt there is some band bending happening there is some depletion region and therefore there will be some flow of current yes sir okay cycle i have a doubt from the previous slide of short channel the current sorry the current is decreased like why is it decreasing current is uh charge flow per unit time so in short channel like charge velocity saturation of electric field that you will probably not even observe okay velocity saturation has a behavior of silicon so but the electric fields were never so high that you would observe it on a long channel device so uh so like is it like a velocity saturation velocity saturation v1 velocity saturation v2 v1 is when the electric field goes that high velocity would saturate yes in long channel devices electric field doesn't reach there what is electric field it is uh delta v by l your length is large so electric field is low okay okay or channel devices length is reduced so electric field goes high okay so okay yes sir so uh yes um i really didn't understand this uh sub threshold um conduction part i mean how are we getting that exponential graph and then how it varies okay so it's not again we observe this one silicon we realize it is exponential and then we model it okay because as uh gagamdeep said it's like it's almost like you know uh pn junction right but i'm confused as to where a pn junction will be formed because there's a before vt there's a depletion region right between wait wait wait depreciation region oh no no no no where would a depletion region be formed so there is a is it not so this is a pn junction is it not yes similarly there's a pn junction here yeah and then depending on gate voltage there is a depletion region here yeah if this depletion region is very less let us say that the gate voltage is such that the separation region is very less they'll be very minuscule conduction of current because even if electrons enter here they will exit from here there is a very large region where they could exit from okay into the body now you increase the gate voltage depletion region became large right now most electrons will move from here to here okay okay and that that relationship is exponential in nature depletion region and huge surge of electrons moving from the source region to the drain region okay uh but so this is a id versus bgs right so this should be the you know slope should be pointing upwards when you're if you're leaving here getting vd fixed and you're increasing vgs you're increasing the overdrive so i mean in long channel devices it grows in a quadratic manner right yeah so here i'm assuming this is for a short channel device is it yes so i mean it has a very different behavior like um because it's i mean the slope is decreasing how so i mean huh because initially the change of charge or change of current is exponential then it goes quadratic then velocity saturation happens it becomes linear the slope has to degrade uh okay okay yeah yeah yeah sorry we're confused all right you're saying the same thing yeah so this is logarithmic axis right yes that is why exponential looks to be linear yes sir this this leakage sir it will be completely dependent on vds now it is dependent on exponentially this substrate leakage this thing will be completely dependent on vgs so whatever this vds not vgs vds so that is what i am telling you it is also dependent on vgs so that is how that is the behavior because the depletion region so there was this this depletion region there was this depletion region if my vds is negative that is i do not have any depletion layer then there is no connection between these two there will be no vd no id okay as soon as i increase vds what happens depletion region starts to become there so electron that enters into this depletion region rushes there yes earlier there was no such path so when there was no such facts there would be no nothing so vgs were dependent sugar if this vds is low this path is this region through which electrons can move from here to here is lesser current would be lesser yes so there is a dependence on vdf so basically at uh in this graph one thing so basically we want low heating uh uh because more leakage will occur due to low heat so according to we want more leakage like we want less leakage so that's why we should be near to the highest your vt should be as high as possible so that when your gate is at zero you have as low current as possible but in advance technologies you will see that technologies because you want speed and you want to lower the vdd of operation you go to lower vts so the curve would would become something like this okay okay additionally see let us say this is this this is the device if i say that my sub threshold slope goes bad what happens if my sub threshold slope goes bad then i will have lower sub threshold current so we want a sub threshold slope such that within 60 millivolts which is the limit of silicon within 60 millivolts you should be able to reduce current by one decade so this should be 60 millivolts okay but in reality it is anywhere between 70 to 100. the lower it is the better that technology is but there are other reasons because of which it cannot really come to 60 60 is a theoretical limit for silicon okay um so yeah but i'm still a little bit confused in the previous slide um can you show me the like the small length um it's more in small channel yeah so there you i mean it's much quadratic than linear and this is id versus bgs right and then uh in the graph for sub threshold it's the slope is decreasing quadratic and then linear so look at this this is exponential axis there's a logarithmic axis there okay this is right uh okay okay okay okay this is logarithmic axis and that was linear access right right fine okay okay so yes sir in the sub threshold when you were discussing threshold you said that when we were going towards like higher than higher notes then the basically that there we were getting the changes so that we were not basically reducing the sub threshold or the leakage currents basically so like does it mean that we cannot escape that kind of phenomena because you said that the graph is shifting upward that way it was cutting the like this id access the y-axis it is moving up you showed that yeah so so we wish i showed something like this that the slope is not good yeah yes sir so so i mean like even if you're going towards that if you reduce the vt then also we cannot escape this kind of phenomena basically somehow it somehow it just jumps back and we get the same kind of effect yeah so leakage is a very major issue in advanced technologies okay okay so earlier we used to think that if we reduce the bt we would reduce the leakage but it is not happening that way vt reduction would also always lead to increase in leakage so vd reduction would increase the leakage yes what does vt reduction mean vt direction means that i will shift this entire curve a little more on this side right okay okay i i didn't think of in shifting terms i was thinking like reducing vt means shifting it now okay right so it means it will hit it at a higher current so leakage would definitely increase as you increase the as you decrease the vp okay so the more speed i am going towards then i'm getting the more leakage kind of thing okay okay okay thank you sir okay so this is in the same technology if you reduce beauty this will happen what i'm saying is if the technology is bad then even with the same vt you can actually end up having higher leakage so this i cannot understand it with this even the same technology how what exactly this is this is a different technology so a technology has a characteristic sub threshold slope okay okay if you change the technology the slope would change okay so i have same vt but due to short channel effects due to punch through whatever reasons huh due to various reasons i will have a different slope so so these different red curves are basically different technology nodes right yes and having the same bt kind of thing technology nodes it could be 65 nanometer technology only but one could be from tsmc another would be from global foundation another one could be from samsung okay so though they are having the same vt but this sub threshold characteristic characterization different okay so whenever you look at technology you can not just look at vtk you also need to look at how is the leakage moving because that gives you the substantial slope estimate and so i really want that if this 66 within the 60 kind of change we want this yeah i really want one decade reduction within 60 millivolts because silicon okay okay excuse me yeah so i still didn't get why we are having a contracted baby and then [Music] yeah so what happens uh let us go back to the earlier curves so igs this is vgs id characteristic okay for a given vds in saturations yes so we are talking about vds which is saturation vds which is greater than vgs minus vt so in long channel devices as you increased vgs the behavior was quadratic in short channel devices it remains quadratic for a little while but then it becomes becomes linear okay sir and so what was the reason for this uh one reason is velocity saturation but there are other reasons also but we can't we i don't want to go into those details otherwise we will get digressed too too much that is what i'm noticing with this class which is i'm happy because you're learning more things but then we need to progress in terms of syllabus also okay so you can you can use the reference book and you will be able to find out details are there also so that is on the end of this class okay okay so i think it's already 120 we can close the class now uh any questions yes so i have one request to make can i let's handle that question first yeah yes sir i was asking that sir in uh older technologies we when we were not going to very low voltages at that point of time this subtraction current would not really be something that we could was worried about right i mean yeah and and older technologies uh the vt was also very high point seven point eight volt vp so even if the slope was bad the leakage current would be low additionally older technologies the total number of devices that you can put on silicon is also low is also less so total leakage never bothered us an advanced as we are integrating more devices onto the same die and each of those devices is also leaking more because of advanced technology note leakage is a major issue or low power for low power and portable devices leakage is a major issue so we have many schemes as we will look at later in the course also to reduce leakage leakage recovery is a special task that is done when you design chips okay some kind of implants and all this yeah you will see that in videos yes father you you wanted to say something yes sir so it is about the quiz like a quiz for two lectures would be better uh and uh in between them your office are will be a good like will clarify our doubt then we'll move to quiz then it would be better and if you're trying to have a quiz on wednesday or friday next week like then we'll have one more lecture our doubts will not be clarified and like so we'll have it at eight pm on monday don't worry yeah yeah okay then it's okay htm on monday is fine with everyone i believe yes sir i had a question only regarding velocity saturation thing so like we i understood that because of the velocity saturation in the short channel we are not able to achieve the kind of current which we were in the long channel so but the current according to as i also visualize current depends upon the number of charge cases right so even if i am getting the same amount of charge carriers even at a very low kind of voltage then the current i should be able to achieve that kind of like peak like that kind of like voltage current level i mean electric field is it does depend on the number of charge carriers or also on their velocity no so it depends upon the velocity but still if i am able to like achieve the kind of numbers uh like in the terms of density then i'm able even if i'm getting them uh like i'm achieving the velocity higher velocity lower at if we increase the width of the device we will be able to do it okay okay like the deep said okay okay okay okay but then we don't want to increase the size,https://www.youtube.com/watch?v=49fHN0JaBEU,"Link: https://www.youtube.com/watch?v=49fHN0JaBEU
Transcript: current you will now need a larger device yes so what happens in the substantial region so sub-threshold region also there is some current flowing is it not yes sub threshold region also there is some current flowing super threshold region that is above vt we saw that okay it remains quadratic for some time then it goes linear what happens in the sub threshold region the subthreshold region the current changes exponentially you remember this equation the diode current and the slope the slope that we have in this region is called as sub threshold slope this s sir hello yes sir uh i mean like in uh during this condition sir if bgs is uh less than vt then there would be a depletion region right there won't be any kind of inversion layers such that id flows i'm that that's a doubt sir so you tell me can can there be no flow of current in our depletion region uh regarding to the equations and considering the equations i think there shouldn't be any kind of no no forget about equations again sorry so you should not learn it backwards okay so sir my doubt is that let us say there is a pn junction okay let us say there's a pn junction and you're applying two different voltages on the other side between gate and body or uh waves are exactly p and junction you tell me in a mosfet player as a pn junction sir actually if you talk about the current then uh current flow then we should talk about the source and source inversion layer and the drain right so when you made the source you will form a depletion region yes sir yes sir when you make a drain you will form a depletion region yes that is what we saw in the previous slide also now that these new new depletion regions start to appear as arsenal you made those sources yes sir so whenever there is this pn junction so these are pn junctions is it not yes but they won't be evident as bodies at low voltage i'm like they are reversed by asked to be precise yeah but is there no reverse bias current they're always reverse biased yes do not we do not ever want to have those pn junctions powered by us yes sir okay yes but there is a reverse bias current okay okay sir i do understand that's it but what is this exactly current flow between source and drain or source sorry drain and body it could be both over here we are talking about sub threshold current means start flow from source to drain okay sir okay but in reality leakage will happen everywhere okay so because this slide is on sub threshold conduction over here we are talking about current that charge that would flow from source to the drain okay i know that there is there is a depletion rate in a pn junction on the source there is also a pn junction on the drain and there is a depletion region in between them yes sir so that depletion region is all connected so if some electrons enter into this depletion region they will be at once pulled towards the drain is it not yes sir that might happen i'm like the minority charge so that is what the sub threshold conduction is about that even when you are not at vt there is some band bending happening there is some depletion region and therefore there will be some flow of current yes sir okay cycle i have a doubt from the previous slide of short channel the current sorry the current is decreased like why is it decreasing current is uh charge flow per unit time so in short channel like charge velocity saturation of electric field that you will probably not even observe okay velocity saturation has a behavior of silicon so but the electric fields were never so high that you would observe it on a long channel device so uh so like is it like a velocity saturation velocity saturation v1 velocity saturation v2 v1 is when the electric field goes that high velocity would saturate yes in long channel devices electric field doesn't reach there what is electric field it is uh delta v by l your length is large so electric field is low okay okay or channel devices length is reduced so electric field goes high okay so okay yes sir so uh yes um i really didn't understand this uh sub threshold um conduction part i mean how are we getting that exponential graph and then how it varies okay so it's not again we observe this one silicon we realize it is exponential and then we model it okay because as uh gagamdeep said it's like it's almost like you know uh pn junction right but i'm confused as to where a pn junction will be formed because there's a before vt there's a depletion region right between wait wait wait depreciation region oh no no no no where would a depletion region be formed so there is a is it not so this is a pn junction is it not yes similarly there's a pn junction here yeah and then depending on gate voltage there is a depletion region here yeah if this depletion region is very less let us say that the gate voltage is such that the separation region is very less they'll be very minuscule conduction of current because even if electrons enter here they will exit from here there is a very large region where they could exit from okay into the body now you increase the gate voltage depletion region became large right now most electrons will move from here to here okay okay and that that relationship is exponential in nature depletion region and huge surge of electrons moving from the source region to the drain region okay uh but so this is a id versus bgs right so this should be the you know slope should be pointing upwards when you're if you're leaving here getting vd fixed and you're increasing vgs you're increasing the overdrive so i mean in long channel devices it grows in a quadratic manner right yeah so here i'm assuming this is for a short channel device is it yes so i mean it has a very different behavior like um because it's i mean the slope is decreasing how so i mean huh because initially the change of charge or change of current is exponential then it goes quadratic then velocity saturation happens it becomes linear the slope has to degrade uh okay okay yeah yeah yeah sorry we're confused all right you're saying the same thing yeah so this is logarithmic axis right yes that is why exponential looks to be linear yes sir this this leakage sir it will be completely dependent on vds now it is dependent on exponentially this substrate leakage this thing will be completely dependent on vgs so whatever this vds not vgs vds so that is what i am telling you it is also dependent on vgs so that is how that is the behavior because the depletion region so there was this this depletion region there was this depletion region if my vds is negative that is i do not have any depletion layer then there is no connection between these two there will be no vd no id okay as soon as i increase vds what happens depletion region starts to become there so electron that enters into this depletion region rushes there yes earlier there was no such path so when there was no such facts there would be no nothing so vgs were dependent sugar if this vds is low this path is this region through which electrons can move from here to here is lesser current would be lesser yes so there is a dependence on vdf so basically at uh in this graph one thing so basically we want low heating uh uh because more leakage will occur due to low heat so according to we want more leakage like we want less leakage so that's why we should be near to the highest your vt should be as high as possible so that when your gate is at zero you have as low current as possible but in advance technologies you will see that technologies because you want speed and you want to lower the vdd of operation you go to lower vts so the curve would would become something like this okay okay additionally see let us say this is this this is the device if i say that my sub threshold slope goes bad what happens if my sub threshold slope goes bad then i will have lower sub threshold current so we want a sub threshold slope such that within 60 millivolts which is the limit of silicon within 60 millivolts you should be able to reduce current by one decade so this should be 60 millivolts okay but in reality it is anywhere between 70 to 100. the lower it is the better that technology is but there are other reasons because of which it cannot really come to 60 60 is a theoretical limit for silicon okay um so yeah but i'm still a little bit confused in the previous slide um can you show me the like the small length um it's more in small channel yeah so there you i mean it's much quadratic than linear and this is id versus bgs right and then uh in the graph for sub threshold it's the slope is decreasing quadratic and then linear so look at this this is exponential axis there's a logarithmic axis there okay this is right uh okay okay okay okay this is logarithmic axis and that was linear access right right fine okay okay so yes sir in the sub threshold when you were discussing threshold you said that when we were going towards like higher than higher notes then the basically that there we were getting the changes so that we were not basically reducing the sub threshold or the leakage currents basically so like does it mean that we cannot escape that kind of phenomena because you said that the graph is shifting upward that way it was cutting the like this id access the y-axis it is moving up you showed that yeah so so we wish i showed something like this that the slope is not good yeah yes sir so so i mean like even if you're going towards that if you reduce the vt then also we cannot escape this kind of phenomena basically somehow it somehow it just jumps back and we get the same kind of effect yeah so leakage is a very major issue in advanced technologies okay okay so earlier we used to think that if we reduce the bt we would reduce the leakage but it is not happening that way vt reduction would also always lead to increase in leakage so vd reduction would increase the leakage yes what does vt reduction mean vt direction means that i will shift this entire curve a little more on this side right okay okay i i didn't think of in shifting terms i was thinking like reducing vt means shifting it now okay right so it means it will hit it at a higher current so leakage would definitely increase as you increase the as you decrease the vp okay so the more speed i am going towards then i'm getting the more leakage kind of thing okay okay okay thank you sir okay so this is in the same technology if you reduce beauty this will happen what i'm saying is if the technology is bad then even with the same vt you can actually end up having higher leakage so this i cannot understand it with this even the same technology how what exactly this is this is a different technology so a technology has a characteristic sub threshold slope okay okay if you change the technology the slope would change okay so i have same vt but due to short channel effects due to punch through whatever reasons huh due to various reasons i will have a different slope so so these different red curves are basically different technology nodes right yes and having the same bt kind of thing technology nodes it could be 65 nanometer technology only but one could be from tsmc another would be from global foundation another one could be from samsung okay so though they are having the same vt but this sub threshold characteristic characterization different okay so whenever you look at technology you can not just look at vtk you also need to look at how is the leakage moving because that gives you the substantial slope estimate and so i really want that if this 66 within the 60 kind of change we want this yeah i really want one decade reduction within 60 millivolts because silicon okay okay excuse me yeah so i still didn't get why we are having a contracted baby and then [Music] yeah so what happens uh let us go back to the earlier curves so igs this is vgs id characteristic okay for a given vds in saturations yes so we are talking about vds which is saturation vds which is greater than vgs minus vt so in long channel devices as you increased vgs the behavior was quadratic in short channel devices it remains quadratic for a little while but then it becomes becomes linear okay sir and so what was the reason for this uh one reason is velocity saturation but there are other reasons also but we can't we i don't want to go into those details otherwise we will get digressed too too much that is what i'm noticing with this class which is i'm happy because you're learning more things but then we need to progress in terms of syllabus also okay so you can you can use the reference book and you will be able to find out details are there also so that is on the end of this class okay okay so i think it's already 120 we can close the class now uh any questions yes so i have one request to make can i let's handle that question first yeah yes sir i was asking that sir in uh older technologies we when we were not going to very low voltages at that point of time this subtraction current would not really be something that we could was worried about right i mean yeah and and older technologies uh the vt was also very high point seven point eight volt vp so even if the slope was bad the leakage current would be low additionally older technologies the total number of devices that you can put on silicon is also low is also less so total leakage never bothered us an advanced as we are integrating more devices onto the same die and each of those devices is also leaking more because of advanced technology note leakage is a major issue or low power for low power and portable devices leakage is a major issue so we have many schemes as we will look at later in the course also to reduce leakage leakage recovery is a special task that is done when you design chips okay some kind of implants and all this yeah you will see that in videos yes father you you wanted to say something yes sir so it is about the quiz like a quiz for two lectures would be better uh and uh in between them your office are will be a good like will clarify our doubt then we'll move to quiz then it would be better and if you're trying to have a quiz on wednesday or friday next week like then we'll have one more lecture our doubts will not be clarified and like so we'll have it at eight pm on monday don't worry yeah yeah okay then it's okay htm on monday is fine with everyone i believe yes sir i had a question only regarding velocity saturation thing so like we i understood that because of the velocity saturation in the short channel we are not able to achieve the kind of current which we were in the long channel so but the current according to as i also visualize current depends upon the number of charge cases right so even if i am getting the same amount of charge carriers even at a very low kind of voltage then the current i should be able to achieve that kind of like peak like that kind of like voltage current level i mean electric field is it does depend on the number of charge carriers or also on their velocity no so it depends upon the velocity but still if i am able to like achieve the kind of numbers uh like in the terms of density then i'm able even if i'm getting them uh like i'm achieving the velocity higher velocity lower at if we increase the width of the device we will be able to do it okay okay like the deep said okay okay okay okay but then we don't want to increase the size"
vqkD13iBp8U,thank you sir yeah so let's move to today's class now so we've looked at mass capacitances and we looked at mosfet also has a capacitance where we said that the high frequency behavior and low frequency behavior of a mosfet capacitance would be same you remember this we talked about this not just in the last class but also in the office hours and at in much at much length and much detail so why is that the case because there is a source and drain region which is a you know cache of charges right next there so if you if you need more more uh electrons or holes whatever you need you will get them from that region so even at even at very high frequency uh the change in charge density would happen only in the inversion layer but then this this still now is about the gate capacitance in reality mosfets have many more capacitances mosfet transistors yeah mosfet is a transistor so mosfets has many more capacitances are you able to relate to this perspective view of a mosfet yes so where all do you think you will have capacitances when you look at the 3d structure so we have some overlap capacitances of gate and source create and drain and then we'll have some junction capacitances from source to body and from brain to body are there any other capacitances here wherever there is a change in medium sir i'm like whenever there is a change in medium then we would have some capacitance over there okay so contact yeah depletion capacitances we already also mentioned that the source and uh drains will have their junctions and that junction would lead to capacitance that is what you're talking about the same as the mass capacitance that we've already discussed that length it's apart from them okay so you're saying that there is a another capacitance that appears from ground from gate to body from inversion to body but that is the same medium how can there be a capacitance between inversion layer and the body that is all silicon anything there is to flow it will flow but current flow can happen if there so between inversion and and the silicon body there is no capacitance cannot be because they are connected charge will flow start flows so if the inversion layer is not there so don't get confused if the inversion layer is not there then we say that gate 2 silicon surface and silicon surface to edge of depletion there are two capacitances in series yes but at that point there is no inversion layer there cannot be a capacitance between inversion layer and the edge of the depletion region because they are electrically connected okay okay so yes yeah i mean um adding to martha's point i didn't understand that if there can be a capacitance between your source and your substrate because of the same reason during the existence of a depletion region then why can't there be a capacitance between your inversion there which is electric and the substrate the source and the substrate are different dopings there is a depletion junction in between them yeah okay if there is no inversion layer then then all all the silicon is same doping there is a depletion layer right but then how are we doing differently okay for a capacitance there need to be two plates yes separated by a dielectric yeah i know where you could apply two independent voltages at two different plates and then they are separated by a dielectric yes so uh if there is a if there is no inversion layer okay where is the plate and if there is an inversion layer there is anywhere connection there is a connection yeah okay so so uh yeah that i got that when there's no inversion there just a depletion region so effectively there are capacitors in series so you uh the effect is that your capacitance gets lower but um so see when there is an inversion layer then the the body the uh region of the uh the region of the substrate right beneath the plate acts like uh right between this uh right beneath the silicon dioxide acts as a an n-type substrate right that's the point of it is just a layer it is just a sheet of electrons that starts to appear there okay so we cannot compare your source and then green with the inversion that are two very different things yes okay okay so if we look at the top level view of the mosfet then this is how it would drop and that is the overlap region and the overlap capacitance that doesn't be mentioned that beneath the grid there is an overlap capacitance but in reality let us say there is a contact over here there will be a gate to contact capacitance and there will be lines of electric field which would run between gate poly vertical poly and the active region the diffusion region so what does this mean this essentially means that in a mosfet there is a capacitance cgb gate and body there is a capacitance between so between gate and source and gate and brain and there is a capacitance between see source and body and brain and body are you able to appreciate all these capacitances yes sir yes ragas so in the previous slide only uh the previous ones are can you move there so this electric field that you're talking about uh between the poly and the drain which is coming out i mean the electric field should be uh in the in the overlapping region right but why what is this overlapping region so diffusion capacitances that you just know the overlap capacity you talked about no that is just one component of gate to drain capacitance that is what i wanted to highlight talked about just one component which is the overlap capacitance but there is this other component of capacitance between gate and drain which would come with the gate to contact coupling and the gate to a diffusion layer coupling so this diffusion layer coupling i'm not able to get exactly what exactly there is a dielectric here let us remove this this is always dielectric this is supposedly a metal metal equivalent because this is drain there is this metal equivalent which is uh poly so there are two metals in between there is a dielectric there will be lines of forces between them so what kind of dielectric will be between this and not silicon dioxide so but that is the gate of light is that that is again everywhere is the silicon dioxide what do you think what do you think is there nothing is there air between these two i mean so places didn't had an idea about this so this all the silicon dioxide we talked about oxidation now yeah okay so we're coming in we talked about oxidation see again i am repeating the same thing again which i repeated in the last session that whatever we talked about whether it was fabrication so why do you think i'm answering all these questions which supposedly should be answered and answered in ssd and not in dvd why do you think i'm taking you through all this so you're trying to connect may be different no because you need to realize that unless you understand things from the very basics you cannot become a good circuit designer also each one of those aspects that we have covered in the class till now whether it was the design flow and hundreds of questions you asked around the design flow or whether it was the fabrication flow and the so many questions you asked around the fabrication flow or this band bending and everything all of this you need to understand to be able to use transistors effectively and become a good circuit designer this course is about circuit design therefore these are the incoming inputs then you need this this kind of knowledge don't assume that it was an independent topic introduction no i would rather not have given that introduction if it was not needed for this course right right so okay so sir so so this gate to drain capacitance in the model that was consisting of this overlap and this also this uh yeah coupling the other coupling this total cgd would have both components in it the overlap capacitance and the gate the polygate to metal and to contact and propagate to diffusion layer capacitance everything will be there and the total cgd so just one more thing in the gate to drain we are we are basically comprising three capacitances right so overlap contact and this above the diffusion layer yes and same goes for the gate to source also yes yes so similarly gate to body you know in different reasons for for example if there is inversion layer then the real body capacitance is something but if your device is off then the body capacitance could be something else yes sir that's the most capacity because the depletion layer would also come into picture there so what whatever components would come would come when we say cgd you should mentally or be able to relate oh all these three things would contribute to the capacitance so if i tell you that my friend please reduce pgd what would you do as a designer can you control this i don't think so sir no but as a designer you can control the spacing between contact and this as a designer you can control the overall diffusion region so as a designer you can reduce the density of contacts and therefore you can control the poly two positive quality drain uh polytube contact or let us say gate to drain capacitance so what do you mean by the density of contact this is mentioned we will see once we look at the layout have we just pop this okay okay so this is the top let us be there so this is the top level view of the device poly and source engine so i can make multiple contacts over here yes sir so if i say that no i will not make two contacts i will make one contact i will reduce the capacitance now because i have reduced the area right so that was what i meant by reducing the number of contacts so as a designer you can do this so until you understand that all these three components exist you will not be able to handle the design the requirements of the design effectively okay so do not think that this is only theory there is a clear application of what we are talking about okay so i can reduce the number of contacts that is the between the three components i have only have a one component which i can play with and and i also said you can reduce the drain region the the drain area so it's a drain area i can reduce now because that is this device i can say oh i will just make it this big i will not extend rain unnecessarily so i mean drain as they made some layouts it is dependent on the active region right yeah yeah so activation you can keep it to the minimum width now not just let it run hundreds of miles so but that is basically controlled by the sizing that we have that we want to achieve this extension i'm talking about okay so i'm not i'm not aware of this parameter right yeah so we will see you will become aware pretty soon you made the layouts now in the assignment also you're making layouts yes sir so but this is not aware of this extension so i'm not controlling this because actually so i mean the bit time controlling so it is oh you're using p cells to design your layouts right you're using t cells to design your layouts you're invoking a pmos and an nmos directly then you're automatically giving away the control that you would have had to the tool none you make the layout by hand maybe the active region makes a poly you will have all the control so right right now when we have done the schematic then we do like generate from source and we get pmos involved so don't do that okay who said generate from sources only way open a virtuoso window and make the active and make the poly you have all the controls so how will you control you're giving away a lever a design lever okay okay so we can keep it to the like the minimum brc that would enable it yeah yeah so you have two levers you thought you had none okay okay so that will basically minimize that over that uh basically the coupling one the gate to drain coupling if it is this yeah see the overlap you have no control over overlap capacitance is a technology feature fabrication because that is that is what is required to ensure there is some bt some whatever that you cannot control okay but whatever you can control at least you should be aware of that right right yes okay yes so this is how the uh gate and the various capacitances you know are kind of seen over here where we say that the sea gate is eox by t-ox into width of the device into length of the device this is clear sir yes sir a small question sir so while you were mentioning about the uh pins on the drain and the gate you said that there might be more than one pin i'm like why are we yeah sorry contact my bad so uh why are we taking more than one contract sir actually i'm like uh firstly why are we taking more than one contract and why are we okay you do a pcell you make a pizza and make a device of width for two microns see how many contacts it will give you yeah sir actually i have made that but but uh in the it has given many contacts that i'm like uh that that was my daughter that's what i'm saying remove them i'm like i should remove those not all of them few of them you mean to say i have to connect them by each other or something sir remove them what does remove mean does remove mean connect no not as such sir uh okay sorry use only what is needed okay sir okay thank you sir i'll try it now why are four needed why is the one not sufficient actually that was my doubt daughter i'm like i didn't know why are we i'm like specified about the number of contacts exactly i'm like why are we even uh looking into it exactly you tell me what are contacts they are they are kind of buyers connecting the metal one with the source or the drain yes sir yes sir so if you have one wire versus you have four wires in parallel what happens okay resistance decreases i don't thank you sir okay so uh what is being shown over here is that as vgs changes as vds changes there is a diff you you can actually end up seeing different capacitance on the gate why is that so the above graph seems to be of the mass capacitor itself yes we've already done all of this okay shows the depletion region being formed and therefore the change of charges happening at the boundary of the depletion region and as soon as the inversion layer comes independent of frequency we at once have high capacitance so what is this lower graph then this these are the two components this is uh the gate coupling with body because depletion region was coming into picture and as soon as the inversion layer is formed there is no further coupling between body and gate now the additional charge comes from source and drain regions remember in the inversion layer we said that in in devices in mosfets the source and and drain will give the additional charge even at very high frequency okay so but in the lower frequency the in when the inversion is forming the charge is coming from the body itself is it then you see you see we've already shown it like this that it is coming from source and brain it is closer now it is showing that when dt has speech i think so then it's coming from source entry so this is the vt point like this so this this line is the vp point you see already this capacitance has started to rise before that what does that mean the charge the inversion is forming due to the source entry yes so since lower graph is just basically elaborating that way that confidence their components this is comp there are various components this is capacitance with bulk this is capacitance with source this is capacitance with drain it's saying that all the three components add up to form cdc gate capacitance and source and drain they have equal coupling because of equal overlap and equal density of charges there therefore this is double overall cdc is double of cgs and cgd so but this ggs is basically due to the overlap right or is it also like all the three ones is because of all three now okay sir uh in this first graph sir sir uh here uh this gate to source and gate to drain both are becoming after uh this vgs is greater than vt so they are becoming half sir uh is this because of the uniform channel formation yes because vds is kept at zero okay so after this in this sir uh this saturate nothing is told about the saturation that is the second graph that is the graph on the right side so if the if we uh increase the v this vds so this vg cs vgs and vgd both will become two by three in case in the first no the due to pinch off the drain will have no influence therefore the gate to drain capacitance goes towards zero okay and this gate to source become will become two by three will increase yes yes okay okay in the same graph yeah yeah this one no no starting the left one in the left one vds is equal to zero so yes so suppose at the end of this graph if the first graph we start increasing vds so then what will happen to vg uh vgs and that is that is what we have done over here no we started in this existing videos that is what happened so that's the continuation of it okay yes notice same points here wlc so here it would actually depend on other factors also known so yeah yeah yeah that is where the graphs are there uh yeah sir this was uh this refers to before so you told us about the three components uh i got the contact capacitance and the coupling capacitance uh that's fine but um didn't quite understand the diffusion level capacitance you talked about we will come to that welcome to that okay and uh second question is in this graph you see uh we are seeing the components uh gcs gcd and gc bulk um but yeah i mean when we had started to mosque capacitance um we were only in a sense i mean from what i understood we were only looking at the um gate to bulk because there was no source order in there yeah but here we see that the gate to bulk capacitance keeps decreasing it vanishes so it decreases for uh for a mass capacitance also now that is where we end up with the depletion region where we go to wd mass and we say this is the minimum capacitance you would have yeah yeah but donating pieces right but in this only in low frequency only low frequency then this change is happening in the inversion layer again but then sir i mean even at high frequency then it after one point it remains constant but that is low that is a low value that's that's low but um in this case it we just see it it just keeps on decreasing until it vanishes so uh okay and but this now starts to come from source and drain region therefore gate capacitance comes up okay so when you're talking about the bulk you're talking about the substituting the lot between inversion here and no no no no no no okay okay okay so now we come to the diffusion capacitance that was what you were asking hey what is happening in the diffusion capacitance so can i you are explaining this i want to ask about the right words graph the graph in the right side i i was not able to understand that yeah tell me so uh here we are we were saying the gcd is decreasing and gcs is increasing why is that so certain uh because pen shop has happened so the drain is no longer connected to the inversion layer okay the drain can no longer so when you change the gate voltage there is no longer any change in the charge towards the drain yes sir that is why that's where cjd goes to zero okay and the source side we have the charge density that is why it is increasing yes now all the charge needs to come from the source side only therefore the component or the value of cgcs increases okay okay okay but because pinch-off has happened the overall inversion layer width has reduced inversion layer availability has reduced therefore the overall capacitance is reduced okay okay so now coming to the diffusion capacitance are you able to see this tub over here i'm calling this a tub because this actually looks like a bathtub or a tub for that matter which is where we have uh doped n plus for the source ordering region let us say now if i say that this is one plate there is a pn junction on all the sides of this plate are you able to see this yes sir all the sides except this one why because depletion depletion yes because the channel is there there's an inversion layer that you're talking about okay if there was no inversion layer then it would come on this side also but in a on device they say there is an inversion layer so this this will not appear so if i want to find the capacitance of this drain or the source what happens i have to measure the capacitance on the side walls and i have to measure the capacitance of the bottom tub bottom bottom of the tub are you able to see this so but the sidewalls is like uh on the side walls you have the dioxide right uh sidewalls you have the okay so let us look at very weird so side walls you have this isolation yes but this there this is there now okay okay so yeah didn't notice okay sir yes so on the channel side the inversion is just at the surface but i have got that wd max so that would also come now because it's not wd max is there so i will get that on that side even though there is a depletion layer there is no other end of the plate because of the channel and the depletion layer so let us look at it like this over here what is what are we saying there is a depletion layer over here and then there is a rotation layer wd max over here and then the source comes so yeah yes sir so where is the other plate now so the substrate for itself will be other plate that is too far away from here and then from the inversion layer and so many places so is it like that it is becoming like negligible kind of thing because of the capacitance so capacitance of uh this part of the plate to this part of the plate it has it is it is such a big long path the dielectric thickness is so long the oxygenated depth is so big that the capacitance is insignificant in comparison to what you will see over here okay okay okay so what do we do we say that okay let us measure the the perimeter and then multiply it with the number which is cj c junction sidewall okay and let us measure the area that is the extension and the width okay so this is ls the extension and the width that will give me the area of the bottom rectangle and i multiply that with c junction and with this i get the entire the overall capacitance of the the diffusion capacitance of the drain or the source region now again if i want to reduce the drain or source capacitance what do i need to do width is fixed but i can reduce the ls are you able to see this so so this diffusion capacitance is the gate 2 ball gate tools i source drain 2 bulk and the source this is yeah in the model yeah and so one more thing say in the junction capacitance of the uh like side walls the the base this x j parameter coming into picture it should also be enough for the parameters we had it only two ls plus w yeah so you will say that c j into x j becomes c j as w ok ok because substance over here you know the depth and based on that you came up with this value of cjsw okay and so one more thing so this ls component will have that overlap component also right because that is there right or it will be subtracted yeah ls would be the entire train region whether it is below the gate or not below the gate if there is okay uh sir so you said that diffusion capacitance is a is a component of your gate to source or gate to grain capacitance but in this case it's it seems like it's a component of your uh so i mean source to bulk no oh oh so i did not say diffusion capacitance i said gate capacitance with the diffusion region okay what i meant was those extra lines of this was am i audible yes sir yeah this was gate capacitance with the diffusion region okay okay the diffusion capacitance when we use the term diffusion capacitance this is what is the diffusion capacitance that we're talking about okay yeah so the diffusion time is coming because that because of the fabrication thing right because we should diffuse the because initially the source and train regions were diffused okay that's why it is coming today they are implanted today the iron implantation is done at an earlier point of time phostine was run through and diffusion happened so that is why we called it diffusion layer so put on okay so now we come to the,https://www.youtube.com/watch?v=vqkD13iBp8U,"Link: https://www.youtube.com/watch?v=vqkD13iBp8U
Transcript: thank you sir yeah so let's move to today's class now so we've looked at mass capacitances and we looked at mosfet also has a capacitance where we said that the high frequency behavior and low frequency behavior of a mosfet capacitance would be same you remember this we talked about this not just in the last class but also in the office hours and at in much at much length and much detail so why is that the case because there is a source and drain region which is a you know cache of charges right next there so if you if you need more more uh electrons or holes whatever you need you will get them from that region so even at even at very high frequency uh the change in charge density would happen only in the inversion layer but then this this still now is about the gate capacitance in reality mosfets have many more capacitances mosfet transistors yeah mosfet is a transistor so mosfets has many more capacitances are you able to relate to this perspective view of a mosfet yes so where all do you think you will have capacitances when you look at the 3d structure so we have some overlap capacitances of gate and source create and drain and then we'll have some junction capacitances from source to body and from brain to body are there any other capacitances here wherever there is a change in medium sir i'm like whenever there is a change in medium then we would have some capacitance over there okay so contact yeah depletion capacitances we already also mentioned that the source and uh drains will have their junctions and that junction would lead to capacitance that is what you're talking about the same as the mass capacitance that we've already discussed that length it's apart from them okay so you're saying that there is a another capacitance that appears from ground from gate to body from inversion to body but that is the same medium how can there be a capacitance between inversion layer and the body that is all silicon anything there is to flow it will flow but current flow can happen if there so between inversion and and the silicon body there is no capacitance cannot be because they are connected charge will flow start flows so if the inversion layer is not there so don't get confused if the inversion layer is not there then we say that gate 2 silicon surface and silicon surface to edge of depletion there are two capacitances in series yes but at that point there is no inversion layer there cannot be a capacitance between inversion layer and the edge of the depletion region because they are electrically connected okay okay so yes yeah i mean um adding to martha's point i didn't understand that if there can be a capacitance between your source and your substrate because of the same reason during the existence of a depletion region then why can't there be a capacitance between your inversion there which is electric and the substrate the source and the substrate are different dopings there is a depletion junction in between them yeah okay if there is no inversion layer then then all all the silicon is same doping there is a depletion layer right but then how are we doing differently okay for a capacitance there need to be two plates yes separated by a dielectric yeah i know where you could apply two independent voltages at two different plates and then they are separated by a dielectric yes so uh if there is a if there is no inversion layer okay where is the plate and if there is an inversion layer there is anywhere connection there is a connection yeah okay so so uh yeah that i got that when there's no inversion there just a depletion region so effectively there are capacitors in series so you uh the effect is that your capacitance gets lower but um so see when there is an inversion layer then the the body the uh region of the uh the region of the substrate right beneath the plate acts like uh right between this uh right beneath the silicon dioxide acts as a an n-type substrate right that's the point of it is just a layer it is just a sheet of electrons that starts to appear there okay so we cannot compare your source and then green with the inversion that are two very different things yes okay okay so if we look at the top level view of the mosfet then this is how it would drop and that is the overlap region and the overlap capacitance that doesn't be mentioned that beneath the grid there is an overlap capacitance but in reality let us say there is a contact over here there will be a gate to contact capacitance and there will be lines of electric field which would run between gate poly vertical poly and the active region the diffusion region so what does this mean this essentially means that in a mosfet there is a capacitance cgb gate and body there is a capacitance between so between gate and source and gate and brain and there is a capacitance between see source and body and brain and body are you able to appreciate all these capacitances yes sir yes ragas so in the previous slide only uh the previous ones are can you move there so this electric field that you're talking about uh between the poly and the drain which is coming out i mean the electric field should be uh in the in the overlapping region right but why what is this overlapping region so diffusion capacitances that you just know the overlap capacity you talked about no that is just one component of gate to drain capacitance that is what i wanted to highlight talked about just one component which is the overlap capacitance but there is this other component of capacitance between gate and drain which would come with the gate to contact coupling and the gate to a diffusion layer coupling so this diffusion layer coupling i'm not able to get exactly what exactly there is a dielectric here let us remove this this is always dielectric this is supposedly a metal metal equivalent because this is drain there is this metal equivalent which is uh poly so there are two metals in between there is a dielectric there will be lines of forces between them so what kind of dielectric will be between this and not silicon dioxide so but that is the gate of light is that that is again everywhere is the silicon dioxide what do you think what do you think is there nothing is there air between these two i mean so places didn't had an idea about this so this all the silicon dioxide we talked about oxidation now yeah okay so we're coming in we talked about oxidation see again i am repeating the same thing again which i repeated in the last session that whatever we talked about whether it was fabrication so why do you think i'm answering all these questions which supposedly should be answered and answered in ssd and not in dvd why do you think i'm taking you through all this so you're trying to connect may be different no because you need to realize that unless you understand things from the very basics you cannot become a good circuit designer also each one of those aspects that we have covered in the class till now whether it was the design flow and hundreds of questions you asked around the design flow or whether it was the fabrication flow and the so many questions you asked around the fabrication flow or this band bending and everything all of this you need to understand to be able to use transistors effectively and become a good circuit designer this course is about circuit design therefore these are the incoming inputs then you need this this kind of knowledge don't assume that it was an independent topic introduction no i would rather not have given that introduction if it was not needed for this course right right so okay so sir so so this gate to drain capacitance in the model that was consisting of this overlap and this also this uh yeah coupling the other coupling this total cgd would have both components in it the overlap capacitance and the gate the polygate to metal and to contact and propagate to diffusion layer capacitance everything will be there and the total cgd so just one more thing in the gate to drain we are we are basically comprising three capacitances right so overlap contact and this above the diffusion layer yes and same goes for the gate to source also yes yes so similarly gate to body you know in different reasons for for example if there is inversion layer then the real body capacitance is something but if your device is off then the body capacitance could be something else yes sir that's the most capacity because the depletion layer would also come into picture there so what whatever components would come would come when we say cgd you should mentally or be able to relate oh all these three things would contribute to the capacitance so if i tell you that my friend please reduce pgd what would you do as a designer can you control this i don't think so sir no but as a designer you can control the spacing between contact and this as a designer you can control the overall diffusion region so as a designer you can reduce the density of contacts and therefore you can control the poly two positive quality drain uh polytube contact or let us say gate to drain capacitance so what do you mean by the density of contact this is mentioned we will see once we look at the layout have we just pop this okay okay so this is the top let us be there so this is the top level view of the device poly and source engine so i can make multiple contacts over here yes sir so if i say that no i will not make two contacts i will make one contact i will reduce the capacitance now because i have reduced the area right so that was what i meant by reducing the number of contacts so as a designer you can do this so until you understand that all these three components exist you will not be able to handle the design the requirements of the design effectively okay so do not think that this is only theory there is a clear application of what we are talking about okay so i can reduce the number of contacts that is the between the three components i have only have a one component which i can play with and and i also said you can reduce the drain region the the drain area so it's a drain area i can reduce now because that is this device i can say oh i will just make it this big i will not extend rain unnecessarily so i mean drain as they made some layouts it is dependent on the active region right yeah yeah so activation you can keep it to the minimum width now not just let it run hundreds of miles so but that is basically controlled by the sizing that we have that we want to achieve this extension i'm talking about okay so i'm not i'm not aware of this parameter right yeah so we will see you will become aware pretty soon you made the layouts now in the assignment also you're making layouts yes sir so but this is not aware of this extension so i'm not controlling this because actually so i mean the bit time controlling so it is oh you're using p cells to design your layouts right you're using t cells to design your layouts you're invoking a pmos and an nmos directly then you're automatically giving away the control that you would have had to the tool none you make the layout by hand maybe the active region makes a poly you will have all the control so right right now when we have done the schematic then we do like generate from source and we get pmos involved so don't do that okay who said generate from sources only way open a virtuoso window and make the active and make the poly you have all the controls so how will you control you're giving away a lever a design lever okay okay so we can keep it to the like the minimum brc that would enable it yeah yeah so you have two levers you thought you had none okay okay so that will basically minimize that over that uh basically the coupling one the gate to drain coupling if it is this yeah see the overlap you have no control over overlap capacitance is a technology feature fabrication because that is that is what is required to ensure there is some bt some whatever that you cannot control okay but whatever you can control at least you should be aware of that right right yes okay yes so this is how the uh gate and the various capacitances you know are kind of seen over here where we say that the sea gate is eox by t-ox into width of the device into length of the device this is clear sir yes sir a small question sir so while you were mentioning about the uh pins on the drain and the gate you said that there might be more than one pin i'm like why are we yeah sorry contact my bad so uh why are we taking more than one contract sir actually i'm like uh firstly why are we taking more than one contract and why are we okay you do a pcell you make a pizza and make a device of width for two microns see how many contacts it will give you yeah sir actually i have made that but but uh in the it has given many contacts that i'm like uh that that was my daughter that's what i'm saying remove them i'm like i should remove those not all of them few of them you mean to say i have to connect them by each other or something sir remove them what does remove mean does remove mean connect no not as such sir uh okay sorry use only what is needed okay sir okay thank you sir i'll try it now why are four needed why is the one not sufficient actually that was my doubt daughter i'm like i didn't know why are we i'm like specified about the number of contacts exactly i'm like why are we even uh looking into it exactly you tell me what are contacts they are they are kind of buyers connecting the metal one with the source or the drain yes sir yes sir so if you have one wire versus you have four wires in parallel what happens okay resistance decreases i don't thank you sir okay so uh what is being shown over here is that as vgs changes as vds changes there is a diff you you can actually end up seeing different capacitance on the gate why is that so the above graph seems to be of the mass capacitor itself yes we've already done all of this okay shows the depletion region being formed and therefore the change of charges happening at the boundary of the depletion region and as soon as the inversion layer comes independent of frequency we at once have high capacitance so what is this lower graph then this these are the two components this is uh the gate coupling with body because depletion region was coming into picture and as soon as the inversion layer is formed there is no further coupling between body and gate now the additional charge comes from source and drain regions remember in the inversion layer we said that in in devices in mosfets the source and and drain will give the additional charge even at very high frequency okay so but in the lower frequency the in when the inversion is forming the charge is coming from the body itself is it then you see you see we've already shown it like this that it is coming from source and brain it is closer now it is showing that when dt has speech i think so then it's coming from source entry so this is the vt point like this so this this line is the vp point you see already this capacitance has started to rise before that what does that mean the charge the inversion is forming due to the source entry yes so since lower graph is just basically elaborating that way that confidence their components this is comp there are various components this is capacitance with bulk this is capacitance with source this is capacitance with drain it's saying that all the three components add up to form cdc gate capacitance and source and drain they have equal coupling because of equal overlap and equal density of charges there therefore this is double overall cdc is double of cgs and cgd so but this ggs is basically due to the overlap right or is it also like all the three ones is because of all three now okay sir uh in this first graph sir sir uh here uh this gate to source and gate to drain both are becoming after uh this vgs is greater than vt so they are becoming half sir uh is this because of the uniform channel formation yes because vds is kept at zero okay so after this in this sir uh this saturate nothing is told about the saturation that is the second graph that is the graph on the right side so if the if we uh increase the v this vds so this vg cs vgs and vgd both will become two by three in case in the first no the due to pinch off the drain will have no influence therefore 
the gate to drain capacitance goes towards zero okay and this gate to source become will become two by three will increase yes yes okay okay in the same graph yeah yeah this one no no starting the left one in the left one vds is equal to zero so yes so suppose at the end of this graph if the first graph we start increasing vds so then what will happen to vg uh vgs and that is that is what we have done over here no we started in this existing videos that is what happened so that's the continuation of it okay yes notice same points here wlc so here it would actually depend on other factors also known so yeah yeah yeah that is where the graphs are there uh yeah sir this was uh this refers to before so you told us about the three components uh i got the contact capacitance and the coupling capacitance uh that's fine but um didn't quite understand the diffusion level capacitance you talked about we will come to that welcome to that okay and uh second question is in this graph you see uh we are seeing the components uh gcs gcd and gc bulk um but yeah i mean when we had started to mosque capacitance um we were only in a sense i mean from what i understood we were only looking at the um gate to bulk because there was no source order in there yeah but here we see that the gate to bulk capacitance keeps decreasing it vanishes so it decreases for uh for a mass capacitance also now that is where we end up with the depletion region where we go to wd mass and we say this is the minimum capacitance you would have yeah yeah but donating pieces right but in this only in low frequency only low frequency then this change is happening in the inversion layer again but then sir i mean even at high frequency then it after one point it remains constant but that is low that is a low value that's that's low but um in this case it we just see it it just keeps on decreasing until it vanishes so uh okay and but this now starts to come from source and drain region therefore gate capacitance comes up okay so when you're talking about the bulk you're talking about the substituting the lot between inversion here and no no no no no no okay okay okay so now we come to the diffusion capacitance that was what you were asking hey what is happening in the diffusion capacitance so can i you are explaining this i want to ask about the right words graph the graph in the right side i i was not able to understand that yeah tell me so uh here we are we were saying the gcd is decreasing and gcs is increasing why is that so certain uh because pen shop has happened so the drain is no longer connected to the inversion layer okay the drain can no longer so when you change the gate voltage there is no longer any change in the charge towards the drain yes sir that is why that's where cjd goes to zero okay and the source side we have the charge density that is why it is increasing yes now all the charge needs to come from the source side only therefore the component or the value of cgcs increases okay okay okay but because pinch-off has happened the overall inversion layer width has reduced inversion layer availability has reduced therefore the overall capacitance is reduced okay okay so now coming to the diffusion capacitance are you able to see this tub over here i'm calling this a tub because this actually looks like a bathtub or a tub for that matter which is where we have uh doped n plus for the source ordering region let us say now if i say that this is one plate there is a pn junction on all the sides of this plate are you able to see this yes sir all the sides except this one why because depletion depletion yes because the channel is there there's an inversion layer that you're talking about okay if there was no inversion layer then it would come on this side also but in a on device they say there is an inversion layer so this this will not appear so if i want to find the capacitance of this drain or the source what happens i have to measure the capacitance on the side walls and i have to measure the capacitance of the bottom tub bottom bottom of the tub are you able to see this so but the sidewalls is like uh on the side walls you have the dioxide right uh sidewalls you have the okay so let us look at very weird so side walls you have this isolation yes but this there this is there now okay okay so yeah didn't notice okay sir yes so on the channel side the inversion is just at the surface but i have got that wd max so that would also come now because it's not wd max is there so i will get that on that side even though there is a depletion layer there is no other end of the plate because of the channel and the depletion layer so let us look at it like this over here what is what are we saying there is a depletion layer over here and then there is a rotation layer wd max over here and then the source comes so yeah yes sir so where is the other plate now so the substrate for itself will be other plate that is too far away from here and then from the inversion layer and so many places so is it like that it is becoming like negligible kind of thing because of the capacitance so capacitance of uh this part of the plate to this part of the plate it has it is it is such a big long path the dielectric thickness is so long the oxygenated depth is so big that the capacitance is insignificant in comparison to what you will see over here okay okay okay so what do we do we say that okay let us measure the the perimeter and then multiply it with the number which is cj c junction sidewall okay and let us measure the area that is the extension and the width okay so this is ls the extension and the width that will give me the area of the bottom rectangle and i multiply that with c junction and with this i get the entire the overall capacitance of the the diffusion capacitance of the drain or the source region now again if i want to reduce the drain or source capacitance what do i need to do width is fixed but i can reduce the ls are you able to see this so so this diffusion capacitance is the gate 2 ball gate tools i source drain 2 bulk and the source this is yeah in the model yeah and so one more thing say in the junction capacitance of the uh like side walls the the base this x j parameter coming into picture it should also be enough for the parameters we had it only two ls plus w yeah so you will say that c j into x j becomes c j as w ok ok because substance over here you know the depth and based on that you came up with this value of cjsw okay and so one more thing so this ls component will have that overlap component also right because that is there right or it will be subtracted yeah ls would be the entire train region whether it is below the gate or not below the gate if there is okay uh sir so you said that diffusion capacitance is a is a component of your gate to source or gate to grain capacitance but in this case it's it seems like it's a component of your uh so i mean source to bulk no oh oh so i did not say diffusion capacitance i said gate capacitance with the diffusion region okay what i meant was those extra lines of this was am i audible yes sir yeah this was gate capacitance with the diffusion region okay okay the diffusion capacitance when we use the term diffusion capacitance this is what is the diffusion capacitance that we're talking about okay yeah so the diffusion time is coming because that because of the fabrication thing right because we should diffuse the because initially the source and train regions were diffused okay that's why it is coming today they are implanted today the iron implantation is done at an earlier point of time phostine was run through and diffusion happened so that is why we called it diffusion layer so put on okay so now we come to the"
36WFzgPvj3I,component next component of our what do you say vlsi devices which is buyers and we've already talked about buyers a little earlier so we can be relatively quick now so this is what wires are what are they made of we discussed this in much detail earlier what are the wires made of copper aluminium so in advanced technologies they're always all all fabs and advanced technologies use copper in earlier technologies let us say 180 nanometer and and and older people use aluminum because the copper process was not as defined yet however today you will also find technologies which use 180 nanometers with copper these are hybrid technologies to gain density or to have more current carrying capability and so on but yes what we are looking at is that these wires are made out of copper which is more ductile than aluminium and therefore these wires can be drawn very close to each other we also know that these wires are like these cuboids this is wire one this is wire two and when they run parallel to each other this is the kind of 3d space they will create amongst themselves so what happens what all kinds of capacitances will you see here so this is a metal running beneath let us say this is metal one and this is metal two so what all kind of capacitances will this wire one see so this uh this will see a capacitance between the other wire in the same layer and due to these kinds of forces okay yeah and i'm assuming there will be another layer above these bars yes so there could be another wire running above it so there would be lines of forces like this also and lines of forces like this are you able to see this the voice is not clear uh sir i am unable to picturize this so uh how is it different this m1 and wire on can you please there are different metal layers now we saw the dual dimension process yes yes yes so what were we doing we were making one metal layer then we made vrs and the second metal layer then we made vrs and the third metal layer so these are these metal layers the lowest plate is metal one then you have these wires in metal two then we have metal three up there okay so yeah got it okay so but metal one and different materials have been connected with diana so like but suppose i am running a clock and i am running a data signal uh data signal is running in metal one clock is running in metal two will i connect them also with the vr no no no there are two independent signals running in two different metals what's the big deal so um we're talking over here as about two things in this slide we're talking about two things width of the wires and the spacing between the wires we're also talking about thickness height of the wire and the inter metal dielectric height h okay an important thing is what is the ratio of thickness versus width of the wire in old processes wires were like this so inter metal capacitances played a big role because of lines of forces but in today's advanced technologies wires are like this so even if there is a metal layer going running from above it then there are few lines of forces between them but there are more lines of forces in the intra metal region are you able to see this so what are we what we are talking about essentially is that there are different components of capacitances c top c bot and c adjacent so in older technologies see top and c bot for the dominating capacitances but in advanced technologies of today c adjacent is a very big component of the total capacitance okay and if you want to look at how does how do these capacitances change as as you bring the wires closer or something like that you will notice that this is how it appears so we have m1 and m3 planes there planes means there is a high density of wires there and the spacing between my metal two wires is is changing like this so what do i observe that when the width of the wire is less let us look here when the width of the wire is less then an isolated wire would have this capacitance whereas a dense a dense structure of wires in metal two and method three planes would have this capacitance now if my wire width is very large then adjacent capacitance does not change much when i have isolated when i have isolated uh metal two wires then the capacitance doesn't change much but when i put metal one in metal three planes because the width of my wire is large this inter metal capacitance also starts to play a significant role so what do you mean by isolated i mean isolated as it means no metal one metal metal three planes this metal two is there okay so so we are looking at a plane not between layers here in this graph yeah um okay so what else can you reduce from here if your wires metal two wires were very close let us say 320 nanometer closed then the change in capacitance of buyers because of whether there is a metal plate up there or down there doesn't really matter much are you able to see this also so what does this hollow rhombus represent according to you so i mean s is the distance between the two wires in the same plane in the same plane right so i am saying that two wires are very close they are only 320 nanometers apart yes sir you see if there was only single wire and no other wire the wire capacitance would have been something like 60 or 70 acrocytes per micron when i brought other wires close to it reduce the spacing the capacitance has increased from that 60 to something like 230 okay right now when the wire was only there was only single wire because the spacing is infinity means there is only single wire and i put in the metal one and metal three planes the capacitors increased from 62 130 more than doubled but in a dense wire configuration when i put the metal one in the metal three planes the capacitance increased from 220 to only 230 in significant change are you able to see this okay so it means that at a very small when you're going to very smaller dimensions then the inter metal one is getting neglected intra metal capacitance dominates between the same layer it is dominating but yeah between lenses now okay yes and if you were using wide wires then yes intra metal also has some influence see what happened for very wide wires the capacitance increased from 260 to 380. i know but if your wires are thin which is usually the case then there is not much impact of whether there is a wire running up there or not that doesn't change the wire capacitance significantly are you able to see this yes sir yeah yes okay so let us look at how do these capacitances compare amongst each other typically dense fires would have a capacitance of something like 0.2 farads per micron whereas a gate would have a capacitance of one to two centified per micron we discussed this in the last session i had asked you if i have to implement the capacitance with gates or with metals i prefer to implement a capacitor with with gates why because it is much much denser you see we put the numbers over here today and uh we we see that the diffusion capacitance is also very high why because over there also there is only this pn junction the dielectric thickness is very thin okay so what is this division capacitor is coming here so i'm not no we're just talking about different capacitive components as to why how do the what is the uh typical range of different capacitances that come into picture okay so in the earlier models we are giving a number to the model yeah yeah so we're just talking about this earlier model now we're comparing the wire capacitance with this diffusion capacitance now okay okay okay it has nothing to do with our capacitance we're just saying because you're now putting the numbers i have not given you any numbers till now no first time i am giving you some numbers so so that you get a feel of what what order we are talking about okay so diffusion capacitance is actually comparable to gate capacitance but diffusion is very resistive so we do not even if we have to make capacitances we would not use diffusion as a medium to make those capacitances or even if i use a diffusion thing i will put lots of contacts over it i will put lots of wires over it metal over it so that the resistance reduces so this point i'm not going to understand to avoid using diffusion runners what is this so let us say i have a inverter that is connected to let us say another okay sorry i accidentally pressed end slide so there ya go i have to restart them this card let me restart the slideshow yeah you're able to see the slide again yes sir so let us say we have an inverter that is driving another inverter what does that mean that means there will be a poly a p mass and an n mass and the output of this pmos and n mass will go and connect to the poly of this other inverter something like this we want to do what is being said is you connected them through wires now don't go to diffusion layer and route through diffusion route only through metal now you will think why would i want to route through diffusion you may want to route through diffusion because there is the metal space is already occupied by some other metal there there is some other signal that is running in metal one so you don't have metal one available so you say okay let me go through diffusion and run it you can't do that but that is very resistive simon what is routing diffusion meaning here i mean we're connecting the metal one to the poly that is diffusion no routing means connecting with these wires this is routing yes sir yes this i understand so what is being said is don't use diffusion for routing purposes don't use diffusion runners for in place of wires so what this means what is this diffusion layer i could just make a diffusion layer like this and i would say i will see diffusion layer means active region so current will flow through a diffusion layer also we are using the diffusion you have to connect the active regions but connect them through metal okay just don't extend the active regions and connect like the both the greens okay so for very short wires you can possibly use polysilicon at times but avoid diffusion okay okay so uh one very important a quick concept so this we had already seen last time in the earlier thing we had already seen that so very quick concept i would want to give is that of sheet resistance see this edge as a designer you have no control over it do you see that this is the technology feature yes so the total resistance of a wire in that this row over s is actually constant for you yes height is in r but your overall resistance then is only dependent on l by w which we can say that l by w is equal to number of squares that i can make on this wire in the direction of flow of current are you able to see this l by w has no dimension because l is also in micron w is also in micron so it has no dimension in itself what does l by w represent the number of squares that i can make or that i have to travel in the direction of flow of the current yes so what is the unit of sheet resistance then ohms per meter per square not meter square as many squares that will be the resistance that will so i will simply multiply sheet resistance with the number of squares and i will get the value of resistance so if i have to flow current in this direction what will be the value of how many squares are there in this direction let us say this is the total length of the wires how many squares in this direction so i will get the value of 2r naught if i have to flow current in this direction now what sir half i'm not by 2 r not by 2. we have to define a unit uh square also right uh unit square is always by defined by the width when i was moving in when i was moving current in this direction the width was l and the length of which i was running was w so w by l is 1 by 2 that is where r naught by 2. when i'm moving in the other direction when i'm moving in this direction my width is w and length is f so it becomes uh and length is twice of w therefore it becomes 2 2 r naught are you able to see this so what is this square concept we are talking about because we have right so we are talking why we are talking so what is the formula of resistance rho l by a rho l by a that is what we have written over here yeah yes sir what is a the cross section through which the current is flowing yeah so i said rho by h is r naught etch [Music] no no you make metal one is you have the flexibility to change the bits of the wire you have the flexibility to change the length of the wire can you change the thickness of the wire when you're making a layout no no sir so that has fixed for the for for a given technology is it not yeah yeah yes that is what we are calling as are not okay now what do i multiply r naught with to get the value of resistance the number of squares that have to be traversed this ratio is the number of squares okay so i think we are already on time now so this this also we had we had already seen earlier so we will not look into this again we've already even had a a question in your quiz on this topic uh we will we can probably talk about polishing but that we can do later also sometime so we'll talk about these models in the next class,https://www.youtube.com/watch?v=36WFzgPvj3I,"Link: https://www.youtube.com/watch?v=36WFzgPvj3I
Transcript: component next component of our what do you say vlsi devices which is buyers and we've already talked about buyers a little earlier so we can be relatively quick now so this is what wires are what are they made of we discussed this in much detail earlier what are the wires made of copper aluminium so in advanced technologies they're always all all fabs and advanced technologies use copper in earlier technologies let us say 180 nanometer and and and older people use aluminum because the copper process was not as defined yet however today you will also find technologies which use 180 nanometers with copper these are hybrid technologies to gain density or to have more current carrying capability and so on but yes what we are looking at is that these wires are made out of copper which is more ductile than aluminium and therefore these wires can be drawn very close to each other we also know that these wires are like these cuboids this is wire one this is wire two and when they run parallel to each other this is the kind of 3d space they will create amongst themselves so what happens what all kinds of capacitances will you see here so this is a metal running beneath let us say this is metal one and this is metal two so what all kind of capacitances will this wire one see so this uh this will see a capacitance between the other wire in the same layer and due to these kinds of forces okay yeah and i'm assuming there will be another layer above these bars yes so there could be another wire running above it so there would be lines of forces like this also and lines of forces like this are you able to see this the voice is not clear uh sir i am unable to picturize this so uh how is it different this m1 and wire on can you please there are different metal layers now we saw the dual dimension process yes yes yes so what were we doing we were making one metal layer then we made vrs and the second metal layer then we made vrs and the third metal layer so these are these metal layers the lowest plate is metal one then you have these wires in metal two then we have metal three up there okay so yeah got it okay so but metal one and different materials have been connected with diana so like but suppose i am running a clock and i am running a data signal uh data signal is running in metal one clock is running in metal two will i connect them also with the vr no no no there are two independent signals running in two different metals what's the big deal so um we're talking over here as about two things in this slide we're talking about two things width of the wires and the spacing between the wires we're also talking about thickness height of the wire and the inter metal dielectric height h okay an important thing is what is the ratio of thickness versus width of the wire in old processes wires were like this so inter metal capacitances played a big role because of lines of forces but in today's advanced technologies wires are like this so even if there is a metal layer going running from above it then there are few lines of forces between them but there are more lines of forces in the intra metal region are you able to see this so what are we what we are talking about essentially is that there are different components of capacitances c top c bot and c adjacent so in older technologies see top and c bot for the dominating capacitances but in advanced technologies of today c adjacent is a very big component of the total capacitance okay and if you want to look at how does how do these capacitances change as as you bring the wires closer or something like that you will notice that this is how it appears so we have m1 and m3 planes there planes means there is a high density of wires there and the spacing between my metal two wires is is changing like this so what do i observe that when the width of the wire is less let us look here when the width of the wire is less then an isolated wire would have this capacitance whereas a dense a dense structure of wires in metal two and method three planes would have this capacitance now if my wire width is very large then adjacent capacitance does not change much when i have isolated when i have isolated uh metal two wires then the capacitance doesn't change much but when i put metal one in metal three planes because the width of my wire is large this inter metal capacitance also starts to play a significant role so what do you mean by isolated i mean isolated as it means no metal one metal metal three planes this metal two is there okay so so we are looking at a plane not between layers here in this graph yeah um okay so what else can you reduce from here if your wires metal two wires were very close let us say 320 nanometer closed then the change in capacitance of buyers because of whether there is a metal plate up there or down there doesn't really matter much are you able to see this also so what does this hollow rhombus represent according to you so i mean s is the distance between the two wires in the same plane in the same plane right so i am saying that two wires are very close they are only 320 nanometers apart yes sir you see if there was only single wire and no other wire the wire capacitance would have been something like 60 or 70 acrocytes per micron when i brought other wires close to it reduce the spacing the capacitance has increased from that 60 to something like 230 okay right now when the wire was only there was only single wire because the spacing is infinity means there is only single wire and i put in the metal one and metal three planes the capacitors increased from 62 130 more than doubled but in a dense wire configuration when i put the metal one in the metal three planes the capacitance increased from 220 to only 230 in significant change are you able to see this okay so it means that at a very small when you're going to very smaller dimensions then the inter metal one is getting neglected intra metal capacitance dominates between the same layer it is dominating but yeah between lenses now okay yes and if you were using wide wires then yes intra metal also has some influence see what happened for very wide wires the capacitance increased from 260 to 380. i know but if your wires are thin which is usually the case then there is not much impact of whether there is a wire running up there or not that doesn't change the wire capacitance significantly are you able to see this yes sir yeah yes okay so let us look at how do these capacitances compare amongst each other typically dense fires would have a capacitance of something like 0.2 farads per micron whereas a gate would have a capacitance of one to two centified per micron we discussed this in the last session i had asked you if i have to implement the capacitance with gates or with metals i prefer to implement a capacitor with with gates why because it is much much denser you see we put the numbers over here today and uh we we see that the diffusion capacitance is also very high why because over there also there is only this pn junction the dielectric thickness is very thin okay so what is this division capacitor is coming here so i'm not no we're just talking about different capacitive components as to why how do the what is the uh typical range of different capacitances that come into picture okay so in the earlier models we are giving a number to the model yeah yeah so we're just talking about this earlier model now we're comparing the wire capacitance with this diffusion capacitance now okay okay okay it has nothing to do with our capacitance we're just saying because you're now putting the numbers i have not given you any numbers till now no first time i am giving you some numbers so so that you get a feel of what what order we are talking about okay so diffusion capacitance is actually comparable to gate capacitance but diffusion is very resistive so we do not even if we have to make capacitances we would not use diffusion as a medium to make those capacitances or even if i use a diffusion thing i will put lots of contacts over it i will put lots of wires over it metal over it so that the resistance reduces so this point i'm not going to understand to avoid using diffusion runners what is this so let us say i have a inverter that is connected to let us say another okay sorry i accidentally pressed end slide so there ya go i have to restart them this card let me restart the slideshow yeah you're able to see the slide again yes sir so let us say we have an inverter that is driving another inverter what does that mean that means there will be a poly a p mass and an n mass and the output of this pmos and n mass will go and connect to the poly of this other inverter something like this we want to do what is being said is you connected them through wires now don't go to diffusion layer and route through diffusion route only through metal now you will think why would i want to route through diffusion you may want to route through diffusion because there is the metal space is already occupied by some other metal there there is some other signal that is running in metal one so you don't have metal one available so you say okay let me go through diffusion and run it you can't do that but that is very resistive simon what is routing diffusion meaning here i mean we're connecting the metal one to the poly that is diffusion no routing means connecting with these wires this is routing yes sir yes this i understand so what is being said is don't use diffusion for routing purposes don't use diffusion runners for in place of wires so what this means what is this diffusion layer i could just make a diffusion layer like this and i would say i will see diffusion layer means active region so current will flow through a diffusion layer also we are using the diffusion you have to connect the active regions but connect them through metal okay just don't extend the active regions and connect like the both the greens okay so for very short wires you can possibly use polysilicon at times but avoid diffusion okay okay so uh one very important a quick concept so this we had already seen last time in the earlier thing we had already seen that so very quick concept i would want to give is that of sheet resistance see this edge as a designer you have no control over it do you see that this is the technology feature yes so the total resistance of a wire in that this row over s is actually constant for you yes height is in r but your overall resistance then is only dependent on l by w which we can say that l by w is equal to number of squares that i can make on this wire in the direction of flow of current are you able to see this l by w has no dimension because l is also in micron w is also in micron so it has no dimension in itself what does l by w represent the number of squares that i can make or that i have to travel in the direction of flow of the current yes so what is the unit of sheet resistance then ohms per meter per square not meter square as many squares that will be the resistance that will so i will simply multiply sheet resistance with the number of squares and i will get the value of resistance so if i have to flow current in this direction what will be the value of how many squares are there in this direction let us say this is the total length of the wires how many squares in this direction so i will get the value of 2r naught if i have to flow current in this direction now what sir half i'm not by 2 r not by 2. we have to define a unit uh square also right uh unit square is always by defined by the width when i was moving in when i was moving current in this direction the width was l and the length of which i was running was w so w by l is 1 by 2 that is where r naught by 2. when i'm moving in the other direction when i'm moving in this direction my width is w and length is f so it becomes uh and length is twice of w therefore it becomes 2 2 r naught are you able to see this so what is this square concept we are talking about because we have right so we are talking why we are talking so what is the formula of resistance rho l by a rho l by a that is what we have written over here yeah yes sir what is a the cross section through which the current is flowing yeah so i said rho by h is r naught etch [Music] no no you make metal one is you have the flexibility to change the bits of the wire you have the flexibility to change the length of the wire can you change the thickness of the wire when you're making a layout no no sir so that has fixed for the for for a given technology is it not yeah yeah yes that is what we are calling as are not okay now what do i multiply r naught with to get the value of resistance the number of squares that have to be traversed this ratio is the number of squares okay so i think we are already on time now so this this also we had we had already seen earlier so we will not look into this again we've already even had a a question in your quiz on this topic uh we will we can probably talk about polishing but that we can do later also sometime so we'll talk about these models in the next class"
Q4NRLQqQn34,but uh we are starting with the layout part which uh you may have already seen and uh which you may have already seen in the tutorials that were already shared with you and and therefore you are already working on your assignment but it is important to take care of a few things it is important to take care of a few things uh so that we can uh make good layouts in line with what we were discussing you know less capacitance and uh and all that so uh let me just give you a quick hands-on run on what things you can take care of when you're making layouts so let us say let me make just these four layers for now so in your layer map table you have green color for active region or some other color so let us say this is the active for nmos or pmos and this is the active for nmos can we say this yes and because this is p mass so we will say there is a bell around it is that okay so now let us say we have to make the functionality of a nand b so what is the circuit something like this a and let us say b are you able to see this are you with me on this part yes sir so what we are saying is that there are two nmoses and two pmosses pmosses are in parallel and muscles are in series so what would you do you would say that okay let me make the police yeah let me make the police where this poly would represent one input this poly would represent another input let us call this a let us call this b now let us make the contacts let us say this is the output i made a contact here this is ground i made a contact here this is now you will have to tell me which one should be output and which one should be vdd so it has one should be output middle one should be output why because it no because it is shared the beam i could short them like this so middle one would have uh less capacitance so output so this could be the way i could have output there you said this cannot change so actually how you're drawing this uh nand layout from this schematic that you just i'm not able to get it okay so you're able to see these signals a and b yes sir the body yes sir so when the poly intersects with the and uh active in the eval what do we get so one is a source and drain we get an n mass so we get a source and a drain there and this is another nmos and by the virtue of shared diffusion region shared active this connection is already being built there this connection is already being built am i right so similarly on the pima side there are two p masses and by the virtue of this shared diffusion region i am either making this connection or i am making this connection either of those two i am making that is what my question is which one like where would you use the shared shared diffusion like shared diffusion should be vdd or shared diffusion should be output that is what my question to you is output shared definition should be output why because we get our output from the middle of the pemos and the lms so i think it could be both because like because then also the source and drainage source is also shared then daniel yeah they are in parallel electrically yeah that's also what i'm thinking it doesn't make a difference to me it doesn't make a difference to you you've already talked about capacitances huh see where did i start this uh this discussion from from a question on capacitances so this is a hint so there can be two things one thing is in the current configuration you are taking the metal over the poly two times okay and and and if you if you do the vdd on both sides then you have to take the take it to above the for the railing that would be going above for the vdd but it would not be over the poly it would be at a minimum drc from the poly maybe you can increase that if you don't want to lose the area so you cannot you cannot but increase that and decrease the capacitance also okay anything else there visit when in the middle one in the that contact to poly there is contact to public capacitance in both sides so there will be initially some load capacitance also so if we could make the capacity capacitance less somehow then switching could be done more faster means we have to discharge and charge less okay so what should we do so i mean as as i can see uh diffusion capacitances won't change how do we connect because we have this because that is dependent up according to me upon the active area only so if the area center diffusion capacitance it doesn't make a difference like where do i know what you're saying so what you're telling me is that this area is same as some of these areas no sir so i am saying as i'm saying that uh the diffusion capacitance depends upon what is the area of my source and drain yeah so if you if i would connect y this y node on on the outer things this is the area that i am looking at anna whereas if i keep my output over here this is the area i will look at no sir but this area will come because it is source of source area is also coming right because we cannot think of your drain area output it's my area if my wire is here why would the capacitance of this node appear on my output so but the diffusion capacitance was the sum of the source right you said total different capacitance of sum of source and drain capacitance we only looked at one capacitance we said whether it is source or drain this is the capac this is how you should calculate the capacitance it was sum of two components what were the two components okay okay right right okay it was sum of two components but what were those two components again this is a hint that was one was the width and the ls length so so such that ls part one of the ls part gets eliminated if we do the middle one tapping so i have only one case so basically though yeah so only one ls gets eliminated or both the ls both the bits get eliminated so see even if you tell me that this area is same as this area what happens there is a junction sidewall junction capacitance also which is appearing only for this here but in the in this region it will it is appearing for all three sites yes sir sir i'm sorry sir but i'm really unable to i'm like uh uh i'm like correlate this both structure sir uh i'm like could you please explain that ceremony so what are you not able to correlate sir uh there are uh four uh uh two pmos and two queen most according to the structure i do understand that but yeah that uh i'm like i literally can't see those fours are over here you can't see four okay yes sir you see this is one transistor let us call this p1 so how did that become a transistor so that was made out actually this is poly running over our active region yes yes sir that becomes a transistor okay okay we saw the top level view of the transistor in the last class also this is how it looked me yes sir so up my last class revised me curry uh actually uh i didn't revise it sir to be honest so we did that in the last class so that is the poly poly over active is a transistor that is p1 so it has its input at a so this is p1 the pmos with input b is let us say call it p2 so this is p2 yes okay the nmas with input a let us call it n1 so this is n1 and mass with input b we call it n2 yes sir okay yes sir uh now i understand about are you able to see yes sir so sir uh uh a small dot sir so uh i'm like uh even this might have been discussed but yeah sir sir where are these drain source and gate regions are exactly of this pmos you tell me what do you see here where are the source and drain regions what is source and drain source so towards the left and right side i'm like of this poly towards the left and right of this poly there is a source and drain region so then what are these ones are exactly and then you're not worked on the assignment yet you're not paying too late i'd say i did that sir and but but when i generated sir they were directly coming so i'm like i didn't see any so again you should so friends it's important because i will be building upon what we discussed in the last class anna whatever i have discussed earlier uh i will be building up upon that so i myself try to upload the lectures within you know as early as possible within one hour two hour of the class have you noticed that yes sir why do i do that to give us time to because i want you to review what we have discussed if there are any questions you should ask the tas in the office hours if there is anything else you should discuss with us in the next class otherwise i will as well upload all the lectures together and towards the you know closer to the midsim or the nsm exam should i do that no sir the intent is that when you look at the uh you know when you go through the class i know you might be in one particular state of mind you might get stuck with some idea some previous topic discussion there is some question pending and you are stuck there and we moved ahead in the class and okay later you asked the question that questions get solved but there is some little concept which you have missed so i share the lectures very as early as possible so that you are able to review the concept and refresh and fill in for anything that you might have missed yes sir it's important now yes sir so please uh review whatever has been you if you're writing notes review from your notes otherwise i'm uploading the lectures review from the lectures so these yellow ones are contacts so if you've made the layouts you would have already seen these contacts me yes sir so why the question then uh i'm like okay uh so there are two pins right so i'm like there are drain and source on the left and right of that but i'm like we have made contact only for one so that we are connecting that i'm like we aren't mentioning the other one uh because it's not needed so yeah yeah see that is where i am responding to gandhi's query how do we reduce the number of contacts how do we reduce the source and drain area see if you would use the p cells which i dissuaded you from using in the last class also if you use the p cells what will happen let us look at it if you use the pieces then you will get one transistor we will get four circuits you will get another transistor you will make another transistor here you will make another transistor here and you will probably connect the poly like this you will probably connect the poly like this again and then you will put contacts everywhere yes sir and make the connection accordingly hello so what happens in all this in all this okay you may say that okay this is ground this is vdd uh this is the shared node i will connect them like this i will connect them like this huh yes sir and this is again vdd and i say this is my output yes sir so what is happening now what is what how many capacitances do we see if we just count poly to contact capacitances there are one two three four five six seven eight eight capacitances from poly to contact yes sir additionally there are eight source entrained capacitances also yes sir so even if we say that area of shared active region even if we say that area of the shared active region is same as the area of these independent actors what happens [Music] just give me a minute [Music] yeah so even if we say that even if we say that this area of shared active is equal to the area of the two independent actors what extra capacitance do i have here i have this side wall capacitance coming in extra plus at least one of these drain capacitances is extra so but that will be basically but when i'm extending the shared region then basically i don't think that will become me an extra thing because the same area would come this under the shared region also right so i said if we go with the assumption go with you know be careful about what i said okay so okay if we look at it over here what would be the length of extension of this region it would be poly2 contact space plus contact width plus uh od extension so you're calling it od diffusion layer you're calling it od in your lsw what do you call it yeah so these three things will make one source or drain region am i right let us put some numbers let us say poly2 contact is 50 nanometer uh contact with this let us say 60 nanometers and let us say od extension beyond poly is 30 nanometer so this would come out to be 140 nanometers yes sir okay now now let us come here so in this region we we are putting one contact so what is the spacing between these two polys poly2 contact plus contact width plus poly2 contact are you able to see this yes let's put the numbers now 50 plus 60 plus 50. 160 nanometer so effectively kidnapping with 140 over here 140 over here the width effective weight over there was 280 280 right over here we are talking about 160 right so diffusion capacitance would reduce drastically diffusion capacitance reduce reduces not just because of area getting reduced it so it also reduces because the sidewall junction capacitance also does not come right right thanks yes okay additionally how many positive contact capacitances do you see now 1 2 4 4 5 six six six wahabi kidney thing how many were there eight eight so you see you are able to reduce that capacitance also so even that the field the field the capacity of the field also reduces because we have the shared trains right there was some field also right there between the uh contact to sorry gate and uh drain gate and source there were three components right so that feel also i think it's reduces because of this yeah because that you can say because the drain area reduces that can reduce yes that will also reduce the poly two the poly two drain capacitance would also reduce because the drain region is smaller in total length yeah,https://www.youtube.com/watch?v=Q4NRLQqQn34,"Link: https://www.youtube.com/watch?v=Q4NRLQqQn34
Transcript: but uh we are starting with the layout part which uh you may have already seen and uh which you may have already seen in the tutorials that were already shared with you and and therefore you are already working on your assignment but it is important to take care of a few things it is important to take care of a few things uh so that we can uh make good layouts in line with what we were discussing you know less capacitance and uh and all that so uh let me just give you a quick hands-on run on what things you can take care of when you're making layouts so let us say let me make just these four layers for now so in your layer map table you have green color for active region or some other color so let us say this is the active for nmos or pmos and this is the active for nmos can we say this yes and because this is p mass so we will say there is a bell around it is that okay so now let us say we have to make the functionality of a nand b so what is the circuit something like this a and let us say b are you able to see this are you with me on this part yes sir so what we are saying is that there are two nmoses and two pmosses pmosses are in parallel and muscles are in series so what would you do you would say that okay let me make the police yeah let me make the police where this poly would represent one input this poly would represent another input let us call this a let us call this b now let us make the contacts let us say this is the output i made a contact here this is ground i made a contact here this is now you will have to tell me which one should be output and which one should be vdd so it has one should be output middle one should be output why because it no because it is shared the beam i could short them like this so middle one would have uh less capacitance so output so this could be the way i could have output there you said this cannot change so actually how you're drawing this uh nand layout from this schematic that you just i'm not able to get it okay so you're able to see these signals a and b yes sir the body yes sir so when the poly intersects with the and uh active in the eval what do we get so one is a source and drain we get an n mass so we get a source and a drain there and this is another nmos and by the virtue of shared diffusion region shared active this connection is already being built there this connection is already being built am i right so similarly on the pima side there are two p masses and by the virtue of this shared diffusion region i am either making this connection or i am making this connection either of those two i am making that is what my question is which one like where would you use the shared shared diffusion like shared diffusion should be vdd or shared diffusion should be output that is what my question to you is output shared definition should be output why because we get our output from the middle of the pemos and the lms so i think it could be both because like because then also the source and drainage source is also shared then daniel yeah they are in parallel electrically yeah that's also what i'm thinking it doesn't make a difference to me it doesn't make a difference to you you've already talked about capacitances huh see where did i start this uh this discussion from from a question on capacitances so this is a hint so there can be two things one thing is in the current configuration you are taking the metal over the poly two times okay and and and if you if you do the vdd on both sides then you have to take the take it to above the for the railing that would be going above for the vdd but it would not be over the poly it would be at a minimum drc from the poly maybe you can increase that if you don't want to lose the area so you cannot you cannot but increase that and decrease the capacitance also okay anything else there visit when in the middle one in the that contact to poly there is contact to public capacitance in both sides so there will be initially some load capacitance also so if we could make the capacity capacitance less somehow then switching could be done more faster means we have to discharge and charge less okay so what should we do so i mean as as i can see uh diffusion capacitances won't change how do we connect because we have this because that is dependent up according to me upon the active area only so if the area center diffusion capacitance it doesn't make a difference like where do i know what you're saying so what you're telling me is that this area is same as some of these areas no sir so i am saying as i'm saying that uh the diffusion capacitance depends upon what is the area of my source and drain yeah so if you if i would connect y this y node on on the outer things this is the area that i am looking at anna whereas if i keep my output over here this is the area i will look at no sir but this area will come because it is source of source area is also coming right because we cannot think of your drain area output it's my area if my wire is here why would the capacitance of this node appear on my output so but the diffusion capacitance was the sum of the source right you said total different capacitance of sum of source and drain capacitance we only looked at one capacitance we said whether it is source or drain this is the capac this is how you should calculate the capacitance it was sum of two components what were the two components okay okay right right okay it was sum of two components but what were those two components again this is a hint that was one was the width and the ls length so so such that ls part one of the ls part gets eliminated if we do the middle one tapping so i have only one case so basically though yeah so only one ls gets eliminated or both the ls both the bits get eliminated so see even if you tell me that this area is same as this area what happens there is a junction sidewall junction capacitance also which is appearing only for this here but in the in this region it will it is appearing for all three sites yes sir sir i'm sorry sir but i'm really unable to i'm like uh uh i'm like correlate this both structure sir uh i'm like could you please explain that ceremony so what are you not able to correlate sir uh there are uh four uh uh two pmos and two queen most according to the structure i do understand that but yeah that uh i'm like i literally can't see those fours are over here you can't see four okay yes sir you see this is one transistor let us call this p1 so how did that become a transistor so that was made out actually this is poly running over our active region yes yes sir that becomes a transistor okay okay we saw the top level view of the transistor in the last class also this is how it looked me yes sir so up my last class revised me curry uh actually uh i didn't revise it sir to be honest so we did that in the last class so that is the poly poly over active is a transistor that is p1 so it has its input at a so this is p1 the pmos with input b is let us say call it p2 so this is p2 yes okay the nmas with input a let us call it n1 so this is n1 and mass with input b we call it n2 yes sir okay yes sir uh now i understand about are you able to see yes sir so sir uh uh a small dot sir so uh i'm like uh even this might have been discussed but yeah sir sir where are these drain source and gate regions are exactly of this pmos you tell me what do you see here where are the source and drain regions what is source and drain source so towards the left and right side i'm like of this poly towards the left and right of this poly there is a source and drain region so then what are these ones are exactly and then you're not worked on the assignment yet you're not paying too late i'd say i did that sir and but but when i generated sir they were directly coming so i'm like i didn't see any so again you should so friends it's important because i will be building upon what we discussed in the last class anna whatever i have discussed earlier uh i will be building up upon that so i myself try to upload the lectures within you know as early as possible within one hour two hour of the class have you noticed that yes sir why do i do that to give us time to because i want you to review what we have discussed if there are any questions you should ask the tas in the office hours if there is anything else you should discuss with us in the next class otherwise i will as well upload all the lectures together and towards the you know closer to the midsim or the nsm exam should i do that no sir the intent is that when you look at the uh you know when you go through the class i know you might be in one particular state of mind you might get stuck with some idea some previous topic discussion there is some question pending and you are stuck there and we moved ahead in the class and okay later you asked the question that questions get solved but there is some little concept which you have missed so i share the lectures very as early as possible so that you are able to review the concept and refresh and fill in for anything that you might have missed yes sir it's important now yes sir so please uh review whatever has been you if you're writing notes review from your notes otherwise i'm uploading the lectures review from the lectures so these yellow ones are contacts so if you've made the layouts you would have already seen these contacts me yes sir so why the question then uh i'm like okay uh so there are two pins right so i'm like there are drain and source on the left and right of that but i'm like we have made contact only for one so that we are connecting that i'm like we aren't mentioning the other one uh because it's not needed so yeah yeah see that is where i am responding to gandhi's query how do we reduce the number of contacts how do we reduce the source and drain area see if you would use the p cells which i dissuaded you from using in the last class also if you use the p cells what will happen let us look at it if you use the pieces then you will get one transistor we will get four circuits you will get another transistor you will make another transistor here you will make another transistor here and you will probably connect the poly like this you will probably connect the poly like this again and then you will put contacts everywhere yes sir and make the connection accordingly hello so what happens in all this in all this okay you may say that okay this is ground this is vdd uh this is the shared node i will connect them like this i will connect them like this huh yes sir and this is again vdd and i say this is my output yes sir so what is happening now what is what how many capacitances do we see if we just count poly to contact capacitances there are one two three four five six seven eight eight capacitances from poly to contact yes sir additionally there are eight source entrained capacitances also yes sir so even if we say that area of shared active region even if we say that area of the shared active region is same as the area of these independent actors what happens [Music] just give me a minute [Music] yeah so even if we say that even if we say that this area of shared active is equal to the area of the two independent actors what extra capacitance do i have here i have this side wall capacitance coming in extra plus at least one of these drain capacitances is extra so but that will be basically but when i'm extending the shared region then basically i don't think that will become me an extra thing because the same area would come this under the shared region also right so i said if we go with the assumption go with you know be careful about what i said okay so okay if we look at it over here what would be the length of extension of this region it would be poly2 contact space plus contact width plus uh od extension so you're calling it od diffusion layer you're calling it od in your lsw what do you call it yeah so these three things will make one source or drain region am i right let us put some numbers let us say poly2 contact is 50 nanometer uh contact with this let us say 60 nanometers and let us say od extension beyond poly is 30 nanometer so this would come out to be 140 nanometers yes sir okay now now let us come here so in this region we we are putting one contact so what is the spacing between these two polys poly2 contact plus contact width plus poly2 contact are you able to see this yes let's put the numbers now 50 plus 60 plus 50. 160 nanometer so effectively kidnapping with 140 over here 140 over here the width effective weight over there was 280 280 right over here we are talking about 160 right so diffusion capacitance would reduce drastically diffusion capacitance reduce reduces not just because of area getting reduced it so it also reduces because the sidewall junction capacitance also does not come right right thanks yes okay additionally how many positive contact capacitances do you see now 1 2 4 4 5 six six six wahabi kidney thing how many were there eight eight so you see you are able to reduce that capacitance also so even that the field the field the capacity of the field also reduces because we have the shared trains right there was some field also right there between the uh contact to sorry gate and uh drain gate and source there were three components right so that feel also i think it's reduces because of this yeah because that you can say because the drain area reduces that can reduce yes that will also reduce the poly two the poly two drain capacitance would also reduce because the drain region is smaller in total length yeah"
D59Otum6EqA,mould also so uh when we are doing the schematic sir so we were we were much precise on the bits to be precise so when we generated it uh we got the uh yeah we did generate but i will try it again using this so when we generated it we got the uh ps and pmos and nmos of different lengths i'm like okay whenever i give the width as seven or eight it and the width of nmos has a four or five you are using widths of seven microns in your assignment yes sir oh my god uh so we really need that white transistors sir actually we didn't know how to cut the pmos and nmos into fingers so uh literally i placed one below the other vertically by generating it and uh that that's how it happens so so there is 20 femto load on the inverter yes sir and 25 20 and 7 and they were asking in 20 picoseconds sir i'm like uh even that was not possible by using ns i'm not okay that was possible but a bit hard to achieve in nsvt lp but it was happening in nlp tlp uh so uh yes so what was your question uh one second sir actually i forgot my question uh okay yeah i i yeah i got i i got it so uh whenever we were using the width sir we i'm like for suppose seven and four uh we we got different uh lengths of the pmos and n monster sir but uh now here if we do it directly then uh how would we mention i'm not measure the width of the pmos and nmrs because we are just running the poly over the active regions so over there width was predefined in the schematic and then we went to the layout directly and we generated so over here when you're making these rectangles the active rectangles you make this as width c and you make this as bit pen okay so we are supposed to measure that with a scale and that's it right sir yeah how else would you ensure the accuracy okay sir part would be the this that we had to basically ensure the length part would be when we are making when without the pieces the length part will have to be the channel length plus these are poly to contact and then that length length the length which you use 60 nanometer or 65 nanometer or 80 nanometer this is l the width of the poly yeah and then i have to for the minimum drc i will take that po po to co and that so that will issue the minimum area yes minimum area would also have this minimum active to od to n well spacing and so many see all these will lead to rules me yes sir yeah yeah so actually this it's the first load so we're not aware of all these rules so that's why maybe so that is why i'm covering this in the class don't worry don't worry you're not i know you've not done this earlier okay so sir i had one doubt so suppose for example like earlier we were seeing the like nand structure right so for example you made a shared like shared basically some area was shared right and to me uh for example what i'm looking at is that what area capacitance is basically getting transferred to the output so i'm only focusing on that right so for example if i say i've only considered an nmos a for example and uh for example right we have a poly right generally we draw one poly and then we have a one source string suppose we kind of like uh to reduce that area maybe to like if we have a for example uh like me uh sort of divide the poly sort of and like make a like a like some kind of structure delica so that we have a like brain in the common and then we are connecting source with metal one and then we are connecting to so for example to the what exactly the fact that i'm looking at here like so the i'm only looking at the diffusion capacitance area see only the thing i'm looking at diffusion should reduce and then basically whatever appears at the load that would be my driving factor only yeah so yeah let me take you to that this is actually raghav what you're asking is if i try to answer vaishnav's question that okay i have seven microns of cmos and five microns of pen mask and i have to draw them how do i draw them so avid possibly what you guys are doing is you are saying that okay i will make one big pmos over here i will make one big n moss over here and i will make a poly between them and this is what how my thing would look like yeah whatever be the width you are this is five microns and i'm done with my inverter but that is not how that is not how library cell layouts are made come to think of it i tell you you have to make a wall we are going back to the construction analogy i want you to make a brick wall and then i say that okay some bricks are uh this tall other some other brick is this tall another brick is this tall and then there is a brick which is this wide but that tall and so on so will you be able to make a good wall no sir no yeah what is done is we say that okay nothing doing nothing of this or doing all the cells that you have to make whether it is an inverter whether it is a nand gate whether it is a nor gate or an aoi or whatever cells you are making we will use a standard fixed height now what you will what you can change is that if there is a small cell you will use only this much width but if it's a big cell you will use much larger width using the same area but the height is fixed now what happens now you can actually place these tiles one over another and you can make a big wall am i right are you able to see this yes sir so but i have one thing to ask so here as when i'm when i'm drawing the layout the height is not even in my control so height is fixed now as of now i am telling you you will have to fix the height otherwise how will you go about making this wall later but right now with the inverter we are having okay because we are having two cells only so that's why it is because you did not even think you have to hide constraints if i tell you you have to constrain the height what will you do so but the tight parameter i couldn't see that it was anywhere mentioned in the like it is not mentioned but i am telling you now so somewhere we can change the height you are seeing that so let me say let me ask you if i have to draw the seven micron or the p mass in a height of one micron what will you do sir actually i'm not able to get that height and said that what exactly is meaning by this height than one micron are you meaning that the thickness of the gate oxide no no no i am saying this vertical extent should be less than one micron but my effective female should be seven microns wide i mean so this extension is itself the width right so i mean sorry i can't break place one by one each other in vertical one micro one micro one micro seven times and connect them so what i can do is i will say that so now let me go to so this is this is how the layout view would look okay let's say that uh we will see it's not a layout it takes a lot of time i have to make so many rectangles so there's a different representation of layouts which is called as stick diagrams so you will find lots of details on stick diagrams on your west a also okay so what do we do we say that okay there is one p mass uh so each so this this this horizontal line represents what we call as uh active region of let us say maximum one one micron width can we say this can we say this that this horizontal line represents active region active this this kind of a rectangle which is one micron wide can i make this assumption so you're taking the bit to be one micron right yeah but i'm showing it representing it only as one line i'm not making it into a rectangle over here i made this rectangle to represent the active region right where i'm saying i'm just using a line i'm just using a stick can i do that okay so you're not representing the length basically of channel i'm i'm just representing the width the width of the active region i'm not even talking about polyethylene i am not using rectangles i am just using sticks that is why it is called a stick diagram similarly i use sticks for the poly also so let me say that this represents poly this rectangle the rectangle that we have made over here that is represented by one stick over here vertical stick red one in color can i say this yes let me say contacts i am representing by such process can i say this is it yes yes now if i have to make a pmos which is 7 microns wide what do i do i say that okay i have just one micron width available to me to make a seven micron device i will put seven p mosses in parallel and what does parallel mean parallel means that i will have to short we will short all the drains together and not all the planes so i will now short let us say ah sorry and this and i will short the other like this black one is also metal i'll just use vdd for black and or what else do i need to shot i need to also short the police w gate connector are you able to see this so it's a bit confusing sir i mean uh like one is black and what what what why why can't be a single one i'm not able to get no no i just use the black one because it was available ready there i can make it do don't worry let me make it blue i mean it's a vine why not connecting all the eight contacts with a single like metal kind of running like you're missing two sets right okay you tell me you should have the answer for this we are connecting the drains together and source together right sir in this yeah if i connect all eight of them together then all the sources will be shorted yes yeah okay okay so what do i need to do to make two devices in parallel i need to short their gates and the source and the drains there are three nodes that i need to short am i right yes sir that is what i am doing one two and three so now whatever device size whether you want to make seven microns or ten microns or whatever can you make it within the height of let us say a total height of one point yeah five microns or something let us say whatever can you make it yes so this process is called as splitting into fingers sir yes so using this parallel dividing it into fingers won't this increase the area uh yes but what were you constrained about you have to build a wall yes yes sir actually i was i tried a similar thing i was able to make the specification in smaller bits but then i thought of area then i skipped this idea you have to do it like this you have to fix the height so how do you fix the height which we hide boldly or how do i arrive at a height how much high do i need for these cells version you have a question your hand is raised sorry sir uh okay so how do we raise how do we fix the height so this height i'm not able to visualize it so for example this width itself the height we are still talking about the width itself no see how it is okay let us look at it like this let me visualize it because i'm not able to get what exactly i mean my height height by number of uh pmos or nmos we want so that we can fix the height of uh each pmos smaller so let us go back to this layout i want to find the height of this this cell how would i calculate it i will say there is active to nvel od to envelope spacing plus let us say this is wp wp plus od to any then plus od to the n by 2 od yeah right plus width of n mass yeah and then and then extension of poly and then if i would make up if i have to consider that i have to make walls then this cell would would come above another cell are you are you able to see this so this this hole is a one cell this whole nand gate yeah this would be one cell there would be another cell that would come beneath it so i have to ensure this poly to poly spacing is also taken care of okay okay so i will do po2po by two why why buy two the minimum spacing is we have to ensure right yeah because if i leave half drc here half drc in the other cell overall full drc will be met yeah so the other pos of the another cell you're talking about now in excel okay okay so what what has happened now now this is what is my height so wound the p tap and that uh via that that also come into picture here because in layout very smart so it's taking me further ahead in the session great so now look at it like this why do we need peter and end taps yeah yeah that that was not clear even yesterday i asked in the office also so i mean because because it was very we have uh actually in the virtual layout like the gui we are taking we are calling it as a vr but i don't i was able to relate it why we're calling it vr i mean it doesn't appears to me like we are creating some vr or that no no it's not about vr my question is why do we need n-tap and p-tap so i see motherhood if you have raised your hands mother you have a question yes sir i have questions yeah so can you show [Music] this is one entire drain region for different this is one active region which gets split into source and drain depending on where the poly is okay so so uh so some wooden source and drain i mean the source let us let us call the first source and drain for transistor one and the next source entrance because i put s over here this is the source this is the drain then for for this part this one be the this is the because drain is shared so this is the drain then that becomes the source now source is shared so for the other thing the other part becomes a drain so that is why we connected alternate uh contacts alternate active regions we can we connected through metals to get source and drain nodes so this node is drain node and this node is source node and this node is great date okay and so how are two sources uh adjacent source entries being isolated from each other you tell me let us draw the let us draw the horizontal or the cross section view so what will we find there we will it's called wait wait let us s give me a minute so let us draw the cross section let us say this is the silicon surface let us say uh one poly second poly third poly fourth poly and so on so what is happening in this source and drain region you are getting this diffusion first diffusion second diffusion third diffusion fourth diffusion fifth diffusion then what did you do you made metals and you connected this one with this and this and through another set of metals you connected this let me just and this and you would go here um so is there a way that source and drain would get shorted amongst each other henna so look just look at the cross section it will not happen source antenna separated from each other through the depletion region okay,https://www.youtube.com/watch?v=D59Otum6EqA,"Link: https://www.youtube.com/watch?v=D59Otum6EqA
Transcript: mould also so uh when we are doing the schematic sir so we were we were much precise on the bits to be precise so when we generated it uh we got the uh yeah we did generate but i will try it again using this so when we generated it we got the uh ps and pmos and nmos of different lengths i'm like okay whenever i give the width as seven or eight it and the width of nmos has a four or five you are using widths of seven microns in your assignment yes sir oh my god uh so we really need that white transistors sir actually we didn't know how to cut the pmos and nmos into fingers so uh literally i placed one below the other vertically by generating it and uh that that's how it happens so so there is 20 femto load on the inverter yes sir and 25 20 and 7 and they were asking in 20 picoseconds sir i'm like uh even that was not possible by using ns i'm not okay that was possible but a bit hard to achieve in nsvt lp but it was happening in nlp tlp uh so uh yes so what was your question uh one second sir actually i forgot my question uh okay yeah i i yeah i got i i got it so uh whenever we were using the width sir we i'm like for suppose seven and four uh we we got different uh lengths of the pmos and n monster sir but uh now here if we do it directly then uh how would we mention i'm not measure the width of the pmos and nmrs because we are just running the poly over the active regions so over there width was predefined in the schematic and then we went to the layout directly and we generated so over here when you're making these rectangles the active rectangles you make this as width c and you make this as bit pen okay so we are supposed to measure that with a scale and that's it right sir yeah how else would you ensure the accuracy okay sir part would be the this that we had to basically ensure the length part would be when we are making when without the pieces the length part will have to be the channel length plus these are poly to contact and then that length length the length which you use 60 nanometer or 65 nanometer or 80 nanometer this is l the width of the poly yeah and then i have to for the minimum drc i will take that po po to co and that so that will issue the minimum area yes minimum area would also have this minimum active to od to n well spacing and so many see all these will lead to rules me yes sir yeah yeah so actually this it's the first load so we're not aware of all these rules so that's why maybe so that is why i'm covering this in the class don't worry don't worry you're not i know you've not done this earlier okay so sir i had one doubt so suppose for example like earlier we were seeing the like nand structure right so for example you made a shared like shared basically some area was shared right and to me uh for example what i'm looking at is that what area capacitance is basically getting transferred to the output so i'm only focusing on that right so for example if i say i've only considered an nmos a for example and uh for example right we have a poly right generally we draw one poly and then we have a one source string suppose we kind of like uh to reduce that area maybe to like if we have a for example uh like me uh sort of divide the poly sort of and like make a like a like some kind of structure delica so that we have a like brain in the common and then we are connecting source with metal one and then we are connecting to so for example to the what exactly the fact that i'm looking at here like so the i'm only looking at the diffusion capacitance area see only the thing i'm looking at diffusion should reduce and then basically whatever appears at the load that would be my driving factor only yeah so yeah let me take you to that this is actually raghav what you're asking is if i try to answer vaishnav's question that okay i have seven microns of cmos and five microns of pen mask and i have to draw them how do i draw them so avid possibly what you guys are doing is you are saying that okay i will make one big pmos over here i will make one big n moss over here and i will make a poly between them and this is what how my thing would look like yeah whatever be the width you are this is five microns and i'm done with my inverter but that is not how that is not how library cell layouts are made come to think of it i tell you you have to make a wall we are going back to the construction analogy i want you to make a brick wall and then i say that okay some bricks are uh this tall other some other brick is this tall another brick is this tall and then there is a brick which is this wide but that tall and so on so will you be able to make a good wall no sir no yeah what is done is we say that okay nothing doing nothing of this or doing all the cells that you have to make whether it is an inverter whether it is a nand gate whether it is a nor gate or an aoi or whatever cells you are making we will use a standard fixed height now what you will what you can change is that if there is a small cell you will use only this much width but if it's a big cell you will use much larger width using the same area but the height is fixed now what happens now you can actually place these tiles one over another and you can make a big wall am i right are you able to see this yes sir so but i have one thing to ask so here as when i'm when i'm drawing the layout the height is not even in my control so height is fixed now as of now i am telling you you will have to fix the height otherwise how will you go about making this wall later but right now with the inverter we are having okay because we are having two cells only so that's why it is because you did not even think you have to hide constraints if i tell you you have to constrain the height what will you do so but the tight parameter i couldn't see that it was anywhere mentioned in the like it is not mentioned but i am telling you now so somewhere we can change the height you are seeing that so let me say let me ask you if i have to draw the seven micron or the p mass in a height of one micron what will you do sir actually i'm not able to get that height and said that what exactly is meaning by this height than one micron are you meaning that the thickness of the gate oxide no no no i am saying this vertical extent should be less than one micron but my effective female should be seven microns wide i mean so this extension is itself the width right so i mean sorry i can't break place one by one each other in vertical one micro one micro one micro seven times and connect them so what i can do is i will say that so now let me go to so this is this is how the layout view would look okay let's say that uh we will see it's not a layout it takes a lot of time i have to make so many rectangles so there's a different representation of layouts which is called as stick diagrams so you will find lots of details on stick diagrams on your west a also okay so what do we do we say that okay there is one p mass uh so each so this this this horizontal line represents what we call as uh active region of let us say maximum one one micron width can we say this can we say this that this horizontal line represents active region active this this kind of a rectangle which is one micron wide can i make this assumption so you're taking the bit to be one micron right yeah but i'm showing it representing it only as one line i'm not making it into a rectangle over here i made this rectangle to represent the active region right where i'm saying i'm just using a line i'm just using a stick can i do that okay so you're not representing the length basically of channel i'm i'm just representing the width the width of the active region i'm not even talking about polyethylene i am not using rectangles i am just using sticks that is why it is called a stick diagram similarly i use sticks for the poly also so let me say that this represents poly this rectangle the rectangle that we have made over here that is represented by one stick over here vertical stick red one in color can i say this yes let me say contacts i am representing by such process can i say this is it yes yes now if i have to make a pmos which is 7 microns wide what do i do i say that okay i have just one micron width available to me to make a seven micron device i will put seven p mosses in parallel and what does parallel mean parallel means that i will have to short we will short all the drains together and not all the planes so i will now short let us say ah sorry and this and i will short the other like this black one is also metal i'll just use vdd for black and or what else do i need to shot i need to also short the police w gate connector are you able to see this so it's a bit confusing sir i mean uh like one is black and what what what why why can't be a single one i'm not able to get no no i just use the black one because it was available ready there i can make it do don't worry let me make it blue i mean it's a vine why not connecting all the eight contacts with a single like metal kind of running like you're missing two sets right okay you tell me you should have the answer for this we are connecting the drains together and source together right sir in this yeah if i connect all eight of them together then all the sources will be shorted yes yeah okay okay so what do i need to do to make two devices in parallel i need to short their gates and the source and the drains there are three nodes that i need to short am i right yes sir that is what i am doing one two and three so now whatever device size whether you want to make seven microns or ten microns or whatever can you make it within the height of let us say a total height of one point yeah five microns or something let us say whatever can you make it yes so this process is called as splitting into fingers sir yes so using this parallel dividing it into fingers won't this increase the area uh yes but what were you constrained about you have to build a wall yes yes sir actually i was i tried a similar thing i was able to make the specification in smaller bits but then i thought of area then i skipped this idea you have to do it like this you have to fix the height so how do you fix the height which we hide boldly or how do i arrive at a height how much high do i need for these cells version you have a question your hand is raised sorry sir uh okay so how do we raise how do we fix the height so this height i'm not able to visualize it so for example this width itself the height we are still talking about the width itself no see how it is okay let us look at it like this let me visualize it because i'm not able to get what exactly i mean my height height by number of uh pmos or nmos we want so that we can fix the height of uh each pmos smaller so let us go back to this layout i want to find the height of this this cell how would i calculate it i will say there is active to nvel od to envelope spacing plus let us say this is wp wp plus od to any then plus od to the n by 2 od yeah right plus width of n mass yeah and then and then extension of poly and then if i would make up if i have to consider that i have to make walls then this cell would would come above another cell are you are you able to see this so this this hole is a one cell this whole nand gate yeah this would be one cell there would be another cell that would come beneath it so i have to ensure this poly to poly spacing is also taken care of okay okay so i will do po2po by two why why buy two the minimum spacing is we have to ensure right yeah because if i leave half drc here half drc in the other cell overall full drc will be met yeah so the other pos of the another cell you're talking about now in excel okay okay so what what has happened now now this is what is my height so wound the p tap and that uh via that that also come into picture here because in layout very smart so it's taking me further ahead in the session great so now look at it like this why do we need peter and end taps yeah yeah that that was not clear even yesterday i asked in the office also so i mean because because it was very we have uh actually in the virtual layout like the gui we are taking we are calling it as a vr but i don't i was able to relate it why we're calling it vr i mean it doesn't appears to me like we are creating some vr or that no no it's not about vr my question is why do we need n-tap and p-tap so i see motherhood if you have raised your hands mother you have a question yes sir i have questions yeah so can you show [Music] this is one entire drain region for different this is one active region which gets split into source and drain depending on where the poly is okay so so uh so some wooden source and drain i mean the source let us let us call the first source and drain for transistor one and the next source entrance because i put s over here this is the source this is the drain then for for this part this one be the this is the because drain is shared so this is the drain then that becomes the source now source is shared so for the other thing the other part becomes a drain so that is why we connected alternate uh contacts alternate active regions we can we connected through metals to get source and drain nodes so this node is drain node and this node is source node and this node is great date okay and so how are two sources uh adjacent source entries being isolated from each other you tell me let us draw the let us draw the horizontal or the cross section view so what will we find there we will it's called wait wait let us s give me a minute so let us draw the cross section let us say this is the silicon surface let us say uh one poly second poly third poly fourth poly and so on so what is happening in this source and drain region you are getting this diffusion first diffusion second diffusion third diffusion fourth diffusion fifth diffusion then what did you do you made metals and you connected this one with this and this and through another set of metals you connected this let me just and this and you would go here um so is there a way that source and drain would get shorted amongst each other henna so look just look at the cross section it will not happen source antenna separated from each other through the depletion region okay"
3Dg814jyk_o,how did we make that decision that from where i'm going to tap the vdd and from where i'm going to tap down i have not concluded that yet have we concluded that question yet you've not even answered my question yet so we'll come to that we will come to that in fact you should be able to tell me by after the as we progress what should be i said that and uh that p type is because we want the bodies of all the nmos to connect to ground and the and the n12 m1 bi is for nvel should be connected to vdd so we are tapping that yeah you've heard about latch up any one of you yes we talked about latch up in one of the earlier classes also what is latch up there is a internal bjt that gets on yeah because there is this pn region which is there i know so latch up can happen and what did we say sir so can you elaborate on this latch up i'm not able to get it uh so latch up though uh already one of the earlier courses even i think uh any course on silicon technology would have covered on laptop now so i will look into it yeah so what happens is there is this you're talking about an inverter let us say an inverter only one of them is in the pivot and the other is in the n so what is this region suppose let us say this is n well this is n mos so what is this region this is p this is n this is n this is n this is p this is p are you able to see this yes sir so what happens is if you will so any west day has it rabi has it all those books have it so what happens is that uh this npn and pnp kind of uh bjt configurations get built so we can we kind of end up making a circuit where if there is some value of resistance in one place then this circuit would go into a huge current flow situation everything will completely burn out it must say it can be an egg bnpf so the only way to avoid that is that you have to reduce these resistances what happens when i reduce the resistance suppose i have to sink current i through this if i reduce the resistance what happens the voltage that appears and the base and emitter of across the vbe for this particular bjt will reduce similarly if i reduce this resistance the vbe for this one would reduce so i would be able to ensure that none of the transistors is on but if this resistance goes high what happens for the same current this vbe will go high and the transistors will turn on and once these parasitic bjp is turned on there is huge flow of current which is called as latch up it's kind of making a latch it is a positive feedback loop that comes into picture that is why the term latch so the substrate kind of gets latched up and it completely burns out so so this current is flowing within the substrate right because the clutch-up is happening within that substrate yeah so you tell me when we said that uh we have a transistor switching happening so some charges would flow now yes sir some charges would flow into the body and form the body yeah different bodies might be connected all the different end builds of that people yeah so that flow of charge is happening through the body so there is some current that is flowing even if that current is small some current is flowing is it not yes sir but then what is this all about the resistance so but this resistance is basically what this character is characterizes which part is characterizing this resistance the resistance of the body the substrate region okay so but that would be controlled by the doping we have what kind of dopamine doping yes and also suppose i say that okay over here i put a n plus and i put vdd over here so this resistance was from vdd to this n now vdd is available right here so the resistance is less suppose this entire latch up is based on our assumption that there is a transistor being formed but yeah that this doesn't feel like a very good transistor because in because in a transistor the base region is very very thin yes but here yeah always we thought that this would not cause a problem but it causes problems even with very low gain even if the gain is 1.1 it is again is it not it will not act very fast it will take one second to respond but within one second there will be latch up and what happens your device will burn out are you able to see this so so with this p tap and this m1 and w we are creating this n plus regions or that regions and that basically helps us in preventing the latch up there these are called substrate connections and they have to be given at a at a distance or at a maximum spacing as specified by the technology people so spacing which spacing you're talking about here the spacing between uh two p taps or two end tabs so technology people tell that every 30 microns you have to have place a p tap otherwise there can be latch up okay okay right okay david you said uh sorry in earlier lectures you told that uh substrate coupling extraction uh will be not doing in this course so the thing is that uh uh we won't be taking care of issues like latch up but when i was making the way we're not taking care of substrate coupling extraction but did i also say we will not take care of flatup oh no sir so that is a reduction you are making i did not say that lancep is something every designer has to take care of come whatever may so because i observed that when i was putting in tap for pmos and not enclosing with the envelope it was showing something lup yeah i thought that would do something strange for you yes so it will not even do lvs screen if you do not put speed apps and taps it will give you stamping error so the the the system will not even let you proceed if you do not put these uh taps there okay okay whenever we create the pin we would get a bigger name of our g ground we'll get that as bigger one uh what i'm saying what what when i using the word tap i am meaning substrate connections okay okay don't confuse it with contacts contacts are something else so for the pmos the envel mmo was the tap right for the p mass the n bill m1 yeah was the tab right no tap is made separately for example in an anvil when the pmos is made in an anvil you will make an n plus region so i'm talking with the layout that we are making for the to connect the nmos we are using the p tab right but for that vdd for the pmos we are using a m1 envelope via and that is basically maybe doing the kind of substrate connection so that's my asking so that would be a considered as a p tab sorry the tab for the pmos no don't uh so avi if you're using t cells the tab will come automatically okay you will have you have a a p cell for tap okay otherwise if you're making layouts like this so that your layouts are denser they are closer to what you wanted in the schematic and so on then you will have to make a tab separately see are we in this particular layout what did i not show i did not show the uh i did not so tap is not vr tap is something else that is what let us let me complete so what i what what i am not showing is another layer which is over here for the n mass it is called as uh and it is called as n plus and for the p mass we have another layer which is called as p plus have you seen that layer in your layout yes sir yes sir so i have not shown that layer to you of yourself yes hello so what you how you make a tap is if you have to make a substrate connection for the evil then instead of n plus you will make a p plus region and in that you will only make an active and you will connect that actors with ground so now what happens now you what have you done you made this as n plus what not n plus you made this as p plus yes sir and this is p plus so what is happening there is a p well and in this you have made a p plus region so between them there is no d there is no uh depletion region per se oh between the p l and p plus there is simple flow of current that can happen there is no depletion region which will ever come into picture it's not a junction so actually in the layout there was a tutorial so in the tutorial we were said that the n plus and the p plus there or only kind of shows us that what kind of doping has to go there but they are not actually in the layer they are not going to the fabrication they are not being processed yeah yeah so but so i have made active and only have shown the active to be there i have not shown the design related to the p plus layer okay so the p plus layer here is basically telling us that the active will be of the p type right yes okay yeah so so this was the contact actually was that we had to basically uh instantiate using a create via option only ptap in the virtuoso but for the above for the pmos we for the same kind of to do that we had to use a m1 and po m1 no sir m1 po sorry uh it was m1 invel m1 and value because what you need to do there is you need to in the n well you need to create an n plus active region and then n plus to n well there is a direct flow of charge there is no junction there just sir so but this is not technically a vr right no this is not via okay yeah there's the option option it was coming in the vr so okay yes it got it option was showing via actually whatever it was okay so it is not a vr if you in an interview you say via they will say you don't know anything about vlsi so why is that it does not go to fabrication i mean for providing a condition to substrate we need a we need this n plus or p plus yeah yeah so this is information at the time of so you will not see an artifact of nps layer on silicon can you you made this let us say you made this n plus or p plus layer over here would you see anything like in this in this cross section view do you see anywhere where the n plus is ending and p plus is starting can you see an artifact on silicon not in this diagram but it should be like this in any diagram you will not see that n plus mask is required therefore you need to make this but otherwise after that mask nothing else only active region is what is get what will get doped other part is field oxide there will be no impact on it so the active region is what will you will see on silicon and the mask for the n plus and p plus is much larger than that active region active region gets the doping so this is real dopings that are going on silicon yeah they are dupings but you cannot see the artifact of n plus layer the layer that you made over here this will not appear on silicon this layer will not appear on silicon it will only appear as that the the doping of the active enclosed within the send plus layer is n and type okay so that this this particular region has a higher doping than yes that the doping over here is n type and the doping on the p plus region is p type that is the only thing you can deduce but you will not be able to see an artifact of this layer on silica okay so and each one of these each one of each one of these is also connected to the vcc or ground whichever doping is yes so we were coming to the,https://www.youtube.com/watch?v=3Dg814jyk_o,"Link: https://www.youtube.com/watch?v=3Dg814jyk_o
Transcript: how did we make that decision that from where i'm going to tap the vdd and from where i'm going to tap down i have not concluded that yet have we concluded that question yet you've not even answered my question yet so we'll come to that we will come to that in fact you should be able to tell me by after the as we progress what should be i said that and uh that p type is because we want the bodies of all the nmos to connect to ground and the and the n12 m1 bi is for nvel should be connected to vdd so we are tapping that yeah you've heard about latch up any one of you yes we talked about latch up in one of the earlier classes also what is latch up there is a internal bjt that gets on yeah because there is this pn region which is there i know so latch up can happen and what did we say sir so can you elaborate on this latch up i'm not able to get it uh so latch up though uh already one of the earlier courses even i think uh any course on silicon technology would have covered on laptop now so i will look into it yeah so what happens is there is this you're talking about an inverter let us say an inverter only one of them is in the pivot and the other is in the n so what is this region suppose let us say this is n well this is n mos so what is this region this is p this is n this is n this is n this is p this is p are you able to see this yes sir so what happens is if you will so any west day has it rabi has it all those books have it so what happens is that uh this npn and pnp kind of uh bjt configurations get built so we can we kind of end up making a circuit where if there is some value of resistance in one place then this circuit would go into a huge current flow situation everything will completely burn out it must say it can be an egg bnpf so the only way to avoid that is that you have to reduce these resistances what happens when i reduce the resistance suppose i have to sink current i through this if i reduce the resistance what happens the voltage that appears and the base and emitter of across the vbe for this particular bjt will reduce similarly if i reduce this resistance the vbe for this one would reduce so i would be able to ensure that none of the transistors is on but if this resistance goes high what happens for the same current this vbe will go high and the transistors will turn on and once these parasitic bjp is turned on there is huge flow of current which is called as latch up it's kind of making a latch it is a positive feedback loop that comes into picture that is why the term latch so the substrate kind of gets latched up and it completely burns out so so this current is flowing within the substrate right because the clutch-up is happening within that substrate yeah so you tell me when we said that uh we have a transistor switching happening so some charges would flow now yes sir some charges would flow into the body and form the body yeah different bodies might be connected all the different end builds of that people yeah so that flow of charge is happening through the body so there is some current that is flowing even if that current is small some current is flowing is it not yes sir but then what is this all about the resistance so but this resistance is basically what this character is characterizes which part is characterizing this resistance the resistance of the body the substrate region okay so but that would be controlled by the doping we have what kind of dopamine doping yes and also suppose i say that okay over here i put a n plus and i put vdd over here so this resistance was from vdd to this n now vdd is available right here so the resistance is less suppose this entire latch up is based on our assumption that there is a transistor being formed but yeah that this doesn't feel like a very good transistor because in because in a transistor the base region is very very thin yes but here yeah always we thought that this would not cause a problem but it causes problems even with very low gain even if the gain is 1.1 it is again is it not it will not act very fast it will take one second to respond but within one second there will be latch up and what happens your device will burn out are you able to see this so so with this p tap and this m1 and w we are creating this n plus regions or that regions and that basically helps us in preventing the latch up there these are called substrate connections and they have to be given at a at a distance or at a maximum spacing as specified by the technology people so spacing which spacing you're talking about here the spacing between uh two p taps or two end tabs so technology people tell that every 30 microns you have to have place a p tap otherwise there can be latch up okay okay right okay david you said uh sorry in earlier lectures you told that uh substrate coupling extraction uh will be not doing in this course so the thing is that uh uh we won't be taking care of issues like latch up but when i was making the way we're not taking care of substrate coupling extraction but did i also say we will not take care of flatup oh no sir so that is a reduction you are making i did not say that lancep is something every designer has to take care of come whatever may so because i observed that when i was putting in tap for pmos and not enclosing with the envelope it was showing something lup yeah i thought that would do something strange for you yes so it will not even do lvs screen if you do not put speed apps and taps it will give you stamping error so the the the system will not even let you proceed if you do not put these uh taps there okay okay whenever we create the pin we would get a bigger name of our g ground we'll get that as bigger one uh what i'm saying what what when i using the word tap i am meaning substrate connections okay okay don't confuse it with contacts contacts are something else so for the pmos the envel mmo was the tap right for the p mass the n bill m1 yeah was the tab right no tap is made separately for example in an anvil when the pmos is made in an anvil you will make an n plus region so i'm talking with the layout that we are making for the to connect the nmos we are using the p tab right but for that vdd for the pmos we are using a m1 envelope via and that is basically maybe doing the kind of substrate connection so that's my asking so that would be a considered as a p tab sorry the tab for the pmos no don't uh so avi if you're using t cells the tab will come automatically okay you will have you have a a p cell for tap okay otherwise if you're making layouts like this so that your layouts are denser they are closer to what you wanted in the schematic and so on then you will have to make a tab separately see are we in this particular layout what did i not show i did not show the uh i did not so tap is not vr tap is something else that is what let us let me complete so what i what what i am not showing is another layer which is over here for the n mass it is called as uh and it is called as n plus and for the p mass we have another layer which is called as p plus have you seen that layer in your layout yes sir yes sir so i have not shown that layer to you of yourself yes hello so what you how you make a tap is if you have to make a substrate connection for the evil then instead of n plus you will make a p plus region and in that you will only make an active and you will connect that actors with ground so now what happens now you what have you done you made this as n plus what not n plus you made this as p plus yes sir and this is p plus so what is happening there is a p well and in this you have made a p plus region so between them there is no d there is no uh depletion region per se oh between the p l and p plus there is simple flow of current that can happen there is no depletion region which will ever come into picture it's not a junction so actually in the layout there was a tutorial so in the tutorial we were said that the n plus and the p plus there or only kind of shows us that what kind of doping has to go there but they are not actually in the layer they are not going to the fabrication they are not being processed yeah yeah so but so i have made active and only have shown the active to be there i have not shown the design related to the p plus layer okay so the p plus layer here is basically telling us that the active will be of the p type right yes okay yeah so so this was the contact actually was that we had to basically uh instantiate using a create via option only ptap in the virtuoso but for the above for the pmos we for the same kind of to do that we had to use a m1 and po m1 no sir m1 po sorry uh it was m1 invel m1 and value because what you need to do there is you need to in the n well you need to create an n plus active region and then n plus to n well there is a direct flow of charge there is no junction there just sir so but this is not technically a vr right no this is not via okay yeah there's the option option it was coming in the vr so okay yes it got it option was showing via actually whatever it was okay so it is not a vr if you in an interview you say via they will say you don't know anything about vlsi so why is that it does not go to fabrication i mean for providing a condition to substrate we need a we need this n plus or p plus yeah yeah so this is information at the time of so you will not see an artifact of nps layer on silicon can you you made this let us say you made this n plus or p plus layer over here would you see anything like in this in this cross section view do you see anywhere where the n plus is ending and p plus is starting can you see an artifact on silicon not in this diagram but it should be like this in any diagram you will not see that n plus mask is required therefore you need to make this but otherwise after that mask nothing else only active region is what is get what will get doped other part is field oxide there will be no impact on it so the active region is what will you will see on silicon and the mask for the n plus and p plus is much larger than that active region active region gets the doping so this is real dopings that are going on silicon yeah they are dupings but you cannot see the artifact of n plus layer the layer that you made over here this will not appear on silicon this layer will not appear on silicon it will only appear as that the the doping of the active enclosed within the send plus layer is n and type okay so that this this particular region has a higher doping than yes that the doping over here is n type and the doping on the p plus region is p type that is the only thing you can deduce but you will not be able to see an artifact of this layer on silica okay so and each one of these each one of each one of these is also connected to the vcc or ground whichever doping is yes so we were coming to the"
Hyej-EEgy5o,when i was making the inverter so i what i did to reduce the height so i i did that i put the both the nmos and pimas side by side and so after that i made the connections and i i had some space for nba sorry the tabs also so i also made those steps inside that periphery only so after that actually sir i had to make the pp and np layer parallel to each other there but vertically vertically parallel sim normally what we do is we we make it horizontally parallel so who who gave okay so i will tell you what what actually happens so let us look at how the template of the of the least cell is made you say that i will not make any taps in the in my every cell because the drc says that there should be a tap every 30 microns so if i make a tap in every cell then i am unnecessarily over compensating or overusing the drc the drc requires once every 30 microns if i'm making a tap continuously then i'm wasting lots of area so i simply put a metal one and i say this will carry ground on the top i put a metal one and i say this will carry vdd okay and this vdd thickness or ground thickness you can say is 2x 2x x means minimum wire width okay and then what you say is half of this thickness will go on the other side from will come from the other cell and half i will keep in mind so you say that okay this is how my cell height would look like okay then what you also do is you make an envel you make it such that so now you make an envel this is your template now what you will do is you will make devices over here and you will make those poly poly regions stuff like that okay so what are we talking about over here if i had to make a much bigger device i would simply break it into multiple fingers like i have made the nmos in three fingers and pmos and two fingers over here nmos and two fingers and the femors and one finger over here so how do i decide this height any idea sir uh do we know that i'm like previously do we know what are the sizes of pmos and nmos are exactly so that um no you do not know how will you decide this height so actually i asked this the the height of the standard salary decided based upon the that that so are all of you attending office hours also yes sir but this it has not got to this advance earlier we were having tools related tools were not working so till now that only yes okay so see what happens is uh when we make this wall you remember the wall of standard cells that we were talking about this wall so what do i need to do i need to connect a flip flop from here with a you know a flip flop from here with a buffer over there i need to connect something you know some input of this flip flop with the adjacent cell some input of this adjacent cell with an adjacent cell some input from here would come from here and so on and that is how your connectivity would be made all these these walls on these these regions that you're talking about are basically your and gates nand gates buffers and so on so based on what your circuit is you will need to make connections every here they are everywhere yes sir so these connections uh cannot be made in metal one why cannot we made a metal one because metal one we have already blocked over here like this i know so metal one you cannot route over and you know you cannot with metal one you cannot cross from one one layer to another one layer matlab knee one row to another because metal one is blocked so what do you do you will use metal two metal three another higher level of metals to connect between different rows of these standard cells are you with me till now so i mean so different rows of standard cell okay okay okay different standard cells right right yeah yeah these are three i have shown three rows over here okay yeah and so one thing's just here only in the middle one that you have drawn common in that only you're saying that in that metal one only uh 30 micron spacing we have to put a ptappy tab right you're seeing that yeah we will come to that oh yes we will come to that okay so what are we saying so we will use metal two metal c and other metals to do this routing between these cells am i right so how many how many such cells would you do you think they will be in any design let us say an intel processor how many such cells would be there do you know millions of them millions of them you know in the total chip there would be millions of such cells in any macro small processor there would still be uh thousands if not lacks of them okay so you have to connect cells across thousands of cells and so many cells so you will need lots of wires to run around huh yes sir so we say that this height should be such that sufficient number of wires can run over these cells okay so the height is determined by how many wires do you want to run so there could be a 12 track library what does 12 track means that 12 wires of metal two can run over the cell now let us consider let us say in 65 nanometer wire width minimum wire width is what is your minimum drc for wire width it is 0.9 0.2 nanometers and minimum wire spacing is again 90 nanometer almost i know so if i have to make two wires or if i have to similarly make multiple wires what would happen to make one wire i have to give a spacing of 180 nanometer okay this is also called pitch right this is pitch so for one track i need 180 nanometer height i have to make 12 tracks what would be the height 180 to 12 so 2.16 microns are you able to see this for a 12 track library the height from this point to this point is 2.16 and every structure that you make inside this this height should leave half drc from this this boundary which is called as pr boundary so at this point i'm not able to get this pr boundary point what exactly mean by that this is the perimeter boundary you may say then adjacent cell will come and abut at the perimeter boundary when we were calculating the height over here we said half drc of poly to polyspacing has to be kept yes because the adjacent cell will also leave half drc i will leave half drc so all the structures should have half drc from the pr boundary if i ensure that in every cell my entire system will be drc clean so this half drc is between the poly and the metal wire that is running right no pr boundary okay so i mean can you show in this only where this metal one is coming right and that okay so in this metal one would be coming would be coming let us say here half above this boundary half below this boundary okay and okay so since this metal is also like shade between different cells this metal ground yeah viridian ground can be shared so sir here i am having two kind of dishes one is that i have to maintain with the poly of one cells and other cell and also this wire thickness right there will be some that yeah thickness that is not a drc that is how you placed it okay but so there would be some minimum uh thickness of the wire right that but like you have to maintain okay so but there is no like drc between the metal and the poly this no there are different layers okay metal one is different layer poly is in different layer okay and that we saw in the fabrication steps also now yeah yeah okay so you link it with all the previous lectures and so just with just a trivia so this metal one is interconnected with this poly via tungsten right because that is the base no this is vdd this vdd will not be connected to the poly vdd will be connected to source and drain yeah yeah okay i know so there is there is this uh metal one that is running down there and that is how this this region will get its ground there is this metal one running up here that is how this region will get their vdd okay but this metal one and that connection is between uh tungsten right yeah this yellows are timestamps yeah yeah okay they are contacts contacts are tungsten like metal one is running above the active region so there would be some kind of vertical aggression also now that is also that we don't call up the year no okay that is true whatever you want to make a connection you have to make a contact otherwise it just runs through runs above it it's like a flyover when you want to have a connection you make a pillar okay there's this span from below which many things can run that pillar itself is a contact right right yeah yeah oh excuse me sir yes can you please go to the previous diagram on the right hand side yeah so what are these these by so we were talking about these bodies that are in between metal metal this ground and vdd so yeah we were talking about some constraint on these bias minimum spacing i didn't get that one so we were talking about how many wires can i run from above one cell so these wires are also on metal one here now they will metal two so the metal one is only for vdd in gram by nothing we really drowned all the local connections see all these local connections we made in metal one only now all these local connections are also in metal one we made this local connections in metal one only yes sir so this is not just vdd on ground all the local connections are also metal one so metal one is blocked metal one is blocked if you want to route anything around here you have to use metal two so why is exactly that i'm sorry can you do it without shorting no that is why it is blocked accident yes sir so you need to go by the flyover okay so this metallic one is above this all these cells like i'm quite not able to visualize this in 3d what do you mean by above all these cells like these cells are in a horizontal plane then we have above them we have metal one and above that we have metal two yeah so look at this so we make contacts vertical contacts yes this is the sidewall this is the cross section view yes so then there will be a metal one connecting these ones and there will be a different metal one connecting these ones okay okay okay what about the minimum spacing that you have to ensure the rc so you always have to ensure now that you cannot do away with it and we are talking about that i'm sorry so we are talking about these spacings in metal yes because metal two are the number of wires that you can carry above the cell which are passed through so if if there are 12 wires that have to cross each wire has to be at least minimum width and there should be a minimum spacing between them now yes so yeah so here we are saying we it is 12 tracks like we can have 12 wires so like in between metal one ground and metal when vdd we have this distance in which we look but so why is it why we are calling it as height what do you want to call it the distance between two metals okay call it distance between two metals how do what difference does it make see we're talking about this wall hello we're talking about this wall so i said that i will want to call this the height of one brick as height you want to call it distance between two metals you call it two decisions your choice so actually i want to use lesser words okay okay so this high technology was quite confusing for me to visualize the uh these things in 3d that is why i was asking so this is heightened 2d cells 2d center okay okay sir yes sir uh yes sir so there was a metal running above the stand i'm like above one cell and below one cell right sir so uh for suppose we are giving uh pdd for the above one and the ground for the below one so the the cell adjacent to this i am not the cell below this uh the same cell would be repeating right sir so the cell below this and like how how is it using vdd sir i'm like because the pmos of of that is even oh no if you will not use what did we do over here what did we do over here we said source drain and then for the other cell it is drain and source similarly for one cell you will say let us say this is running vdd we know that the other one is running ground then you know this is running vdd and this is running ground what is the big deal some cells are vertically placed other cells are flipping but flip okay yeah uh and one more doubt so this i'm like uh this small dot so uh sir as we are doing only for it it's for one cell right sir so uh the uh this um like uh the software which we use it uh automatically knows that we have to flip this cell uh i'm like uh because we don't look for uh one right so okay okay thank you so the tool will do it the tool will do it don't worry thank you okay so now taps ourselves we talked about the height of these cells and everything what about taps excuse me sir one more thing is that this height is composed of bit of bmos and inverse no no this height is coming from how many tracks you are running through it this height if i have four tracks the height will be four w plus four s okay okay so this height is also in the middle so is cell is defined by number of metal height of this two tracks you can run above it now it's a two dimensional height right so this is the breakdown that we talked about this brick wall that we talked about that is also regarding metal ones or is it regarding standard cells that is standard cell scale bricks so each each standard cell you will consider as a brick in that wall and so the height we are talking about in this diagram and height that would probably be that they are different that it's not letting me zoom so you see this i had made so this is the height this is the height of one stand itself so the height of until here is three h because you put three bricks one over another yes sir and these bricks are off pmos or in most work there will be one simple these bricks have p masses and n masses both there is a p mass here and there's an n mos here okay so anna yes sir and why is the side then uh is only constrained by the number of wires that we can put in between that is that is how uh that is the uh what do you say that is how it is defined now if you may want to make a wider transistor you make it in fingers okay so it's okay so instead of increasing the height i just cascade raise the number of fingers you increase the width you see that is why different cells have different width in this brick wall okay they have the same height though,https://www.youtube.com/watch?v=Hyej-EEgy5o,"Link: https://www.youtube.com/watch?v=Hyej-EEgy5o
Transcript: when i was making the inverter so i what i did to reduce the height so i i did that i put the both the nmos and pimas side by side and so after that i made the connections and i i had some space for nba sorry the tabs also so i also made those steps inside that periphery only so after that actually sir i had to make the pp and np layer parallel to each other there but vertically vertically parallel sim normally what we do is we we make it horizontally parallel so who who gave okay so i will tell you what what actually happens so let us look at how the template of the of the least cell is made you say that i will not make any taps in the in my every cell because the drc says that there should be a tap every 30 microns so if i make a tap in every cell then i am unnecessarily over compensating or overusing the drc the drc requires once every 30 microns if i'm making a tap continuously then i'm wasting lots of area so i simply put a metal one and i say this will carry ground on the top i put a metal one and i say this will carry vdd okay and this vdd thickness or ground thickness you can say is 2x 2x x means minimum wire width okay and then what you say is half of this thickness will go on the other side from will come from the other cell and half i will keep in mind so you say that okay this is how my cell height would look like okay then what you also do is you make an envel you make it such that so now you make an envel this is your template now what you will do is you will make devices over here and you will make those poly poly regions stuff like that okay so what are we talking about over here if i had to make a much bigger device i would simply break it into multiple fingers like i have made the nmos in three fingers and pmos and two fingers over here nmos and two fingers and the femors and one finger over here so how do i decide this height any idea sir uh do we know that i'm like previously do we know what are the sizes of pmos and nmos are exactly so that um no you do not know how will you decide this height so actually i asked this the the height of the standard salary decided based upon the that that so are all of you attending office hours also yes sir but this it has not got to this advance earlier we were having tools related tools were not working so till now that only yes okay so see what happens is uh when we make this wall you remember the wall of standard cells that we were talking about this wall so what do i need to do i need to connect a flip flop from here with a you know a flip flop from here with a buffer over there i need to connect something you know some input of this flip flop with the adjacent cell some input of this adjacent cell with an adjacent cell some input from here would come from here and so on and that is how your connectivity would be made all these these walls on these these regions that you're talking about are basically your and gates nand gates buffers and so on so based on what your circuit is you will need to make connections every here they are everywhere yes sir so these connections uh cannot be made in metal one why cannot we made a metal one because metal one we have already blocked over here like this i know so metal one you cannot route over and you know you cannot with metal one you cannot cross from one one layer to another one layer matlab knee one row to another because metal one is blocked so what do you do you will use metal two metal three another higher level of metals to connect between different rows of these standard cells are you with me till now so i mean so different rows of standard cell okay okay okay different standard cells right right yeah yeah these are three i have shown three rows over here okay yeah and so one thing's just here only in the middle one that you have drawn common in that only you're saying that in that metal one only uh 30 micron spacing we have to put a ptappy tab right you're seeing that yeah we will come to that oh yes we will come to that okay so what are we saying so we will use metal two metal c and other metals to do this routing between these cells am i right so how many how many such cells would you do you think they will be in any design let us say an intel processor how many such cells would be there do you know millions of them millions of them you know in the total chip there would be millions of such cells in any macro small processor there would still be uh thousands if not lacks of them okay so you have to connect cells across thousands of cells and so many cells so you will need lots of wires to run around huh yes sir so we say that this height should be such that sufficient number of wires can run over these cells okay so the height is determined by how many wires do you want to run so there could be a 12 track library what does 12 track means that 12 wires of metal two can run over the cell now let us consider let us say in 65 nanometer wire width minimum wire width is what is your minimum drc for wire width it is 0.9 0.2 nanometers and minimum wire spacing is again 90 nanometer almost i know so if i have to make two wires or if i have to similarly make multiple wires what would happen to make one wire i have to give a spacing of 180 nanometer okay this is also called pitch right this is pitch so for one track i need 180 nanometer height i have to make 12 tracks what would be the height 180 to 12 so 2.16 microns are you able to see this for a 12 track library the height from this point to this point is 2.16 and every structure that you make inside this this height should leave half drc from this this boundary which is called as pr boundary so at this point i'm not able to get this pr boundary point what exactly mean by that this is the perimeter boundary you may say then adjacent cell will come and abut at the perimeter boundary when we were calculating the height over here we said half drc of poly to polyspacing has to be kept yes because the adjacent cell will also leave half drc i will leave half drc so all the structures should have half drc from the pr boundary if i ensure that in every cell my entire system will be drc clean so this half drc is between the poly and the metal wire that is running right no pr boundary okay so i mean can you show in this only where this metal one is coming right and that okay so in this metal one would be coming would be coming let us say here half above this boundary half below this boundary okay and okay so since this metal is also like shade between different cells this metal ground yeah viridian ground can be shared so sir here i am having two kind of dishes one is that i have to maintain with the poly of one cells and other cell and also this wire thickness right there will be some that yeah thickness that is not a drc that is how you placed it okay but so there would be some minimum uh thickness of the wire right that but like you have to maintain okay so but there is no like drc between the metal and the poly this no there are different layers okay metal one is different layer poly is in different layer okay and that we saw in the fabrication steps also now yeah yeah okay so you link it with all the previous lectures and so just with just a trivia so this metal one is interconnected with this poly via tungsten right because that is the base no this is vdd this vdd will not be connected to the poly vdd will be connected to source and drain yeah yeah okay i know so there is there is this uh metal one that is running down there and that is how this this region will get its ground there is this metal one running up here that is how this region will get their vdd okay but this metal one and that connection is between uh tungsten right yeah this yellows are timestamps yeah yeah okay they are contacts contacts are tungsten like metal one is running above the active region so there would be some kind of vertical aggression also now that is also that we don't call up the year no okay that is true whatever you want to make a connection you have to make a contact otherwise it just runs through runs above it it's like a flyover when you want to have a connection you make a pillar okay there's this span from below which many things can run that pillar itself is a contact right right yeah yeah oh excuse me sir yes can you please go to the previous diagram on the right hand side yeah so what are these these by so we were talking about these bodies that are in between metal metal this ground and vdd so yeah we were talking about some constraint on these bias minimum spacing i didn't get that one so we were talking about how many wires can i run from above one cell so these wires are also on metal one here now they will metal two so the metal one is only for vdd in gram by nothing we really drowned all the local connections see all these local connections we made in metal one only now all these local connections are also in metal one we made this local connections in metal one only yes sir so this is not just vdd on ground all the local connections are also metal one so metal one is blocked metal one is blocked if you want to route anything around here you have to use metal two so why is exactly that i'm sorry can you do it without shorting no that is why it is blocked accident yes sir so you need to go by the flyover okay so this metallic one is above this all these cells like i'm quite not able to visualize this in 3d what do you mean by above all these cells like these cells are in a horizontal plane then we have above them we have metal one and above that we have metal two yeah so look at this so we make contacts vertical contacts yes this is the sidewall this is the cross section view yes so then there will be a metal one connecting these ones and there will be a different metal one connecting these ones okay okay okay what about the minimum spacing that you have to ensure the rc so you always have to ensure now that you cannot do away with it and we are talking about that i'm sorry so we are talking about these spacings in metal yes because metal two are the number of wires that you can carry above the cell which are passed through so if if there are 12 wires that have to cross each wire has to be at least minimum width and there should be a minimum spacing between them now yes so yeah so here we are saying we it is 12 tracks like we can have 12 wires so like in between metal one ground and metal when vdd we have this distance in which we look but so why is it why we are calling it as height what do you want to call it the distance between two metals okay call it distance between two metals how do what difference does it make see we're talking about this wall hello we're talking about this wall so i said that i will want to call this the height of one brick as height you want to call it distance between two metals you call it two decisions your choice so actually i want to use lesser words okay okay so this high technology was quite confusing for me to visualize the uh these things in 3d that is why i was asking so this is heightened 2d cells 2d center okay okay sir yes sir uh yes sir so there was a metal running above the stand i'm like above one cell and below one cell right sir so uh for suppose we are giving uh pdd for the above one and the ground for the below one so the the cell adjacent to this i am not the cell below this uh the same cell would be repeating right sir so the cell below this and like how how is it using vdd sir i'm like because the pmos of of that is even oh no if you will not use what did we do over here what did we do over here we said source drain and then for the other cell it is drain and source similarly for one cell you will say let us say this is running vdd we know that the other one is running ground then you know this is running vdd and this is running ground what is the big deal some cells are vertically placed other cells are flipping but flip okay yeah uh and one more doubt so this i'm like uh this small dot so uh sir as we are doing only for it it's for one cell right sir so uh the uh this um like uh the software which we use it uh automatically knows that we have to flip this cell uh i'm like uh because we don't look for uh one right so okay okay thank you so the tool will do it the tool will do it don't worry thank you okay so now taps ourselves we talked about the height of these cells and everything what about taps excuse me sir one more thing is that this height is composed of bit of bmos and inverse no no this height is coming from how many tracks you are running through it this height if i have four tracks the height will be four w plus four s okay okay so this height is also in the middle so is cell is defined by number of metal height of this two tracks you can run above it now it's a two dimensional height right so this is the breakdown that we talked about this brick wall that we talked about that is also regarding metal ones or is it regarding standard cells that is standard cell scale bricks so each each standard cell you will consider as a brick in that wall and so the height we are talking about in this diagram and height that would probably be that they are different that it's not letting me zoom so you see this i had made so this is the height this is the height of one stand itself so the height of until here is three h because you put three bricks one over another yes sir and these bricks are off pmos or in most work there will be one simple these bricks have p masses and n masses both there is a p mass here and there's an n mos here okay so anna yes sir and why is the side then uh is only constrained by the number of wires that we can put in between that is that is how uh that is the uh what do you say that is how it is defined now if you may want to make a wider transistor you make it in fingers okay so it's okay so instead of increasing the height i just cascade raise the number of fingers you increase the width you see that is why different cells have different width in this brick wall okay they have the same height though"
g1jq_Tl89PA,oh okay sir yes sir i have a general question sir so sir uh the unlike the layout which we have made below was for uh a bar b right sir uh i'm like yes sir uh i'm like okay so sir uh my doubt is that uh so when we consider a chip or some thing sir so if uh how does that know that uh how many standard cells should i make of this kind you write an rtr no sir i have i'm like okay okay yes sir yes sir yes sir no so the schematic you will tell i want a nand gate yes that will tell sir but uh uh so like this many number of cells are present right sir so see that was why we covered that vdf pura design flow now yes sir what did we say we will write the rtl we'll simulate it we'll see the functionality is correct then we will go to the synthesis stage in that synthesis stage i will get to know how many nand gates okay so it's pre-defined you cannot forget any of the lectures till now okay okay sir however fluffy they might sound you to be sound sound to you you cannot forget any one of them they are the basis they are the foundation that is the basic understanding on which we are building all this now yes sir i i do understand my doubt is that whenever we write a rtelser so my doubt is that if all this all this is supposed to get into cheap price finally at the uh at the end of the uh end of the task it's supposed to be great and it's supposed to be written into the i'm like it's supposed to be configured on the chip so rtl which we write is uh which we write is uh i'm like uh it's before that right sir so uh so how i'm like uh even in rtl we just write a code that's it i'm like uh what i have seen which we just write a code how how is the hardware i'm like how does that decide key okay i need this many number of nand gates i need this many number of numbers but we we write only one line over there sir yeah see you write one line but there are ten gates that are introduced because of that line i'm like this step is called synthesis so if you simulate a very log and tell me that i know very log i will not pay any heat to what you have told me unless you tell me i have i know how to write verilog and i have synthesized very log into you know 100 gate designs 500 gate designs or 1 million gate designs then i will know okay how complex serialize you can write okay okay sir understood thank you sir okay otherwise very long is simple c language yes sir yes but we call it hardware description language why because we are making hardware out of that yes and that first step of converting that c english language into into something which is closer to vlsi is synthesis okay sir thank you sir certain now we the undergrads have done in eld we have done very long in led so we were focusing mainly on fpgas so we did not much very so we wrote mostly behavioral codes behavioral descriptions and we did not think that uh how many hand gates will it use our how many markets no no but elt maybe you must have seen now this many look up tables are used this much has been used you must have looked at the resources that are getting used yes so you were looking at that yes sir each resistor entry in the lookup table represents some gate you can assume that yes yes one lookup table can be converted into an equivalent combination yes exactly so you're already looking at that you just not realize that this is actually going on silicon also like this this is the first time that i am thinking about that i never thought about reducing the resource utilization to an extent i should think about and gates and power you put the where you put the for loops for loops all at once can be considered as parallelism so generate for loops or combinatorial formats whichever [Music] so if you could if you do not put for loops uh for parts which do not need to be put in parallel or do not need to be replicated you can save area it may increase time to execute a time to execute the entire instruction yes but you will save area yes sir yes that is uh yes instance at this we can save area at the instance level module level area we can say but let us say that i need an adder i just write a single line of verilog c equals to a plus b so now i have no control over how much yes now the fpga which which fbga board you are using that will define which adder is being used yes yes so what do we do in silicon uh so we will come towards the end of this course we will talk about different kinds of adders also don't worry okay so there are there are different kinds of adders some would have lesser areas some would have lesser delay some would have lesser race conditions so i'm looking for that yeah carry look at adder ripple carry adders all those things you will see will not go into too much detail because that is simple combinatorial logic you can always get it see this information you will not get in the books so my intent is i give you this kind of information in the class unfortunately out of 93 students only 35 are attending the class today so i am i am here i am here to offer and give you additional information and answer your queries but you have to be here to ask those questions so my question was where is the strap now we not made the strap here so where does the strap come where do where do we make the tap for the people and the envelope to prevent latch up sir at the end of that drc length 30 yeah so what we say is that if my this wall you know the wall that i have made if this wall is 30 microns so i will simply make uh taps at the boundary of this wall okay or usually my walls would be thousands of microns wide so what do i do i say that okay these are my rows in these i will put tabs at regular intervals you've seen pillars in flowers so those pillars come after regular intervals may so these steps you make after regular intervals so that no point this point no point has a tab which is farther than drc distance away sir yes drc so this one cell that in particular wall is basically a standard cell right no no no no i'm not i've just shown you rows now the standard cells and this would be very small ones so what is what the vertical ones the vertical ones that i have shown in this view are the tabs i should have probably used a different color let me use it actually so so this basically this different kind of for example say i take up one layer only and these different blocks they are basically one standard cells now right no a standard cell for example and this there could be a buffer here there could be a flip flop so actually it's not visible so can you move to the different side because that will be available now yes yes so there could be a buffer here there could be a flip flop here there could be an inverter here there could be a y here so there are so many cells here these dark blue ones that i made they are taps so that is what i am saying the spacing between these tabs these the spacing between these tabs is such that uh so this was a tab this was a tab so the spacing is such that no no active region can be can be there which has a sp has a distance of more than 30 micron from the closest tab so which active region sir in each of these cells there is some active now yes sir yeah yeah so each actor will have some tap within 30 microns of it okay so sir this basically the standard cell that sorry this topology basically we are showing you you're showing the standard cell draws here right yeah i am showing you a uh uh 1000 meter top level view of earth let us say yeah again as you come closer you will see that the standard cell has these active regions in it yes sir but you will see them only when you come closer there are taps and there are these cells so there are these small small cells there are boundaries but as you come closer you will be able to see even identify the cars that are parked outside the house yes sir i've seen google maps no satellite maps in google yeah yes so my question so my question is also this that for example these are standard cell rows right and for example once i have placed this standard cells in these different rows then i am doing the tapping thing yes you can do that or you can actually fixate the tabs first and then place the standard cells in there so because right when we are doing it so this was basically we are doing in placement so after placement the tapping would be done during the placement tapping taps will also be placed okay after i have placed those in the standard cell rows so but like in the layout we are doing with each kind of yeah have you made any tap have i shown any tap over here no sir i know okay because i am saying that at the system level i am taking care of it you don't bother about it at the cell level let us save area okay so basically tapping thing happens automatically by the tool itself so you will have to make a standard cell which is tap type so we'll have to make a standard fill this may tap tap functionality hogi and the tool will place those tabs at regular intervals yeah so but that standard cell i will get in the library format right so you will make that okay those libraries okay just like you're making this nand gate or something over here similarly you will make this tab cell also so so this actually is for example in this only this uh in which you have shown the tell 12 track the height one this diagram only so the tapping the 30 micron is basically the distance between the for example the active of this nmos and this tapping so for example like it happens here cells away okay the tap the substrate connection for this and mass could be 10 cells away okay and it is still fine because it meets my drc requirements okay fine but that has to happen for every active initiative for everything yeah for no active should the tab be farther than the drc distance away okay okay yeah so i have been pressured so there is still one question which is pending as of now the question is from which we started but so one row is consisting of many standard cells right one row yes one row has many standard cells in it and those standard cells uh may consist of uh uh n and die unit like a flip flop or an adder something like that yeah just one row can have uh many sub rows of nmos and pmos no you can have another nmr right here below it provided you are meeting all the drc's you can have multiple rows of n masses enough you have to meet the drc you cannot violate the height answer how are these these rows separated from each other they are not separated there they are abutting that is where you will share the metals now that is where this vdd will be shared with the cell which is flipped and put on the top that there is this vdd then gnd then vdd then gnd so the boundaries of these carry vdd and gnd and they are shared across the top row and the bottom row okay between two tabs there would be many standard cells so in that way i have to share the angle for that many number of standards and also yes and well so the template would be such that this envelope will continue from the left to the right this envel will continue from left to the right so sir that is why it is not advised to make np and pp parallel to each other vertically right yes the first question where should the the drain which which should be connected to output and which should be connected to vdd yeah animation please sorry so i was asking the same question you're asking the same question you don't have an answer yet no no still not okay debris sir actually had one question that suppose the length of the row is three times the size of the drc for minimum length from where the strap is to be kept so if it is two times the drc then you can keep at keep at two ends but if it is three times then all right in that case what is run you will put two straps uh like you will how do i will show you so if the total length is 3 3x so what you will do you will put a strap here you will put a strap here x x x in fact this can be x by 2 2x and x by 2. okay something like that between two two rows somehow we have to add just between two rows name within a row you will put it okay so what is this trap he's talking about divgy the the n plus and p plus connections for the substrate taps tabs are also called straps okay right multiple names so see we are all out to confuse you yeah we are all out to confuse you so uh it's okay don't worry ask ask if you get confused so it's important to attend the class yeah so before going to the answer of the question i also wanted to ask that till now the when you started the real question the only factor other factor i was thinking about of the diffusion capacitance right but for example in the mosfet capacitance when you're modeling it weeks out of three kind of capacitance one was that from the gate to the either source of the drain one from from the gate to the channel and one from both the diffusion capacitance so like so why we are not considering the gate to the channel capacitance or other two capacitors when we were comparing this topology with this one original one that i had made what did we say we counted the number of gate to contact capacitances we counted all the capacitances there yeah yes actually so now so one thing so we are not talked about this uh gate to the channel okay so that that is basically controlled by the specification that someone has given yeah that is that as a designer you saw that you want a 5 micron device or a 7 micron device how can at the layout state you change that requirement so sir uh as of now i can see that the as a designer the most important that i control is the active region and the contacts if i can share it i can reduce the contacts if i share it we can reduce the diffusion capacitance but only the active region i'm considering it for example that is only the thing that i'm we're focusing on like most of our time to control that okay and within this active region the diffusion capacitor is the most important that's like for focusing on that it seems to be right yeah so now tell me this is my nand gate palette two devices cooper p moses and h and so which one should be ground which one should be so this is uh since we're just making a stick diagram corresponding to this one so this is ground so i make a wire to ground over here connected to ground and this is my output my voltage sorry this is my ground because b connects to ground and this is my output now where should this metal one go should it go to this one or should it go to the boundary ones your middle one sir why sir uh because sir that's obvious right sir if we give to the leftmost connection then we won't consider this right most uh no we saw now we can connect it like this so if i take it to this one i will take the middle one and do it like this yes sir i can't do it it is not obvious it is not obvious because of that reason what you are telling me it could be obvious because of some other reason the side of my standard cell i do not want two vdd coming out why i mean from the standard seller design so i have to attach to the rail railing that will be really going up up there so i could make two connections what's the big deal so if i say that i if i say that this is my output then this will go to vdd this will go to vdd what's the big deal there is a metal running here what's the big deal of that so the sidewall capacitance would play a role over here because we need to connect uh the input to the contact that is in uh that is between the two gates okay so you're saying this is how you should make it yes sir is everyone agree in agreement with this yes sir what happened yeah can we and i also think about signal integrity because because this metal one is crossing the poly two times there and here we can also do it one time okay so what is it that you really want anyways see what are these poly this is signal a this is signal b this is out so anyway if you even if you look at the schematic over here if you look at the schematic over there you will see there is some coupling capacitance between b and out there is already something there yes why is there something you tell me because a and out there is this drain capacitance there is this contact to poly capacitance everything is already there so that will add some capacitance i'm not saying it will not have any capacitor so there is already so much capacitance out there that a and y already have right so what's the big deal if you use this as the output what happens output capacitance reduces if you were using this as the output there would be extra drain and source capacitance that you would have to bear we have 20 fentanyl you are adding more capacitance on the load then so that so addition is due to the side wall only that yes not just sidewall we also did the calculation on uh the arianna so but either you said we are taking to be like the same no we calculated that this one this one would be 140 nanometer extension this one would be 140 nanometer extension so total extension will be 280 280 nanometer into wp over here the central area would be 160 into wp we calculated this we started with the assumption but i then gave you the exact calculation that is so less okay so we are considering two thing that one after the sharing the of the active regions then we are placing it between so two to reduce that yes okay right see again in the lecture we progress i start with an assumption but then i clarified that assumption is invalid in fact when you do sharing you save area and when you save area you are also sharing source entrained uh capacitances you are saving on that also so source and twin is a diffusion one right yes yeah okay so we have the answer to the first question where we started from and we did not even open one slide today,https://www.youtube.com/watch?v=g1jq_Tl89PA,"Link: https://www.youtube.com/watch?v=g1jq_Tl89PA
Transcript: oh okay sir yes sir i have a general question sir so sir uh the unlike the layout which we have made below was for uh a bar b right sir uh i'm like yes sir uh i'm like okay so sir uh my doubt is that uh so when we consider a chip or some thing sir so if uh how does that know that uh how many standard cells should i make of this kind you write an rtr no sir i have i'm like okay okay yes sir yes sir yes sir no so the schematic you will tell i want a nand gate yes that will tell sir but uh uh so like this many number of cells are present right sir so see that was why we covered that vdf pura design flow now yes sir what did we say we will write the rtl we'll simulate it we'll see the functionality is correct then we will go to the synthesis stage in that synthesis stage i will get to know how many nand gates okay so it's pre-defined you cannot forget any of the lectures till now okay okay sir however fluffy they might sound you to be sound sound to you you cannot forget any one of them they are the basis they are the foundation that is the basic understanding on which we are building all this now yes sir i i do understand my doubt is that whenever we write a rtelser so my doubt is that if all this all this is supposed to get into cheap price finally at the uh at the end of the uh end of the task it's supposed to be great and it's supposed to be written into the i'm like it's supposed to be configured on the chip so rtl which we write is uh which we write is uh i'm like uh it's before that right sir so uh so how i'm like uh even in rtl we just write a code that's it i'm like uh what i have seen which we just write a code how how is the hardware i'm like how does that decide key okay i need this many number of nand gates i need this many number of numbers but we we write only one line over there sir yeah see you write one line but there are ten gates that are introduced because of that line i'm like this step is called synthesis so if you simulate a very log and tell me that i know very log i will not pay any heat to what you have told me unless you tell me i have i know how to write verilog and i have synthesized very log into you know 100 gate designs 500 gate designs or 1 million gate designs then i will know okay how complex serialize you can write okay okay sir understood thank you sir okay otherwise very long is simple c language yes sir yes but we call it hardware description language why because we are making hardware out of that yes and that first step of converting that c english language into into something which is closer to vlsi is synthesis okay sir thank you sir certain now we the undergrads have done in eld we have done very long in led so we were focusing mainly on fpgas so we did not much very so we wrote mostly behavioral codes behavioral descriptions and we did not think that uh how many hand gates will it use our how many markets no no but elt maybe you must have seen now this many look up tables are used this much has been used you must have looked at the resources that are getting used yes so you were looking at that yes sir each resistor entry in the lookup table represents some gate you can assume that yes yes one lookup table can be converted into an equivalent combination yes exactly so you're already looking at that you just not realize that this is actually going on silicon also like this this is the first time that i am thinking about that i never thought about reducing the resource utilization to an extent i should think about and gates and power you put the where you put the for loops for loops all at once can be considered as parallelism so generate for loops or combinatorial formats whichever [Music] so if you could if you do not put for loops uh for parts which do not need to be put in parallel or do not need to be replicated you can save area it may increase time to execute a time to execute the entire instruction yes but you will save area yes sir yes that is uh yes instance at this we can save area at the instance level module level area we can say but let us say that i need an adder i just write a single line of verilog c equals to a plus b so now i have no control over how much yes now the fpga which which fbga board you are using that will define which adder is being used yes yes so what do we do in silicon uh so we will come towards the end of this course we will talk about different kinds of adders also don't worry okay so there are there are different kinds of adders some would have lesser areas some would have lesser delay some would have lesser race conditions so i'm looking for that yeah carry look at adder ripple carry adders all those things you will see will not go into too much detail because that is simple combinatorial logic you can always get it see this information you will not get in the books so my intent is i give you this kind of information in the class unfortunately out of 93 students only 35 are attending the class today so i am i am here i am here to offer and give you additional information and answer your queries but you have to be here to ask those questions so my question was where is the strap now we not made the strap here so where does the strap come where do where do we make the tap for the people and the envelope to prevent latch up sir at the end of that drc length 30 yeah so what we say is that if my this wall you know the wall that i have made if this wall is 30 microns so i will simply make uh taps at the boundary of this wall okay or usually my walls would be thousands of microns wide so what do i do i say that okay these are my rows in these i will put tabs at regular intervals you've seen pillars in flowers so those pillars come after regular intervals may so these steps you make after regular intervals so that no point this point no point has a tab which is farther than drc distance away sir yes drc so this one cell that in particular wall is basically a standard cell right no no no no i'm not i've just shown you rows now the standard cells and this would be very small ones so what is what the vertical ones the vertical ones that i have shown in this view are the tabs i should have probably used a different color let me use it actually so so this basically this different kind of for example say i take up one layer only and these different blocks they are basically one standard cells now right no a standard cell for example and this there could be a buffer here there could be a flip flop so actually it's not visible so can you move to the different side because that will be available now yes yes so there could be a buffer here there could be a flip flop here there could be an inverter here there could be a y here so there are so many cells here these dark blue ones that i made they are taps so that is what i am saying the spacing between these tabs these the spacing between these tabs is such that uh so this was a tab this was a tab so the spacing is such that no no active region can be can be there which has a sp has a distance of more than 30 micron from the closest tab so which active region sir in each of these cells there is some active now yes sir yeah yeah so each actor will have some tap within 30 microns of it okay so sir this basically the standard cell that sorry this topology basically we are showing you you're showing the standard cell draws here right yeah i am showing you a uh uh 1000 meter top level view of earth let us say yeah again as you come closer you will see that the standard cell has these active regions in it yes sir but you will see them only when you come closer there are taps and there are these cells so there are these small small cells there are boundaries but as you come closer you will be able to see even identify the cars that are parked outside the house yes sir i've seen google maps no satellite maps in google yeah yes so my question so my question is also this that for example these are standard cell rows right and for example once i have placed this standard cells in these different rows then i am doing the tapping thing yes you can do that or you can actually fixate the tabs first and then place the standard cells in there so because right when we are doing it so this was basically we are doing in placement so after placement the tapping would be done during the placement tapping taps will also be placed okay after i have placed those in the standard cell rows so but like in the layout we are doing with each kind of yeah have you made any tap have i shown any tap over here no sir i know okay because i am saying that at the system level i am taking care of it you don't bother about it at the cell level let us save area okay so basically tapping thing happens automatically by the tool itself so you will have to make a standard cell which is tap type so we'll have to make a standard fill this may tap tap functionality hogi and the tool will place those tabs at regular intervals yeah so but that standard cell i will get in the library format right so you will make that okay those libraries okay just like you're making this nand gate or something over here similarly you will make this tab cell also so so this actually is for example in this only this uh in which you have shown the tell 12 track the height one this diagram only so the tapping the 30 micron is basically the distance between the for example the active of this nmos and this tapping so for example like it happens here cells away okay the tap the substrate connection for this and mass could be 10 cells away okay and it is still fine because it meets my drc requirements okay fine but that has to happen for every active initiative for everything yeah for no active should the tab be farther than the drc distance away okay okay yeah so i have been pressured so there is still one question which is pending as of now the question is from which we started but so one row is consisting of many standard cells right one row yes one row has many standard cells in it and those standard cells uh may consist of uh uh n and die unit like a flip flop or an adder something like that yeah just one row can have uh many sub rows of nmos and pmos no you can have another nmr right here below it provided you are meeting all the drc's you can have multiple rows of n masses enough you have to meet the drc you cannot violate the height answer how are these these rows separated from each other they are not separated there they are abutting that is where you will share the metals now that is where this vdd will be shared with the cell which is flipped and put on the top that there is this vdd then gnd then vdd then gnd so the boundaries of these carry vdd and gnd and they are shared across the top row and the bottom row okay between two tabs there would be many standard cells so in that way i have to share the angle for that many number of standards and also yes and well so the template would be such that this envelope will continue from the left to the right this envel will continue from left to the right so sir that is why it is not advised to make np and pp parallel to each other vertically right yes the first question where should the the drain which which should be connected to output and which should be connected to vdd yeah animation please sorry so i was asking the same question you're asking the same question you don't have an answer yet no no still not okay debris sir actually had one question that suppose the length of the row is three times the size of the drc for minimum length from where the strap is to be kept so if it is two times the drc then you can keep at keep at two ends but if it is three times then all right in that case what is run you will put two straps uh like you will how do i will show you so if the total length is 3 3x so what you will do you will put a strap here you will put a strap here x x x in fact this can be x by 2 2x and x by 2. okay something like that between two two rows somehow we have to add just between two rows name within a row you will put it okay so what is this trap he's talking about divgy the the n plus and p plus connections for the substrate taps tabs are also called straps okay right multiple names so see we are all out to confuse you yeah we are all out to confuse you so uh it's okay don't worry ask ask if you get confused so it's important to attend the class yeah so before going to the answer of the question i also wanted to ask that till now the when you started the real question the only factor other factor i was thinking about of the diffusion capacitance right but for example in the mosfet capacitance when you're modeling it weeks out of three kind of capacitance one was that from the gate to the either source of the drain one from from the gate to the channel and one from both the diffusion capacitance so like so why we are not considering the gate to the channel capacitance or other two capacitors when we were comparing this topology with this one original one that i had made what did we say we counted the number of gate to contact capacitances we counted all the capacitances there yeah yes actually so now so one thing so we are not talked about this uh gate to the channel okay so that that is basically controlled by the specification that someone has given yeah that is that as a designer you saw that you want a 5 micron device or a 7 micron device how can at the layout state you change that requirement so sir uh as of now i can see that the as a designer the most important that i control is the active region and the contacts if i can share it i can reduce the contacts if i share it we can reduce the diffusion capacitance but only the active region i'm considering it for example that is only the thing that i'm we're focusing on like most of our time to control that okay and within this active region the diffusion capacitor is the most important that's like for focusing on that it seems to be right yeah so now tell me this is my nand gate palette two devices cooper p moses and h and so which one should be ground which one should be so this is uh since we're just making a stick diagram corresponding to this one so this is ground so i make a wire to ground over here connected to ground and this is my output my voltage sorry this is my ground because b connects to ground and this is my output now where should this metal one go should it go to this one or should it go to the boundary ones your middle one sir why sir uh because sir that's obvious right sir if we give to the leftmost connection then we won't consider this right most uh no we saw now we can connect it like this so if i take it to this one i will take the middle one and do it like this yes sir i can't do it it is not obvious it is not obvious because of that reason what you are telling me it could be obvious because of some other reason the side of my standard cell i do not want two vdd coming out why i mean from the standard seller design so i have to attach to the rail railing that will be really going up up there so i could make two connections what's the big deal so if i say that i if i say that this is my output then this will go to vdd this will go to vdd what's the big deal there is a metal running here what's the big deal of that so the sidewall capacitance would play a role over here because we need to connect uh the input to the contact that is in uh that is between the two gates okay so you're saying this is how you should make it yes sir is everyone agree in agreement with this yes sir what happened yeah can we and i also think about signal integrity because because this metal one is crossing the poly two times there and here we can also do it one time okay so what is it that you really want anyways see what are these poly this is signal a this is signal b this is out so anyway if you even if you look at the schematic over here if you look at the schematic over there you will see there is some coupling capacitance between b and out there is already something there yes why is there something you tell me because a and out there is this drain capacitance there is this contact to poly capacitance everything is already there so that will add some capacitance i'm not saying it will not have any capacitor so there is already so much capacitance out there that a and y already 
have right so what's the big deal if you use this as the output what happens output capacitance reduces if you were using this as the output there would be extra drain and source capacitance that you would have to bear we have 20 fentanyl you are adding more capacitance on the load then so that so addition is due to the side wall only that yes not just sidewall we also did the calculation on uh the arianna so but either you said we are taking to be like the same no we calculated that this one this one would be 140 nanometer extension this one would be 140 nanometer extension so total extension will be 280 280 nanometer into wp over here the central area would be 160 into wp we calculated this we started with the assumption but i then gave you the exact calculation that is so less okay so we are considering two thing that one after the sharing the of the active regions then we are placing it between so two to reduce that yes okay right see again in the lecture we progress i start with an assumption but then i clarified that assumption is invalid in fact when you do sharing you save area and when you save area you are also sharing source entrained uh capacitances you are saving on that also so source and twin is a diffusion one right yes yeah okay so we have the answer to the first question where we started from and we did not even open one slide today"
kn9vJ1U2M0Y,[Music] so basically there is some amount of dishing that happens in the copper since it is very tactile so this kind of small small tubs or maybe thank you so what is happening over here is that uh oh yes this thing has again got stuck it seems just give me a moment so when we do the fabrication process now when we are fabricating devices or whatever so what happens is that at some point of time you will do chemo mechanical polishing in which what we essentially do is we flatten out the surfaces okay and in that flattening out the surfaces there is a mechanical force that is also applied so when that mechanical force is applied so when we are polishing so this is the surface of the wafer and we are kind of applying some mechanical force scrubbing it also so what happens when you are scrubbing the floor or something but the dirt or the uneven surface on the top will become polished will move out and you will have something which is clean stable flat now if it is if the surface that you are polishing is uh how do we put it if the surface that you're polishing is of same mechanical strength then what happens then when you polish everywhere the depth or the the the amount of surface removed from the top is almost the same what does that mean that means that your surface remains flat however in copper we understand that we also have this thin layer of barriers that is put around the thin layer of barrier that is put around copper you remember that yes sir so this barrier has much higher mechanical strength than copper so what does this do this barrier then starts to stay strong whereas others other parts of the system kind of get scrubbed okay so i'm trying to bring my slides back to you but it's somehow not working so i wanted to show that to you others i will go to whiteboard and show it so you're able to see my whiteboard yes so what is happening here is that you have this copper barrier hello yeah alright so you have this copper barrier i think they don't want the system doesn't want me to take thing up so i have this copper barrier and i have filled copper inside it let's use a color there i felt copper inside it inside it means i just did the deposition of copper copper filled everywhere and over here i also have what i call as silicon dioxide okay so this region is silicon dioxide you are able to see this episcopal silicon dioxide can be fences to deposit copper and make copper wires all this we've discussed in the fabrication section so we deposited copper and now we want to remove the excess copper so what we do is we run a cmp process through which we say this extra copper will get removed and as we do it we understand there is one mechanical strength of the oxide there is another mechanical strength of the copper and there is a very different mechanical strength with which the barrier holds its level so what happens is that if i have a very thin wire it works fine consider a case i have a very wide wire there is oxide here there is oxide here and there is copper that is filled here so in a very thin wire a cmp machine would come a cmp machine let me show it with what color let me show it with green color over here okay the cmp machine would come and with this barrier and with this barrier it will it will kind of stop there itself whereas when it is a thick metal wire then the cmp machine this barrier will stop it from going deeper over here also on the edge the barrier will stop it from scraping extra copper but in the middle because copper is much softer than the barrier and you are applying some particular force the cmp machine will go deeper so the final copper that you will get is not a flat metal there okay the final copper that you will get will have this kind of a structure hello okay so what so this this is called as dishing okay so are you able to realize what is happening if dishing happens are you okay with it or is there some challenge that you will face as a circuit designer so resistance of bias increase yes see you made you've made a wide wire what was the purpose of making a wide wire because you wanted its resistance to be less but what happened because you made a wide wire there was dishing that happened and the effective resistance did not decrease as much as you wanted it too so yes sir but like uh when you're discussing the wires so there was one uh concept for use aspect ratio and in you that you said that the for the advanced technologies that is higher so by that mean this basically t would be much higher than the weight so this this car this basically effect should be less advanced technologies yeah that is the case now we're talking about the same technology see over here the width is so much lesser than the height is it not yes sir so this this width is let us say 50 nanometer huh but this width that i am talking about is 1 micron so when the width is one micron the depth will not change now that's the technology so that this the one micron you're talking about so these are different metal layers you're talking about no no no no same metal you can make wider metals than the minimum drc now yes sir so but then i just made a wider metal so that i have lesser resistance so but then uh in the when the width is one micron then the height will be also much more than that it's the asterisk maintained so what what do you what can you maintain in a technology can you maintain the depth in which to which you will make the holes in silicon dioxide or you want you will be able to maintain the aspect ratio what is it that you will maintain in the technology you've seen the fabrication process henna we've covered the fabrication process so what was the fabrication process we said we will deposit oxide then we will put masks at some places huh and then we will expose uv radiations we will do something at some places the mass would remain other places the mass would not remain so wherever the mask remain let us say we would now make holes so would you now decide to make holes based on the based on the size of the mask or you will make holes based on your technology specifications masks masks say so if i have a wider hole you say i will go deeper oh depth depth is not dependent on mass depth cannot be dependent on master only the width with which we are width of the mask which are placing that so that is what i am saying this depth is fixed so sir for a particular technology that aspect ratio doesn't have to remain the same for like that you're saying that that is a decision aspect ratio for the minimum wire will remain constant for the technology but for the minimum wire we always talk when we talked about aspect ratio we're talking about minimum wires placed next to each other but not you will not make only minimum wires on your designs now you are worried about resistances okay so like as i go up the metal layers then the aspect pressure won't remain no i'm not even talking about up the metal layers i'm simply talking about even in your standard cell you are making those vdd and gnd rails i said they are 2x the minimum width did i not say that yes yes sir so do you think the depths will also be twice so i mean every depth is decided by their technology right the depth will remain same now yeah so if that remains same what happens for very wide wires this is how this is how it would appear like yeah okay so aspect ratio was only for the minimum kind of basically to give a understanding this is the thickness of the wire that is how we calculate the sheet resistance now remember yes sir heat resistance was rho by h this is h now that will not change depending whether your wire is thicker or thinner yes hannah this edge remains constant this is h here and this is h here both the places yes okay so now what do you do you do not want this dishing it's not clear we do not want this dishing to happen so what do we do what can you do physically ranjit you are saying something uh sir we should go for uh less wide open no but then the resistance would anyways increase i want low resistance only oh sorry if the width is reduced then the resistance okay resistance again so it will run what can you do yes sir i've shown in the image we can just i'm like make it as a different tub and like upper side it should be small and the lower side it should be big and it should be the resistance but again you want it to have a wide wire so that your resistance reduces but the other resistance map is better yeah what do we do we don't want this introduce more barriers wow good nickel how do we introduce more barrier you're going in the right direction nikhil we want to make the roof now and the roof is sagging what do you do in between yes you will put a pillar in between so what is done then is that in the metals when i have very my wide metals running there is a drc that you will see which is called as slotting so i have to make such slots very thin slots okay so what happens i get oxide and barriers over here both okay and they give the required mechanical strength to my system okay this is called as slotting so but how did this solve the problem because then it is again reducing the copper area yeah but effectively what happens is that the copper area reduces only by this much and that do not always do you realize this over here i still get full width so what happens is that after slotting you will see that the this width this depth will not happen it will be almost okay so what will happen is this let me use the same color this will be now almost like this does that in between there is some little block somewhere so effectively your width was then not 1 micron your width was let us say 0.98 micron but what we were experiencing earlier was that overall resistance has increased by more than 40 percent also because of dishing so one banana like in banana point six now by using the slotting you are limited it to only two to three percent so there is a loss clearly there is a loss but it is much lesser than the loss you would get because of dishing so yes serena technology when we define the width of wire width so that is dependent upon how fine uh things i can make on the silicon that is the minimum environment yes so since this barrier would also have some drc yes yeah so there is drc link to slotting you will see that so does that not really stretch the limits of technology in which i am so big so be it we are a designer we can ask for anything under the sun let's do that that's a technology team enable it job technology team up they know we can't do it then we will see okay uh so thank you guys we will start with the inverter part in the next class and thanks for a very good candid discussion today and uh i hope this is a this turns out to be a very good learning experience for all of us okay so yes sir the floating that we are doing in this uh copper wire is it on the surface or it is inside the copper inside the copper i make barriers over here so i will make 10 thin oxides oxide pillars in between okay so this is top view and this is you may say cross section view saw yeah yeah so so can we do anything else i mean like we are doing slotting to avoid dishing so can we do something like we can use uh like the polishing thing you said with something which doesn't like give us this uh this concave or this shape in the copper i mean it flattens it completely i mean yeah that would be nice that would be nice but we don't have that kind of technology yet and this is also cheap enough so that is what is implemented yeah so in this floating four structures that we made inside the sir couldn't we make just the structure that was effectively appearing on the surface so that the effective width for the uh cmd machine would have decreased but yeah inside still we are using some technique to manufacture this this is like this is like going outside making holes around oxide this is the standard process now you are saying that okay i have processes to make these holes i have processes to make these holes i also want some floating stuff to be made never now how would you make that floating stuff there sir it is still made in this force floating diagram that you shown to us i'm sorry there is some immigration going on at my place yeah you're saying something sir it was still made sir in the first floating diagram so can't you just remove those three slotting points inside the copper no they're not made on the surface shivam they are made in the copper in this copper you will have to have this barrier there this barrier will give the mechanical strength and there will be oxide inside it so it will actually be in the copper you have copper on all sides and this is what will happen this is how it will appear this cross section said this barrier would also be a conducting but harder uh harder metal barrier is very resistive it does not conduct as good as copper it is very resistive yes moment sir after slotting will this not affect the resistance of the wire because we have introduced the battery moment when we set this back instead of 0.6 okay so we are compensating by this so it can actually stand but much lesser than dishing sir hello yeah yes sir so sir when you are presenting the slide sir i i saw that the barrier sorry the barrier was a bit of in a triangular shape or it was not in rectangle but it was a trapezoid uh yeah yeah that is a fabrication inaccuracy don't worry about that okay okay okay thank you it is not intended to be that it becomes that because of fabrication and accuracy okay thank,https://www.youtube.com/watch?v=kn9vJ1U2M0Y,"Link: https://www.youtube.com/watch?v=kn9vJ1U2M0Y
Transcript: [Music] so basically there is some amount of dishing that happens in the copper since it is very tactile so this kind of small small tubs or maybe thank you so what is happening over here is that uh oh yes this thing has again got stuck it seems just give me a moment so when we do the fabrication process now when we are fabricating devices or whatever so what happens is that at some point of time you will do chemo mechanical polishing in which what we essentially do is we flatten out the surfaces okay and in that flattening out the surfaces there is a mechanical force that is also applied so when that mechanical force is applied so when we are polishing so this is the surface of the wafer and we are kind of applying some mechanical force scrubbing it also so what happens when you are scrubbing the floor or something but the dirt or the uneven surface on the top will become polished will move out and you will have something which is clean stable flat now if it is if the surface that you are polishing is uh how do we put it if the surface that you're polishing is of same mechanical strength then what happens then when you polish everywhere the depth or the the the amount of surface removed from the top is almost the same what does that mean that means that your surface remains flat however in copper we understand that we also have this thin layer of barriers that is put around the thin layer of barrier that is put around copper you remember that yes sir so this barrier has much higher mechanical strength than copper so what does this do this barrier then starts to stay strong whereas others other parts of the system kind of get scrubbed okay so i'm trying to bring my slides back to you but it's somehow not working so i wanted to show that to you others i will go to whiteboard and show it so you're able to see my whiteboard yes so what is happening here is that you have this copper barrier hello yeah alright so you have this copper barrier i think they don't want the system doesn't want me to take thing up so i have this copper barrier and i have filled copper inside it let's use a color there i felt copper inside it inside it means i just did the deposition of copper copper filled everywhere and over here i also have what i call as silicon dioxide okay so this region is silicon dioxide you are able to see this episcopal silicon dioxide can be fences to deposit copper and make copper wires all this we've discussed in the fabrication section so we deposited copper and now we want to remove the excess copper so what we do is we run a cmp process through which we say this extra copper will get removed and as we do it we understand there is one mechanical strength of the oxide there is another mechanical strength of the copper and there is a very different mechanical strength with which the barrier holds its level so what happens is that if i have a very thin wire it works fine consider a case i have a very wide wire there is oxide here there is oxide here and there is copper that is filled here so in a very thin wire a cmp machine would come a cmp machine let me show it with what color let me show it with green color over here okay the cmp machine would come and with this barrier and with this barrier it will it will kind of stop there itself whereas when it is a thick metal wire then the cmp machine this barrier will stop it from going deeper over here also on the edge the barrier will stop it from scraping extra copper but in the middle because copper is much softer than the barrier and you are applying some particular force the cmp machine will go deeper so the final copper that you will get is not a flat metal there okay the final copper that you will get will have this kind of a structure hello okay so what so this this is called as dishing okay so are you able to realize what is happening if dishing happens are you okay with it or is there some challenge that you will face as a circuit designer so resistance of bias increase yes see you made you've made a wide wire what was the purpose of making a wide wire because you wanted its resistance to be less but what happened because you made a wide wire there was dishing that happened and the effective resistance did not decrease as much as you wanted it too so yes sir but like uh when you're discussing the wires so there was one uh concept for use aspect ratio and in you that you said that the for the advanced technologies that is higher so by that mean this basically t would be much higher than the weight so this this car this basically effect should be less advanced technologies yeah that is the case now we're talking about the same technology see over here the width is so much lesser than the height is it not yes sir so this this width is let us say 50 nanometer huh but this width that i am talking about is 1 micron so when the width is one micron the depth will not change now that's the technology so that this the one micron you're talking about so these are different metal layers you're talking about no no no no same metal you can make wider metals than the minimum drc now yes sir so but then i just made a wider metal so that i have lesser resistance so but then uh in the when the width is one micron then the height will be also much more than that it's the asterisk maintained so what what do you what can you maintain in a technology can you maintain the depth in which to which you will make the holes in silicon dioxide or you want you will be able to maintain the aspect ratio what is it that you will maintain in the technology you've seen the fabrication process henna we've covered the fabrication process so what was the fabrication process we said we will deposit oxide then we will put masks at some places huh and then we will expose uv radiations we will do something at some places the mass would remain other places the mass would not remain so wherever the mask remain let us say we would now make holes so would you now decide to make holes based on the based on the size of the mask or you will make holes based on your technology specifications masks masks say so if i have a wider hole you say i will go deeper oh depth depth is not dependent on mass depth cannot be dependent on master only the width with which we are width of the mask which are placing that so that is what i am saying this depth is fixed so sir for a particular technology that aspect ratio doesn't have to remain the same for like that you're saying that that is a decision aspect ratio for the minimum wire will remain constant for the technology but for the minimum wire we always talk when we talked about aspect ratio we're talking about minimum wires placed next to each other but not you will not make only minimum wires on your designs now you are worried about resistances okay so like as i go up the metal layers then the aspect pressure won't remain no i'm not even talking about up the metal layers i'm simply talking about even in your standard cell you are making those vdd and gnd rails i said they are 2x the minimum width did i not say that yes yes sir so do you think the depths will also be twice so i mean every depth is decided by their technology right the depth will remain same now yeah so if that remains same what happens for very wide wires this is how this is how it would appear like yeah okay so aspect ratio was only for the minimum kind of basically to give a understanding this is the thickness of the wire that is how we calculate the sheet resistance now remember yes sir heat resistance was rho by h this is h now that will not change depending whether your wire is thicker or thinner yes hannah this edge remains constant this is h here and this is h here both the places yes okay so now what do you do you do not want this dishing it's not clear we do not want this dishing to happen so what do we do what can you do physically ranjit you are saying something uh sir we should go for uh less wide open no but then the resistance would anyways increase i want low resistance only oh sorry if the width is reduced then the resistance okay resistance again so it will run what can you do yes sir i've shown in the image we can just i'm like make it as a different tub and like upper side it should be small and the lower side it should be big and it should be the resistance but again you want it to have a wide wire so that your resistance reduces but the other resistance map is better yeah what do we do we don't want this introduce more barriers wow good nickel how do we introduce more barrier you're going in the right direction nikhil we want to make the roof now and the roof is sagging what do you do in between yes you will put a pillar in between so what is done then is that in the metals when i have very my wide metals running there is a drc that you will see which is called as slotting so i have to make such slots very thin slots okay so what happens i get oxide and barriers over here both okay and they give the required mechanical strength to my system okay this is called as slotting so but how did this solve the problem because then it is again reducing the copper area yeah but effectively what happens is that the copper area reduces only by this much and that do not always do you realize this over here i still get full width so what happens is that after slotting you will see that the this width this depth will not happen it will be almost okay so what will happen is this let me use the same color this will be now almost like this does that in between there is some little block somewhere so effectively your width was then not 1 micron your width was let us say 0.98 micron but what we were experiencing earlier was that overall resistance has increased by more than 40 percent also because of dishing so one banana like in banana point six now by using the slotting you are limited it to only two to three percent so there is a loss clearly there is a loss but it is much lesser than the loss you would get because of dishing so yes serena technology when we define the width of wire width so that is dependent upon how fine uh things i can make on the silicon that is the minimum environment yes so since this barrier would also have some drc yes yeah so there is drc link to slotting you will see that so does that not really stretch the limits of technology in which i am so big so be it we are a designer we can ask for anything under the sun let's do that that's a technology team enable it job technology team up they know we can't do it then we will see okay uh so thank you guys we will start with the inverter part in the next class and thanks for a very good candid discussion today and uh i hope this is a this turns out to be a very good learning experience for all of us okay so yes sir the floating that we are doing in this uh copper wire is it on the surface or it is inside the copper inside the copper i make barriers over here so i will make 10 thin oxides oxide pillars in between okay so this is top view and this is you may say cross section view saw yeah yeah so so can we do anything else i mean like we are doing slotting to avoid dishing so can we do something like we can use uh like the polishing thing you said with something which doesn't like give us this uh this concave or this shape in the copper i mean it flattens it completely i mean yeah that would be nice that would be nice but we don't have that kind of technology yet and this is also cheap enough so that is what is implemented yeah so in this floating four structures that we made inside the sir couldn't we make just the structure that was effectively appearing on the surface so that the effective width for the uh cmd machine would have decreased but yeah inside still we are using some technique to manufacture this this is like this is like going outside making holes around oxide this is the standard process now you are saying that okay i have processes to make these holes i have processes to make these holes i also want some floating stuff to be made never now how would you make that floating stuff there sir it is still made in this force floating diagram that you shown to us i'm sorry there is some immigration going on at my place yeah you're saying something sir it was still made sir in the first floating diagram so can't you just remove those three slotting points inside the copper no they're not made on the surface shivam they are made in the copper in this copper you will have to have this barrier there this barrier will give the mechanical strength and there will be oxide inside it so it will actually be in the copper you have copper on all sides and this is what will happen this is how it will appear this cross section said this barrier would also be a conducting but harder uh harder metal barrier is very resistive it does not conduct as good as copper it is very resistive yes moment sir after slotting will this not affect the resistance of the wire because we have introduced the battery moment when we set this back instead of 0.6 okay so we are compensating by this so it can actually stand but much lesser than dishing sir hello yeah yes sir so sir when you are presenting the slide sir i i saw that the barrier sorry the barrier was a bit of in a triangular shape or it was not in rectangle but it was a trapezoid uh yeah yeah that is a fabrication inaccuracy don't worry about that okay okay okay thank you it is not intended to be that it becomes that because of fabrication and accuracy okay thank"
_3zsV5VQEMI,okay so today what we are going to do is essentially completing the wire models we discussed wires now we'll look at wire delay models and stuff and then we will start with inverter today okay so uh wires all of us know are are there along the entire chip they run from uh one end of the chip to another these are global wires and then there obviously there are interconnects you also use wires when you design your circuits and everything so that much is you know evident to all of you now with them what is very important to realize is also that as technology is scaling devices are becoming faster because of technology scaling your channel length is reducing so current is increasing or the time to you know the the device current per unit micron square is increasing all that is happening so device delays are becoming lesser however we understand that as the wires come closer their capacitance increases and as they become thinner their resistance also increases so what would be happening to the interconnect delays so we are saying device delays are reducing as technology scales but what happens to the interconnect delays as technology scales so they increase the interconnect delays increase so it is very important to understand how to model interconnect delays in your circuits and what kind of [Music] you know delays can happen because of interconnects so in an advanced soc and where you have possibly long critical paths also uh one data point shows that up to 70 of total delay in a critical path was rc delays so there is a critical path on a global signal this global signal is running from one place to a distant location on the same day and up to 70 of total delay in that critical path was due to wires in in small circuits just about 20 to 30 percent of delay could be because of fires but in big circuits that is the kind of impact or big circuits means big systems up to 70 of delay could be because of rc interconnect okay so uh what i am showing as of now is the most simple or the simplest model of a wire delay so what is it you simply model the capacitance you're not even modeling the resistance of the wire you you club all the capacitance into one c lump and you say that is all it is do you think this is okay sir yes so this c lamp this is a so for example in the earlier slides you showed us the c adjacent and c ground write a figure so so that c lamp is characterizing all those capacitances yeah yeah everything okay so this is let us say this c wire is distributed over 100 microns so c lambda summing of all those there was a intra metal capacitance there was intermediate capacitance there was metal to substrate capacitance all of that is added and put our sea lump okay so do you think this is accurate no sir no no why first thing we already i just mentioned that resistances are not taken care of at all and uh just the driver resistance is brought into picture so when the resistances were less let us say in 189 180 nanometer technology or 250 nanometer technology this model could have worked but today when we are talking about 18 nanometer it no longer works so what do we do we look at the next model the next model is lumped rc model where we say that okay we will also model the resistances but not too many of them okay and we say that the delay or the effective resistance from node i let us say this is node i to node k let us say this is not k would be given as sum of rjs where rj is elements of all that so effectively delay is k from 1 to n c k into r i k so what is uh i'm just not sure if we have an example okay so this is something that is important and i would want you to do some numerical from the question bank that you already have made available on this okay what is important to see is how does rik change when i am talking about delay at node 2 or delay at node i or delay at node 4 okay it is simple you just need to apply this kind of formula and you will get there but i want you to work on some numericals for this these are simple this is simple addition and multiplication can i assume you can do this sir so what you're saying is that 2 4 and one are respectively the different output position output points that i'm taking in this circuit right yeah okay okay could be no one inverter could be driving four four inputs somewhere else okay yeah then an and gate output could be going to two places yes sir and so so one thing i wanted to ask right key for example sir when we have for example severe game having two gates and there's a wire between them so what we talk about the delay happening is for so first of all there is the input pin capacitance of the gate that is driven then there is the wire thing and then there's also the capacitance in in uh intrinsic to the device itself so this this c basically characterizes all of that i just actually i couldn't understand that let us say let us say ci would be the wire of the capacitance and the wire of the you know the the capacitance of the gate also the capacitance including cgd cgs plus cgb everything that is the load that we are putting at that that node node four or node i or anything so because since it's a metal wire so in itself it doesn't have any capacitance but we are mod why why why no sir if you take an individual wire only no there is a substrate on which it will run now okay substrate is ground so there is a there is always a capacitance of even a isolated wire with ground or vdd whatever so i couldn't get that so what you're seeing is so when i draw a wire let us say i made a wire and there is no other material around it because this is just a wire there was some contact uh some via there and there was some other wire through which it was coming and let us forget the capacitance of this part and let us say this is the other part of the wire which or whose capacitance i want to see let us say this is a substrate so if there is no other metal around here to which lines of electric field lines would go then the line of forces would go to the ground so into the substrate right into the substrate so there will be a capacitance with substrate no wire can exist without any capacitance a capacitance value may be less or it could be large that's a different thing uh because even between the inter metal there's silicon dioxide right so it is also there yeah yeah yeah so there would be definitely some capacitance between this all that would be there but method on substrate can be a capacitance if you cut make a cut over here there will be so many lines of forces that you'll be cutting so that will give you a measure of capacitance between these two so but say for example i am taking a metal three wire and it is isolated so i have below it silicon dioxide right yeah so one is the one charge is a dielectric so all this is let us say this is metal three let us say this is method three yes sir okay so this is dielectric yes sir okay now tell me okay a little bit substrate now substrate which could be considered as the other other plate of the capacitor there is this one plate there is the other plate and this other plate is say held at gnd or vdd let us say gnds and vdds substrate level what's the big deal so it is the basic p p substrate right you're talking about yeah uh p substitute our n subset so this is okay we substitute this is n substrate and well okay so but still uh as we go higher up this component will get negligible right yes it will reduce okay it should reduce because what happens is then uh then what happens is that it will reduce simply because there will be other wires which will to which these lines of forces will somewhere you know far away but even then that is closer than what you will see in the ground so these line of forces will dominate them but every isolated wire will have some capacitance because there is current flowing through it so there is bound to the electric field those lines of field would terminate somewhere yeah yes so but like in our model this our delay model we are basically characterizing all the capacitances the inter intra and this also in this one all that is clubbed into this place okay okay so okay and what we are saying is that whenever i had a turn in the wire or wherever i had a you know bifurcation in the wire that is where i also bifurcate my i i kind of make a split and i put the capacitance there and then i have the other resistance coming into picture and so on okay okay got this okay [Music] here if we are talking solely about the wires then in that case this model would not contain the gate capacitances of the mosfets and uh output the intrinsic capacitance at the terminal at the terminal that is 2 4 and ci it would contain the gate because that's the load so sorry if we talk about uh tool maybe so it uses some kind of if you talk about the some tool like for example genus or anything like that does uh a logical thing so those wire load models will not because they're the you do not even know what the output capacitance is but i'm talking up when you're analyzing a circuit when you're analyzing a circuit then this ci or you can what you can do is you can put another c load ahead of it i would rather not do that i would say ci includes that it makes it simpler because they are in parallel anyway so they will be added yes okay good morning good morning actually can i imagine each note to be a gate and grain junction no one okay no these are wires uh so as i just mentioned uh each node let us say this node one or note three they could be places where my wire bifurcated into two parts okay yeah i got that okay so i was basically thinking like what in uh okay now this is only wire delays this is only via delays only at the terminal end i'm saying you can add the load capacitance there otherwise yeah the basically the junction represents a point and where the bifurcates don't use the word junction because junction there is a junction capacitance that we know of if you confuse people so junction i know you are talking about a train junction for example no so don't use the word junction over here you simply say the thing bifurcates so i was trying to imagine like if there are two inverters in series and uh it lay wire leaves from the drain then goes to the gate of the another inverter so yeah there is a resistance up to that wire and then that wire also can that inverter can drive another circuit another another gate so if it is something like this then i would say we are only talking about this part okay yeah there is nothing else there okay okay only when there is something like okay now this goes to a nand gate and from here it also goes to a nor gate somewhere only when there is something like this that we're talking about remaining parts okay now you know because then we are we're adding more parts onto the picture that is when these paths start to figure in otherwise no okay we're talking only about the wire capacitance in this one but uh i would strongly recommend you to do some numericals uh numerical class may this is a simple addition of multiplication i i don't think we need to do the numerical in the class but i would recommend you to do it it's important for you to estimate okay okay yes mother uh so uh i did not understand the equation this path s2i intersection path s2k what is this s okay so uh all paths all paths which are from uh source to output i and from source to output k s stands for source here we are talking about the capacitance only but at the point the the r point the input point where we you have given a pulse there will be an output capacitance of a gate and at the uh 0.2 and 0.4 there would be some like if if this gate is driving some another gates then this point 2 and 4 will have some input capacitance of those gates yes but so we already said that c2 and c4 and ci would include the load capacitance that is what i just suggested or you can put them in parallel or you can put them in parallel okay ci to c2 c4 and ci uh as far as the capacitance the self loading of the driver is concerned you're right it comes into picture so we can put it there but because we are also considering the driver as the source uh it will not really make much of an impact in the overall delay calculation yes sir okay thank you uh sir what is this uh source we're talking about is it the voltage source we're providing yeah we're just saying that okay there is a voltage source okay,https://www.youtube.com/watch?v=_3zsV5VQEMI,"Link: https://www.youtube.com/watch?v=_3zsV5VQEMI
Transcript: okay so today what we are going to do is essentially completing the wire models we discussed wires now we'll look at wire delay models and stuff and then we will start with inverter today okay so uh wires all of us know are are there along the entire chip they run from uh one end of the chip to another these are global wires and then there obviously there are interconnects you also use wires when you design your circuits and everything so that much is you know evident to all of you now with them what is very important to realize is also that as technology is scaling devices are becoming faster because of technology scaling your channel length is reducing so current is increasing or the time to you know the the device current per unit micron square is increasing all that is happening so device delays are becoming lesser however we understand that as the wires come closer their capacitance increases and as they become thinner their resistance also increases so what would be happening to the interconnect delays so we are saying device delays are reducing as technology scales but what happens to the interconnect delays as technology scales so they increase the interconnect delays increase so it is very important to understand how to model interconnect delays in your circuits and what kind of [Music] you know delays can happen because of interconnects so in an advanced soc and where you have possibly long critical paths also uh one data point shows that up to 70 of total delay in a critical path was rc delays so there is a critical path on a global signal this global signal is running from one place to a distant location on the same day and up to 70 of total delay in that critical path was due to wires in in small circuits just about 20 to 30 percent of delay could be because of fires but in big circuits that is the kind of impact or big circuits means big systems up to 70 of delay could be because of rc interconnect okay so uh what i am showing as of now is the most simple or the simplest model of a wire delay so what is it you simply model the capacitance you're not even modeling the resistance of the wire you you club all the capacitance into one c lump and you say that is all it is do you think this is okay sir yes so this c lamp this is a so for example in the earlier slides you showed us the c adjacent and c ground write a figure so so that c lamp is characterizing all those capacitances yeah yeah everything okay so this is let us say this c wire is distributed over 100 microns so c lambda summing of all those there was a intra metal capacitance there was intermediate capacitance there was metal to substrate capacitance all of that is added and put our sea lump okay so do you think this is accurate no sir no no why first thing we already i just mentioned that resistances are not taken care of at all and uh just the driver resistance is brought into picture so when the resistances were less let us say in 189 180 nanometer technology or 250 nanometer technology this model could have worked but today when we are talking about 18 nanometer it no longer works so what do we do we look at the next model the next model is lumped rc model where we say that okay we will also model the resistances but not too many of them okay and we say that the delay or the effective resistance from node i let us say this is node i to node k let us say this is not k would be given as sum of rjs where rj is elements of all that so effectively delay is k from 1 to n c k into r i k so what is uh i'm just not sure if we have an example okay so this is something that is important and i would want you to do some numerical from the question bank that you already have made available on this okay what is important to see is how does rik change when i am talking about delay at node 2 or delay at node i or delay at node 4 okay it is simple you just need to apply this kind of formula and you will get there but i want you to work on some numericals for this these are simple this is simple addition and multiplication can i assume you can do this sir so what you're saying is that 2 4 and one are respectively the different output position output points that i'm taking in this circuit right yeah okay okay could be no one inverter could be driving four four inputs somewhere else okay yeah then an and gate output could be going to two places yes sir and so so one thing i wanted to ask right key for example sir when we have for example severe game having two gates and there's a wire between them so what we talk about the delay happening is for so first of all there is the input pin capacitance of the gate that is driven then there is the wire thing and then there's also the capacitance in in uh intrinsic to the device itself so this this c basically characterizes all of that i just actually i couldn't understand that let us say let us say ci would be the wire of the capacitance and the wire of the you know the the capacitance of the gate also the capacitance including cgd cgs plus cgb everything that is the load that we are putting at that that node node four or node i or anything so because since it's a metal wire so in itself it doesn't have any capacitance but we are mod why why why no sir if you take an individual wire only no there is a substrate on which it will run now okay substrate is ground so there is a there is always a capacitance of even a isolated wire with ground or vdd whatever so i couldn't get that so what you're seeing is so when i draw a wire let us say i made a wire and there is no other material around it because this is just a wire there was some contact uh some via there and there was some other wire through which it was coming and let us forget the capacitance of this part and let us say this is the other part of the wire which or whose capacitance i want to see let us say this is a substrate so if there is no other metal around here to which lines of electric field lines would go then the line of forces would go to the ground so into the substrate right into the substrate so there will be a capacitance with substrate no wire can exist without any capacitance a capacitance value may be less or it could be large that's a different thing uh because even between the inter metal there's silicon dioxide right so it is also there yeah yeah yeah so there would be definitely some capacitance between this all that would be there but method on substrate can be a capacitance if you cut make a cut over here there will be so many lines of forces that you'll be cutting so that will give you a measure of capacitance between these two so but say for example i am taking a metal three wire and it is isolated so i have below it silicon dioxide right yeah so one is the one charge is a dielectric so all this is let us say this is metal three let us say this is method three yes sir okay so this is dielectric yes sir okay now tell me okay a little bit substrate now substrate which could be considered as the other other plate of the capacitor there is this one plate there is the other plate and this other plate is say held at gnd or vdd let us say gnds and vdds substrate level what's the big deal so it is the basic p p substrate right you're talking about yeah uh p substitute our n subset so this is okay we substitute this is n substrate and well okay so but still uh as we go higher up this component will get negligible right yes it will reduce okay it should reduce because what happens is then uh then what happens is that it will reduce simply because there will be other wires which will to which these lines of forces will somewhere you know far away but even then that is closer than what you will see in the ground so these line of forces will dominate them but every isolated wire will have some capacitance because there is current flowing through it so there is bound to the electric field those lines of field would terminate somewhere yeah yes so but like in our model this our delay model we are basically characterizing all the capacitances the inter intra and this also in this one all that is clubbed into this place okay okay so okay and what we are saying is that whenever i had a turn in the wire or wherever i had a you know bifurcation in the wire that is where i also bifurcate my i i kind of make a split and i put the capacitance there and then i have the other resistance coming into picture and so on okay okay got this okay [Music] here if we are talking solely about the wires then in that case this model would not contain the gate capacitances of the mosfets and uh output the intrinsic capacitance at the terminal at the terminal that is 2 4 and ci it would contain the gate because that's the load so sorry if we talk about uh tool maybe so it uses some kind of if you talk about the some tool like for example genus or anything like that does uh a logical thing so those wire load models will not because they're the you do not even know what the output capacitance is but i'm talking up when you're analyzing a circuit when you're analyzing a circuit then this ci or you can what you can do is you can put another c load ahead of it i would rather not do that i would say ci includes that it makes it simpler because they are in parallel anyway so they will be added yes okay good morning good morning actually can i imagine each note to be a gate and grain junction no one okay no these are wires uh so as i just mentioned uh each node let us say this node one or note three they could be places where my wire bifurcated into two parts okay yeah i got that okay so i was basically thinking like what in uh okay now this is only wire delays this is only via delays only at the terminal end i'm saying you can add the load capacitance there otherwise yeah the basically the junction represents a point and where the bifurcates don't use the word junction because junction there is a junction capacitance that we know of if you confuse people so junction i know you are talking about a train junction for example no so don't use the word junction over here you simply say the thing bifurcates so i was trying to imagine like if there are two inverters in series and uh it lay wire leaves from the drain then goes to the gate of the another inverter so yeah there is a resistance up to that wire and then that wire also can that inverter can drive another circuit another another gate so if it is something like this then i would say we are only talking about this part okay yeah there is nothing else there okay okay only when there is something like okay now this goes to a nand gate and from here it also goes to a nor gate somewhere only when there is something like this that we're talking about remaining parts okay now you know because then we are we're adding more parts onto the picture that is when these paths start to figure in otherwise no okay we're talking only about the wire capacitance in this one but uh i would strongly recommend you to do some numericals uh numerical class may this is a simple addition of multiplication i i don't think we need to do the numerical in the class but i would recommend you to do it it's important for you to estimate okay okay yes mother uh so uh i did not understand the equation this path s2i intersection path s2k what is this s okay so uh all paths all paths which are from uh source to output i and from source to output k s stands for source here we are talking about the capacitance only but at the point the the r point the input point where we you have given a pulse there will be an output capacitance of a gate and at the uh 0.2 and 0.4 there would be some like if if this gate is driving some another gates then this point 2 and 4 will have some input capacitance of those gates yes but so we already said that c2 and c4 and ci would include the load capacitance that is what i just suggested or you can put them in parallel or you can put them in parallel okay ci to c2 c4 and ci uh as far as the capacitance the self loading of the driver is concerned you're right it comes into picture so we can put it there but because we are also considering the driver as the source uh it will not really make much of an impact in the overall delay calculation yes sir okay thank you uh sir what is this uh source we're talking about is it the voltage source we're providing yeah we're just saying that okay there is a voltage source okay"
T3evXVYqVz4,what are these rc models you know the stem press the step response how is the the what is the difference between the step response of a lumped model and a distributed rc network you know for example if you look at propagation delay from zero to fifty percent a lumped network would use a delay of 0.69 of rc whereas in a real rc network the delay would be only 0.38 rc and the 10 to 90 delay would be much larger much pessimistic for a lumped network than for a distributed network so what does it mean it means that lambda use karna instead we would want to use something like a pi model so you see this looks like a pi or like a t model okay and what is what has been empirically observed is that uh a three stage pi model a pi 3 model or a t3 model is a very accurate representation of most of the designs okay now typically you will see that when you do not really want absolute picosecond level accuracy you can as well go to a single pi model but if you really want very high accuracy a pi 3 model is still good enough and there's much lesser simulation time than a real distributed rc network lesser simulation you tell me how do how do simulators uh work yeah i'm not sure so you studied mattresses and your mathematics courses yes all of you have even b-tech students at triple iit and m-tech students have studied mattresses am i right yes sir so you thought they were being taught for esoteric purpose no they were taught because those are actually used by simulators simulators make mattresses and for every device they have you know a row or a column associated with them and that is how simulators do matrix transformations do their calculations and so on okay because there are multiple things which are working together so all those parallel threads or all those parallel nodes are evaluated simultaneously so if you have more number of elements what happens the matrix size increases actually matrix size depends on number of nodes so yeah i think i could relate with that and that there are number of nodes are increasing so yes so as soon as you increase the total number of elements uh things would things would increase the simulation time increases okay so actually you said simulation time would decrease decrease unlike that that's the reason why simulation time would decrease with the pi model and the pi 3 would oh okay it would decrease from a distributed rc network a distributed rc network would have thousands of small small resistances and capacitances that would have in it okay okay we are lumping them into a pi model or a pi 3 model so from there the simulation time would definitely reduce significantly okay so the simulation time is more in pi 3 model right than pi model yes but it is still much lesser than a distributed network okay uh yes i'm i am not familiar with the term distributed rc network so so distributed rc networks are we just showed that in the previous slider this is the distributed so over here this is this distributed c but there is a long wire and we say that okay all these small resistances i will i will actually show all the small resistances i will not lump them okay okay that is distributed rc so what you say is that okay i had this uh wire going from here to the inverter and then it took a turn it went into a nor gate or something huh so i put a distributed rc network would say okay uh i would want to make a rc of this i would want to make a rc of this i would want to make a rc of this a separate rc of this rc of this rc of this and so on every schematic as soon as i make the layout you will see the metal would have moved from vr1 to vr2 from metal one to metal two through a vr1 so all those transitions it would you will see okay so i'll post out extraction so the first extracted file you will see there are so many resistances and so many capacitances because at every vr it is taking a break okay every vi it says no now the new wire has started so i will model it separately so new capacitance comes into picture a new resistance comes into picture every turn something happens okay so that is distributed rc and you can imagine how many uh resistance so epic simple inverter even though it does because of metal one do you realize this yeah yeah so uh how did we so like i understand how for uh in a distributed network you would have that specific delay of point three uh eight right yeah so but uh how did we write for this we simply calculated analyzed okay common characteristics propagation delay would be something which will be 0.38 rc and if you just make a lambda thing and you will see that the delay would be different that's it we just did the analysis circuit circuits of course okay so you must have done rca networks huh yeah yes yeah that's it so uh just rc network modeling with rc network offers a certain advantage because the distributed rc network has you know if you are trying to um convert it into a distributed organization that the simulation time would reduce if i have lesser lesser uh components oh i understand that what you're just talking about that is why we're talking about these models otherwise the distributed was good enough it was very accurate okay okay yes sir so this pie model and distributor see different things two different things yeah yeah yeah vr has a different resistance model for it so if you will open the drm of any any technology you will see that resistances and vrs capacitance of contacts and vias have a completely different resistance profile than wires so but they are also copper right so why yeah they are standing yellow so the thing is that uh see vr that length is not in your control is it no sir when i make a wire i can decide how long or short i have to make this fire but for a vr you have no control over this depth this is defined by the process yes sir so whenever we put a vr we say this vr has a resistance of 10 ohms let us say now if i cannot afford 10 ohms i will put two vrs what will be the effective resistance five five i make three vrs four vrs and i can reduce the overall resistance okay okay so see in a wire you can reduce the resistance by making wider wires yes but vias you can't do that therefore we ask our resistance alex and therefore because it is given separately the tool understands it as a separate wire so sir in the elmore delay slide that was basically a distributed network you were showing uh that was this one yeah so you can call it a distributed network you may not in the sense that uh if because i have not really shown all the different or i have not shown these three components separately to you have i i have lumped all of this into anarchy yes sir so this is not really a distributed not not purely distributed but yeah wherever there is a turn even a pio model you will have to model it like this that okay so but like what is the difference between the lumped and the distributed one the lumped was actually i'm not getting confused between that okay in lumped we have no resistance also no resistance and all the capacitors are simply added okay in distributed we are distributed considering all the resistance separately and all the capacitance separately and disability yes and then they come to an intermediate pi or a c model so like pi is like an intimate between the lambda and the distributed you can say yes okay okay yeah so the caught itself thanks we do not pay that much simulation time but we get almost similar accuracy yeah yeah yes got it okay so while three segment pi model as i mentioned is very accurate but typically single segment pi model is used okay so now we come to crosstalk you understand what crosstalk is you've heard about this term earlier so i have the question from the via part that you were saying uh like if we want lesser resistance we can add two or three vias but i have read in the course like the cost of fabricating a via is much more than the metals like is it feasible to have two or three vias in place of one to just reduce the resistance or is it a good thing like so uh if it is not leading to any increase in area okay we would usually want to have redundancy in vrs and contacts okay okay but if you not want to open overkill either for example if you make a pcell of a device which is let us say 10 micron wide you will see there are hundreds of contacts it will put automatically they can happen laser you need not use a pc at all for making your inverter layout then i have you i have used yeah yeah so when you made the p cell and you made a device of let's say four micron bits how many contacts would it put on the source and drain how that that you have told in tens of them yeah as many as it could put yes sir so that is an overkill so that leads to increase in gate capacitance get to source and get to drain capacity that we don't want to do but we definitely would want to say that okay every third contact i would want to keep or every second contact i would want to keep just so that i reduced the total capacitance between gate and these contacts polyamide contacts but uh i still i am able to reduce the resistance also okay okay so multiple or this redundancy of resistances and vr's is preferred this is in fact called as design for manufacturability dsm okay so there are checks there are checks that say that you could have put two contacts over here why did you put only one okay so there are such checks also but we have to be very judicious we have to be very careful cam overdo not okay so yes yeah so in this pi or t model when we have a very long wires then this may be true but when we have wires which branch too much then maybe this model will fail because there are parallel actually uh it is for global signals that we use the spy and t models small interconnects the resistances and capacitances are small enough see if the overall value of the delay is 10 pico seconds whether you are measuring uh it accurately at at 9.7 pico seconds or whether you are measuring it at 8 00 seconds two pico seconds to after some electricity in accuracy doesn't matter so if the delays that that could be impacted are within the accuracy of your simulator or your simulation setup you don't bother about making pi np models only when you have global signals where the interconnect delays and assemblies three the interconnect delay could be 30 to 70 percent of your critical path delay so for the big big delays we want to model them as pi or t okay so so we need accuracy when we are dealing with such long interventions yes when we're dealing with long interconnects we definitely need accuracy some accuracy okay so if you give me a circuit and say that okay this much amount of delay i have to meet so as a designer when i'm starting to look at all the topologies that i can use so how can i really use this kind of model because i don't know the length but at the time of uh schematic design so what you can do is okay this capacitance is of very high importance to me this delay is is is the longest delay so i would not want to add any wire delay into it so you say you can put commands in your schematic that make these make the layout of these devices as close to each other as possible so that when you start to lay them out you you remember okay this was an important consideration so that you can do and when making the layout but otherwise uh you cannot really do much so what we usually do is we simply add some parasitic capacitance on every every intermediate node we say okay this node this node is going from one inverter to another at least two phantom farad capacitance to i diagram so we just put some some value there so that our final delays are not far away from our initial targets based upon experience yeah based on the experience and technology characterization and stuff like that yes ma'am but what lumped does is it uh it models the same between two nodes but like uh that diagram you wish it was taking all those turns and curves and modeling it as one resistance and one capacitance yeah that's the backlog okay answer another thing you you mentioned uh mentioned a point about the number of contacts we had when we were modeling for a certain bridge of females and animals and uh how we should we should be careful not to do an overkill right so when we reduce the number of contacts i understand how that would reduce the capacitance between the poly and the contact but uh how will that affect the resistance exactly so uh you see contact resistance let us say is uh 10 ohms let us say and you made 10 contacts your resistance became 1 ohm now you reduce 5 of them one key got two okay but one is that like two is as low as one yes so you say okay let me have two let me have uh you know lesser contacts than all 10 objects the resistance doesn't have that much impact in terms of in terms of magnitude yeah because finally if it is a very big driver then the resistance of the global rc network is more important okay then there would be other constraints which could come because of the total current that this rc network has to drive for example if it's a very huge capacitance and you're talking of driving it every every clock cycle then you understand that okay if the current has to flow in every cycle then i have to be careful that even after some ageing and some degradation and resistances even after that my system will work fine so then you may want to put seven contacts instead of five so there are rules for that also there are rules linked to electro migration also so don't worry there are there these are slightly advanced topics we will possibly talk about these failure modes in the last lecture of this course okay okay but just so but in the last point you mentioned that um in that case if you if you're talking about huge driver so 10 so let us assume that 10 were the by default you got from that is the maximum contacts you can put yeah we said we will in a typical case and it is not a very big driver it will reduce from 10 to 5 or 10 to 4 but if this driver is operating every cycle if the activity rate of this driver is very high then electromigration rules may require me to put seven contacts instead of four or five so that even after aging things are fine,https://www.youtube.com/watch?v=T3evXVYqVz4,"Link: https://www.youtube.com/watch?v=T3evXVYqVz4
Transcript: what are these rc models you know the stem press the step response how is the the what is the difference between the step response of a lumped model and a distributed rc network you know for example if you look at propagation delay from zero to fifty percent a lumped network would use a delay of 0.69 of rc whereas in a real rc network the delay would be only 0.38 rc and the 10 to 90 delay would be much larger much pessimistic for a lumped network than for a distributed network so what does it mean it means that lambda use karna instead we would want to use something like a pi model so you see this looks like a pi or like a t model okay and what is what has been empirically observed is that uh a three stage pi model a pi 3 model or a t3 model is a very accurate representation of most of the designs okay now typically you will see that when you do not really want absolute picosecond level accuracy you can as well go to a single pi model but if you really want very high accuracy a pi 3 model is still good enough and there's much lesser simulation time than a real distributed rc network lesser simulation you tell me how do how do simulators uh work yeah i'm not sure so you studied mattresses and your mathematics courses yes all of you have even b-tech students at triple iit and m-tech students have studied mattresses am i right yes sir so you thought they were being taught for esoteric purpose no they were taught because those are actually used by simulators simulators make mattresses and for every device they have you know a row or a column associated with them and that is how simulators do matrix transformations do their calculations and so on okay because there are multiple things which are working together so all those parallel threads or all those parallel nodes are evaluated simultaneously so if you have more number of elements what happens the matrix size increases actually matrix size depends on number of nodes so yeah i think i could relate with that and that there are number of nodes are increasing so yes so as soon as you increase the total number of elements uh things would things would increase the simulation time increases okay so actually you said simulation time would decrease decrease unlike that that's the reason why simulation time would decrease with the pi model and the pi 3 would oh okay it would decrease from a distributed rc network a distributed rc network would have thousands of small small resistances and capacitances that would have in it okay okay we are lumping them into a pi model or a pi 3 model so from there the simulation time would definitely reduce significantly okay so the simulation time is more in pi 3 model right than pi model yes but it is still much lesser than a distributed network okay uh yes i'm i am not familiar with the term distributed rc network so so distributed rc networks are we just showed that in the previous slider this is the distributed so over here this is this distributed c but there is a long wire and we say that okay all these small resistances i will i will actually show all the small resistances i will not lump them okay okay that is distributed rc so what you say is that okay i had this uh wire going from here to the inverter and then it took a turn it went into a nor gate or something huh so i put a distributed rc network would say okay uh i would want to make a rc of this i would want to make a rc of this i would want to make a rc of this a separate rc of this rc of this rc of this and so on every schematic as soon as i make the layout you will see the metal would have moved from vr1 to vr2 from metal one to metal two through a vr1 so all those transitions it would you will see okay so i'll post out extraction so the first extracted file you will see there are so many resistances and so many capacitances because at every vr it is taking a break okay every vi it says no now the new wire has started so i will model it separately so new capacitance comes into picture a new resistance comes into picture every turn something happens okay so that is distributed rc and you can imagine how many uh resistance so epic simple inverter even though it does because of metal one do you realize this yeah yeah so uh how did we so like i understand how for uh in a distributed network you would have that specific delay of point three uh eight right yeah so but uh how did we write for this we simply calculated analyzed okay common characteristics propagation delay would be something which will be 0.38 rc and if you just make a lambda thing and you will see that the delay would be different that's it we just did the analysis circuit circuits of course okay so you must have done rca networks huh yeah yes yeah that's it so uh just rc network modeling with rc network offers a certain advantage because the distributed rc network has you know if you are trying to um convert it into a distributed organization that the simulation time would reduce if i have lesser lesser uh components oh i understand that what you're just talking about that is why we're talking about these models otherwise the distributed was good enough it was very accurate okay okay yes sir so this pie model and distributor see different things two different things yeah yeah yeah vr has a different resistance model for it so if you will open the drm of any any technology you will see that resistances and vrs capacitance of contacts and vias have a completely different resistance profile than wires so but they are also copper right so why yeah they are standing yellow so the thing is that uh see vr that length is not in your control is it no sir when i make a wire i can decide how long or short i have to make this fire but for a vr you have no control over this depth this is defined by the process yes sir so whenever we put a vr we say this vr has a resistance of 10 ohms let us say now if i cannot afford 10 ohms i will put two vrs what will be the effective resistance five five i make three vrs four vrs and i can reduce the overall resistance okay okay so see in a wire you can reduce the resistance by making wider wires yes but vias you can't do that therefore we ask our resistance alex and therefore because it is given separately the tool understands it as a separate wire so sir in the elmore delay slide that was basically a distributed network you were showing uh that was this one yeah so you can call it a distributed network you may not in the sense that uh if because i have not really shown all the different or i have not shown these three components separately to you have i i have lumped all of this into anarchy yes sir so this is not really a distributed not not purely distributed but yeah wherever there is a turn even a pio model you will have to model it like this that okay so but like what is the difference between the lumped and the distributed one the lumped was actually i'm not getting confused between that okay in lumped we have no resistance also no resistance and all the capacitors are simply added okay in distributed we are distributed considering all the resistance separately and all the capacitance separately and disability yes and then they come to an intermediate pi or a c model so like pi is like an intimate between the lambda and the distributed you can say yes okay okay yeah so the caught itself thanks we do not pay that much simulation time but we get almost similar accuracy yeah yeah yes got it okay so while three segment pi model as i mentioned is very accurate but typically single segment pi model is used okay so now we come to crosstalk you understand what crosstalk is you've heard about this term earlier so i have the question from the via part that you were saying uh like if we want lesser resistance we can add two or three vias but i have read in the course like the cost of fabricating a via is much more than the metals like is it feasible to have two or three vias in place of one to just reduce the resistance or is it a good thing like so uh if it is not leading to any increase in area okay we would usually want to have redundancy in vrs and contacts okay okay but if you not want to open overkill either for example if you make a pcell of a device which is let us say 10 micron wide you will see there are hundreds of contacts it will put automatically they can happen laser you need not use a pc at all for making your inverter layout then i have you i have used yeah yeah so when you made the p cell and you made a device of let's say four micron bits how many contacts would it put on the source and drain how that that you have told in tens of them yeah as many as it could put yes sir so that is an overkill so that leads to increase in gate capacitance get to source and get to drain capacity that we don't want to do but we definitely would want to say that okay every third contact i would want to keep or every second contact i would want to keep just so that i reduced the total capacitance between gate and these contacts polyamide contacts but uh i still i am able to reduce the resistance also okay okay so multiple or this redundancy of resistances and vr's is preferred this is in fact called as design for manufacturability dsm okay so there are checks there are checks that say that you could have put two contacts over here why did you put only one okay so there are such checks also but we have to be very judicious we have to be very careful cam overdo not okay so yes yeah so in this pi or t model when we have a very long wires then this may be true but when we have wires which branch too much then maybe this model will fail because there are parallel actually uh it is for global signals that we use the spy and t models small interconnects the resistances and capacitances are small enough see if the overall value of the delay is 10 pico seconds whether you are measuring uh it accurately at at 9.7 pico seconds or whether you are measuring it at 8 00 seconds two pico seconds to after some electricity in accuracy doesn't matter so if the delays that that could be impacted are within the accuracy of your simulator or your simulation setup you don't bother about making pi np models only when you have global signals where the interconnect delays and assemblies three the interconnect delay could be 30 to 70 percent of your critical path delay so for the big big delays we want to model them as pi or t okay so so we need accuracy when we are dealing with such long interventions yes when we're dealing with long interconnects we definitely need accuracy some accuracy okay so if you give me a circuit and say that okay this much amount of delay i have to meet so as a designer when i'm starting to look at all the topologies that i can use so how can i really use this kind of model because i don't know the length but at the time of uh schematic design so what you can do is okay this capacitance is of very high importance to me this delay is is is the longest delay so i would not want to add any wire delay into it so you say you can put commands in your schematic that make these make the layout of these devices as close to each other as possible so that when you start to lay them out you you remember okay this was an important consideration so that you can do and when making the layout but otherwise uh you cannot really do much so what we usually do is we simply add some parasitic capacitance on every every intermediate node we say okay this node this node is going from one inverter to another at least two phantom farad capacitance to i diagram so we just put some some value there so that our final delays are not far away from our initial targets based upon experience yeah based on the experience and technology characterization and stuff like that yes ma'am but what lumped does is it uh it models the same between two nodes but like uh that diagram you wish it was taking all those turns and curves and modeling it as one resistance and one capacitance yeah that's the backlog okay answer another thing you you mentioned uh mentioned a point about the number of contacts we had when we were modeling for a certain bridge of females and animals and uh how we should we should be careful not to do an overkill right so when we reduce the number of contacts i understand how that would reduce the capacitance between the poly and the contact but uh how will that affect the resistance exactly so uh you see contact resistance let us say is uh 10 ohms let us say and you made 10 contacts your resistance became 1 ohm now you reduce 5 of them one key got two okay but one is that like two is as low as one yes so you say okay let me have two let me have uh you know lesser contacts than all 10 objects the resistance doesn't have that much impact in terms of in terms of magnitude yeah because finally if it is a very big driver then the resistance of the global rc network is more important okay then there would be other constraints which could come because of the total current that this rc network has to drive for example if it's a very huge capacitance and you're talking of driving it every every clock cycle then you understand that okay if the current has to flow in every cycle then i have to be careful that even after some ageing and some degradation and resistances even after that my system will work fine so then you may want to put seven contacts instead of five so there are rules for that also there are rules linked to electro migration also so don't worry there are there these are slightly advanced topics we will possibly talk about these failure modes in the last lecture of this course okay okay but just so but in the last point you mentioned that um in that case if you if you're talking about huge driver so 10 so let us assume that 10 were the by default you got from that is the maximum contacts you can put yeah we said we will in a typical case and it is not a very big driver it will reduce from 10 to 5 or 10 to 4 but if this driver is operating every cycle if the activity rate of this driver is very high then electromigration rules may require me to put seven contacts instead of four or five so that even after aging things are fine"
-1cu0NsFpEM,okay so crosstalk so any so you know you're talking about different types of capacitances of capacitance between two adjacent wires capacitance between intermittent you know one wire above one wire below and so on so the capacitance that we were talking about or characterizing till now was static capacitance where we said that this is the total capacitance where lines of fields are there and there is no transition specifically happening in either a or b there is a constant flow of current through a through b this is a steady state value but in reality we will have our signals toggle that is where we will be able to give stimuli or you know test our circuits so let us say there is this wire a and there is this wire b and wire a grows from zero to one wire b at the same time wants to go from one to zero what would happen so because of capacitive coupling uh the other wire and the wire that is going upward would also want the other wire to go go upward and and and it would become a vice versa in the case of b1 so basically the effective capacitance that it will see between each other so it will kind of double yes so what happens is that when the transitions on the two wires are opposite in direction we understand that the effective capacitance that we will see is slightly higher than regular if everything was quiet it could have simply gone up at a particular pace but now since the other wire is going down it would slow it down as if the capacitance is higher so due to coupling because of coupling the the two wires will start to influence each other a is trying to go up b is trying to go down so because b is trying to go down due to this coupling capacitance this a will now also try to go down a bit so whatever rate at it was going up it will no longer be able to go up at the same rate it will go at a slower rate similarly it was trying to go down but a was going up so it would try to pull b also up and b will actually fall at a slower rate than what it was targeted to be able to so sir it is basically both the transition times of both the signals are getting packed in this way yes okay but transition time getting impacted essentially means for for a circuit designer that rc is increasing i know so r is not changing so what do we say that we say that due to miller effects capacitance is changing so uh when i say that a transition time when they say the capacitance is decreasing so i would that will lead to propagation right not the transition i'm not going to understand you said that what you said just you know what would be talking about 0 to 50 delay what is that transition delay to here okay okay so what we are essentially saying is that uh let us say uh you know b is constant and on a you are bringing about a transition okay the c effective is c ground plus c adjacent now if b is switching alongside a then what happens because a and b are both switching together they they do not they appear to be same wires so they see adjacent kind of vanishes from the picture okay but when they are going in opposite directions then just as we saw this sea addison kind of doubles up both try to slow each other down so what we are saying is that there is this miller capacitance factor which gets multiplied with c adjacent depending on how my other signals are behaving so sir when this when they are uh talking in opposite directions so first i take the effect of a and keep be constant so i take it as one effect and then vice versa that's why i'm saying twice basically i'm taking the effect of both a and b separately and then adding them together yeah okay okay okay so this mirror capacitance factor is something that you should be aware of when you route buyers when you you know lay wires next to each other so if you know that there are two signals which are bound to go in opposite directions you better space them apart so that's the adjacent reduces but if there are wires which will typically run together in parallel you can keep them close also excuse me sir yes mother so this constant vdd means that a and b are running same are running different currents now they're running different voltages but they are running same constant voltages so a is toggling or let us say b is stopping and a is constant the other one signal is toggling the other is constant oh okay good okay yes the pump suppose it's a very big socket and we someone is making me out and they don't know like do we need to am i doubted like that they don't know that they will be talking opposite only then uh which is do we every time have to know each and every manual detail of the very big circuit so that other personally you know sometimes for example if you were designing a memory then you know that at any given point of time only one word line will go up or at the output of the decoder only one of the signals will go to one the rim others will remain zero so some circuits you can predict at other places you may not be able to predict so when you are able to predict you do something when you are not able to predict you do something else for example if some signals capacitance you just want to be constant you will then shield it you will shield it from other place otherwise so typically memory can there for example there are two or three decoders that run parallel to each other so in between those decoding lines you know one set of decoding lines and the other set of decoding lines there is a shielding okay so that's all that we can do okay what is important is to realize that the static capacitance that you typically see is not really the only capacitance so this becomes yeah this becomes very important when you're making layouts for uh for analog circuits for example you're making circuits for a layout for plls or even sense amplifiers for that matter in a memory because there you want capacitance to be predictable but then if it can change simply because of its environment you could be at risk okay so okay yes sir uh sir can we say that breaking a large device into too many fingers can increase the crosstalk no they're clear no because for a large device breaking it into fingers uh then both a and b will always switch in parallel with each other okay because they're in parallel all these transistors that you've now made they are parallel with each other the gates are shorted sources are shorter drains are also shorted so this middle capacitance will not bother you at that time yes yeah priyanka so i want to like uh if one buyer is affecting another wire so like what is the use of minimum drc then like [Music] uh okay i ask you to draw two lines uh just uh about a pencil network one micron away from each other uh like when we make the layout like we said nothing like minimum the rc uh then if the minimum the rc is not said we get there on which basis that drc is uh that is what that is the experiment i'm asking you to do now do you have a pen and a paper with you yes so just draw two lines parallel to each other at a spacing of one micron one micron is the thickness of your hair can you make them or do you think they will start to touch each other i can't make it is like they will start to touch each other so how how how closest can you make them without touching each other so that is drc that is drc it is a drc is about manufacturability it is not about electrical behavior what we are talking about now is electrical behavior are you able to see this yeah yes yes sir you're gonna be breaking it into finger like uh they've just asked uh then in that case it is a kind of smart thing to do since uh my both the signals would go in same direction and the capacitance would eventually decrease yeah that is why we discussed breaking devices into fingers because it it it can help many times listen okay so you will see there is a sweet spot there you break it into too many fingers that also doesn't help because then the overall parasitics because of sidewall capacitance start to increase just do a experiment you will see okay you had a question yeah so what are the implications of this process implications of crosstalk um let us say you are running an analog signal which is small single in nature just toggling by four five millivolts 10 millivolts and over there you have this miller capacitance crosstalk coming into picture and the adjacent signal is a digital signal going from zero to vdd what would happen um that's four or five millivolts the real signal that you had will simply vanish you will only have the crosstalk related disturbance there noise there huh so one has to be very so we are digital cores but even in digital course we have implication on delays in an analog course you will see crosstalk is can kill your circuit completely rather so so basically this miller capacitance factor is saying that the greater it will be the greater the crosstalk will be right yes okay okay yes it's a measure of crosstalk effect you can say that so this miller capacitance is this being calculated through miller's theorem by breaking the stop capacitance into two capacitances between ground uh estimated like that yes okay okay so that can kind of brings us to a closure of devices now this was a very important section of the course where we talked about mass capacitors mos transistors and also interconnects so unless we know the bricks and uh you know the bricks and mortar that we have to use we will not be able to make houses anna so we have just understood the strength of different kinds of components the weaknesses of different components and now we will start to use them in our designs the first and the simplest design that we know of is an inverter all of you know what an inverter is what is an inverter,https://www.youtube.com/watch?v=-1cu0NsFpEM,"Link: https://www.youtube.com/watch?v=-1cu0NsFpEM
Transcript: okay so crosstalk so any so you know you're talking about different types of capacitances of capacitance between two adjacent wires capacitance between intermittent you know one wire above one wire below and so on so the capacitance that we were talking about or characterizing till now was static capacitance where we said that this is the total capacitance where lines of fields are there and there is no transition specifically happening in either a or b there is a constant flow of current through a through b this is a steady state value but in reality we will have our signals toggle that is where we will be able to give stimuli or you know test our circuits so let us say there is this wire a and there is this wire b and wire a grows from zero to one wire b at the same time wants to go from one to zero what would happen so because of capacitive coupling uh the other wire and the wire that is going upward would also want the other wire to go go upward and and and it would become a vice versa in the case of b1 so basically the effective capacitance that it will see between each other so it will kind of double yes so what happens is that when the transitions on the two wires are opposite in direction we understand that the effective capacitance that we will see is slightly higher than regular if everything was quiet it could have simply gone up at a particular pace but now since the other wire is going down it would slow it down as if the capacitance is higher so due to coupling because of coupling the the two wires will start to influence each other a is trying to go up b is trying to go down so because b is trying to go down due to this coupling capacitance this a will now also try to go down a bit so whatever rate at it was going up it will no longer be able to go up at the same rate it will go at a slower rate similarly it was trying to go down but a was going up so it would try to pull b also up and b will actually fall at a slower rate than what it was targeted to be able to so sir it is basically both the transition times of both the signals are getting packed in this way yes okay but transition time getting impacted essentially means for for a circuit designer that rc is increasing i know so r is not changing so what do we say that we say that due to miller effects capacitance is changing so uh when i say that a transition time when they say the capacitance is decreasing so i would that will lead to propagation right not the transition i'm not going to understand you said that what you said just you know what would be talking about 0 to 50 delay what is that transition delay to here okay okay so what we are essentially saying is that uh let us say uh you know b is constant and on a you are bringing about a transition okay the c effective is c ground plus c adjacent now if b is switching alongside a then what happens because a and b are both switching together they they do not they appear to be same wires so they see adjacent kind of vanishes from the picture okay but when they are going in opposite directions then just as we saw this sea addison kind of doubles up both try to slow each other down so what we are saying is that there is this miller capacitance factor which gets multiplied with c adjacent depending on how my other signals are behaving so sir when this when they are uh talking in opposite directions so first i take the effect of a and keep be constant so i take it as one effect and then vice versa that's why i'm saying twice basically i'm taking the effect of both a and b separately and then adding them together yeah okay okay okay so this mirror capacitance factor is something that you should be aware of when you route buyers when you you know lay wires next to each other so if you know that there are two signals which are bound to go in opposite directions you better space them apart so that's the adjacent reduces but if there are wires which will typically run together in parallel you can keep them close also excuse me sir yes mother so this constant vdd means that a and b are running same are running different currents now they're running different voltages but they are running same constant voltages so a is toggling or let us say b is stopping and a is constant the other one signal is toggling the other is constant oh okay good okay yes the pump suppose it's a very big socket and we someone is making me out and they don't know like do we need to am i doubted like that they don't know that they will be talking opposite only then uh which is do we every time have to know each and every manual detail of the very big circuit so that other personally you know sometimes for example if you were designing a memory then you know that at any given point of time only one word line will go up or at the output of the decoder only one of the signals will go to one the rim others will remain zero so some circuits you can predict at other places you may not be able to predict so when you are able to predict you do something when you are not able to predict you do something else for example if some signals capacitance you just want to be constant you will then shield it you will shield it from other place otherwise so typically memory can there for example there are two or three decoders that run parallel to each other so in between those decoding lines you know one set of decoding lines and the other set of decoding lines there is a shielding okay so that's all that we can do okay what is important is to realize that the static capacitance that you typically see is not really the only capacitance so this becomes yeah this becomes very important when you're making layouts for uh for analog circuits for example you're making circuits for a layout for plls or even sense amplifiers for that matter in a memory because there you want capacitance to be predictable but then if it can change simply because of its environment you could be at risk okay so okay yes sir uh sir can we say that breaking a large device into too many fingers can increase the crosstalk no they're clear no because for a large device breaking it into fingers uh then both a and b will always switch in parallel with each other okay because they're in parallel all these transistors that you've now made they are parallel with each other the gates are shorted sources are shorter drains are also shorted so this middle capacitance will not bother you at that time yes yeah priyanka so i want to like uh if one buyer is affecting another wire so like what is the use of minimum drc then like [Music] uh okay i ask you to draw two lines uh just uh about a pencil network one micron away from each other uh like when we make the layout like we said nothing like minimum the rc uh then if the minimum the rc is not said we get there on which basis that drc is uh that is what that is the experiment i'm asking you to do now do you have a pen and a paper with you yes so just draw two lines parallel to each other at a spacing of one micron one micron is the thickness of your hair can you make them or do you think they will start to touch each other i can't make it is like they will start to touch each other so how how how closest can you make them without touching each other so that is drc that is drc it is a drc is about manufacturability it is not about electrical behavior what we are talking about now is electrical behavior are you able to see this yeah yes yes sir you're gonna be breaking it into finger like uh they've just asked uh then in that case it is a kind of smart thing to do since uh my both the signals would go in same direction and the capacitance would eventually decrease yeah that is why we discussed breaking devices into fingers because it it it can help many times listen okay so you will see there is a sweet spot there you break it into too many fingers that also doesn't help because then the overall parasitics because of sidewall capacitance start to increase just do a experiment you will see okay you had a question yeah so what are the implications of this process implications of crosstalk um let us say you are running an analog signal which is small single in nature just toggling by four five millivolts 10 millivolts and over there you have this miller capacitance crosstalk coming into picture and the adjacent signal is a digital signal going from zero to vdd what would happen um that's four or five millivolts the real signal that you had will simply vanish you will only have the crosstalk related disturbance there noise there huh so one has to be very so we are digital cores but even in digital course we have implication on delays in an analog course you will see crosstalk is can kill your circuit completely rather so so basically this miller capacitance factor is saying that the greater it will be the greater the crosstalk will be right yes okay okay yes it's a measure of crosstalk effect you can say that so this miller capacitance is this being calculated through miller's theorem by breaking the stop capacitance into two capacitances between ground uh estimated like that yes okay okay so that can kind of brings us to a closure of devices now this was a very important section of the course where we talked about mass capacitors mos transistors and also interconnects so unless we know the bricks and uh you know the bricks and mortar that we have to use we will not be able to make houses anna so we have just understood the strength of different kinds of components the weaknesses of different components and now we will start to use them in our designs the first and the simplest design that we know of is an inverter all of you know what an inverter is what is an inverter"
hM594Hm2zcA,so you give an input one it gives an output zero you give an input zero it gives an output one something like this huh if so this is the bjt inverter this must be this many people would have studied in their earliest uh electronics course because bjts were are the brilliant butter of first year courses few places bjts are not even talked about people only talk about cmos only but yeah this is one one of the oldest implementation of an inverter when cmos did not exist only bjts existed so what we said was that if you increase vi what happens the current that can flow through this bjt increases and therefore v out goes to zero and this is the transfer characteristic what does it mean how how will a vi a change in vi transfer to a change in v out that's why it's called transfer characteristic clearly you cannot get a very clean 0 over here because there is some resistance of this bjt that will come into picture and also there is a continuous flow of current are you able to see this yes so not really the best way to design an inverter especially in today's technologies so we come to mos inverters let us say this is something we do so over here again you will notice that there is a continuous flow of current that will happen when the output is intended to be kept at 0. when v out is expected to be 0 then there is a continuous flow of current that will happen from vs so we move to what is called as c mass what is the beauty of cmos that when the input is 0 the pmos is on and the inverse is off so what happens once you charge the output capacitance no further current would flow you know this all of you any mirror you have a question so from our previous courses what we did was that we used to bias our bjt to a particular voltage and then at a particular bias point and then we used to give it small signal voltage as an input that's a small similar to lasting analysis then however today we'd lastly talk about small signal analysis and bjts because we know that would be similar okay in fact today we talk of even small signal on cmos only bjts are avoided because they simply have a lot of gate current and other inefficiencies in there uh but uh yeah that is probably the only place that bjts are used for analog circuits where small signals have to be handled very carefully you need lots of gain and everything you can't do without a bjt then answer what uh what were the disadvantages we were facing uh like in the previous slide when we use mosfet technology for example so yeah what were the problems we were facing responsibilities i put a one over here so what happens uh this device is fully on it will sync current and this will continue to provide current so there's a short circuit path so when the output is intended to be zero there's a short circuit path so again when the pmos was not being able to be manufactured this was still better than bjt but now that we also have pmosses we only use cmos okay and this this part one on the right you already know very well isn't it we've discussed this in detail what is this the layout layout of an inverter and there could be another layout of the inverter where so if you want to connect two layouts to inverters uh you simply abut them you know so we discussed abutment you simply about them and the output of one you short to the input of the other and bingo you have the output there in fact b already exists you only need to make this connection and your two inverters are connected into a buffer vdd and ground already shared because they get connected like this they're able to relate this we've already discussed this in the class in the class also office hours also multiple times and this is the inverter with a strap where we say that okay i will also have a strap within the standard cell and we already agreed that this is no longer a good idea because you see this this kind of height is wasted so we said that no we will not do that we will in fact have it like this only where the straps will be added later you remember this uh sir in this in this on lisa how is this what is the strap part here in this this part yeah okay so this is the n mass but you notice they have a n plus over here instead of p plus yeah yeah yes so this becomes the strap connection yes so what would happen in uh normal standard cell would be that if metal would be running over the ground and at some place along the line the staff would be placed and it would not occupy a specific area like it is occupying here into that correct so for example if i have to put a strap i will simply add a strap cell here and over here there will be what do you say the substrate connection for the pmos substrate inverse substrate connection for the pivot and the vdd on ground will go ahead like this and then you will have another cell that would you could put over here and so on so um did i did i answer you or did i answer something else completely uh sir okay i got i got it i got my bike yes okay sir i have a question once instead yes sir here you have drawn od uh the yellow one and green one so in that od you have made a l type of cut so so this l type of cuts and would this be feasible in that technology that yes yeah yeah you can't do that we would want you to avoid it in advanced technologies we would want you to avoid it but in earlier technologies just to reduce the source and drain capacitance source and drain leakage basically reducing the source drain area we would do that no it's no challenges we can't do that in 65 you can't do that okay enter in 18 you will not be allowed to do this sir in the next slide that you show this trap so there there you are drawing a np layer and pp they're very very small yes but sir it has a minimum drc of minimum area so can we draw it inside like that very very small no so this is this is for a still older technology you may say this is a one micron technology you see lam or this is 0.6 micron technology i know this is very old technology in those technologies it was possible that was the way it was designed okay the way i said hello when do we use these two those two inverters two inverters yeah buffer to make a buffer yeah yeah back the two inverters right one after the other so that we have a buffer and reducing the so the substrate resistance yeah so the straps are providing the vdd and ground connections to the substrates okay um so this is for substrate connections straps are substrate connections it was in middle previously i'm sorry that that police silicon was in middle and the red car in the previous market now it moves to left side is there any specific reason no no no specific reason this is the kind of layout you will use today this is just how it was used to it it could have been done and was used was probably done earlier today you will see that uh poly will only be vertical you will not be even allowed to route poly in two directions so that this is the layout you will end up using anyway earlier okay people thought that okay you know i will simply make i i don't even need to make an extra virus you see the out is going out till here and the n is also connected by material to here you just above them and they get connected so that was the intent at some point of time but not really needed moreover they wanted to make buttered straps so source kasathi they just butted the strap region uh today straps are not handled like this at all so it's it's really not a challenge okay tyler uh on the inverter when we were drawing a single inverter i think you were explaining the circuit of the inverter with p was inverse so can you please explain the circuit so a bit of pmos and nmos yes sir you're talking about response time or something like that uh yes sir so you were explaining the capacitor will charge and then someone asks doubt don't worry you will not miss anything yeah this circuit huh i think you were actually saying that when the input is zero the pmos is on nmos is off yes so the capacitor will charge and that's it no further current i know whereas in bjt and mosfet the most mass inverters there were there was a continuous flow of current yes so that is the beauty of cmos okay so so that's it current goes only during the transition transient period after that and before that current is zero whereas in bjts and other places the current will flow for uh continuously is when your input is let us say one or zero whatever okay okay thank you yeah uh rajneesh you have a question uh yes sir sir in the previous lecture uh sir when uh i was doing some uh the custom layout in that when over the od when i was doing this making the source and the trend then sir this non-buttered error was coming drc so sir i was not able to figure out that what was the mistake in that drc was coming that it is non-butted so i was not able to clear itself non-buttered drc was coming yes sir it was written did you did you strap did you put the proper straps on your circuit and everything yes sir but yes sir your scraps are put in yes so i don't know what exactly this would mean so just check the language and uh okay so okay i'll figure it out yeah okay okay yeah so now we come to the dc response what do you mean by dc response so i mean we give input as a dc signal and we see this response by the circuit yeah in the dc domain itself if my input is held constant at a particular voltage level at what voltage my output would be held at that is my dc response i'm not talking about transitioning from 0 to 1 i'm talking about if my input is at say 200 millivolts where will my output be for example we are saying when vn is equal to zero the output uh when v is equal to zero or v equal to vdd the output will be vdd or output will be zero that is dc huh and in between these it depends on the transistor size and current such that the current from the nmos and pmos is balanced are you with me over here in dc current any capacitance or anything else doesn't even come into picture because talking about all transient being taken care of and now where does the value stabilize so what do you mean by the balancing of this uh ids these uh pmos current inverse current you tell me there is this node what is the kirchhoff's current law according to this node incoming what does scripture of current law say some incoming is close to outgoing yeah so where all the current could be coming in here and going up from here only these two nmos and p master yeah yes sir so we are saying that kirchhoff's current law cannot be violated okay okay that is all nothing else okay so uh let us look at this this much you know you know what is the cutoff region uh what is the linear region for the nmos what is the saturated region for the nmos and the pmos also so pmos is simply the duel of this you remember this much yes sir huh so uh yeah the bms is simply the dual of that and mos volatility if they try to make the current curves i ids curves uh ids vds curves for different various values this is something what you would get provided that you are saying that beta n is equal to beta p so vg vgs p5 will be equal to or the current at vdsp5 and magnitude will be equal to current at vgsn5 is this okay so beta factor is here beta factor is that over here we are saying that current at a particular vds has been equalized by changing the width by making the pmos wider there is a ratio of mobility the pmos has lower mobility the the holes in the pmos the carriers in the pmos have lower mobility than the carriers in the nmos so that you compensate by making the pmus wider so that overall beta that comes in the current equation is equal this beta is k and c x yeah and also includes w and l into it so actually i'm not able to get what exactly we know beta here like u so this current what is the current equation yeah w and w by l and then vgs minus vp the whole square something all this is being put as beta okay okay fine again okay so we're simply saying that you size the p mass up in such a way that k so this is what this is how your ids vds curves would look like yes sir huh so if we now plot them for a circuit per say what would happen we said ids and id ids n and idst should be equal that is where i will get to know where my device is in different positions am i right that is what we said so i would essentially need to plot ids n and absolute value of ids p1 over the other to get something like this are you with me huh the y axis is uh it's a ratio like there are two different values like comma it's a comma comma comma okay okay we already said that beta n is equal to beta p you're just going forward from there okay okay so what happens now we start to say that for a given ids n and idsp what will be the value of v out can we make that thing out so v out is all those points where the current values are equal can we say this hello listen so how does this become this appear then so the first point is let us say uh so where are the values see there is one intersection happening here are you able to see that then there is another intersection happening here another happening here and so on so if we start to plot it like this then this is the way our inter intersections would play out at different values of v in see what am i doing i'm changing the value of v in at different values of v in different curves would come into picture there is this curve for the n mass and this curve for the p mass huh so where do they intersect at a value of v in they intersect at almost vdd so v out will be almost vdd when we are when vn is equal to 0.2 when v in goes to 0.4 these are the two curves that come into picture and my v out will be almost equal to vdd though not equal to vdd slightly lesser than vdd there you go to vn equal to 0.6 and you see array the intersection point now has come to almost zero to go to point eight it is act zero so now when you plot when now when you plot it you see that okay v in zero v in one v in two mean three v in four v in five and you get what you call as the transfer characteristic of your inverter are you able to see this any questions so what will happen at vdd by 2 like when we have it is not zero or vtd yeah so our vdd by two we would probably have had this point yes sir so what's with the output when v is is that for different bean values we plotted the ids curve for the pmos and mass and then the intersection points is the second graph right the red one yes we plotted the intersection points over here and then we started i can simply plot them over here that is my v out yeah yeah i got it sir that is how you make the transfer characteristics yeah and the intersection point was coming because of the kids of lawn mitsubi because of intersection of being one for uh p mos and v in one for the n mass yeah the current has to be equal right yes currents have to be kcl yeah yes goddess thank you so uh yes so in the left graph what were we plotting on x axis and y x now on y axis particularly on the left side graph this is current na ids in an [Music] vn is equal to vds value see this this characteristic that you see is for different values of vts is it not yes sir but for any mean value there will only be one of these lines valid yes so for any v in value there is just one of these lines which is valid that is what we are showing okay huh so now at different points abcdef abcde where are my different transistors so at a my nmos is in cut off cmos is in linear and you can actually put this fill this entire table like this can you verify this table is filled correctly any questions any confusion around it sure uh i have a confusion in region b and d and the region b and d where we are say uh saying that region b and d yes sir so do we want to go back to the curves once again and see yes sir so region b is when your v in is uh between vdd by two and uh vtn so let us say it is point four vdd is it okay point four curve decay so you see what is happening my n mass isn't clearly in saturation what about my p mass isn't linear okay anna sir one more oh okay okay understood sir oh i had one more question also that looking at the point in the graph we can also predict the amount of current that could be flowing right yeah or the distance was not the ideal value vertical axis that is the amount of current that is flowing okay yes so what is the amount of current that is flowing now tell me certain b and d the current uh through the nmos would be very low so when the input is at vdd by two when the input is rpd by two okay so this is your current pump so there is no current when the input was zero or when the input was one only when the transition was happening there was some current yes okay thank you sir sir in this current one so when we had in the points b and b then basically the pmos and or either of the female 7 was in linear right so the current so i mean if except for when both are in cut off then some current would be flowing so i am not able to understand this curve actually so let us look at it over here quran so at different at this value then my let us say this is point a v n is equal to 0.2 is point a what is the value of current it's almost zero yeah i go to point b what is the value of current now okay right okay this is the value now it is not zero it is more than zero now if i had a bean is equal to 0.5 you will see that uh it would be somewhere here the point of intersection would have been somewhere here but both yes see this is very important uh those of you who are mtext students you probably already realize that you never got to see an inverter like this ever earlier did you yes sir huh so almost nowhere you will see inverter being taught in such detail and with such uh you know uh cut off the saturation but this is very important for you to understand even though we are talking about digital circuits uh if you do not understand where your device is operating in for example you will not know how to make a capacitance capacitance so these concepts are really important they will really help you become good circuit designers so is cheesecake rma please be very comfortable with it i can give you uh another circuit and ask you keep onsite device saturation may have and and stuff like that typically interviews so good designers when they interview you you will they will typically end up asking you the transfer characteristics of an inverter somewhere in one question or another okay so please be very well versed with this idea so we have covered two critical concepts please practice and this concept also i'm saying that we have covered it in class we are covering it i am trying to resolve all your queries but even if you get queries again at home you can read the book you can review the lecture again but please be very clear about this concept yes there was a question yes sir so so when both the devices like nmos and pmos are in saturation i am seeing that i have the max amount of current so that means that this will be the point that will be associated with the maximum power dissipation kind of the most powerful right so like but what exactly is the utility of this region i mean i'm getting it but uh is it like because so this power is static power or the dynamic power for example this power what will how would i we're talking about dc analysis so there's nothing dynamic can yet yet okay so it's static power only if you will bias your inverter at this point it will consume the maximum current but do you realize it is also the most sensitive a small change in invert input one millivolt here or one millivolt there the output will change swing by 100 millivolts yeah yes sir that's the importance of this point okay so like uh for example like generally sena key the cmos uh inverter has zero static power dissipation it has only dynamic thing but from here i can see that no there is some dissipation because we are over here talking about using an inverter as an amplifier you see that is what i'm saying if you put a small signal at c what happens output would travel from uh you just toggle the input from plus minus three millivolts output will toggle by plus minus three hundred millivolts yeah it's amplifying 100 times so when you want to use the inverter as an amplifier then amplifier will consume current but otherwise if you want to use it as a digital logic then you don't need to worry about the c point c point will just come and go like this it's so fast okay so so like for me the v in for example if i have to do for the digital circuit so the v in will be the basically the biasing voltage which is circuit vn will simply come come from zero and go to vdd and let us say hundred picoseconds so within hundred picoseconds this abcde would have already moved okay so but still this current this curve will get now right so the area will come and go to the combination so you can possibly plot it with time you can do it like this so uh i say that uh sna so what i a typical question that i ask in interviews i would ask in interviews would be that these are a b c d e this is my input and this is time access okay i would ask people to plot the current waveform with respect to time what would you do the plot would actually come like this only yeah this is just a different way of putting the question now you notice that if i improve the input slope what happens then this area would be much lesser yes okay right this value remains same but the charge that i consume that i waste reduces significantly that is where when we will talk about power later in this course we will talk about using good rise time and fall time yeah so so the the y axis basically would be remain the same but the x axis the time and the bits would decrease yeah yeah if you have good rise time and fall time you can reduce overall charge consumed in this transition because you have reduced the pulse width for this current curve yeah yes sir okay yes got it sir so this is something we will anyways cover later but concept should augment clarify career the concept should be clear for everyone now mother you have a question yes sir so why were we talking about biasing in this circuit when we are making a digital inverter no because if we want to make an amplifier out of an inverter then we want to talk about biasing also yes and what is an inverter it can operate like anything okay so so when we are making use of this inverter as a common source amplifier then we are talking about biasing not just a common source is simply saying huh an amplifier okay and in digital we won't pay much attention to this c region we will just go from a to e directly so if your input slope is bad as in the top timing curve yes sir then the c region also becomes very important because that c region would also exist for a long time it will define the total current consumption now yes sir so if your input is rising very very slowly or falling very very slowly then the c region also is there for a long time then this kind of becomes time access so the charge that you consume that is transferred from vdg to ground that is wasted increases and our power increases so c region doesn't seem to be appearing for a very long time it is just a if this is my curve time this is if this is my input waveform with respect to time then the c region is going to be there for a longer time now in comparison to here yes yes yeah that is what i'm talking about okay okay yes yes yes can we also uh change this uh width of this current loop by changing changing the width of the mosfets yes obviously because as soon as you change the width of the mosfets uh ids and vds would change the whole you know ideas and vds are dependent on width is dependent on width of the device yes so sir i have confusion in this thing only that let's say that i want this to be a very very fast transition uh inverter so ico can increase uh pretty much by some amount and i increase the inverse width by something so basically after increasing the width of the pmos and mass although this uh transition is very very fast but but the current has also increased so basically i i will now have more current through my mosfets this is the input transition not the output transition there is some other inverter driving v in now to get a good slope on vn you have to increase the size of this inverter talking about the rise and fall time of the input of the input now so that input riser falls [Music] [Laughter] there is a logical effort velocity will come to that and probably the next class,https://www.youtube.com/watch?v=hM594Hm2zcA,"Link: https://www.youtube.com/watch?v=hM594Hm2zcA
Transcript: so you give an input one it gives an output zero you give an input zero it gives an output one something like this huh if so this is the bjt inverter this must be this many people would have studied in their earliest uh electronics course because bjts were are the brilliant butter of first year courses few places bjts are not even talked about people only talk about cmos only but yeah this is one one of the oldest implementation of an inverter when cmos did not exist only bjts existed so what we said was that if you increase vi what happens the current that can flow through this bjt increases and therefore v out goes to zero and this is the transfer characteristic what does it mean how how will a vi a change in vi transfer to a change in v out that's why it's called transfer characteristic clearly you cannot get a very clean 0 over here because there is some resistance of this bjt that will come into picture and also there is a continuous flow of current are you able to see this yes so not really the best way to design an inverter especially in today's technologies so we come to mos inverters let us say this is something we do so over here again you will notice that there is a continuous flow of current that will happen when the output is intended to be kept at 0. when v out is expected to be 0 then there is a continuous flow of current that will happen from vs so we move to what is called as c mass what is the beauty of cmos that when the input is 0 the pmos is on and the inverse is off so what happens once you charge the output capacitance no further current would flow you know this all of you any mirror you have a question so from our previous courses what we did was that we used to bias our bjt to a particular voltage and then at a particular bias point and then we used to give it small signal voltage as an input that's a small similar to lasting analysis then however today we'd lastly talk about small signal analysis and bjts because we know that would be similar okay in fact today we talk of even small signal on cmos only bjts are avoided because they simply have a lot of gate current and other inefficiencies in there uh but uh yeah that is probably the only place that bjts are used for analog circuits where small signals have to be handled very carefully you need lots of gain and everything you can't do without a bjt then answer what uh what were the disadvantages we were facing uh like in the previous slide when we use mosfet technology for example so yeah what were the problems we were facing responsibilities i put a one over here so what happens uh this device is fully on it will sync current and this will continue to provide current so there's a short circuit path so when the output is intended to be zero there's a short circuit path so again when the pmos was not being able to be manufactured this was still better than bjt but now that we also have pmosses we only use cmos okay and this this part one on the right you already know very well isn't it we've discussed this in detail what is this the layout layout of an inverter and there could be another layout of the inverter where so if you want to connect two layouts to inverters uh you simply abut them you know so we discussed abutment you simply about them and the output of one you short to the input of the other and bingo you have the output there in fact b already exists you only need to make this connection and your two inverters are connected into a buffer vdd and ground already shared because they get connected like this they're able to relate this we've already discussed this in the class in the class also office hours also multiple times and this is the inverter with a strap where we say that okay i will also have a strap within the standard cell and we already agreed that this is no longer a good idea because you see this this kind of height is wasted so we said that no we will not do that we will in fact have it like this only where the straps will be added later you remember this uh sir in this in this on lisa how is this what is the strap part here in this this part yeah okay so this is the n mass but you notice they have a n plus over here instead of p plus yeah yeah yes so this becomes the strap connection yes so what would happen in uh normal standard cell would be that if metal would be running over the ground and at some place along the line the staff would be placed and it would not occupy a specific area like it is occupying here into that correct so for example if i have to put a strap i will simply add a strap cell here and over here there will be what do you say the substrate connection for the pmos substrate inverse substrate connection for the pivot and the vdd on ground will go ahead like this and then you will have another cell that would you could put over here and so on so um did i did i answer you or did i answer something else completely uh sir okay i got i got it i got my bike yes okay sir i have a question once instead yes sir here you have drawn od uh the yellow one and green one so in that od you have made a l type of cut so so this l type of cuts and would this be feasible in that technology that yes yeah yeah you can't do that we would want you to avoid it in advanced technologies we would want you to avoid it but in earlier technologies just to reduce the source and drain capacitance source and drain leakage basically reducing the source drain area we would do that no it's no challenges we can't do that in 65 you can't do that okay enter in 18 you will not be allowed to do this sir in the next slide that you show this trap so there there you are drawing a np layer and pp they're very very small yes but sir it has a minimum drc of minimum area so can we draw it inside like that very very small no so this is this is for a still older technology you may say this is a one micron technology you see lam or this is 0.6 micron technology i know this is very old technology in those technologies it was possible that was the way it was designed okay the way i said hello when do we use these two those two inverters two inverters yeah buffer to make a buffer yeah yeah back the two inverters right one after the other so that we have a buffer and reducing the so the substrate resistance yeah so the straps are providing the vdd and ground connections to the substrates okay um so this is for substrate connections straps are substrate connections it was in middle previously i'm sorry that that police silicon was in middle and the red car in the previous market now it moves to left side is there any specific reason no no no specific reason this is the kind of layout you will use today this is just how it was used to it it could have been done and was used was probably done earlier today you will see that uh poly will only be vertical you will not be even allowed to route poly in two directions so that this is the layout you will end up using anyway earlier okay people thought that okay you know i will simply make i i don't even need to make an extra virus you see the out is going out till here and the n is also connected by material to here you just above them and they get connected so that was the intent at some point of time but not really needed moreover they wanted to make buttered straps so source kasathi they just butted the strap region uh today straps are not handled like this at all so it's it's really not a challenge okay tyler uh on the inverter when we were drawing a single inverter i think you were explaining the circuit of the inverter with p was inverse so can you please explain the circuit so a bit of pmos and nmos yes sir you're talking about response time or something like that uh yes sir so you were explaining the capacitor will charge and then someone asks doubt don't worry you will not miss anything yeah this circuit huh i think you were actually saying that when the input is zero the pmos is on nmos is off yes so the capacitor will charge and that's it no further current i know whereas in bjt and mosfet the most mass inverters there were there was a continuous flow of current yes so that is the beauty of cmos okay so so that's it current goes only during the transition transient period after that and before that current is zero whereas in bjts and other places the current will flow for uh continuously is when your input is let us say one or zero whatever okay okay thank you yeah uh rajneesh you have a question uh yes sir sir in the previous lecture uh sir when uh i was doing some uh the custom layout in that when over the od when i was doing this making the source and the trend then sir this non-buttered error was coming drc so sir i was not able to figure out that what was the mistake in that drc was coming that it is non-butted so i was not able to clear itself non-buttered drc was coming yes sir it was written did you did you strap did you put the proper straps on your circuit and everything yes sir but yes sir your scraps are put in yes so i don't know what exactly this would mean so just check the language and uh okay so okay i'll figure it out yeah okay okay yeah so now we come to the dc response what do you mean by dc response so i mean we give input as a dc signal and we see this response by the circuit yeah in the dc domain itself if my input is held constant at a particular voltage level at what voltage my output would be held at that is my dc response i'm not talking about transitioning from 0 to 1 i'm talking about if my input is at say 200 millivolts where will my output be for example we are saying when vn is equal to zero the output uh when v is equal to zero or v equal to vdd the output will be vdd or output will be zero that is dc huh and in between these it depends on the transistor size and current such that the current from the nmos and pmos is balanced are you with me over here in dc current any capacitance or anything else doesn't even come into picture because talking about all transient being taken care of and now where does the value stabilize so what do you mean by the balancing of this uh ids these uh pmos current inverse current you tell me there is this node what is the kirchhoff's current law according to this node incoming what does scripture of current law say some incoming is close to outgoing yeah so where all the current could be coming in here and going up from here only these two nmos and p master yeah yes sir so we are saying that kirchhoff's current law cannot be violated okay okay that is all nothing else okay so uh let us look at this this much you know you know what is the cutoff region uh what is the linear region for the nmos what is the saturated region for the nmos and the pmos also so pmos is simply the duel of this you remember this much yes sir huh so uh yeah the bms is simply the dual of that and mos volatility if they try to make the current curves i ids curves uh ids vds curves for different various values this is something what you would get provided that you are saying that beta n is equal to beta p so vg vgs p5 will be equal to or the current at vdsp5 and magnitude will be equal to current at vgsn5 is this okay so beta factor is here beta factor is that over here we are saying that current at a particular vds has been equalized by changing the width by making the pmos wider there is a ratio of mobility the pmos has lower mobility the the holes in the pmos the carriers in the pmos have lower mobility than the carriers in the nmos so that you compensate by making the pmus wider so that overall beta that comes in the current equation is equal this beta is k and c x yeah and also includes w and l into it so actually i'm not able to get what exactly we know beta here like u so this current what is the current equation yeah w and w by l and then vgs minus vp the whole square something all this is being put as beta okay okay fine again okay so we're simply saying that you size the p mass up in such a way that k so this is what this is how your ids vds curves would look like yes sir huh so if we now plot them for a circuit per say what would happen we said ids and id ids n and idst should be equal that is where i will get to know where my device is in different positions am i right that is what we said so i would essentially need to plot ids n and absolute value of ids p1 over the other to get something like this are you with me huh the y axis is uh it's a ratio like there are two different values like comma it's a comma comma comma okay okay we already said that beta n is equal to beta p you're just going forward from there okay okay so what happens now we start to say that for a given ids n and idsp what will be the value of v out can we make that thing out so v out is all those points where the current values are equal can we say this hello listen so how does this become this appear then so the first point is let us say uh so where are the values see there is one intersection happening here are you able to see that then there is another intersection happening here another happening here and so on so if we start to plot it like this then this is the way our inter intersections would play out at different values of v in see what am i doing i'm changing the value of v in at different values of v in different curves would come into picture there is this curve for the n mass and this curve for the p mass huh so where do they intersect at a value of v in they intersect at almost vdd so v out will be almost vdd when we are when vn is equal to 0.2 when v in goes to 0.4 these are the two curves that come into picture and my v out will be almost equal to vdd though not equal to vdd slightly lesser than vdd there you go to vn equal to 0.6 and you see array the intersection point now has come to almost zero to go to point eight it is act zero so now when you plot when now when you plot it you see that okay v in zero v in one v in two mean three v in four v in five and you get what you call as the transfer characteristic of your inverter are you able to see this any questions so what will happen at vdd by 2 like when we have it is not zero or vtd yeah so our vdd by two we would probably have had this point yes sir so what's with the output when v is is that for different bean values we plotted the ids curve for the pmos and mass and then the intersection points is the second graph right the red one yes we plotted the intersection points over here and then we started i can simply plot them over here that is my v out yeah yeah i got it sir that is how you make the transfer characteristics yeah and the intersection point was coming because of the kids of lawn mitsubi because of intersection of being one for uh p mos and v in one for the n mass yeah the current has to be equal right yes currents have to be kcl yeah yes goddess thank you so uh yes so in the left graph what were we plotting on x axis and y x now on y axis particularly on the left side graph this is current na ids in an [Music] vn is equal to vds value see this this characteristic that you see is for different values of vts is it not yes sir but for any mean value there will only be one of these lines valid yes so for any v in value there is just one of these lines which is valid that is what we are showing okay huh so now at different points abcdef abcde where are my different transistors so at a my nmos is in cut off cmos is in linear and you can actually put this fill this entire table like this can you verify this table is filled correctly any questions any confusion around it sure uh i have a confusion in region b and d and the region b and d where we are say uh saying that region b and d yes sir so do we want to go back to the curves once again and see yes sir so region b is when your v in is uh between vdd by two and uh vtn so let us say it is point four vdd is it okay point four curve decay so you see what is happening my n mass isn't clearly in saturation what about my p mass isn't linear okay anna sir one more oh okay okay understood sir oh i had one more question also that looking at the point in the graph we can also predict the amount of current that could be flowing right yeah or the distance was not the ideal value vertical axis that is the amount of current that is flowing okay yes so what is the amount of current that is 
flowing now tell me certain b and d the current uh through the nmos would be very low so when the input is at vdd by two when the input is rpd by two okay so this is your current pump so there is no current when the input was zero or when the input was one only when the transition was happening there was some current yes okay thank you sir sir in this current one so when we had in the points b and b then basically the pmos and or either of the female 7 was in linear right so the current so i mean if except for when both are in cut off then some current would be flowing so i am not able to understand this curve actually so let us look at it over here quran so at different at this value then my let us say this is point a v n is equal to 0.2 is point a what is the value of current it's almost zero yeah i go to point b what is the value of current now okay right okay this is the value now it is not zero it is more than zero now if i had a bean is equal to 0.5 you will see that uh it would be somewhere here the point of intersection would have been somewhere here but both yes see this is very important uh those of you who are mtext students you probably already realize that you never got to see an inverter like this ever earlier did you yes sir huh so almost nowhere you will see inverter being taught in such detail and with such uh you know uh cut off the saturation but this is very important for you to understand even though we are talking about digital circuits uh if you do not understand where your device is operating in for example you will not know how to make a capacitance capacitance so these concepts are really important they will really help you become good circuit designers so is cheesecake rma please be very comfortable with it i can give you uh another circuit and ask you keep onsite device saturation may have and and stuff like that typically interviews so good designers when they interview you you will they will typically end up asking you the transfer characteristics of an inverter somewhere in one question or another okay so please be very well versed with this idea so we have covered two critical concepts please practice and this concept also i'm saying that we have covered it in class we are covering it i am trying to resolve all your queries but even if you get queries again at home you can read the book you can review the lecture again but please be very clear about this concept yes there was a question yes sir so so when both the devices like nmos and pmos are in saturation i am seeing that i have the max amount of current so that means that this will be the point that will be associated with the maximum power dissipation kind of the most powerful right so like but what exactly is the utility of this region i mean i'm getting it but uh is it like because so this power is static power or the dynamic power for example this power what will how would i we're talking about dc analysis so there's nothing dynamic can yet yet okay so it's static power only if you will bias your inverter at this point it will consume the maximum current but do you realize it is also the most sensitive a small change in invert input one millivolt here or one millivolt there the output will change swing by 100 millivolts yeah yes sir that's the importance of this point okay so like uh for example like generally sena key the cmos uh inverter has zero static power dissipation it has only dynamic thing but from here i can see that no there is some dissipation because we are over here talking about using an inverter as an amplifier you see that is what i'm saying if you put a small signal at c what happens output would travel from uh you just toggle the input from plus minus three millivolts output will toggle by plus minus three hundred millivolts yeah it's amplifying 100 times so when you want to use the inverter as an amplifier then amplifier will consume current but otherwise if you want to use it as a digital logic then you don't need to worry about the c point c point will just come and go like this it's so fast okay so so like for me the v in for example if i have to do for the digital circuit so the v in will be the basically the biasing voltage which is circuit vn will simply come come from zero and go to vdd and let us say hundred picoseconds so within hundred picoseconds this abcde would have already moved okay so but still this current this curve will get now right so the area will come and go to the combination so you can possibly plot it with time you can do it like this so uh i say that uh sna so what i a typical question that i ask in interviews i would ask in interviews would be that these are a b c d e this is my input and this is time access okay i would ask people to plot the current waveform with respect to time what would you do the plot would actually come like this only yeah this is just a different way of putting the question now you notice that if i improve the input slope what happens then this area would be much lesser yes okay right this value remains same but the charge that i consume that i waste reduces significantly that is where when we will talk about power later in this course we will talk about using good rise time and fall time yeah so so the the y axis basically would be remain the same but the x axis the time and the bits would decrease yeah yeah if you have good rise time and fall time you can reduce overall charge consumed in this transition because you have reduced the pulse width for this current curve yeah yes sir okay yes got it sir so this is something we will anyways cover later but concept should augment clarify career the concept should be clear for everyone now mother you have a question yes sir so why were we talking about biasing in this circuit when we are making a digital inverter no because if we want to make an amplifier out of an inverter then we want to talk about biasing also yes and what is an inverter it can operate like anything okay so so when we are making use of this inverter as a common source amplifier then we are talking about biasing not just a common source is simply saying huh an amplifier okay and in digital we won't pay much attention to this c region we will just go from a to e directly so if your input slope is bad as in the top timing curve yes sir then the c region also becomes very important because that c region would also exist for a long time it will define the total current consumption now yes sir so if your input is rising very very slowly or falling very very slowly then the c region also is there for a long time then this kind of becomes time access so the charge that you consume that is transferred from vdg to ground that is wasted increases and our power increases so c region doesn't seem to be appearing for a very long time it is just a if this is my curve time this is if this is my input waveform with respect to time then the c region is going to be there for a longer time now in comparison to here yes yes yeah that is what i'm talking about okay okay yes yes yes can we also uh change this uh width of this current loop by changing changing the width of the mosfets yes obviously because as soon as you change the width of the mosfets uh ids and vds would change the whole you know ideas and vds are dependent on width is dependent on width of the device yes so sir i have confusion in this thing only that let's say that i want this to be a very very fast transition uh inverter so ico can increase uh pretty much by some amount and i increase the inverse width by something so basically after increasing the width of the pmos and mass although this uh transition is very very fast but but the current has also increased so basically i i will now have more current through my mosfets this is the input transition not the output transition there is some other inverter driving v in now to get a good slope on vn you have to increase the size of this inverter talking about the rise and fall time of the input of the input now so that input riser falls [Music] [Laughter] there is a logical effort velocity will come to that and probably the next class"
L69CwjaRr2g,what were we discussing in the last class it's a dc transfer characteristics dc transfer characteristics often of a cmos inverter okay what does this mean for different values of v in what will be the v out and the input is stable and the output is expected to be stable am i right yes this is something like a bias current simulation see what is the what will be the current flowing what will be the uh what will be the state of my system if my vn is at some particular level okay and we saw that at different values of vn my system uh you know some devices were in cutoff or linear or saturation and so on due to which i had a certain certain kind of a current waveform arising out of it you remember that we said that in this thing the current will be like very high over here and then at e again it will be zero you remember this yes and we also said that while this is a v in over v out kind of a curve you could also have it as a uh v out over uh timing kind of a curve you remember that that i could actually say that my v in is moving like this so this is point a this is point b this is point c this is point d and this is point e so what happens the current at a is is plotted here current at b is plotted here current at c is plotted here current at d is plotted here and then current at e is spotted here and i can get actually the timing waveform for the current also from this curve itself if i have the timing waveform of the input are you able to see this we discussed this part also yes and we also discussed that that this is one reason why we want the ice time and fall times to be sharp to be steep so that we have lesser current flowing through the system or the lesser duration for which this very high current would flow you remember this yes sir now so let us keep this learning uh with us we will pick it up in just a little while when we talk about transient analysis but we will not talk about the same thing again we will talk about other aspects of transient analysis but this is something which you should be able to do for transient analysis also okay now tell me one thing in this curve if we had assumed that beta n is equal to beta p you remember yes sir and that is why the c or this this inflection point was coming at almost like vdd by 2. now what would happen if i change if i make beta n stronger than beta p it will fall down faster it will fall down faster so this is not a time now this is v out by v so what happens to this curve i think it will shift it will shift towards left not with what happens if i make beta p is greater than much greater than beta n right right yeah so uh such curves you know such transistors which we have such inverters or such gates where we have uh beta n not equal to beta p you would notice that the the infection point will be on either side of vdd by two okay these are called skewed gates there is importance there is a relevance for these gates we will look at that a little later in the course but i just want you to keep that in your mind you know park it for yourself that this is how uh like this this characteristic that we just did can be used to represent skewed gates also and this vowed by v incur can be used to actually represent any other gate also just that because of different beta ratio your curve could be over here or over here so are you able to see this yes sir yes so what do you mean by the other gates and this like nand gate nor gate xor gate five input nand gate two input nand gate three input nand gate all the various range of gates that you may want to use in your designs later so both of the all these gates will have these kind of characteristics only yeah all these girls will have v out by v in characteristic is it not same okay the trend would be the same not same because beta ratio will be different they will have slightly different but the trend would be same right yeah so the intent the intent to say is that uh you will be able to like by using exactly the same method as we used for the inverter you should be able to build transfer characteristics for any other gate also so sir like can i also say that with the inverter itself the inverter structure only if i change the data ratios in the inverted structure i can get the different characteristics of the other gates also this is what you're saying i mean here i'm not saying that what i'm saying is that if you change the beta ratio you will get different characteristics what i'm also saying is that by using the same method you can build characteristics of other gates also which if they are inverting gates would be very similar to the inverter characteristics if they are non-inverting gates the characteristics would be different but by using the same method you can arrive at transfer characteristics of any curve lining so like you did with the current graph like intersecting points okay so but like what is the relevance of this changes beta ratio i mean as a designer why i'm looking at this because so as i mentioned we will cover it later also but since there is a question uh see at times you may want my inverter to not switch so the next slide will see at times for example if you look at this over here suppose this is the characteristic that that we have designed for our inverter now what happens let v in change by even this much value v in can now change by this much value but output will not change are you able to see this okay so so that can also discover itself it will mean that uh the pmos will be like the for pmos to be pmos and uh nmos current to be equal the pull down so that means the linear current of n must be sufficient to counter the circuit energy current of the p noise so fast for this particular curve the p mass is much bigger than the n mass okay so the saturation current of the n mass will be more than easily encountered taken care of by the linear current of the p mass yeah yeah yes okay so now what has happened my low noise margin i have increased but what happened to the high noise margin now if my input was at one over here even a small blip would mean my output will go to 1. so my higher noise margin has reduced okay yeah that's the relevance of this bit direction yeah so if you change the skew ratio if you change the skewing and the beta ratio then you will essentially end up changing the noise margins that your gate would have okay we'll just come to that in the meanwhile i saw that someone had a question you had a question so so i understood uh if beta p is greater than beta and then the curve is shifting towards right and uh also it is shifting towards left but is much greater than beta n then the saturation current of nmos is much lesser than even the linear current of pmos [Music] so even with the you know even though nmos is trying to sync as much current as it can the linear current of the pmos is so high that it kind of does not allow the output capacitance to discharge okay okay we are not doing transient analysis yet but what we are saying is that the uh the current of the pmos in the linear region is so high that n mass even in saturation cannot sink more current okay that is where my characteristics become something like this yes i can can you please explain this low noise and high noise yeah i will just come to that i will just know there's a separate site for that okay sir uh yes sir sir so you were saying that with the no i said by using the method of how we built the inverter characteristics we should be able to build characteristics okay so we're talking about the method not exactly that inverter so just a small follow up in this only so for example when you are saying that we can extend this method to other gates also they would be looking at the what the current is going in the pull-up network and the pull-down network as a whole right and then we even have to apply this kind of characteristics yes okay we will talk about pull-up network and pull-down network and we will have to keep other inputs in such a situation that they do not influence the output okay i did not i still didn't understand the last pointer that the other gates collapsed [Music] gate and my one input is already let us say one this input was zero this input b was zero now what happens when b goes from zero to one what will happen if you want to find the transfer graph yeah if you want to find the transfer characteristics of this gate now what would you do you would you would keep b at different values of uh voltage v and you will gradually change and do you realize that this this inverter or this nmos is just like a some on resistance r on and this p mass is actually off so this doesn't even figure in into our analysis at such a high resistance so we are essentially looking at idp and idn this damsync has much current because it is fully one how was the other uh transistor of that r of which you just because the input is one so the pmos is off there okay yeah yeah okay so this nand gate do you see it is kind of collapsed into an inverter okay okay so that is what i mean by that statement nothing else so um about you know the skewed gate influencing the characteristics of other gates so when when this collapses into an equivalent uh inverter it will also,https://www.youtube.com/watch?v=L69CwjaRr2g,"Link: https://www.youtube.com/watch?v=L69CwjaRr2g
Transcript: what were we discussing in the last class it's a dc transfer characteristics dc transfer characteristics often of a cmos inverter okay what does this mean for different values of v in what will be the v out and the input is stable and the output is expected to be stable am i right yes this is something like a bias current simulation see what is the what will be the current flowing what will be the uh what will be the state of my system if my vn is at some particular level okay and we saw that at different values of vn my system uh you know some devices were in cutoff or linear or saturation and so on due to which i had a certain certain kind of a current waveform arising out of it you remember that we said that in this thing the current will be like very high over here and then at e again it will be zero you remember this yes and we also said that while this is a v in over v out kind of a curve you could also have it as a uh v out over uh timing kind of a curve you remember that that i could actually say that my v in is moving like this so this is point a this is point b this is point c this is point d and this is point e so what happens the current at a is is plotted here current at b is plotted here current at c is plotted here current at d is plotted here and then current at e is spotted here and i can get actually the timing waveform for the current also from this curve itself if i have the timing waveform of the input are you able to see this we discussed this part also yes and we also discussed that that this is one reason why we want the ice time and fall times to be sharp to be steep so that we have lesser current flowing through the system or the lesser duration for which this very high current would flow you remember this yes sir now so let us keep this learning uh with us we will pick it up in just a little while when we talk about transient analysis but we will not talk about the same thing again we will talk about other aspects of transient analysis but this is something which you should be able to do for transient analysis also okay now tell me one thing in this curve if we had assumed that beta n is equal to beta p you remember yes sir and that is why the c or this this inflection point was coming at almost like vdd by 2. now what would happen if i change if i make beta n stronger than beta p it will fall down faster it will fall down faster so this is not a time now this is v out by v so what happens to this curve i think it will shift it will shift towards left not with what happens if i make beta p is greater than much greater than beta n right right yeah so uh such curves you know such transistors which we have such inverters or such gates where we have uh beta n not equal to beta p you would notice that the the infection point will be on either side of vdd by two okay these are called skewed gates there is importance there is a relevance for these gates we will look at that a little later in the course but i just want you to keep that in your mind you know park it for yourself that this is how uh like this this characteristic that we just did can be used to represent skewed gates also and this vowed by v incur can be used to actually represent any other gate also just that because of different beta ratio your curve could be over here or over here so are you able to see this yes sir yes so what do you mean by the other gates and this like nand gate nor gate xor gate five input nand gate two input nand gate three input nand gate all the various range of gates that you may want to use in your designs later so both of the all these gates will have these kind of characteristics only yeah all these girls will have v out by v in characteristic is it not same okay the trend would be the same not same because beta ratio will be different they will have slightly different but the trend would be same right yeah so the intent the intent to say is that uh you will be able to like by using exactly the same method as we used for the inverter you should be able to build transfer characteristics for any other gate also so sir like can i also say that with the inverter itself the inverter structure only if i change the data ratios in the inverted structure i can get the different characteristics of the other gates also this is what you're saying i mean here i'm not saying that what i'm saying is that if you change the beta ratio you will get different characteristics what i'm also saying is that by using the same method you can build characteristics of other gates also which if they are inverting gates would be very similar to the inverter characteristics if they are non-inverting gates the characteristics would be different but by using the same method you can arrive at transfer characteristics of any curve lining so like you did with the current graph like intersecting points okay so but like what is the relevance of this changes beta ratio i mean as a designer why i'm looking at this because so as i mentioned we will cover it later also but since there is a question uh see at times you may want my inverter to not switch so the next slide will see at times for example if you look at this over here suppose this is the characteristic that that we have designed for our inverter now what happens let v in change by even this much value v in can now change by this much value but output will not change are you able to see this okay so so that can also discover itself it will mean that uh the pmos will be like the for pmos to be pmos and uh nmos current to be equal the pull down so that means the linear current of n must be sufficient to counter the circuit energy current of the p noise so fast for this particular curve the p mass is much bigger than the n mass okay so the saturation current of the n mass will be more than easily encountered taken care of by the linear current of the p mass yeah yeah yes okay so now what has happened my low noise margin i have increased but what happened to the high noise margin now if my input was at one over here even a small blip would mean my output will go to 1. so my higher noise margin has reduced okay yeah that's the relevance of this bit direction yeah so if you change the skew ratio if you change the skewing and the beta ratio then you will essentially end up changing the noise margins that your gate would have okay we'll just come to that in the meanwhile i saw that someone had a question you had a question so so i understood uh if beta p is greater than beta and then the curve is shifting towards right and uh also it is shifting towards left but is much greater than beta n then the saturation current of nmos is much lesser than even the linear current of pmos [Music] so even with the you know even though nmos is trying to sync as much current as it can the linear current of the pmos is so high that it kind of does not allow the output capacitance to discharge okay okay we are not doing transient analysis yet but what we are saying is that the uh the current of the pmos in the linear region is so high that n mass even in saturation cannot sink more current okay that is where my characteristics become something like this yes i can can you please explain this low noise and high noise yeah i will just come to that i will just know there's a separate site for that okay sir uh yes sir sir so you were saying that with the no i said by using the method of how we built the inverter characteristics we should be able to build characteristics okay so we're talking about the method not exactly that inverter so just a small follow up in this only so for example when you are saying that we can extend this method to other gates also they would be looking at the what the current is going in the pull-up network and the pull-down network as a whole right and then we even have to apply this kind of characteristics yes okay we will talk about pull-up network and pull-down network and we will have to keep other inputs in such a situation that they do not influence the output okay i did not i still didn't understand the last pointer that the other gates collapsed [Music] gate and my one input is already let us say one this input was zero this input b was zero now what happens when b goes from zero to one what will happen if you want to find the transfer graph yeah if you want to find the transfer characteristics of this gate now what would you do you would you would keep b at different values of uh voltage v and you will gradually change and do you realize that this this inverter or this nmos is just like a some on resistance r on and this p mass is actually off so this doesn't even figure in into our analysis at such a high resistance so we are essentially looking at idp and idn this damsync has much current because it is fully one how was the other uh transistor of that r of which you just because the input is one so the pmos is off there okay yeah yeah okay so this nand gate do you see it is kind of collapsed into an inverter okay okay so that is what i mean by that statement nothing else so um about you know the skewed gate influencing the characteristics of other gates so when when this collapses into an equivalent uh inverter it will also"
WMW0XjpJhfs,so sir our main job would be to select the inputs so that we get those equivalent kind of structures right yeah yeah you can do that okay so now as we were saying just just now that if i have a if i have an inverter which is uh toggling at say vdd by 2 what what am i saying that on the low side i have this kind of region where output will not toggle and on the high side i have this kind of region where again output will not double it is in this region that i would not know or in fact behave in a you could say over here between here and here it is in this region that i have i do not know where my output is are you able to see this so this is called as logical high input range and logical no input low input range and the output as we said will always go to either vdd or ground so logical low output range and logical high output range that when when the output has risen to let us say 80 percent of vdd we say it is high we don't really need it to be full vdd huh and this this difference between them is called as noise margin okay and if we have a skewed gate this gate would either go here or here and because of which noise margin of one side may reduce noise margin on the other side would increase because what would happen the output would still output ah high and output low range would still remain the same but input intermediate range would shift up let us say like this so what has happened the noise margin on the high side has reduced whereas that on the low side increases are you able to see this any questions so what is significance of this noise margin okay uh we were talking about crosstalk what will crosstalk do it will generate some small pulses here and there some glitches here and there so you do not want your outputs to keep traveling for every little glitch so that is what this noise margin prevents it saves power so noise will now not bother your circuit your outputs will not unnecessarily toggle because of noise so so my input has to be in uh in has to be above this noise margin or it can be in this noise margin as well um so that we have with extent so in this case my input can actually be in this noise margin and i will still consider it as logical high that is what the definition of noise margin is my output will remain here that is the strength of my gate but this is additional margin that i am giving that even if i input a slightly lower than my output high range i will still be able to uh consider that as one okay so that if output of one gate is fed into another the in the noise cannot er and noise get overlapped with uh yeah so let us look at it like this i made a very good output curve over here i i followed this okay now in between i had some coupling capacitance coming into picture with another wire and therefore by the time it reached here my output fell a little i was giving an output high of this its output was high but it fell a little so it came to this level now for this particular inverter i would still consider it as a high signal so whatever crosstalk this wire introduced into my system it did not spoil the logic level i had sufficient noise margin noise introduced by this adjacent buyer did not change my output okay so got yourself okay yes sir yes okay so uh i'm still not getting this point like uh if we have input greater than that c region then the output will be low intermediate then the output will be my first inverter gave the outputs of logical high and logical low like whatever is drawn yes now in this long path there was some crosstalk yes we added some noise okay how much noise can this crosstalk add or another reason could be adding noise how much noise can be added that my second inverter still considers it as one okay so that is my noise margin height okay similarly on the low side if i had this first inverter giving an output 0 how much noise can this crosstalk add so that the second inverter is still considered okay that is in noise noise raster mad you know i have become i have become insensitive to the noise that got added in in the in the process of some other output reaching my input gate okay huh okay you can now notice here i have become insensitive to that noise that is why it is called noise margin okay so okay because if more noise could be would be inserted then i do not know what my output would be okay yes uh sir in this picture itself the left one is the characteristics of the left uh output characteristics of the first inverter and the right one is the inverter of the characteristics of the second water right so but like i wanted to ask for a given inverter if the this intermediate region the area for example if you consider this area itself this would be fixed right this can only shift up and down yeah no not exactly depends on technology and voltage of operation so because uh right current knowledge uh like the voltage but that could be using for different inverters that would be same so so like even this uh if fish change the beta ratio then this either i will get the noise margin increased on the high side or the low side so one has to compensate on the behalf of other there will be some loss so so like this region then has to remain constant but no that that is an assumption you are making raghav in the previous slide we simply said that this region will go up or low i did not really say that this region will remain constant also for example look at this curve in this case this region is this big at least yes sir but look at this curve the original one this region is probably smaller so how would this region change i do not know there is no way to uh clearly look at tell it based on some model or some what do you say analysis uh see if you you will actually have to analyze the the inverter on on your card to seek exactly so actually i was making the deduction based on the fact that for example if i'm able to change this area this transition area then i can have gains on both the low side on the also the high side also typically if you if you skew it typically if you skew it this indeterminate region would all would probably increase because what happens is they look at this either stop here this goes bad okay okay so like okay like in that kind of situation in which i gain on both of that cannot happen so that may not happen yeah that you will probably be able to do if you increase the voltage of operation yeah yeah okay generally you are saying sir that this beta ratio affects this in that the area increases so like the degradation has to be it will be more amplified than basically than if you would have not been there but it's shifting also it wasn't shifting i'm not saying that also rather i simply said i do not know what to say about indeterminate region it can increase it can remain constant it could reduce it depends on the technology and voltage of operation and what kind of skew you are talking about that's all that i said okay sir yes sir uh so can you please go back to the previous slide servants yes sir so sir in this graph for suppose we are taking uh vdd by 2 at the center point and the graph is the same beta p by beta n equal to 1 so in that noise margin is something that's that we are giving the flexibility towards the top side and the bottom side axle so like the top side we are calling it as noise margin high the bottom side you are calling it as noise margin low okay okay there is no relevance i'm like we don't call the between areas any kind of noise or something no you see that that is where nmh and nml yes yes okay so how to maximize noise margin yes ma'am yeah uh can you go back to the previous slide please noise emergence this is also on nice margin only tell me no i mean the the last last one yeah so here um on the top we have indicated vdd and on the bottom g uh round but um according to the inverter characteristics this top one should indicate uh when we say logical high input range we mean that the range of inputs for which the output will be logical high rate no logical low logical low inverter inverter will invert logical high input range it will convert to logical low output range so what's this uh what's the logic of you know subtracting your output range from the input range let us both are identical inverters okay this inverter gives its output based on this output characteristic the output when it starts from here and reaches the input of the second inverter there is crosstalk in between which introduces noise okay now the inverter at its receiving input stage considers a much wider range as logic high right right so what does this mean that this much of noise nmh kind of noise can be accepted from crosstalk or any other reason okay okay that is why it is called as noise margin right right okay and just clear this line inside just clarifying this statement like we have this noise margin like this much noise we can tolerate and if the noise is greater than this then the operation will be entered am i right sir we do not know what the output would be yeah okay okay so thank you okay so i i know these these many questions because we want to increase the noise margin so how do we increase the noise margin so uh we can i think we can make beta p equal to beta n so that our curve was steep at a point so that we would have a good noise motion on the top and the bottom yeah so if beta p is equal to beta n that is how we can do it what is now how do we first before that we need to see what is really the noise margin should i start to call noise margin from here until here or from where to where so a typical definition that is used is that in this transfer characteristic the points where i have a unity slope from zero to one and one to zero side those are the the intermediate region is called as in the the region between that is intermediate region and i have the remaining part as noise margin is that okay so you will get v o l and v o h from this curve and v i l and v i h also from this curve so now i will be able to identify what is the noise margin for this particular gate so like in short we are saying that when both the devices are in saturation we exclude that area and then the remaining response you can say that okay so having looked at this and having also talked about transient analysis a little while back we understand that dc analysis is what happens to v out if v n is constant transient analysis is what happens to v out if v in changes over time and we also discussed already that the same kind of characteristic will stay stay valid you just need to time you know you just need to put a b c d e along the time axis okay we already discussed this in the last class also this is just kind of summarizing it but when we do that there are different figures of merit which would also come into picture and that is what we need to look at okay so what we are saying that uh at time t equal to t naught my input is toggling and uh my output was vdd at time t less than t naught how would my output change after time t equal to t naught and you notice c load starts to figure in now we already discussed in the last class in response to one of your questions that why did we not consider c load in the stat in the char in the uh transfer active sticks because it is the input outputs are not changing so capacitance is not valid however uh in a transient analysis we know that v out is changing over time therefore c load starts to figure in what will be the impact of c load on the current waveforms any ideas [Music] uh my word okay so if i'm transitioning from zero to one my output should be going from one to zero why would pmos be sourcing more current now sorry in case you of the reverse logic because now we're uh about zero to one transition only we're talking about zero to one transition only a b okay and this night we're talking about zero to one you're talking about response to a unit input so zero to one transition happening there what is the response to that so my question is how will the current change so we are talking here about step response right yes response to the step input this step input i think at the edges where this changes there would be a bulb unlike there would be a u-shaped curve going high then it's rising and while followed it will go down are we falling we are only looking at input rise then eight will go over there and then bulp at the edge at which the value is one so i'm asking about the current curve so maybe the uh curve will be uh more wider because there will be more charge stored in the c load so the i versus t will be more wider rather than a peak okay so uh what is being said is that because there is a load over here this would prevent any change in output voltage this will resist any change in output voltage it will start to sink it's on charge so that output doesn't change and therefore my delays would increase and therefore this curve would become wider is that what you want to say yes sir okay and anything else would happen so see in the transfer characteristics we said id n is equal to idp can we say this here no transfer practices this was always the case can we say the same thing here no sir why so as i can think for example if we in b have no control b being changing as we have applied so if being is changing so i know that for this particular time of period my pmos will be on my nmos will be on but this v out i think is because of c load because of this i think i'm not able to able to say that e what time my pms will be in linear saturation so these kind of the current i think i won't be able to stay sometimes mad this uh pmos will be linear and must be saturation and this current is also going so i mean sometimes i think that maybe the pmos could be driving more current to the sea load and see let us look at it very simply just if we know the output is going to be zero now we know that this capacitance has to discharge capacitor currents so this capacitance the charge that this capacitor has has to be sunk to zero yes sir yeah so the nmas will finally sink more charge than the p mass yeah so the nmos current has to be or either the duration of the nmos current or the amount of nmos current whatever we talk about has to be more than the pmos current yeah during that transition also right so ids cannot be equal to idsp ids n cannot be equal to idsp yes in fact it could be something like this only not but there is a pmos current which also comes but pmos current closes n mass remains in the saturation region for a little longer it discharges the capacitor and then enters into the linear region so this could be the first curve over here could be idsp and the second workforce could be ids n are you able to see this so nmos remained in saturation for a longer period so that it would sink the charge from c load this this region should be able to give you the charge stored on c load are you able to see this yes sir yeah so the power will definitely increase because this uh this region is charge given by the pmos and must took all that charge okay this was the extra charge so this extra charge represents the charge coming from the capacitor so if you are just given the current characteristics you can find out the capacitance that is connected on the load are you able to see this yeah yeah yes i did thank you very much was initially charged somewhat of what how is that that charge left out which the capacitor is just producing afterwards will continue to remain in saturation region for a longer duration of time and only then capacitance discharges it will go into linear region so then its current would discharge,https://www.youtube.com/watch?v=WMW0XjpJhfs,"Link: https://www.youtube.com/watch?v=WMW0XjpJhfs
Transcript: so sir our main job would be to select the inputs so that we get those equivalent kind of structures right yeah yeah you can do that okay so now as we were saying just just now that if i have a if i have an inverter which is uh toggling at say vdd by 2 what what am i saying that on the low side i have this kind of region where output will not toggle and on the high side i have this kind of region where again output will not double it is in this region that i would not know or in fact behave in a you could say over here between here and here it is in this region that i have i do not know where my output is are you able to see this so this is called as logical high input range and logical no input low input range and the output as we said will always go to either vdd or ground so logical low output range and logical high output range that when when the output has risen to let us say 80 percent of vdd we say it is high we don't really need it to be full vdd huh and this this difference between them is called as noise margin okay and if we have a skewed gate this gate would either go here or here and because of which noise margin of one side may reduce noise margin on the other side would increase because what would happen the output would still output ah high and output low range would still remain the same but input intermediate range would shift up let us say like this so what has happened the noise margin on the high side has reduced whereas that on the low side increases are you able to see this any questions so what is significance of this noise margin okay uh we were talking about crosstalk what will crosstalk do it will generate some small pulses here and there some glitches here and there so you do not want your outputs to keep traveling for every little glitch so that is what this noise margin prevents it saves power so noise will now not bother your circuit your outputs will not unnecessarily toggle because of noise so so my input has to be in uh in has to be above this noise margin or it can be in this noise margin as well um so that we have with extent so in this case my input can actually be in this noise margin and i will still consider it as logical high that is what the definition of noise margin is my output will remain here that is the strength of my gate but this is additional margin that i am giving that even if i input a slightly lower than my output high range i will still be able to uh consider that as one okay so that if output of one gate is fed into another the in the noise cannot er and noise get overlapped with uh yeah so let us look at it like this i made a very good output curve over here i i followed this okay now in between i had some coupling capacitance coming into picture with another wire and therefore by the time it reached here my output fell a little i was giving an output high of this its output was high but it fell a little so it came to this level now for this particular inverter i would still consider it as a high signal so whatever crosstalk this wire introduced into my system it did not spoil the logic level i had sufficient noise margin noise introduced by this adjacent buyer did not change my output okay so got yourself okay yes sir yes okay so uh i'm still not getting this point like uh if we have input greater than that c region then the output will be low intermediate then the output will be my first inverter gave the outputs of logical high and logical low like whatever is drawn yes now in this long path there was some crosstalk yes we added some noise okay how much noise can this crosstalk add or another reason could be adding noise how much noise can be added that my second inverter still considers it as one okay so that is my noise margin height okay similarly on the low side if i had this first inverter giving an output 0 how much noise can this crosstalk add so that the second inverter is still considered okay that is in noise noise raster mad you know i have become i have become insensitive to the noise that got added in in the in the process of some other output reaching my input gate okay huh okay you can now notice here i have become insensitive to that noise that is why it is called noise margin okay so okay because if more noise could be would be inserted then i do not know what my output would be okay yes uh sir in this picture itself the left one is the characteristics of the left uh output characteristics of the first inverter and the right one is the inverter of the characteristics of the second water right so but like i wanted to ask for a given inverter if the this intermediate region the area for example if you consider this area itself this would be fixed right this can only shift up and down yeah no not exactly depends on technology and voltage of operation so because uh right current knowledge uh like the voltage but that could be using for different inverters that would be same so so like even this uh if fish change the beta ratio then this either i will get the noise margin increased on the high side or the low side so one has to compensate on the behalf of other there will be some loss so so like this region then has to remain constant but no that that is an assumption you are making raghav in the previous slide we simply said that this region will go up or low i did not really say that this region will remain constant also for example look at this curve in this case this region is this big at least yes sir but look at this curve the original one this region is probably smaller so how would this region change i do not know there is no way to uh clearly look at tell it based on some model or some what do you say analysis uh see if you you will actually have to analyze the the inverter on on your card to seek exactly so actually i was making the deduction based on the fact that for example if i'm able to change this area this transition area then i can have gains on both the low side on the also the high side also typically if you if you skew it typically if you skew it this indeterminate region would all would probably increase because what happens is they look at this either stop here this goes bad okay okay so like okay like in that kind of situation in which i gain on both of that cannot happen so that may not happen yeah that you will probably be able to do if you increase the voltage of operation yeah yeah okay generally you are saying sir that this beta ratio affects this in that the area increases so like the degradation has to be it will be more amplified than basically than if you would have not been there but it's shifting also it wasn't shifting i'm not saying that also rather i simply said i do not know what to say about indeterminate region it can increase it can remain constant it could reduce it depends on the technology and voltage of operation and what kind of skew you are talking about that's all that i said okay sir yes sir uh so can you please go back to the previous slide servants yes sir so sir in this graph for suppose we are taking uh vdd by 2 at the center point and the graph is the same beta p by beta n equal to 1 so in that noise margin is something that's that we are giving the flexibility towards the top side and the bottom side axle so like the top side we are calling it as noise margin high the bottom side you are calling it as noise margin low okay okay there is no relevance i'm like we don't call the between areas any kind of noise or something no you see that that is where nmh and nml yes yes okay so how to maximize noise margin yes ma'am yeah uh can you go back to the previous slide please noise emergence this is also on nice margin only tell me no i mean the the last last one yeah so here um on the top we have indicated vdd and on the bottom g uh round but um according to the inverter characteristics this top one should indicate uh when we say logical high input range we mean that the range of inputs for which the output will be logical high rate no logical low logical low inverter inverter will invert logical high input range it will convert to logical low output range so what's this uh what's the logic of you know subtracting your output range from the input range let us both are identical inverters okay this inverter gives its output based on this output characteristic the output when it starts from here and reaches the input of the second inverter there is crosstalk in between which introduces noise okay now the inverter at its receiving input stage considers a much wider range as logic high right right so what does this mean that this much of noise nmh kind of noise can be accepted from crosstalk or any other reason okay okay that is why it is called as noise margin right right okay and just clear this line inside just clarifying this statement like we have this noise margin like this much noise we can tolerate and if the noise is greater than this then the operation will be entered am i right sir we do not know what the output would be yeah okay okay so thank you okay so i i know these these many questions because we want to increase the noise margin so how do we increase the noise margin so uh we can i think we can make beta p equal to beta n so that our curve was steep at a point so that we would have a good noise motion on the top and the bottom yeah so if beta p is equal to beta n that is how we can do it what is now how do we first before that we need to see what is really the noise margin should i start to call noise margin from here until here or from where to where so a typical definition that is used is that in this transfer characteristic the points where i have a unity slope from zero to one and one to zero side those are the the intermediate region is called as in the the region between that is intermediate region and i have the remaining part as noise margin is that okay so you will get v o l and v o h from this curve and v i l and v i h also from this curve so now i will be able to identify what is the noise margin for this particular gate so like in short we are saying that when both the devices are in saturation we exclude that area and then the remaining response you can say that okay so having looked at this and having also talked about transient analysis a little while back we understand that dc analysis is what happens to v out if v n is constant transient analysis is what happens to v out if v in changes over time and we also discussed already that the same kind of characteristic will stay stay valid you just need to time you know you just need to put a b c d e along the time axis okay we already discussed this in the last class also this is just kind of summarizing it but when we do that there are different figures of merit which would also come into picture and that is what we need to look at okay so what we are saying that uh at time t equal to t naught my input is toggling and uh my output was vdd at time t less than t naught how would my output change after time t equal to t naught and you notice c load starts to figure in now we already discussed in the last class in response to one of your questions that why did we not consider c load in the stat in the char in the uh transfer active sticks because it is the input outputs are not changing so capacitance is not valid however uh in a transient analysis we know that v out is changing over time therefore c load starts to figure in what will be the impact of c load on the current waveforms any ideas [Music] uh my word okay so if i'm transitioning from zero to one my output should be going from one to zero why would pmos be sourcing more current now sorry in case you of the reverse logic because now we're uh about zero to one transition only we're talking about zero to one transition only a b okay and this night we're talking about zero to one you're talking about response to a unit input so zero to one transition happening there what is the response to that so my question is how will the current change so we are talking here about step response right yes response to the step input this step input i think at the edges where this changes there would be a bulb unlike there would be a u-shaped curve going high then it's rising and while followed it will go down are we falling we are only looking at input rise then eight will go over there and then bulp at the edge at which the value is one so i'm asking about the current curve so maybe the uh curve will be uh more wider because there will be more charge stored in the c load so the i versus t will be more wider rather than a peak okay so uh what is being said is that because there is a load over here this would prevent any change in output voltage this will resist any change in output voltage it will start to sink it's on charge so that output doesn't change and therefore my delays would increase and therefore this curve would become wider is that what you want to say yes sir okay and anything else would happen so see in the transfer characteristics we said id n is equal to idp can we say this here no transfer practices this was always the case can we say the same thing here no sir why so as i can think for example if we in b have no control b being changing as we have applied so if being is changing so i know that for this particular time of period my pmos will be on my nmos will be on but this v out i think is because of c load because of this i think i'm not able to able to say that e what time my pms will be in linear saturation so these kind of the current i think i won't be able to stay sometimes mad this uh pmos will be linear and must be saturation and this current is also going so i mean sometimes i think that maybe the pmos could be driving more current to the sea load and see let us look at it very simply just if we know the output is going to be zero now we know that this capacitance has to discharge capacitor currents so this capacitance the charge that this capacitor has has to be sunk to zero yes sir yeah so the nmas will finally sink more charge than the p mass yeah so the nmos current has to be or either the duration of the nmos current or the amount of nmos current whatever we talk about has to be more than the pmos current yeah during that transition also right so ids cannot be equal to idsp ids n cannot be equal to idsp yes in fact it could be something like this only not but there is a pmos current which also comes but pmos current closes n mass remains in the saturation region for a little longer it discharges the capacitor and then enters into the linear region so this could be the first curve over here could be idsp and the second workforce could be ids n are you able to see this so nmos remained in saturation for a longer period so that it would sink the charge from c load this this region should be able to give you the charge stored on c load are you able to see this yes sir yeah so the power will definitely increase because this uh this region is charge given by the pmos and must took all that charge okay this was the extra charge so this extra charge represents the charge coming from the capacitor so if you are just given the current characteristics you can find out the capacitance that is connected on the load are you able to see this yeah yeah yes i did thank you very much was initially charged somewhat of what how is that that charge left out which the capacitor is just producing afterwards will continue to remain in saturation region for a longer duration of time and only then capacitance discharges it will go into linear region so then its current would discharge"
6cFWYI9sBJw,now we look at now because you're talking about transient characteristics and now we say that there is going to be some capacitors which are going to get charged or discharged or stuff like that so now we look at uh different timings that we have talked about already or you know you have seen that in the assignment already so there are different kinds of delays propagation delays are you know there is a propagation delay from input rising so output falling propagation delay from uh input falling to output rising so this is tpdr ppdf you may also be called reading it as tp uh hl or t p l h something like this okay and average of these two is used to say what is the average propagation delay okay and the rise time and the fall time that you looked at in your assignment also is about uh the slope of the output which would depend on the load that we have is that okay these four timings any question they are simple you've already done the assignment on that also okay so now there is another set of delays which are called as contamination delays what do you think contamination delays are uh you've done an assignment on inverter you will not be able to respond on contamination delay based on the inverter let us consider a nand gate now can you think of a contamination delay the definition appears to be similar to propagation delay yes sir so this is best case delay earliest that my output can bubble consider the case of a nand gate so we will go into this in more detail in a little while now let us say on the on the zero to one side uh you know output transitioning from zero to one because a and b have are kind of in parallel with each other so the delays will always be the same however if just one of them is toggling but what happens if both of them toggle together so if one of them was toggling either a or toggling or b toggling this could be my output waveform but when both toggle together what happens i have extra drive strength to to charge this capacitor and therefore my delay so my input would have been let us say input went low here so my input to output delay now reduces this lesser delay is called as contamination delay okay so yes can you please explain this last part again so uh are you able to see that when both a and p a and b are simultaneously driving the output capacitance it will transition faster yes sir so instead of this transition i will see a much faster transition on the output okay so the difference between these two okay now okay yes so just like you have pdr and pdf you have contamin contamination delay rising and contamination delay calling and average contamination delay associated with the gates why is contamination delay important sir this determines the speed at which the output switches so why am i interested in the shortest delay also typically i should be interested in only the longest delay yes i even that is my question i mean shortest but someone was saying something so so qualifying the uh combinational path delay requirements in a synchronous circuit yeah so usually you look at you know longest delay path that is what you call the critical path so choice all of you are saying whole time also the punk yes so contamination delay is important to validate the whole time paths you've done flip flops what is set up time and hold time of a flip flop hello before which uh uh just the range for which uh the data uh should remain stable for the blockage so that the flip flop should uh capture that that data and uh after that blockage the that time is called the whole time so the range surface of data should again remain stable so that it perfectly captures the data any other response so b-tech students you also done the setup and hold times in your eld and other courses dc erdberg [Music] the amount of time we will have to hold our d input constant before the rising temperature and whole time and whole time is um the amount of time after the clock edge for which d should because yeah so now do you realize that the contamination delay can mean that your output can now change faster so your whole time violations can appear if you do not consider contamination delay in your analysis therefore both propagation delay and contamination delay are to be characterized for any gate that you will design in your projects also so i still did not understand how it is uh rising faster in this case i mean if a and b are switching together so let us say a was a a was one initially and b was also one both were one okay so output was 0 0 now let us say only a goes to 0 yes what would happen a device of width w wp will charge the capacitor yes in a different case only b goes to zero what would happen a device of only bits w will charge the capacitor now let us consider a case where both simultaneously go to zero what two devices charging it up means double the current okay yeah that means that the password will get charged faster okay okay raghav uh yes yes i wanted to ask that i get it that this whole time requirement we are considering contamination but so for example as i can see like the setup time is much more than the whole time requirements i mean but from this for example so this when you're seeing this whole time required contamination delay i mean i will always get some kind of delay so why i'm burying why i am basically modeling it because i just want this delay to be there so it will be always be there so like in calculations like how it will help me so uh we will look at that uh in longer paths later raghav but for now realize that we have for any design we have to qualify setup and hold both am i right yes sir yeah yes sir and to be able to analyze the whole path i need the fastest delays okay so because i have to analyze that as a sign of requirement i need the fastest delay also so as a library designer you have to characterize both the propagation delay and the contamination delay so so like for example when i am characterizing this whole delay i will toggle both the inputs a and b at the same time and i will get what the delay will get will be my contamination delay but so then how will i model the other delay because then basically so there are different kinds of so if you will open the dot lift file of any gate so there is a there is a format in which the input to output delays are characterized yes sir okay so in that format there is an option to also to add two delays linked between two pins that a to y there is there is one propagation delay and there is one contamination delay so you have an option to add both the delays and one file itself the tools that will do the static timing analysis will take care of both the you know delays i am asking that what how i will basically come up with this uh another delay apart from the contamination rate because then i can basically depending upon how much difference i'm getting between the a input and the input toggling i can get different kind of delays yeah so i have done three simulations i will in one simulation i will toggle only a i will get a to y delay and second simulation i will toggle only b i will get b to y delay and then third simulation i will toggle a and b both and i will get the a a slash b to y delay so i'll take an average off yeah okay okay okay the max will become the propagation delay the min will become the contamination delay i know so either i do three simulations or i i do i make my stimuli in such a way that in one simulation it says i'm able to calculate all three of them that is a that is a choice every designer has so i understood that okay now two devices are have charged the capacitor but now when it when it has to discharge right so again i mean if not discharging through the nmos now how does having two nmos um in series help in faster discharging of the capacitor so let us look at it thank you because this is something we want to discuss in just a little while also so thank you for bringing it up now we can discuss it now itself let us say this node had a small capacitance cx over here let us say can we say this yeah now my input my output was at one initially and it has to now go to zero huh so what happened either of a or b was 0 which has now gone to 1 which means it has to discharge now let us first assume that b was 1 already a has now gone 1 what happens because d was already one the cx is already discharged to ground okay so there will be one delay right right now let us say a was one a was one already and b was zero so b is going to one now now what happens not just this one has to discharge the cx also has to discharge okay so this delay will be longer yes so one of the propagation delays will be more than the other propagation delay so these capacitors like cx we have face it's uh it's basically your according to your equivalent models right when we um study the equilibrium models for rc uh in steam because diffusion capacitance shear diffusion finger devices all that you're talking about extra capacitances on source and drain yeah yeah yeah so that is exactly what we're talking about over here okay,https://www.youtube.com/watch?v=6cFWYI9sBJw,"Link: https://www.youtube.com/watch?v=6cFWYI9sBJw
Transcript: now we look at now because you're talking about transient characteristics and now we say that there is going to be some capacitors which are going to get charged or discharged or stuff like that so now we look at uh different timings that we have talked about already or you know you have seen that in the assignment already so there are different kinds of delays propagation delays are you know there is a propagation delay from input rising so output falling propagation delay from uh input falling to output rising so this is tpdr ppdf you may also be called reading it as tp uh hl or t p l h something like this okay and average of these two is used to say what is the average propagation delay okay and the rise time and the fall time that you looked at in your assignment also is about uh the slope of the output which would depend on the load that we have is that okay these four timings any question they are simple you've already done the assignment on that also okay so now there is another set of delays which are called as contamination delays what do you think contamination delays are uh you've done an assignment on inverter you will not be able to respond on contamination delay based on the inverter let us consider a nand gate now can you think of a contamination delay the definition appears to be similar to propagation delay yes sir so this is best case delay earliest that my output can bubble consider the case of a nand gate so we will go into this in more detail in a little while now let us say on the on the zero to one side uh you know output transitioning from zero to one because a and b have are kind of in parallel with each other so the delays will always be the same however if just one of them is toggling but what happens if both of them toggle together so if one of them was toggling either a or toggling or b toggling this could be my output waveform but when both toggle together what happens i have extra drive strength to to charge this capacitor and therefore my delay so my input would have been let us say input went low here so my input to output delay now reduces this lesser delay is called as contamination delay okay so yes can you please explain this last part again so uh are you able to see that when both a and p a and b are simultaneously driving the output capacitance it will transition faster yes sir so instead of this transition i will see a much faster transition on the output okay so the difference between these two okay now okay yes so just like you have pdr and pdf you have contamin contamination delay rising and contamination delay calling and average contamination delay associated with the gates why is contamination delay important sir this determines the speed at which the output switches so why am i interested in the shortest delay also typically i should be interested in only the longest delay yes i even that is my question i mean shortest but someone was saying something so so qualifying the uh combinational path delay requirements in a synchronous circuit yeah so usually you look at you know longest delay path that is what you call the critical path so choice all of you are saying whole time also the punk yes so contamination delay is important to validate the whole time paths you've done flip flops what is set up time and hold time of a flip flop hello before which uh uh just the range for which uh the data uh should remain stable for the blockage so that the flip flop should uh capture that that data and uh after that blockage the that time is called the whole time so the range surface of data should again remain stable so that it perfectly captures the data any other response so b-tech students you also done the setup and hold times in your eld and other courses dc erdberg [Music] the amount of time we will have to hold our d input constant before the rising temperature and whole time and whole time is um the amount of time after the clock edge for which d should because yeah so now do you realize that the contamination delay can mean that your output can now change faster so your whole time violations can appear if you do not consider contamination delay in your analysis therefore both propagation delay and contamination delay are to be characterized for any gate that you will design in your projects also so i still did not understand how it is uh rising faster in this case i mean if a and b are switching together so let us say a was a a was one initially and b was also one both were one okay so output was 0 0 now let us say only a goes to 0 yes what would happen a device of width w wp will charge the capacitor yes in a different case only b goes to zero what would happen a device of only bits w will charge the capacitor now let us consider a case where both simultaneously go to zero what two devices charging it up means double the current okay yeah that means that the password will get charged faster okay okay raghav uh yes yes i wanted to ask that i get it that this whole time requirement we are considering contamination but so for example as i can see like the setup time is much more than the whole time requirements i mean but from this for example so this when you're seeing this whole time required contamination delay i mean i will always get some kind of delay so why i'm burying why i am basically modeling it because i just want this delay to be there so it will be always be there so like in calculations like how it will help me so uh we will look at that uh in longer paths later raghav but for now realize that we have for any design we have to qualify setup and hold both am i right yes sir yeah yes sir and to be able to analyze the whole path i need the fastest delays okay so because i have to analyze that as a sign of requirement i need the fastest delay also so as a library designer you have to characterize both the propagation delay and the contamination delay so so like for example when i am characterizing this whole delay i will toggle both the inputs a and b at the same time and i will get what the delay will get will be my contamination delay but so then how will i model the other delay because then basically so there are different kinds of so if you will open the dot lift file of any gate so there is a there is a format in which the input to output delays are characterized yes sir okay so in that format there is an option to also to add two delays linked between two pins that a to y there is there is one propagation delay and there is one contamination delay so you have an option to add both the delays and one file itself the tools that will do the static timing analysis will take care of both the you know delays i am asking that what how i will basically come up with this uh another delay apart from the contamination rate because then i can basically depending upon how much difference i'm getting between the a input and the input toggling i can get different kind of delays yeah so i have done three simulations i will in one simulation i will toggle only a i will get a to y delay and second simulation i will toggle only b i will get b to y delay and then third simulation i will toggle a and b both and i will get the a a slash b to y delay so i'll take an average off yeah okay okay okay the max will become the propagation delay the min will become the contamination delay i know so either i do three simulations or i i do i make my stimuli in such a way that in one simulation it says i'm able to calculate all three of them that is a that is a choice every designer has so i understood that okay now two devices are have charged the capacitor but now when it when it has to discharge right so again i mean if not discharging through the nmos now how does having two nmos um in series help in faster discharging of the capacitor so let us look at it thank you because this is something we want to discuss in just a little while also so thank you for bringing it up now we can discuss it now itself let us say this node had a small capacitance cx over here let us say can we say this yeah now my input my output was at one initially and it has to now go to zero huh so what happened either of a or b was 0 which has now gone to 1 which means it has to discharge now let us first assume that b was 1 already a has now gone 1 what happens because d was already one the cx is already discharged to ground okay so there will be one delay right right now let us say a was one a was one already and b was zero so b is going to one now now what happens not just this one has to discharge the cx also has to discharge okay so this delay will be longer yes so one of the propagation delays will be more than the other propagation delay so these capacitors like cx we have face it's uh it's basically your according to your equivalent models right when we um study the equilibrium models for rc uh in steam because diffusion capacitance shear diffusion finger devices all that you're talking about extra capacitances on source and drain yeah yeah yeah so that is exactly what we're talking about over here okay"
_Gx_rVnCYSY,yes sir sir i mean i am not able to really get this uh kind of the the delay uh for this when you're saying that if b is toggle one and then it will be longer for that and not everyone's gonna get it so we'll just see we will just look at the delays model we will just see that don't worry okay so now we look at various models of delays one simple model is you assume that there is some you know when when the input changes there is an i average that will flow and the capacitor would discharge this model will give you know i need to find this value of n and everything two to be able to come up with an accurate delay another model could be you say that okay there is an effective r on the device is on there is an effective r on the capacitor swallowed at one and this discharges through this resistor so that is another way to model the propagation delay through an inverter ion method is usually simpler because r on estimation for a linear region you can still do much more easily and instead of you know calculating the i average from this kind of occurs you remember this transfer characteristic to find out i average of this transfer correction can be very tricky so this uh you know iron model is is usually a simpler model to work with also more intuitive actually okay uh so if you have a uh input transitioning from uh like in this blue curve from zero to one and then from one to zero the output will transition from one to zero and zero to one and your propagation delay would be measured something like this equivalent resistance of the uh n mass plus equivalent to this from the p mass divided by two but can you tell me why uh yeah this equivalent resistance can you tell me why this happens who can tell me we already discussed this in one of the offices also but i just want to review with you why does this happen in the past because it's a coupling capacitance between the capacitance because of that coupling capacitance between what so i mean the input and the output like the gate input with the output right it gets the miller the capacitance capacitance that we talked about where we said that an analog circuit should be much more relevant but you see in digital circuits also we see these notches because as the gate as the gate input goes from zero to one there is a coupling with source entrain there the source is ground or vdd that is that will not change much but the other side which is not driven to vdd or ground that side will is a floating capacitor so it will see some extra buildup of charge and this uh this is what you will see observe in the transient response okay it can also be understood you know in some cases like when you will talk about memory design and stuff like that so it will also be understood like that there is a inversion layer here when the device is on there is an inversion layer here and when you turn it off all at once this charge has to go somewhere this charge will go to the source or drain region half will go towards the source half will go to the drain and that will appear as this this is also another way to look at it this this phenomena also happens okay there are two things that come into picture so actually so essentially cgd and the cgs are getting coupled with the cr right yeah yes that is what is coming into picture so if you want to improve the performance what do you do the formula is cl into r so if we can keep the load capacitance to be small we would improve the delays if we can keep the self-loading because we know that the drain of the nmos and the pmos also become a part of float capacitance to be small we will get lesser capacitance if i increase the sizes what happens r on and like r on off the p mass and the n mass would decrease so i can improve the delays there but as i do that what happens abhim nakata keep the drain capacitance is small if you increase the device sizes what happens to the drain capacitances diffusion capacitance increases diffusion capacitance increases so this is called as self loading so you just cannot keep on increasing the size after some time you will not see any benefit because the device is loading itself so you are reducing the r equivalent but capacitance is also increasing so it is kind of a self-defeating mechanism after some time and then what about vdd the r equivalent seems to be dependent on vdd somewhere what would you do to vdd you would want to increase the vdd to reduce delays or decrease variety to reduce delay so we need to increase supply you need to increase the vdd why sir because [Music] the current would increase again uh on increasing the variation okay so because current would increase my overall resistance would reduce yes okay raghav you have a question uh yes sir i have some questions so for example in this overloading thing uh because if we increase the size too much this peak that we are seeing that will basically become too much that is the effect we will be seeing overloading self loading yeah so this peak will become too much and it will become enlarged over the time that you're saying effectively no i did not use the word enlarge did i use the wooden latch so i mean this uh maximum peak range would increase right so you're saying maximum peak may increase because of bigger device bigger more charge in the channel region yes but the duration of this peak i did not comment anything about because the devices are bigger than the discharge would also be faster so even if the peak is higher it will discharge equally fast okay so so like what do you exactly we did not use the word overloading we use the word self-loading yeah self-loading is the capacitance on the of the mosfet itself out coming as coming on the output see there is some cd over here yeah yes yes i know so this is c out so the cd is in parallel with c out as you increase the device size the cd increases yes yes so effectively see how it increases for you yeah that is what is being talked about over here that happened but and so my other question was that's the higher modeling this uh like r on thing with the like what value like how will we model this transistor with the r on i get it that would be the channel resistance but like i give you the complete formula you use this formula to find out your addon so which this other formula this one r equivalent okay okay okay same integration [Music] there are equations which with which you can do all of that don't worry so if you just add something more you will actually be able to identify full delay through some equations okay so so we have to get use these formulas to get the r on equivalent if i give you such questions which involves these formulas then i will also give the formula with it okay don't worry i don't want you to remember all this crap these are long channel models not even valid today okay these are you know simpler estimations just to give you an idea okay the intent being that when you look at this formula you should know that okay if i improve if i increase the vdd the delay would reduce if i reduce this then the delay would increase and so on that kind of estimate you should be able to make out of such formula okay so this is what you're talking about and we're talking about self-loading as you increase the device i see initially the delays improve so quickly but up after some time because of self-loading the slope degrades finally the slope is so bad that you are increasing the size of the device see 8 10 12 you're increasing the size of the device but the delay is not really changing much you've increased the size of the device by how much 50 how much has the delay changed not even five percent so yes it's a bit of probably but all these optimizations we are doing so are we trying to decrease the rise and fall time or the uh rising and falling propagation uh we are more interested in propagation delay see rise time and fall time we talked about are important to reduce power okay so if you will do this then power would also reduce but see increasing the size also means increase in capacitances so a power buddy so when we're talking about delays you're only talking about delay ruby so i mean um what what are the ways of reducing rise and fall times because intuitively the same methods should be applied yes intuitively the same methods have to be applied and you will notice that uh if you reduce the load capacitance in some way right so self loading for the rise and fall time would start to appear much faster much earlier yes yes because cluster is charging yes that's it okay so so can you come back to this uh discussion when we're discussing the effect of vdd on the delays so i can see from the equation that the resistance was also proportional to the vdd but you said that if i increase the vdd my delays would increase certain decrease the resistance was proportional to uh inversely proportional to id also you notice that okay and this has vd's vdd in it again yeah so there is the serial that is getting subtracted also so vdd increases this thing would also reduce both complexes so you have to do you have to do numerical analysis to arrive at the answer okay so like presently i'm saying that if i increase the bdd my delays would reduce right yes okay similarly for for beta ratio as you change the beta ratio the delays will there will be a sweet spot where the low to high and high to low delays would both be lower and you will you will have a beta ratio range which you would want to keep in your design okay so beta ratio you will see will typically in the theme of 65 also you want to keep it between 1.5 to 2.75 2.6 something like that okay uh we already discussed this that we are looking at first order rc response which is a decaying exponential they're talking about delay as uh effective resistance into capacitance and uh we we're really looking at you know essentially average current and all those things but this is too inaccurate to predict current at any given time but good enough to predict the rc delays if we try to look at the model of the delay you know r on we can say that a device which is k times a unit device size would have r by k the effective r on and k c as the effective load capacitance is this thing clear to you so this case is the diffusion one right kc times the same yeah the the load capacitance because of drain and source region okay so c would be when the we have unit yes okay now what happens with the pmos we say that the p mass the resistance is already 2r because of mobility constraints so for the pmos the capacitance capacitances will move in the same ratio in fact the resistance would also move in the same ratio but final resistance will be not r by k but 2 r by k because even in a unit unit thing the capacitor resistance was 2r so what essentially we are seeing is capacitance is proportional to it resistance is inversely proportional to it uh why is unity uh why does your females have a resistance to work i'm sorry uh what's the reason for unit teamers having resistance uh because the mobility of the p masses uh the hose is lesser than the mobility of the electrons so see what they discussed you will fall back up on all of that only no they behave the same way the resistance is because the mobility of the end masses is uh of the mobility of the electrons is better than the mobility of the hose therefore resistance of the,https://www.youtube.com/watch?v=_Gx_rVnCYSY,"Link: https://www.youtube.com/watch?v=_Gx_rVnCYSY
Transcript: yes sir sir i mean i am not able to really get this uh kind of the the delay uh for this when you're saying that if b is toggle one and then it will be longer for that and not everyone's gonna get it so we'll just see we will just look at the delays model we will just see that don't worry okay so now we look at various models of delays one simple model is you assume that there is some you know when when the input changes there is an i average that will flow and the capacitor would discharge this model will give you know i need to find this value of n and everything two to be able to come up with an accurate delay another model could be you say that okay there is an effective r on the device is on there is an effective r on the capacitor swallowed at one and this discharges through this resistor so that is another way to model the propagation delay through an inverter ion method is usually simpler because r on estimation for a linear region you can still do much more easily and instead of you know calculating the i average from this kind of occurs you remember this transfer characteristic to find out i average of this transfer correction can be very tricky so this uh you know iron model is is usually a simpler model to work with also more intuitive actually okay uh so if you have a uh input transitioning from uh like in this blue curve from zero to one and then from one to zero the output will transition from one to zero and zero to one and your propagation delay would be measured something like this equivalent resistance of the uh n mass plus equivalent to this from the p mass divided by two but can you tell me why uh yeah this equivalent resistance can you tell me why this happens who can tell me we already discussed this in one of the offices also but i just want to review with you why does this happen in the past because it's a coupling capacitance between the capacitance because of that coupling capacitance between what so i mean the input and the output like the gate input with the output right it gets the miller the capacitance capacitance that we talked about where we said that an analog circuit should be much more relevant but you see in digital circuits also we see these notches because as the gate as the gate input goes from zero to one there is a coupling with source entrain there the source is ground or vdd that is that will not change much but the other side which is not driven to vdd or ground that side will is a floating capacitor so it will see some extra buildup of charge and this uh this is what you will see observe in the transient response okay it can also be understood you know in some cases like when you will talk about memory design and stuff like that so it will also be understood like that there is a inversion layer here when the device is on there is an inversion layer here and when you turn it off all at once this charge has to go somewhere this charge will go to the source or drain region half will go towards the source half will go to the drain and that will appear as this this is also another way to look at it this this phenomena also happens okay there are two things that come into picture so actually so essentially cgd and the cgs are getting coupled with the cr right yeah yes that is what is coming into picture so if you want to improve the performance what do you do the formula is cl into r so if we can keep the load capacitance to be small we would improve the delays if we can keep the self-loading because we know that the drain of the nmos and the pmos also become a part of float capacitance to be small we will get lesser capacitance if i increase the sizes what happens r on and like r on off the p mass and the n mass would decrease so i can improve the delays there but as i do that what happens abhim nakata keep the drain capacitance is small if you increase the device sizes what happens to the drain capacitances diffusion capacitance increases diffusion capacitance increases so this is called as self loading so you just cannot keep on increasing the size after some time you will not see any benefit because the device is loading itself so you are reducing the r equivalent but capacitance is also increasing so it is kind of a self-defeating mechanism after some time and then what about vdd the r equivalent seems to be dependent on vdd somewhere what would you do to vdd you would want to increase the vdd to reduce delays or decrease variety to reduce delay so we need to increase supply you need to increase the vdd why sir because [Music] the current would increase again uh on increasing the variation okay so because current would increase my overall resistance would reduce yes okay raghav you have a question uh yes sir i have some questions so for example in this overloading thing uh because if we increase the size too much this peak that we are seeing that will basically become too much that is the effect we will be seeing overloading self loading yeah so this peak will become too much and it will become enlarged over the time that you're saying effectively no i did not use the word enlarge did i use the wooden latch so i mean this uh maximum peak range would increase right so you're saying maximum peak may increase because of bigger device bigger more charge in the channel region yes but the duration of this peak i did not comment anything about because the devices are bigger than the discharge would also be faster so even if the peak is higher it will discharge equally fast okay so so like what do you exactly we did not use the word overloading we use the word self-loading yeah self-loading is the capacitance on the of the mosfet itself out coming as coming on the output see there is some cd over here yeah yes yes i know so this is c out so the cd is in parallel with c out as you increase the device size the cd increases yes yes so effectively see how it increases for you yeah that is what is being talked about over here that happened but and so my other question was that's the higher modeling this uh like r on thing with the like what value like how will we model this transistor with the r on i get it that would be the channel resistance but like i give you the complete formula you use this formula to find out your addon so which this other formula this one r equivalent okay okay okay same integration [Music] there are equations which with which you can do all of that don't worry so if you just add something more you will actually be able to identify full delay through some equations okay so so we have to get use these formulas to get the r on equivalent if i give you such questions which involves these formulas then i will also give the formula with it okay don't worry i don't want you to remember all this crap these are long channel models not even valid today okay these are you know simpler estimations just to give you an idea okay the intent being that when you look at this formula you should know that okay if i improve if i increase the vdd the delay would reduce if i reduce this then the delay would increase and so on that kind of estimate you should be able to make out of such formula okay so this is what you're talking about and we're talking about self-loading as you increase the device i see initially the delays improve so quickly but up after some time because of self-loading the slope degrades finally the slope is so bad that you are increasing the size of the device see 8 10 12 you're increasing the size of the device but the delay is not really changing much you've increased the size of the device by how much 50 how much has the delay changed not even five percent so yes it's a bit of probably but all these optimizations we are doing so are we trying to decrease the rise and fall time or the uh rising and falling propagation uh we are more interested in propagation delay see rise time and fall time we talked about are important to reduce power okay so if you will do this then power would also reduce but see increasing the size also means increase in capacitances so a power buddy so when we're talking about delays you're only talking about delay ruby so i mean um what what are the ways of reducing rise and fall times because intuitively the same methods should be applied yes intuitively the same methods have to be applied and you will notice that uh if you reduce the load capacitance in some way right so self loading for the rise and fall time would start to appear much faster much earlier yes yes because cluster is charging yes that's it okay so so can you come back to this uh discussion when we're discussing the effect of vdd on the delays so i can see from the equation that the resistance was also proportional to the vdd but you said that if i increase the vdd my delays would increase certain decrease the resistance was proportional to uh inversely proportional to id also you notice that okay and this has vd's vdd in it again yeah so there is the serial that is getting subtracted also so vdd increases this thing would also reduce both complexes so you have to do you have to do numerical analysis to arrive at the answer okay so like presently i'm saying that if i increase the bdd my delays would reduce right yes okay similarly for for beta ratio as you change the beta ratio the delays will there will be a sweet spot where the low to high and high to low delays would both be lower and you will you will have a beta ratio range which you would want to keep in your design okay so beta ratio you will see will typically in the theme of 65 also you want to keep it between 1.5 to 2.75 2.6 something like that okay uh we already discussed this that we are looking at first order rc response which is a decaying exponential they're talking about delay as uh effective resistance into capacitance and uh we we're really looking at you know essentially average current and all those things but this is too inaccurate to predict current at any given time but good enough to predict the rc delays if we try to look at the model of the delay you know r on we can say that a device which is k times a unit device size would have r by k the effective r on and k c as the effective load capacitance is this thing clear to you so this case is the diffusion one right kc times the same yeah the the load capacitance because of drain and source region okay so c would be when the we have unit yes okay now what happens with the pmos we say that the p mass the resistance is already 2r because of mobility constraints so for the pmos the capacitance capacitances will move in the same ratio in fact the resistance would also move in the same ratio but final resistance will be not r by k but 2 r by k because even in a unit unit thing the capacitor resistance was 2r so what essentially we are seeing is capacitance is proportional to it resistance is inversely proportional to it uh why is unity uh why does your females have a resistance to work i'm sorry uh what's the reason for unit teamers having resistance uh because the mobility of the p masses uh the hose is lesser than the mobility of the electrons so see what they discussed you will fall back up on all of that only no they behave the same way the resistance is because the mobility of the end masses is uh of the mobility of the electrons is better than the mobility of the hose therefore resistance of the"
fDntVpDkcec,masses twice and we have this uh factor of two because uh we need to maintain the same beta ratio yeah yeah so so no no no so we assumed that mobility of the hose is one by half the mobility of the electrons that is y2r yes yes now to get same delays uh same rise and fall delays you make an inverter with the ratio two is to one okay yeah so and nmus both have same delay yes okay and then you can estimate the delay of an inverter by making an equivalent rc model and you will notice that equivalent delay of a inverter is 6 rc can you work it out over here so we are looking at delay from zero to one what happens nmos is on pmos is off so this particular resistance and capacitance completely goes out of picture we only see this 2c this 2c c c and r and c now this c is between ground and ground so this also capacitance goes out of picture this is my final model 1r and 6c so the delay of an inverter is 6rc so can you explain this whole thing again so do you remember this this is this mosfet the mosfet says that there is a gate capacitance there is source and drain capacitance and there is a resistance yeah i just put the same models for the nmos and the p mosses over here nothing else okay okay and then what i've done is i've removed the invalid capacitances now this part is not in picture so i've removed this part and i've come to an equivalent circuit okay okay okay so the delay of this is 6rc okay but where did the um so we have placed one inverter one after the other but so for the second inverter i mean at node y we have just included the capacitances yeah why do we need to include anything else that is only the gate load no okay if i have to measure the delay of this particular inverter the output only acts as load capacitive load it's only going to the gate okay so for for load purposes yeah you have to take the fan out for considering the load [Music] and the gate but while this we are showing only the source and the drain capacitances and the gate i'm not able to see how his gate model like why is that you tell me will will there be any current that will flow through the gate i mean no sir no then why do i need to show it the gate is somewhere here it's here let this be here how does it matter so but for the uh second stage the input capacitance will be parallel with this right now later okay so we get the inverted delay to be 6rc now a little complex skate so and you will notice that this rc model is actually reasonably accurate look at the spice model and a very a shockley model there are multiple models so look at different models and you will see this is reasonably accurate at least what at fifty percent transition this is very accurate so back of the calculations this method should work fine okay so now what about a three input nand gate what will you do do you realize you will have to size it something like this hello set to maintain will propagation delay i'm sorry sir we are sizing it in this way uh just to maintain equal uh propagation dealer right yes sizing it like this so that it has an equivalent delay of an inverter only so now how is the delays move over here first first are you able to see this is the equivalent inverter delay sizing so if i make an uh you know if if i consider if i consider that there are these three inverters in series then by having 3 i have resistances of r by 3 over here effective resistance is r so this sizing of 3 means that i have the effective r on equivalent to a unit inverter are you able to see this so now that i have the size of 3 how will my capacitances scale they will scale something like this wherever it was 2 it has i have 2c wherever it was 3 i have 3c now again what will i do i will remove the redundant capacitances which are the redundant capacitances the capacitances on the input over here for example or or capacitance between ground and uh and itself or capacitance between vdd and itself so those capacitances i will remove to simplify this on this circuit so how what happens so this is my effective capacitance graph which ones that added 2 c 2 c 2c 2c so 6c and 3c so 9c on the output the other capacitances that are valid are these 3 c capacitances are you with me hello yes sir now let us put the resistances also there so a quick refresh we know the elmore's equation that to get propagation delay i have to do some of our i2 source to ci so r1 c1 plus r1 plus r2 c2 plus r1 plus r2 plus rn 2 cn we remember this we already covered this in last or last to last class elmo's delay so if we apply this on our equivalent circuit now what happens let us say i have h copies on the output so my load would be 9 plus 5 hc my resistances are r by 3 r by 3. hello yes so what will be my delay over here now so tdr propagation delay for rising what what is the rising eye condition one of the n mosses should be off and two of the p monster should be off that will give me the worst delay am i right so one of the p mosses was on and i could get the ppdr as nine plus five hrc because this is the only path are you with me yes sir now what about the falling delay so following delay i have here these two capacitors also into picture which need to be discharged before the output gets discharged we will apply the elmore's delay equation and we will see that the following delay is 12 plus 5 hrc what did i do i simply set this 3c from r by 3 then this 3c from 2r by 3 then this from r you see so answer i get is 12 plus 5 hrc so one thing that is evident is that in a nand gate even if i have sized it equivalent to an to a regular inverter the rise and fall delays will not be equal the rise the propagation delays for rise and fall will not be equal are we able to see this huh and uh what about the contamination delay or the pmos side it is very simple all the three p moses have to turn on simultaneously so the effective resistance would be r by 3 and this would be the fastest that my output would double are you able to see this friends i'm not a client okay so what about the falling contamination delay what happens there so falling contamination delay is your homework you estimate the following contamination delay the fastest delay that would get in contamination for the falling case what would you do we already discussed that for the two input nand gate for three input nand gate i'm giving it to you as homework so you don't need to submit that homework but just do it just to get more clarity for yourself so what how would you calculate the contamination delay for falling so if the um two transistors below i mean if they are already been discharged yes so these capacitances they will already be out of picture and then only this will have to discharge okay you will see it will come to be something similar only okay so before we prove it can we uh can we go back to when we derive the uh rc modulus of pmos and nmos um okay yeah yeah yeah exactly so i mean can you just go over how we derive this okay forget about the term k over here okay so if i have a if i have mosfet and i say it is on what all capacitances and resistances do i have i have a cd i have a cg i have a r on and i have a cs yes so a right now the switch the switch is the mos switch now if the gate is at zero the nmos will not conduct so this is an open connection then okay the drain and the source are not connected that's all answers cd and css are basically diffusion capacitances conclusion plus overlap plus all that yes the all that we discussed yeah but so if you are including the overlap i mean you mean gate to drain and gate resource so what is the gate capacitance you are facing away get capacious come we did all that master passion for cheese now so everything oh sir but we have included that in for our cd and cs now that um gate 2 source capacity but gate 2 inversion layer capacitance will be there now oh yeah of course i know so why did we cover all that so it might be sounding like a solid state devices but you realize this is all very relevant to us,https://www.youtube.com/watch?v=fDntVpDkcec,"Link: https://www.youtube.com/watch?v=fDntVpDkcec
Transcript: masses twice and we have this uh factor of two because uh we need to maintain the same beta ratio yeah yeah so so no no no so we assumed that mobility of the hose is one by half the mobility of the electrons that is y2r yes yes now to get same delays uh same rise and fall delays you make an inverter with the ratio two is to one okay yeah so and nmus both have same delay yes okay and then you can estimate the delay of an inverter by making an equivalent rc model and you will notice that equivalent delay of a inverter is 6 rc can you work it out over here so we are looking at delay from zero to one what happens nmos is on pmos is off so this particular resistance and capacitance completely goes out of picture we only see this 2c this 2c c c and r and c now this c is between ground and ground so this also capacitance goes out of picture this is my final model 1r and 6c so the delay of an inverter is 6rc so can you explain this whole thing again so do you remember this this is this mosfet the mosfet says that there is a gate capacitance there is source and drain capacitance and there is a resistance yeah i just put the same models for the nmos and the p mosses over here nothing else okay okay and then what i've done is i've removed the invalid capacitances now this part is not in picture so i've removed this part and i've come to an equivalent circuit okay okay okay so the delay of this is 6rc okay but where did the um so we have placed one inverter one after the other but so for the second inverter i mean at node y we have just included the capacitances yeah why do we need to include anything else that is only the gate load no okay if i have to measure the delay of this particular inverter the output only acts as load capacitive load it's only going to the gate okay so for for load purposes yeah you have to take the fan out for considering the load [Music] and the gate but while this we are showing only the source and the drain capacitances and the gate i'm not able to see how his gate model like why is that you tell me will will there be any current that will flow through the gate i mean no sir no then why do i need to show it the gate is somewhere here it's here let this be here how does it matter so but for the uh second stage the input capacitance will be parallel with this right now later okay so we get the inverted delay to be 6rc now a little complex skate so and you will notice that this rc model is actually reasonably accurate look at the spice model and a very a shockley model there are multiple models so look at different models and you will see this is reasonably accurate at least what at fifty percent transition this is very accurate so back of the calculations this method should work fine okay so now what about a three input nand gate what will you do do you realize you will have to size it something like this hello set to maintain will propagation delay i'm sorry sir we are sizing it in this way uh just to maintain equal uh propagation dealer right yes sizing it like this so that it has an equivalent delay of an inverter only so now how is the delays move over here first first are you able to see this is the equivalent inverter delay sizing so if i make an uh you know if if i consider if i consider that there are these three inverters in series then by having 3 i have resistances of r by 3 over here effective resistance is r so this sizing of 3 means that i have the effective r on equivalent to a unit inverter are you able to see this so now that i have the size of 3 how will my capacitances scale they will scale something like this wherever it was 2 it has i have 2c wherever it was 3 i have 3c now again what will i do i will remove the redundant capacitances which are the redundant capacitances the capacitances on the input over here for example or or capacitance between ground and uh and itself or capacitance between vdd and itself so those capacitances i will remove to simplify this on this circuit so how what happens so this is my effective capacitance graph which ones that added 2 c 2 c 2c 2c so 6c and 3c so 9c on the output the other capacitances that are valid are these 3 c capacitances are you with me hello yes sir now let us put the resistances also there so a quick refresh we know the elmore's equation that to get propagation delay i have to do some of our i2 source to ci so r1 c1 plus r1 plus r2 c2 plus r1 plus r2 plus rn 2 cn we remember this we already covered this in last or last to last class elmo's delay so if we apply this on our equivalent circuit now what happens let us say i have h copies on the output so my load would be 9 plus 5 hc my resistances are r by 3 r by 3. hello yes so what will be my delay over here now so tdr propagation delay for rising what what is the rising eye condition one of the n mosses should be off and two of the p monster should be off that will give me the worst delay am i right so one of the p mosses was on and i could get the ppdr as nine plus five hrc because this is the only path are you with me yes sir now what about the falling delay so following delay i have here these two capacitors also into picture which need to be discharged before the output gets discharged we will apply the elmore's delay equation and we will see that the following delay is 12 plus 5 hrc what did i do i simply set this 3c from r by 3 then this 3c from 2r by 3 then this from r you see so answer i get is 12 plus 5 hrc so one thing that is evident is that in a nand gate even if i have sized it equivalent to an to a regular inverter the rise and fall delays will not be equal the rise the propagation delays for rise and fall will not be equal are we able to see this huh and uh what about the contamination delay or the pmos side it is very simple all the three p moses have to turn on simultaneously so the effective resistance would be r by 3 and this would be the fastest that my output would double are you able to see this friends i'm not a client okay so what about the falling contamination delay what happens there so falling contamination delay is your homework you estimate the following contamination delay the fastest delay that would get in contamination for the falling case what would you do we already discussed that for the two input nand gate for three input nand gate i'm giving it to you as homework so you don't need to submit that homework but just do it just to get more clarity for yourself so what how would you calculate the contamination delay for falling so if the um two transistors below i mean if they are already been discharged yes so these capacitances they will already be out of picture and then only this will have to discharge okay you will see it will come to be something similar only okay so before we prove it can we uh can we go back to when we derive the uh rc modulus of pmos and nmos um okay yeah yeah yeah exactly so i mean can you just go over how we derive this okay forget about the term k over here okay so if i have a if i have mosfet and i say it is on what all capacitances and resistances do i have i have a cd i have a cg i have a r on and i have a cs yes so a right now the switch the switch is the mos switch now if the gate is at zero the nmos will not conduct so this is an open connection then okay the drain and the source are not connected that's all answers cd and css are basically diffusion capacitances conclusion plus overlap plus all that yes the all that we discussed yeah but so if you are including the overlap i mean you mean gate to drain and gate resource so what is the gate capacitance you are facing away get capacious come we did all that master passion for cheese now so everything oh sir but we have included that in for our cd and cs now that um gate 2 source capacity but gate 2 inversion layer capacitance will be there now oh yeah of course i know so why did we cover all that so it might be sounding like a solid state devices but you realize this is all very relevant to us"
wUHaLuQzSxg,uh what is called as uh you know logical effort the concept of logical efforts and this concept is is uh will help us to size devices gates and chains of devices chains of base mother you have a question yes sir i have a doubt in contamination delay that dust contamination really always affect only hold time or it may in some cases also affect setup times no contamination delay is uh is is fastest today so it will not usually have any bearing on the third time so but in some cases like in to input 90 only in in one case i was seeing that fall daily was increasing so i don't know if it was increasing i'm sorry performed fall delay so that is then the propagation delay contamination delay is always the shortest the smallest delay [Music] okay this is the fastest delay that is the definition of contamination if there is a faster delay then that is the contamination delay okay so anything slower than that will be propagation yeah will be a part of propagation today okay [Music] okay yeah so this method is called logical effort and as i mentioned you know in the last class also that we would want to size circuits get a feel of the circuit and do stuff with that even without doing the first simulation so logical effort will help us do back of the envelope sizing of circuits so what did we do in the last class we did back with another calculations for estimating the delays we did not do any simulation but we could say okay this delay is six units this delay is four units and so on you were able to say that yes sir so with logical effort what we are trying to say is with logical effort we are saying that i will similarly be able to do some circuit sizing without even running one simulation okay so let us say this is an inverter chain if the load capacitance is given what would be the minimum number of stages or what how many stages do i need to have minimum minimum delay and what should be the size of my inverters if we have to answer this question that is when logical effort comes into picture is the question player is the objective of this session clear so in the previous classes we have discussed that given the sizing and everything what will be the backend calculation of the delay now we are doing the exact opposite of that yes because as a circuit designer you need to do both yeah okay okay okay okay so sir yes how will the delays uh decrease or increase i'm like i think it they should increase if we increase the number of stages right so let us see okay okay so uh the first step that we need to do is we need to express delays in process independent units because i don't want to now talk about what would happen in 65 nanometer what would happen in 40 nanometer or 80 nanometer or 180 nanometers i want to come up with a design method which is process independent technology independent and to do that what we do is we say that okay let us talk of a unit d which is basically the absolute value of delay divided by tau and this tau is equal to 3 rc y3 rc y3 rc uh time delay of importer yeah so delay of an inverter without any fan out or in a different way if the inverter was ideal and had no self-loading then the delay with one panel are you with me so we are not considering that two c and c of the uh we will see we will i'm not saying we're not considering i am saying let us represent delays in the standard format where we do d by the absolute by tau and tau is equal to 3 rc we just take i'm not saying we are ignoring anything okay okay did i say i'm ignoring anything no no sir not yet clear three rc is there so you know there are some significance of three rc that is why we are using crc then we say that delay has two components f and p f component represents effort delay which is stage effort that my how big is the output okay and it again has two components one is logical effort so abby definitions so don't get bogged down by so many new terms that you are getting to here just now uh you will have time to absorb them okay so effort delay s is a multiplication of logical effort and electrical effort so logical effort is a relative ability of a gate to deliver current what is it relative to it is related to an inverter so if it's a nand gate we will see how to calculate its logical effort electrical effort is very simple it simply is the ratio of output resist output capacitance with the input capacitance it is also called as fan out okay so three new terms on this particular slide effort delay logical effort and electrical effort okay and then there is parasitic delay this represents the delay of a gate when there was no load so how much would this delay be for an inverter hello there is three rc yes this delay parasitic delay will be three rc so d equal to the so d absolute will be three rc so d equal to be one for an inverter are you able to see this does that mean three rc means one unit delay yes okay okay okay so with these definitions let us see how to estimate the value of g and h2 h2 g and other stuff so that we can overall get the value of total delay in any system so what we did was we plotted the delays offered to input nand and an inverter for uh different electrical effort and these were the graphs that we received what we see is that g for a nand is about four by three parasitic is two and the d is four by three h plus two whereas for the inverter g resolve is one because everything is related to an inverter parasitic delay we found to be one unit so the delay would be h plus one h would be the fan out so how did we get g equal to four by three any ideas because then you will be able to answer the question on nordic no what would be the same thing for not to sir can you just just briefly explain this g and h and were able to distinguish between them the g and h i'm getting h fan out sir is it the slope sir yes it is the slope but to the previous question h is fan out okay in very simple terms that is fan out which is also called as electrical effort in the logical effort terminology okay so the more number of so the more number of grades it would be driving the moon the electrical effect a bigger drive the more delay which is also intuitive yeah answer the g thing the b parameter yeah g is the uh is the ratio of uh or let us say in this case g is the slope of this line g is the logical effort how much extra effort do i need to get to put in in comparison to an inverter what do you mean by effort english me physics may what do we mean by effort so i mean there's some kind of force of the force i have to apply hannah yeah so how do i apply a force on a gate input on a on a gate which is a two input nand gate for example so you can repeat the question just just ask so how do i apply force on a two input nand gate so that it starts to give an output that i desire so we're charging its input so by charging its input capacitances so do you see that there could be some relation between the input capacitance of a two input nand gate and the input capacitance of an inverter so i didn't get the point of charging the input capacitances i mean we are just applying the input signal right huh does your input signal what does the input signal do what does the input signal do so we apply the gate to source voltage and then basically depending upon that the channel is formed and then if there is a capacitance here no yeah yes sir that charges this capacitance okay that is when this will go up now right the gate capacity you're talking about okay so now for an inverter what was the capacitance that you needed to charge so 3c 3c what is the capacitance that you will need to charge for this inverter this nand gate okay okay so we are taking the input signal strength to be out of the equation just the gates yes okay therefore that for the logical effort for uh uh two input nand is four by three okay like how much more it is required compared to the inverter okay okay how much more effort do i need to put to get the same result same response as an inverter would have given okay got it sir okay so what would it be for not to quickly how would you size an r2 what would be the size of the n masses bulla how would i size the nmos is here in the worst case how many nmos is in series so [Music] okay what about the pmos now 5x3 wonderful are all of you able to see this no sir right okay let's go into detail uh the logical effort is the ratio of the input capacitance of a gate to the input capacitance of an inverter delivering the same output current so for a nand gate the c cn is 4 so g is equal to 4 by 3 for a nor gate the cn is 5 therefore g is equal to 5 by 3. so there are different inputs or if the two inputs are there then you take any one input we talk only about a what is happening to it so we're not going to a complex gate i know there could be a complex gate which could appear like this a b and c so c would have different sizing than b so ecological effort let us look at symmetric gates only in the exam you may get complex gates you may want to propose questions of complex rates in your assignment but just to understand the concept let us start with simple symmetric dates what happens so first this four four and one one is clear this was the question is i lost in the beginning also sir yes so this sizings are done just to ensure that we'll have same equivalent resistance both for the rise and the fall time yeah right yes it's not with the delay that we achieved are on okay the but how is this related to same power i did not understand this so uh what is current across a mosfet okay it's voltage divided by our own okay yeah so you will get iron yes yes yes sir got it thank you okay so can i say the lower the logical effort the less will be the delay the lower the logical effort the lesser will be the delay yes because g becomes less so g into h is small yes so when we design do we keep for like more of nand gates in circuit because they are faster we don't know [Music] you would probably want to yes but if you need a nor functionality then you need an functionality so is this calculation for g clear all of you so yes i'm still quite a bit confused in the calculation of g calculation of g or sizing of the gate uh actually the sizing only sizing mecha confusion what is the confusion there what i am understanding is the resistance of both the nmos should be [Music] you have to look at it as in the worst case when only one nmos is on the delay of the nor gate should be equal to the delay of the inverter delaney is output current okay so how would you size the n masses then the same as the inverter yes sir the same applies for the pmos at the current should be same as in an inverter however there are two pmoses in series now so what do you need to do you need to halve the resistance yes sir to half the resistance you need to double the size up yes yes therefore the p mass of inverter should be doubled up therefore p mosses are sized at four okay,https://www.youtube.com/watch?v=wUHaLuQzSxg,"Link: https://www.youtube.com/watch?v=wUHaLuQzSxg
Transcript: uh what is called as uh you know logical effort the concept of logical efforts and this concept is is uh will help us to size devices gates and chains of devices chains of base mother you have a question yes sir i have a doubt in contamination delay that dust contamination really always affect only hold time or it may in some cases also affect setup times no contamination delay is uh is is fastest today so it will not usually have any bearing on the third time so but in some cases like in to input 90 only in in one case i was seeing that fall daily was increasing so i don't know if it was increasing i'm sorry performed fall delay so that is then the propagation delay contamination delay is always the shortest the smallest delay [Music] okay this is the fastest delay that is the definition of contamination if there is a faster delay then that is the contamination delay okay so anything slower than that will be propagation yeah will be a part of propagation today okay [Music] okay yeah so this method is called logical effort and as i mentioned you know in the last class also that we would want to size circuits get a feel of the circuit and do stuff with that even without doing the first simulation so logical effort will help us do back of the envelope sizing of circuits so what did we do in the last class we did back with another calculations for estimating the delays we did not do any simulation but we could say okay this delay is six units this delay is four units and so on you were able to say that yes sir so with logical effort what we are trying to say is with logical effort we are saying that i will similarly be able to do some circuit sizing without even running one simulation okay so let us say this is an inverter chain if the load capacitance is given what would be the minimum number of stages or what how many stages do i need to have minimum minimum delay and what should be the size of my inverters if we have to answer this question that is when logical effort comes into picture is the question player is the objective of this session clear so in the previous classes we have discussed that given the sizing and everything what will be the backend calculation of the delay now we are doing the exact opposite of that yes because as a circuit designer you need to do both yeah okay okay okay okay so sir yes how will the delays uh decrease or increase i'm like i think it they should increase if we increase the number of stages right so let us see okay okay so uh the first step that we need to do is we need to express delays in process independent units because i don't want to now talk about what would happen in 65 nanometer what would happen in 40 nanometer or 80 nanometer or 180 nanometers i want to come up with a design method which is process independent technology independent and to do that what we do is we say that okay let us talk of a unit d which is basically the absolute value of delay divided by tau and this tau is equal to 3 rc y3 rc y3 rc uh time delay of importer yeah so delay of an inverter without any fan out or in a different way if the inverter was ideal and had no self-loading then the delay with one panel are you with me so we are not considering that two c and c of the uh we will see we will i'm not saying we're not considering i am saying let us represent delays in the standard format where we do d by the absolute by tau and tau is equal to 3 rc we just take i'm not saying we are ignoring anything okay okay did i say i'm ignoring anything no no sir not yet clear three rc is there so you know there are some significance of three rc that is why we are using crc then we say that delay has two components f and p f component represents effort delay which is stage effort that my how big is the output okay and it again has two components one is logical effort so abby definitions so don't get bogged down by so many new terms that you are getting to here just now uh you will have time to absorb them okay so effort delay s is a multiplication of logical effort and electrical effort so logical effort is a relative ability of a gate to deliver current what is it relative to it is related to an inverter so if it's a nand gate we will see how to calculate its logical effort electrical effort is very simple it simply is the ratio of output resist output capacitance with the input capacitance it is also called as fan out okay so three new terms on this particular slide effort delay logical effort and electrical effort okay and then there is parasitic delay this represents the delay of a gate when there was no load so how much would this delay be for an inverter hello there is three rc yes this delay parasitic delay will be three rc so d equal to the so d absolute will be three rc so d equal to be one for an inverter are you able to see this does that mean three rc means one unit delay yes okay okay okay so with these definitions let us see how to estimate the value of g and h2 h2 g and other stuff so that we can overall get the value of total delay in any system so what we did was we plotted the delays offered to input nand and an inverter for uh different electrical effort and these were the graphs that we received what we see is that g for a nand is about four by three parasitic is two and the d is four by three h plus two whereas for the inverter g resolve is one because everything is related to an inverter parasitic delay we found to be one unit so the delay would be h plus one h would be the fan out so how did we get g equal to four by three any ideas because then you will be able to answer the question on nordic no what would be the same thing for not to sir can you just just briefly explain this g and h and were able to distinguish between them the g and h i'm getting h fan out sir is it the slope sir yes it is the slope but to the previous question h is fan out okay in very simple terms that is fan out which is also called as electrical effort in the logical effort terminology okay so the more number of so the more number of grades it would be driving the moon the electrical effect a bigger drive the more delay which is also intuitive yeah answer the g thing the b parameter yeah g is the uh is the ratio of uh or let us say in this case g is the slope of this line g is the logical effort how much extra effort do i need to get to put in in comparison to an inverter what do you mean by effort english me physics may what do we mean by effort so i mean there's some kind of force of the force i have to apply hannah yeah so how do i apply a force on a gate input on a on a gate which is a two input nand gate for example so you can repeat the question just just ask so how do i apply force on a two input nand gate so that it starts to give an output that i desire so we're charging its input so by charging its input capacitances so do you see that there could be some relation between the input capacitance of a two input nand gate and the input capacitance of an inverter so i didn't get the point of charging the input capacitances i mean we are just applying the input signal right huh does your input signal what does the input signal do what does the input signal do so we apply the gate to source voltage and then basically depending upon that the channel is formed and then if there is a capacitance here no yeah yes sir that charges this capacitance okay that is when this will go up now right the gate capacity you're talking about okay so now for an inverter what was the capacitance that you needed to charge so 3c 3c what is the capacitance that you will need to charge for this inverter this nand gate okay okay so we are taking the input signal strength to be out of the equation just the gates yes okay therefore that for the logical effort for uh uh two input nand is four by three okay like how much more it is required compared to the inverter okay okay how much more effort do i need to put to get the same result same response as an inverter would have given okay got it sir okay so what would it be for not to quickly how would you size an r2 what would be the size of the n masses bulla how would i size the nmos is here in the worst case how many nmos is in series so [Music] okay what about the pmos now 5x3 wonderful are all of you able to see this no sir right okay let's go into detail uh the logical effort is the ratio of the input capacitance of a gate to the input capacitance of an inverter delivering the same output current so for a nand gate the c cn is 4 so g is equal to 4 by 3 for a nor gate the cn is 5 therefore g is equal to 5 by 3. so there are different inputs or if the two inputs are there then you take any one input we talk only about a what is happening to it so we're not going to a complex gate i know there could be a complex gate which could appear like this a b and c so c would have different sizing than b so ecological effort let us look at symmetric gates only in the exam you may get complex gates you may want to propose questions of complex rates in your assignment but just to understand the concept let us start with simple symmetric dates what happens so first this four four and one one is clear this was the question is i lost in the beginning also sir yes so this sizings are done just to ensure that we'll have same equivalent resistance both for the rise and the fall time yeah right yes it's not with the delay that we achieved are on okay the but how is this related to same power i did not understand this so uh what is current across a mosfet okay it's voltage divided by our own okay yeah so you will get iron yes yes yes sir got it thank you okay so can i say the lower the logical effort the less will be the delay the lower the logical effort the lesser will be the delay yes because g becomes less so g into h is small yes so when we design do we keep for like more of nand gates in circuit because they are faster we don't know [Music] you would probably want to yes but if you need a nor functionality then you need an functionality so is this calculation for g clear all of you so yes i'm still quite a bit confused in the calculation of g calculation of g or sizing of the gate uh actually the sizing only sizing mecha confusion what is the confusion there what i am understanding is the resistance of both the nmos should be [Music] you have to look at it as in the worst case when only one nmos is on the delay of the nor gate should be equal to the delay of the inverter delaney is output current okay so how would you size the n masses then the same as the inverter yes sir the same applies for the pmos at the current should be same as in an inverter however there are two pmoses in series now so what do you need to do you need to halve the resistance yes sir to half the resistance you need to double the size up yes yes therefore the p mass of inverter should be doubled up therefore p mosses are sized at four okay"
GKW7auPWGbA,okay so okay anything else okay so now now that we know this we can actually find out the uh logical effort for various gates you can actually also come to standard formulae that for a nor gate will be 2 n plus 1 by 3 for a nand gate it will be n plus 2 where n is the number of inputs and so on so and as we said in complex gates there could be different logical effort for different inputs so can you benefit from it if at all put your designer hat and tell me if there are if you're using a xor 3 let us say we are using this particular gate how would you like can you benefit from the fact that some inputs have lower logical effort others have larger logical effort so maybe for inputs that don't switch much we can keep them with gates with less logical effect so those that do not switch much you will put them on with uh more logical effort larger logical effort okay so then that will save power interesting very interesting um anything about delays yes larger the logical effort lesser the opposite i think yeah so the gate which has the lesser logical effort on that gate you will apply those signals which arrive late yes so uh that's there as a differential logical effort is not necessarily a bad thing you can also make some good use of it see something like now when life throws lemons at you you better make lemonade so that's what you can also do over here so uh you can now given any gate you will be able to estimate the logical effort there you all just need to do is do the sizing correctly and you will be able to do it now what about parasitic delay what would you tell about panacetic delay over here so these parasitic dnas are gate to source and i mean gate to body and these types of diseases yes these types of capacitances it depends on number of inputs yes it is actually dependent on number of inputs why because you we just saw that the overall sizing of my gates is also dependent on number of inputs so the parasitics that i will possibly observe in my layout will also be dependent on number of inputs so simply we say as many inputs as many you know uh as much of the inverter then for tristate and mux uh the inputs go to two gates and or more gates and therefore we said okay it is 2n okay so now now that we know how to find estimate the delay of an inverter can you estimate the frequency of an end stage ring oscillator what would be the logical effort over here huh in this case for the end stage inverter what would be the logical effort three and uh logical effort these are inverters only now so it has to be one yes another z equal to one it is all inverters what is the electrical effort electrical effort is the fan out how many inverters is one is any inverter connected to the output um your first inverter the output of the first inverter has a nine capacitors capacitances and parallels so we can say n so it is c out over c n yes c out of the first inverter is that equal to cn um no so it's uh because of the other you're also looking at the uh input capacitances of the other inverters right that is coming in the output yeah see parasitics due to self-loading something we are adding later okay the load that this inverter is seeing is that equal to the load that this inverter is showing to its driver oh yes so electrical effort is also one parasitic delay is inverter for one so what is the stage delay stage delay is two are you able to see this questions so so here the electrical effort is one so but like the rc out here is basically the cd diffusion one and it with the in that scene will be the gate oh no so c diffusion we are already putting in the parasitic delay okay then we talk of electrical effort we only talk of the gate gate load of the uh next stage over here okay and the c insert what then is the c and basically i mean see the gate the c n is the gate capacitance of this stage of the of the of the subsequent stage of the stage so see in so for any inverter see for any inverter cn is the capacitance that it shows to the previous state so for this inverter there is a capacitance over here this will be called as its cn and the capacitance over here will be called as c out okay is it going to be the same okay so i mean the c out of one gate is the scene of another gate okay okay so so for the first inverter the gate capacitance of the second inverter will be the c out yes okay and the scene will be its own gate input okay okay so now okay are you is this up till stage delay part player to all of you see we already saw for an inverter we already saw that for an inverter if we talked of it in terms of rcs so there was 2c up there and 1c down here you already saw that anna yeah yeah okay so that is equal to 1d so and in the case of electrical delay can't we just say the fan out of every inverter is one so now what will be the frequency so i still don't get logical effect logical effort of an inverter is one so but we are cascading so we mean so one guys for any inverter for any stage how much effort does the previous stage need to apply in comparison to an inverter to get the same output as an inverter would give that is the definition so if you already have inverters then it is the same effort now okay so we we are looking at only one invert with this entire stage this is the first first we are arriving at the calculation for one stage delay once we have the calculation for one stage delay then we can find the calculation for n stages so you simply multiply it by n okay and just this stage what is this stage space division yeah so what is that this is gh plus p that was the formula okay yes so now what is that what is the frequency now there is no single stage frequency ui we only only have gh pd over here so what is the frequency at which this ring oscillator will oscillate is it 1 by d for 1 by nd 1 by nd no anyone asking or telling so what is the total delay of this inverter chain sir for one stage the delay is uh uh so uh it should it has to be one by two and and now start being with us okay what is the ring oscillator for an ancient oscillator will env even or odd events if you have an even number of stages will it ever oscillate it has to be hard it has to be odd so let us say i gave a input rising input over here so after these end stages what will i get as my input after this end delays the input would finally fall yes sir then after those stages again the input would again go up so what is the clock period then true ending but i have to go through these n stages twice and each each stage consumes a delay of d so since d is equal to 4 we say 4n hmm is this part clear yes sir yes sir so uh and now for a given technology if you know what is the value of d in the sense what is the value of rc what is the value of tau and you have an end stage oscillator can you estimate the frequency yes sir so let us say i have to make a like to make a oscillator of let us say 200 megahertz for a 0.6 micron technology you can easily estimate how many stitches you would need in the ring oscillator now you can do that if i know that for 0.5 4.6 micron technology the delay is 60 picoseconds let us say tau is equal to 60 picoseconds we can do it now yes sir so we've not done even a single simulation we just uses the we just used the information of tau from the technology and i'm able to design this entire chain an entire oscillator are you able to see the beauty of this method not a single simulation but i can estimate okay for this one i will need around 31 status probably 29 or 33 but i am right there somewhere sir so why i'm having a factor of doing denominator just missing out on that so because there are odd status in this chain yes sir yeah so when the input is rising the next time the input will come it will be falling so once an input traverses through all of this and it comes back it will be falling odd enough status yes so yeah yeah so i will have to traverse through this stage all over again to get the rising signal again okay okay all right so n over here n over here yeah okay got it okay okay so what about this now can we estimate the delay now if i say that every inverter is driving four equivalently size inverters what is my delay so h will be four here okay what is the logical effort so for logical effort so one one inverter yeah electrical effort is four hq set four okay pacific delay so one no no one one page delays cheers okay so if i know the technology the tau for a given technology i can immediately estimate the delay there are you able to see this yes now sir so just just to clarify one thing so this parasitic delay uh when i'm looking at the electrical effort that is basically modeling all the outputs that my basically the which is the my stage which is driving and when i'm looking at the parasitic delay i'm looking at the stage itself like which is going to be the driver basically yes right okay yes okay,https://www.youtube.com/watch?v=GKW7auPWGbA,"Link: https://www.youtube.com/watch?v=GKW7auPWGbA
Transcript: okay so okay anything else okay so now now that we know this we can actually find out the uh logical effort for various gates you can actually also come to standard formulae that for a nor gate will be 2 n plus 1 by 3 for a nand gate it will be n plus 2 where n is the number of inputs and so on so and as we said in complex gates there could be different logical effort for different inputs so can you benefit from it if at all put your designer hat and tell me if there are if you're using a xor 3 let us say we are using this particular gate how would you like can you benefit from the fact that some inputs have lower logical effort others have larger logical effort so maybe for inputs that don't switch much we can keep them with gates with less logical effect so those that do not switch much you will put them on with uh more logical effort larger logical effort okay so then that will save power interesting very interesting um anything about delays yes larger the logical effort lesser the opposite i think yeah so the gate which has the lesser logical effort on that gate you will apply those signals which arrive late yes so uh that's there as a differential logical effort is not necessarily a bad thing you can also make some good use of it see something like now when life throws lemons at you you better make lemonade so that's what you can also do over here so uh you can now given any gate you will be able to estimate the logical effort there you all just need to do is do the sizing correctly and you will be able to do it now what about parasitic delay what would you tell about panacetic delay over here so these parasitic dnas are gate to source and i mean gate to body and these types of diseases yes these types of capacitances it depends on number of inputs yes it is actually dependent on number of inputs why because you we just saw that the overall sizing of my gates is also dependent on number of inputs so the parasitics that i will possibly observe in my layout will also be dependent on number of inputs so simply we say as many inputs as many you know uh as much of the inverter then for tristate and mux uh the inputs go to two gates and or more gates and therefore we said okay it is 2n okay so now now that we know how to find estimate the delay of an inverter can you estimate the frequency of an end stage ring oscillator what would be the logical effort over here huh in this case for the end stage inverter what would be the logical effort three and uh logical effort these are inverters only now so it has to be one yes another z equal to one it is all inverters what is the electrical effort electrical effort is the fan out how many inverters is one is any inverter connected to the output um your first inverter the output of the first inverter has a nine capacitors capacitances and parallels so we can say n so it is c out over c n yes c out of the first inverter is that equal to cn um no so it's uh because of the other you're also looking at the uh input capacitances of the other inverters right that is coming in the output yeah see parasitics due to self-loading something we are adding later okay the load that this inverter is seeing is that equal to the load that this inverter is showing to its driver oh yes so electrical effort is also one parasitic delay is inverter for one so what is the stage delay stage delay is two are you able to see this questions so so here the electrical effort is one so but like the rc out here is basically the cd diffusion one and it with the in that scene will be the gate oh no so c diffusion we are already putting in the parasitic delay okay then we talk of electrical effort we only talk of the gate gate load of the uh next stage over here okay and the c insert what then is the c and basically i mean see the gate the c n is the gate capacitance of this stage of the of the of the subsequent stage of the stage so see in so for any inverter see for any inverter cn is the capacitance that it shows to the previous state so for this inverter there is a capacitance over here this will be called as its cn and the capacitance over here will be called as c out okay is it going to be the same okay so i mean the c out of one gate is the scene of another gate okay okay so so for the first inverter the gate capacitance of the second inverter will be the c out yes okay and the scene will be its own gate input okay okay so now okay are you is this up till stage delay part player to all of you see we already saw for an inverter we already saw that for an inverter if we talked of it in terms of rcs so there was 2c up there and 1c down here you already saw that anna yeah yeah okay so that is equal to 1d so and in the case of electrical delay can't we just say the fan out of every inverter is one so now what will be the frequency so i still don't get logical effect logical effort of an inverter is one so but we are cascading so we mean so one guys for any inverter for any stage how much effort does the previous stage need to apply in comparison to an inverter to get the same output as an inverter would give that is the definition so if you already have inverters then it is the same effort now okay so we we are looking at only one invert with this entire stage this is the first first we are arriving at the calculation for one stage delay once we have the calculation for one stage delay then we can find the calculation for n stages so you simply multiply it by n okay and just this stage what is this stage space division yeah so what is that this is gh plus p that was the formula okay yes so now what is that what is the frequency now there is no single stage frequency ui we only only have gh pd over here so what is the frequency at which this ring oscillator will oscillate is it 1 by d for 1 by nd 1 by nd no anyone asking or telling so what is the total delay of this inverter chain sir for one stage the delay is uh uh so uh it should it has to be one by two and and now start being with us okay what is the ring oscillator for an ancient oscillator will env even or odd events if you have an even number of stages will it ever oscillate it has to be hard it has to be odd so let us say i gave a input rising input over here so after these end stages what will i get as my input after this end delays the input would finally fall yes sir then after those stages again the input would again go up so what is the clock period then true ending but i have to go through these n stages twice and each each stage consumes a delay of d so since d is equal to 4 we say 4n hmm is this part clear yes sir yes sir so uh and now for a given technology if you know what is the value of d in the sense what is the value of rc what is the value of tau and you have an end stage oscillator can you estimate the frequency yes sir so let us say i have to make a like to make a oscillator of let us say 200 megahertz for a 0.6 micron technology you can easily estimate how many stitches you would need in the ring oscillator now you can do that if i know that for 0.5 4.6 micron technology the delay is 60 picoseconds let us say tau is equal to 60 picoseconds we can do it now yes sir so we've not done even a single simulation we just uses the we just used the information of tau from the technology and i'm able to design this entire chain an entire oscillator are you able to see the beauty of this method not a single simulation but i can estimate okay for this one i will need around 31 status probably 29 or 33 but i am right there somewhere sir so why i'm having a factor of doing denominator just missing out on that so because there are odd status in this chain yes sir yeah so when the input is rising the next time the input will come it will be falling so once an input traverses through all of this and it comes back it will be falling odd enough status yes so yeah yeah so i will have to traverse through this stage all over again to get the rising signal again okay okay all right so n over here n over here yeah okay got it okay okay so what about this now can we estimate the delay now if i say that every inverter is driving four equivalently size inverters what is my delay so h will be four here okay what is the logical effort so for logical effort so one one inverter yeah electrical effort is four hq set four okay pacific delay so one no no one one page delays cheers okay so if i know the technology the tau for a given technology i can immediately estimate the delay there are you able to see this yes now sir so just just to clarify one thing so this parasitic delay uh when i'm looking at the electrical effort that is basically modeling all the outputs that my basically the which is the my stage which is driving and when i'm looking at the parasitic delay i'm looking at the stage itself like which is going to be the driver basically yes right okay yes okay"
RioleqvE7IM,so we will only look at driver when we are calculating parasitically i'm sorry so we will only be looking at the driver when calculating parasitic damage yeah the gate the gate for which we are calculating the delay we will only look at that we'll not look at the load okay no matter load may even have a lot of parasitic delay at its input yeah like over here we have four inverters as load and we would as well have ten inverters as low it will still take parasitic delay as one okay so because only one inverter is triggered yeah because it is the property of the driver the self loading of the driver there okay so now this is avid we were just looking at one stage delay now what happens if we have a complex path see typically we will not have only inverters capacitance we typically have multiple logics and multiple things coming into picture so in that case we talk about path logical effort which is multiplication of all the incumbent logical efforts path electrical effort which is c out final upon c in which make a doesn't matter okay and then overall path effort would be a multiplication of path efforts of each of these so which would appear to be something like multiplication of gh let us take this example itself i ask you to help me with sizing these nor gates and nand gates there so find the value of x y and z let us say so what do we do keep that question in mind we will just come to it can we probably write f is equal to g h is equal to g h but there is a small catch when there is a branch then you cannot really do that look at it over here g is 1 on this particular path f is 18 so gh is equal to 18. now let us calculate the h h1 and then h2 so what is h1 2 h1 is 2 just so fan out is 2 what about the size it's a 3 okay so it should be 6 then 6. huh and what about h2 6 h2 is also 6 why because 90 by 15 this is 90 and it has it has a gate load of 15. uh so what we say actual main capital f is equal to multiplication of g and the g's and h is so g1 g2 h1 h2 actual mate is equal to 36 but dh was only 18 so there is the factor of 2 where does this 2 come from two branches yes now over here this two can be said as two branches but if these branches were of different sizes we would not be able to put it as branches but if the two things are same size then we say that it is equal to gbh in reality we have to do it something like this branching effort is calculated by c on path plus c of path by c on path so i mean the f here is the stage delay equivalent of like multiple gates so by why we are not incorporating that the parasitic component here itself is a logical and electrical thing why not just can you go to the previous slide friends this is important concept i know you are yourself going to propose questions from this concept because this is full of numericals so it should be very very clear to you so can you just uh please explain the h part the 18 i mean 98 is coming up yeah because we saw that c out was 90 and cn was five so if you overall look at h for the path in which we want to measure the delay that h is 18 okay so we are taking the only the total like uh capacitance at the end of the path and at the input of the path that is what h meant in the in the previous slide what did we say in the still previous slide we had said that that is equal to ch of output on upon cn path that was what the definition of h was so that is what we did yeah so somebody's like so but like here we have like two edges two which right yes answer what is h1 h2 is denoting small h1 h2 h1 is a fan out for this stage h2 is the fan out for the second stage support when this input is driving two loads then how can we guarantee that uh path this path which is being highlighted its delay will not be affected at all by the uh the other part the above that is what we are finally concluding okay okay so that that is where the difference is that is what we are concluding we are not saying anything else sir okay sir but we can say that it won't be affected by the load that the other part is trying yeah because that would like if if this 15 was driving a load of let us say 180 i would still have this delay so sir yeah because i'm not bothered by h3 over here okay the h will change you will not i'm sorry uh the value of h would change the capital uh the capital h for the other but the g would not change the capital h will still be the same definition that is the definition of h okay yes we're just talking about is f equal to g x the question was is s equal to gh that was the question we said no we said there has to be another component which is related to branching in there we are answering only that question we're not saying h is calculated wrong no that was the definition of h please understood so and we are trying to calculate the delay eventually women calculate delay from all these things so if we apply elmore's uh almost delay then this above h3 will also come into picture for calculating delay from h1 to s2 so that is where that is where we're talking about off paths also paths which are not really under consideration okay that is why exactly that is the reason i am so happy that you are able to see that effect that is the nature of delay and because it has to come therefore this component of b which is a multiplication of all bis should also be brought into picture okay okay so yeah so i mean the h was calculated to be 18 so but we have two parts so shouldn't we have done the twice multiplication there itself i mean i wanted to find the delay of this path only okay i wanted to find the delay of this path so i will look at the output delay that this path has and then put the layer at this path i'm not bothered about this part for calculation of h okay so even if you're trying to consider this part the off path is coming into picture just like an elmore's delay yeah so but like uh okay right right if it is connected then it will be basically charging will load now the odd path will also load you have to take them into account okay but this definition doesn't take into account this h1 okay capital h is only c out by c n the basic definition what is the fan out what is c out by c n that's the thing so therefore we need to bring in this component of b and what we do understand is that bh will finally mean h1 into h2 into h3 into whatever h would not be able to that to be for this to be equal this has to be equal to b h so just can we just move again to the previous slide so h1 ms2 okay okay got it sir got it okay uh sir i have a doubt in the same slide can we can we go back so here in the calculation of h we have considered c in as 5 whereas c out as 90 that's that's not a right now because for an inverter at the input we would have three rc no no no wait i have i have five times the size of a regular inverter what do you do yes sir that time it should be five into three hours but if we consider the output at the output of this h2 we'll have 15 into 6 rc which is same as 90 whereas at the input we have uh 3 into 5 rc which has to be 15 so it has to be 90 divided by 15 so 90 is a capacitive load i have put there i'm not even talking about self-loading here yet i have put a wire load there which has a capacitance of 90. shouldn't we consider the self-loading also in this case in the beginning as of now we are not doing it we will do that don't worry okay yeah so i'm happy all of you are noticing that to be parasitic we'll do something about that also don't worry but yeah at least logical effort and electrical effort is that part clear yes sir there is a logical effort which will simply get multiplied electrical effort which will also get multiplied but that multiplication is not equal to h that multiplication is equal to b into h yes yes sir raghav you have a question it's a good criteria i just okay so now we understand that overall delay in a path is the sum of all the all the basic delays then we also define that the parasitic delays of all the stages will simply add up see we are adding parasitic delay with the capacities all the delays of all the parasitic delays will simply add up to finally give me a pass delay which is ds plus p okay if i want to find now the smallest uh or what is the optimal number of stages that i need to have to get the minimum delay we need to see that each delay has the same effort so if there are n stages and the total effort is gi into hi then what is it that i am looking at to have the minimum total delay that is an optimization problem you will see that each stage should have a delay equal to g i h i is equal to capital f total delay raised to power 1 by n so each stage is having equal load in a way okay therefore we can now estimate the minimum delay of an n stage path which is n into f raised to pi one by n plus p question so i mean here we are basically ignoring the fact what each stage is just considering it to be a stage and that kind of distraction yeah saying if it was a nand gate you size it such that its delay is also the same as any other stage if it's a nor gate size it such that its delay is also equal to any other gate like s also one by n yes you remember the first first example that we did that i showed you we did not solve it yet we want to solve it now yes so we say that optimal solution is when each stage bears the equal burden that is the best solution that is when the delay will be the minimum so how would the gates be sized if i know what is my appropriate stage delay i know what my g and h is so see out by seeing i know okay so i know that the gate type i know so i know what g is i now need to decide about c out and c n are you able to see that yes sir if i fix my c out then c in will be represented represented by this formula do you have any collateral okay okay optimal stage delay so for minimum delay then i would be able to estimate c in if i know what c out is huh if i know c n then i can also know what the sizing of my different devices so just a quick question here so if i know so uh depending upon the type of gate i would be looking at i would get the g because that would be complete so but once i get the g i get the same also right why because because i know the sizing based upon when i know the g i know okay this kind of no no no no wait there is an inverter just 5 there was another inverter just 15 how would you know how would you know kihapi reached my fifteen iii at twenty ayah g only tells this g is equal to one but to get the sizing of five i need some more information okay okay so like g is not related to sizing it's like g is only uh logical effort so but like uh so if say a size of an inverter size say five and better size one port will have the same g i mean this all is not descending to rise yes if it is an inverter whether it is size five or whether it is size 1 the g is equal to 1 because it's an inverter that's the topology of the gate that's the property of the gate the size is another property of the gate which could be varying g remains constant foreign effort compared to that inverter so a more bigger gate would be requiring more kind of what even if it is inverter but then for same size inverter let us put it like this but so like you just said now like five or one we will characterize the g as one so that is none g is equal to 1 for for an inverter of size 5 how would i size this particular gate differently so that i get the same current as an inverter of size 5. is equal to one okay right okay so why are we going backwards like we know the c out and available we want a desired c out so like this we should go now uh this looks simple but it is not as simple you will see that there will be chains there will be paths in which there are many gates which are simply there to increase the drive strength we'll come to them in a little while okay okay okay so for now let us just say that output we know is fixed output we always know is fixed now therefore going backwards is easy enough so you're designing some chain to drive an output load now so the output we know and now we go backwards mother you had a question except please go to the prehistoric [Music] uh effort logical and electrical effort mixed of the entire chain capital f small f so f prime that is the optimal stage effort of delay would also include a parasitic component so we're not really talking about delays we're talking about effort and so what does optimal effort mean optimal effort means uh effort such that i will get the minimum delay finally so this f prime is equal to f capital f raised to the power 1 by n is the solution of an optimization problem so you give it to a usf solver or do whatever you will realize that in any system if there are multiple parts contributing to a total delay then each part should have equivalent delay or you know normalized delay to be equivalent or equal to have the minimum delay of the entire system that is what the result says you want to go to the calculations you can i'm not going to them in the class so we know the step or the how do we get this this s equal to f raised to pi 1 by n so this capital f how did we get capital f yes all this what was this effort are you able to see this yes and that was for uh for different types for different difference smallers yeah anything okay and now we are saying that we will we raise it to power one by n to get the optimal optimal stage effort okay so now these stage will have the same logical yeah okay so yes uh serpent branching occurs uh so the stage uh the the fan out is two so both the stages should be two and three or four will be considered like if they're in pad those are parallel so they would be so if they're in parallel they will be considered as branches you will bring in this branch well offender i meant it one by n and in the end would they add one more plus one or they would n would remain same the branching let us see okay so,https://www.youtube.com/watch?v=RioleqvE7IM,"Link: https://www.youtube.com/watch?v=RioleqvE7IM
Transcript: so we will only look at driver when we are calculating parasitically i'm sorry so we will only be looking at the driver when calculating parasitic damage yeah the gate the gate for which we are calculating the delay we will only look at that we'll not look at the load okay no matter load may even have a lot of parasitic delay at its input yeah like over here we have four inverters as load and we would as well have ten inverters as low it will still take parasitic delay as one okay so because only one inverter is triggered yeah because it is the property of the driver the self loading of the driver there okay so now this is avid we were just looking at one stage delay now what happens if we have a complex path see typically we will not have only inverters capacitance we typically have multiple logics and multiple things coming into picture so in that case we talk about path logical effort which is multiplication of all the incumbent logical efforts path electrical effort which is c out final upon c in which make a doesn't matter okay and then overall path effort would be a multiplication of path efforts of each of these so which would appear to be something like multiplication of gh let us take this example itself i ask you to help me with sizing these nor gates and nand gates there so find the value of x y and z let us say so what do we do keep that question in mind we will just come to it can we probably write f is equal to g h is equal to g h but there is a small catch when there is a branch then you cannot really do that look at it over here g is 1 on this particular path f is 18 so gh is equal to 18. now let us calculate the h h1 and then h2 so what is h1 2 h1 is 2 just so fan out is 2 what about the size it's a 3 okay so it should be 6 then 6. huh and what about h2 6 h2 is also 6 why because 90 by 15 this is 90 and it has it has a gate load of 15. uh so what we say actual main capital f is equal to multiplication of g and the g's and h is so g1 g2 h1 h2 actual mate is equal to 36 but dh was only 18 so there is the factor of 2 where does this 2 come from two branches yes now over here this two can be said as two branches but if these branches were of different sizes we would not be able to put it as branches but if the two things are same size then we say that it is equal to gbh in reality we have to do it something like this branching effort is calculated by c on path plus c of path by c on path so i mean the f here is the stage delay equivalent of like multiple gates so by why we are not incorporating that the parasitic component here itself is a logical and electrical thing why not just can you go to the previous slide friends this is important concept i know you are yourself going to propose questions from this concept because this is full of numericals so it should be very very clear to you so can you just uh please explain the h part the 18 i mean 98 is coming up yeah because we saw that c out was 90 and cn was five so if you overall look at h for the path in which we want to measure the delay that h is 18 okay so we are taking the only the total like uh capacitance at the end of the path and at the input of the path that is what h meant in the in the previous slide what did we say in the still previous slide we had said that that is equal to ch of output on upon cn path that was what the definition of h was so that is what we did yeah so somebody's like so but like here we have like two edges two which right yes answer what is h1 h2 is denoting small h1 h2 h1 is a fan out for this stage h2 is the fan out for the second stage support when this input is driving two loads then how can we guarantee that uh path this path which is being highlighted its delay will not be affected at all by the uh the other part the above that is what we are finally concluding okay okay so that that is where the difference is that is what we are concluding we are not saying anything else sir okay sir but we can say that it won't be affected by the load that the other part is trying yeah because that would like if if this 15 was driving a load of let us say 180 i would still have this delay so sir yeah because i'm not bothered by h3 over here okay the h will change you will not i'm sorry uh the value of h would change the capital uh the capital h for the other but the g would not change the capital h will still be the same definition that is the definition of h okay yes we're just talking about is f equal to g x the question was is s equal to gh that was the question we said no we said there has to be another component which is related to branching in there we are answering only that question we're not saying h is calculated wrong no that was the definition of h please understood so and we are trying to calculate the delay eventually women calculate delay from all these things so if we apply elmore's uh almost delay then this above h3 will also come into picture for calculating delay from h1 to s2 so that is where that is where we're talking about off paths also paths which are not really under consideration okay that is why exactly that is the reason i am so happy that you are able to see that effect that is the nature of delay and because it has to come therefore this component of b which is a multiplication of all bis should also be brought into picture okay okay so yeah so i mean the h was calculated to be 18 so but we have two parts so shouldn't we have done the twice multiplication there itself i mean i wanted to find the delay of this path only okay i wanted to find the delay of this path so i will look at the output delay that this path has and then put the layer at this path i'm not bothered about this part for calculation of h okay so even if you're trying to consider this part the off path is coming into picture just like an elmore's delay yeah so but like uh okay right right if it is connected then it will be basically charging will load now the odd path will also load you have to take them into account okay but this definition doesn't take into account this h1 okay capital h is only c out by c n the basic definition what is the fan out what is c out by c n that's the thing so therefore we need to bring in this component of b and what we do understand is that bh will finally mean h1 into h2 into h3 into whatever h would not be able to that to be for this to be equal this has to be equal to b h so just can we just move again to the previous slide so h1 ms2 okay okay got it sir got it okay uh sir i have a doubt in the same slide can we can we go back so here in the calculation of h we have considered c in as 5 whereas c out as 90 that's that's not a right now because for an inverter at the input we would have three rc no no no wait i have i have five times the size of a regular inverter what do you do yes sir that time it should be five into three hours but if we consider the output at the output of this h2 we'll have 15 into 6 rc which is same as 90 whereas at the input we have uh 3 into 5 rc which has to be 15 so it has to be 90 divided by 15 so 90 is a capacitive load i have put there i'm not even talking about self-loading here yet i have put a wire load there which has a capacitance of 90. shouldn't we consider the self-loading also in this case in the beginning as of now we are not doing it we will do that don't worry okay yeah so i'm happy all of you are noticing that to be parasitic we'll do something about that also don't worry but yeah at least logical effort and electrical effort is that part clear yes sir there is a logical effort which will simply get multiplied electrical effort which will also get multiplied but that multiplication is not equal to h that multiplication is equal to b into h yes yes sir raghav you have a question it's a good criteria i just okay so now we understand that overall delay in a path is the sum of all the all the basic delays then we also define that the parasitic delays of all the stages will simply add up see we are adding parasitic delay with the capacities all the delays of all the parasitic delays will simply add up to finally give me a pass delay which is ds plus p okay if i want to find now the smallest uh or what is the optimal number of stages that i need to have to get the minimum delay we need to see that each delay has the same effort so if there are n stages and the total effort is gi into hi then what is it that i am looking at to have the minimum total delay that is an optimization problem you will see that each stage should have a delay equal to g i h i is equal to capital f total delay raised to power 1 by n so each stage is having equal load in a way okay therefore we can now estimate the minimum delay of an n stage path which is n into f raised to pi one by n plus p question so i mean here we are basically ignoring the fact what each stage is just considering it to be a stage and that kind of distraction yeah saying if it was a nand gate you size it such that its delay is also the same as any other stage if it's a nor gate size it such that its delay is also equal to any other gate like s also one by n yes you remember the first first example that we did that i showed you we did not solve it yet we want to solve it now yes so we say that optimal solution is when each stage bears the equal burden that is the best solution that is when the delay will be the minimum so how would the gates be sized if i know what is my appropriate stage delay i know what my g and h is so see out by seeing i know okay so i know that the gate type i know so i know what g is i now need to decide about c out and c n are you able to see that yes sir if i fix my c out then c in will be represented represented by this formula do you have any collateral okay okay optimal stage delay so for minimum delay then i would be able to estimate c in if i know what c out is huh if i know c n then i can also know what the sizing of my different devices so just a quick question here so if i know so uh depending upon the type of gate i would be looking at i would get the g because that would be complete so but once i get the g i get the same also right why because because i know the sizing based upon when i know the g i know okay this kind of no no no no wait there is an inverter just 5 there was another inverter just 15 how would you know how would you know kihapi reached my fifteen iii at twenty ayah g only tells this g is equal to one but to get the sizing of five i need some more information okay okay so like g is not related to sizing it's like g is only uh logical effort so but like uh so if say a size of an inverter size say five and better size one port will have the same g i mean this all is not descending to rise yes if it is an inverter whether it is size five or whether it is size 1 the g is equal to 1 because it's an inverter that's the topology of the gate that's the property of the gate the size is another property of the gate which could be varying g remains constant foreign effort compared to that inverter so a more bigger gate would be requiring more kind of what even if it is inverter but then for same size inverter let us put it like this but so like you just said now like five or one we will characterize the g as one so that is none g is equal to 1 for for an inverter of size 5 how would i size this particular gate differently so that i get the same current as an inverter of size 5. is equal to one okay right okay so why are we going backwards like we know the c out and available we want a desired c out so like this we should go now uh this looks simple but it is not as simple you will see that there will be chains there will be paths in which there are many gates which are simply there to increase the drive strength we'll come to them in a little while okay okay okay so for now let us just say that output we know is fixed output we always know is fixed now therefore going backwards is easy enough so you're designing some chain to drive an output load now so the output we know and now we go backwards mother you had a question except please go to the prehistoric [Music] uh effort logical and electrical effort mixed of the entire chain capital f small f so f prime that is the optimal stage effort of delay would also include a parasitic component so we're not really talking about delays we're talking about effort and so what does optimal effort mean optimal effort means uh effort such that i will get the minimum delay finally so this f prime is equal to f capital f raised to the power 1 by n is the solution of an optimization problem so you give it to a usf solver or do whatever you will realize that in any system if there are multiple parts contributing to a total delay then each part should have equivalent delay or you know normalized delay to be equivalent or equal to have the minimum delay of the entire system that is what the result says you want to go to the calculations you can i'm not going to them in the class so we know the step or the how do we get this this s equal to f raised to pi 1 by n so this capital f how did we get capital f yes all this what was this effort are you able to see this yes and that was for uh for different types for different difference smallers yeah anything okay and now we are saying that we will we raise it to power one by n to get the optimal optimal stage effort okay so now these stage will have the same logical yeah okay so yes uh serpent branching occurs uh so the stage uh the the fan out is two so both the stages should be two and three or four will be considered like if they're in pad those are parallel so they would be so if they're in parallel they will be considered as branches you will bring in this branch well offender i meant it one by n and in the end would they add one more plus one or they would n would remain same the branching let us see okay so"
Cdk33854gqQ,uh are you a b are you able to see that it is equally easy going backwards because c out we know is fixed so from the last stage we go backward and we do the sizing and then we simply check that is it meeting the input capacitance check or not so let us take the same example that i had shown flashed earlier so what is the effective fanout h for this system five five great sorry uh what is the effective g for this system 5 by 3 whole square 25 by 9 25 by 9. what will be capital f yes so capital f will be 125 by nine i know the number of stages is four so i will do the fourth root of 13.9 i will get f equal to 1.93 and i will essentially get all the sizes abc in my system are you able to see this sir yes sir i have a doubt sir so while we were doing uh previously we were doing f power one by and right sir so that means that uh that's the maximum delay which we can have in a stage but uh you you said that that's the minimum delay which we can have like it's mentioned in the previous slide no so capital f is the total path effort yes i want to design this path to have minimum delay you're getting confused between effort and delay now effort of each stage should be equal to get the minimum delay okay therefore i do fourth root of s there are four stages over here and i get f as one point nine three yes i understood uh yeah understood okay so now based on this because f is 1.93 i will be able to calculate all the delay all the gate delays all the gate sizes okay so we can reduce that we just saw the output cap and then calculated the overall number and then distributed it at every stage and then designed it accordingly yeah we estimated the overall effort yes and said each stage will offer equal effort right okay okay so now based on this can you also estimate which of these eight input and gate configuration will be the best fastest do you think you will be able to do this you can size all of them you can also estimate what the total delay is and what is the total area can you do this hello so so here we will be calculating the capital f for each of the configurations and then comparing you will calculate capital s then you will divide it by the number of stages in the first a and b the status is 2 so you will find a square root to get the smallest in the in the case c there are four stages so you would find fourth root to get the smallest and you can size all the gates okay so but like if i want to compare which of which of these would be the fastest so then i would be competing with the capital f right and then choosing based upon capital then i will go okay okay now i need yes you can say capital f plus p you can find the total delay yes you can compare that way also but if you have to size even you can get an estimate of area that is what i am saying the logical effort technique also gives you an estimate of area of the system so what is the trade off area versus speed trade-off you are able to see here are you able to see that yeah yeah if i give more area then i get speed but at what cost of area am i getting that speed is it worth it or not you're able to get that yes yes so edge sir yes can you please move to the previous slide okay yeah the capital s for all of them is 1 by 10 capital f for h capital h would be same capital h would be no it will in fact it may not end up being same because uh uh or you can have a specification of capital h that my input capacitance has to be 1 and has to be 3c and output capacitance has to be something so then the delays would change okay okay and so forth yeah so can i ask right now yeah for the stages the first one has two stage the second has three stages am i right or it will be considered as two stages two sets only and the fourth has four stages yeah okay okay anna yes sir yes as i can calculate that the third option is uh we are getting the low values are in there so uh can we say that if the number of stages are more than our uh this value of delay would be less for something like that can we control something why do you want to jump to such such conclusions when the method to calculate the delay is so simple is the method not simple enough yes sir it's simple but but uh why why unnecessarily complicate your life arrived at this doubt because the uh the values for the first a and b figures for the same size i'm like when i get no right now is going to be a perfect engineer he wants to find shortcuts for everything i'm already giving you a shortcut i'm asking you not to do any simulation and i am able to tell you what the design should be you want a shortcut of that also no nothing yes no no no so let's know uh you know professor respection you must be taking course with them huh yes sir so he very famously says that a good engineer is a lazy person so he looks for shortcuts at all times so i'm not complaining i'm just saying you are going to be a good engineer because you're always continuously looking for shortcuts making life simpler but i would say if you run into deductions into deducing something based on just one example you are putting yourself at risk you should come to such conclusions only after you've seen variety of cases eight example basis but don't arrive at a conclusion yes example you just have one observation not a conclusion yes sir understood okay thank you you will see more examples you will see that what you just said is not valid so this is just one observation consider it as one observation don't jump to a conclusion conclusion you build over time uh sir i have a question sir yes sir in the c case so we have uh four stages suppose in the lower section instead of having a nor gate i have an or gate so at that point of time does it mean that we'll have five stages so how will you make an or gate so nor cascading with inverter so yeah if you if you make an r and then an inverter yes you will have five stairs done but in the uh uh in the above circuit we just have a target which is uh sure that path has just uh of course the technologies this method is agnostic of whatever gate we are talking about is it not yes sir if you have a or gate you will make a nod and then you will make an inverter so you will have those extra status there already so probably what you will end up doing is so if you want to maintain the same logic if you say i will put a or gate here then the next stage instead of being a nand would be a nor gate yes yes and we will not need this inverter so you're putting two inverters here then stages will be four right hanging so again you will have to look at the specific implementation and then do something like don't don't try to conclude yes be with the process if the method is clear then whatever gate i throw at you you should be able to solve it is it not yes seriously i want you to develop that capability yes understood so and why will all this all these things why are we not considering parasitic deals what if sizing some inverter increases by a certain table by too much i'm sorry so um by doing this method if we are not considering parasitic data still we find the optimal sizing so what if the due to optimal sizing my parasitic debris of some stage increases yeah so all those things would happen mother what we are looking at is we want the back of the envelope calculation method this you will finally realize this is not the most accurate thing most accurate thing will finally be your simulation but you want to save all that effort how many circuits will i simulate if i can do some back of the calculation and just get a comparison between them that is good enough for me okay then the best case one i will implement that is the intent of this method we'll come to the parasitics in just a moment you will see okay so this is just an estimate yeah this is a logical effort is only about an estimate okay this is not final delay but this is an estimate to compare multiple topologies you can quickly do this and say okay this topology is going to be better you don't need to implement multiple topologies to do that do you know how time consuming implementing a topology epic inverter of an anime you took more than one week is it not yes sir so if you have to make all these inverters how much time will you take and then you are just implementing one eight input and gate so we don't want to do all that effort they simply say can i do a backup another calculation and that is what it is it will give you a fairly good comparative analysis if you want absolute accuracy go simulate so now what would be x and y over here so that i have least delay what do we do where do we start from output huh output okay so what is the logical effort here two input nand gate three input nand gate to input north hello four by three into five by three into five by three 100 by 27 what is the electrical effort quickly pick so 45 by 8 45 by 8 very good what is branching effort 6 3 into 2 6. what is path effort then there are three stages so best stage effort is five we add parasitic delays so two three two seven total delay is three into five i know there are three stages each state has an effort of three three into five and plus seven twenty two hmm and therefore so the fan therefore the the uh what do you say the overall delay that we're talking about is 22 and what is this 4.4 cube root of 22 yeah okay so so what was how do we do that how do we now size y and x how do we now size y and x how do you know find y and x we know that f equal to 5 what is the g for a nor gate uh c out upon s into a course you see yaki so c out is 45 g is 4 by 3 upon 5 answer is 15 so why we know is 15 now so what about x what is the output load of x so we get x equal to 10 and now what we can do quickly is we can check if sax equal to 10 meets the requirement for this also or not i get c n equal to 8 for this or not okay so that we can verify and then we distribute this 15 and 10 and 8 into the pmos and nmos is that okay are you able to see this so here p p four means the width is like it is four times six yes okay yes okay so we've actually got even the gate sizing through this method without a single simulation do you realize this you've got an area estimate without a single simulation yes so now if i have to design let us say a driver to drive a capacitance of 64 i could have multiple number of stairs and if i follow the same topology same methodology you will realize that i could have one inverter like i have my input delay input capacitance fixed as one so i can have multiple ways to size or multiple site i can have multiple stage paths and i can size them according to the method that we just discussed huh and now can we estimate the delays across all of them can we estimate the delays hello so this for this first stage n equal to one one stage only what is f h what is h g is one what is h over here sixty-four c four plus parasitic just one inverter so one so my total delay is 65 okay now i said let's go to two stages so vaishnav would be very happy to say that oh see i was right the delay reduced we go to three stages the nice will be happier oh the debate reduced more let's go to four stages the delay should reduce more but you see it doesn't yes sir i'm sad no sir oh but do you realize that it is important to uh not jump back conclusions just trying to find conclusions just immediately observation evo that is just one observation and also look at it like this see to reduce delay from 65 to 18 what was the area loss one to nine and what is the area over here this is 21 what is the area over here the last driver itself is 23 look at it the last driver is 23 this is approximately 35. so going you you're continuously increasing area you are reducing delays the best less gain is over here then there is still more gain but at an area loss of almost 2.5 times 2.3 times and from here to here similar gain but an area loss of 4 times so you see you're able to estimate both delay and area through this method and then you can choose which could be the best option for your design i know while this is the fastest you may say that oh i am an area sensitive thing so i will keep this do you realize this are you able to see this any questions [Music] sorry so the slide in which 22 is equals to 4.4 was written what was that i was not able to hear that okay we will come to that let me just complete the topic then i will come to that again okay yes sir this part is clear any questions on this that we will be able to so this method immediately gives us a method to this method immediately gives me a comparison of different implementations both in terms of performance and area and i have not done a single simulation are you with me yes sir right,https://www.youtube.com/watch?v=Cdk33854gqQ,"Link: https://www.youtube.com/watch?v=Cdk33854gqQ
Transcript: uh are you a b are you able to see that it is equally easy going backwards because c out we know is fixed so from the last stage we go backward and we do the sizing and then we simply check that is it meeting the input capacitance check or not so let us take the same example that i had shown flashed earlier so what is the effective fanout h for this system five five great sorry uh what is the effective g for this system 5 by 3 whole square 25 by 9 25 by 9. what will be capital f yes so capital f will be 125 by nine i know the number of stages is four so i will do the fourth root of 13.9 i will get f equal to 1.93 and i will essentially get all the sizes abc in my system are you able to see this sir yes sir i have a doubt sir so while we were doing uh previously we were doing f power one by and right sir so that means that uh that's the maximum delay which we can have in a stage but uh you you said that that's the minimum delay which we can have like it's mentioned in the previous slide no so capital f is the total path effort yes i want to design this path to have minimum delay you're getting confused between effort and delay now effort of each stage should be equal to get the minimum delay okay therefore i do fourth root of s there are four stages over here and i get f as one point nine three yes i understood uh yeah understood okay so now based on this because f is 1.93 i will be able to calculate all the delay all the gate delays all the gate sizes okay so we can reduce that we just saw the output cap and then calculated the overall number and then distributed it at every stage and then designed it accordingly yeah we estimated the overall effort yes and said each stage will offer equal effort right okay okay so now based on this can you also estimate which of these eight input and gate configuration will be the best fastest do you think you will be able to do this you can size all of them you can also estimate what the total delay is and what is the total area can you do this hello so so here we will be calculating the capital f for each of the configurations and then comparing you will calculate capital s then you will divide it by the number of stages in the first a and b the status is 2 so you will find a square root to get the smallest in the in the case c there are four stages so you would find fourth root to get the smallest and you can size all the gates okay so but like if i want to compare which of which of these would be the fastest so then i would be competing with the capital f right and then choosing based upon capital then i will go okay okay now i need yes you can say capital f plus p you can find the total delay yes you can compare that way also but if you have to size even you can get an estimate of area that is what i am saying the logical effort technique also gives you an estimate of area of the system so what is the trade off area versus speed trade-off you are able to see here are you able to see that yeah yeah if i give more area then i get speed but at what cost of area am i getting that speed is it worth it or not you're able to get that yes yes so edge sir yes can you please move to the previous slide okay yeah the capital s for all of them is 1 by 10 capital f for h capital h would be same capital h would be no it will in fact it may not end up being same because uh uh or you can have a specification of capital h that my input capacitance has to be 1 and has to be 3c and output capacitance has to be something so then the delays would change okay okay and so forth yeah so can i ask right now yeah for the stages the first one has two stage the second has three stages am i right or it will be considered as two stages two sets only and the fourth has four stages yeah okay okay anna yes sir yes as i can calculate that the third option is uh we are getting the low values are in there so uh can we say that if the number of stages are more than our uh this value of delay would be less for something like that can we control something why do you want to jump to such such conclusions when the method to calculate the delay is so simple is the method not simple enough yes sir it's simple but but uh why why unnecessarily complicate your life arrived at this doubt because the uh the values for the first a and b figures for the same size i'm like when i get no right now is going to be a perfect engineer he wants to find shortcuts for everything i'm already giving you a shortcut i'm asking you not to do any simulation and i am able to tell you what the design should be you want a shortcut of that also no nothing yes no no no so let's know uh you know professor respection you must be taking course with them huh yes sir so he very famously says that a good engineer is a lazy person so he looks for shortcuts at all times so i'm not complaining i'm just saying you are going to be a good engineer because you're always continuously looking for shortcuts making life simpler but i would say if you run into deductions into deducing something based on just one example you are putting yourself at risk you should come to such conclusions only after you've seen variety of cases eight example basis but don't arrive at a conclusion yes example you just have one observation not a conclusion yes sir understood okay thank you you will see more examples you will see that what you just said is not valid so this is just one observation consider it as one observation don't jump to a conclusion conclusion you build over time uh sir i have a question sir yes sir in the c case so we have uh four stages suppose in the lower section instead of having a nor gate i have an or gate so at that point of time does it mean that we'll have five stages so how will you make an or gate so nor cascading with inverter so yeah if you if you make an r and then an inverter yes you will have five stairs done but in the uh uh in the above circuit we just have a target which is uh sure that path has just uh of course the technologies this method is agnostic of whatever gate we are talking about is it not yes sir if you have a or gate you will make a nod and then you will make an inverter so you will have those extra status there already so probably what you will end up doing is so if you want to maintain the same logic if you say i will put a or gate here then the next stage instead of being a nand would be a nor gate yes yes and we will not need this inverter so you're putting two inverters here then stages will be four right hanging so again you will have to look at the specific implementation and then do something like don't don't try to conclude yes be with the process if the method is clear then whatever gate i throw at you you should be able to solve it is it not yes seriously i want you to develop that capability yes understood so and why will all this all these things why are we not considering parasitic deals what if sizing some inverter increases by a certain table by too much i'm sorry so um by doing this method if we are not considering parasitic data still we find the optimal sizing so what if the due to optimal sizing my parasitic debris of some stage increases yeah so all those things would happen mother what we are looking at is we want the back of the envelope calculation method this you will finally realize this is not the most accurate thing most accurate thing will finally be your simulation but you want to save all that effort how many circuits will i simulate if i can do some back of the calculation and just get a comparison between them that is good enough for me okay then the best case one i will implement that is the intent of this method we'll come to the parasitics in just a moment you will see okay so this is just an estimate yeah this is a logical effort is only about an estimate okay this is not final delay but this is an estimate to compare multiple topologies you can quickly do this and say okay this topology is going to be better you don't need to implement multiple topologies to do that do you know how time consuming implementing a topology epic inverter of an anime you took more than one week is it not yes sir so if you have to make all these inverters how much time will you take and then you are just implementing one eight input and gate so we don't want to do all that effort they simply say can i do a backup another calculation and that is what it is it will give you a fairly good comparative analysis if you want absolute accuracy go simulate so now what would be x and y over here so that i have least delay what do we do where do we start from output huh output okay so what is the logical effort here two input nand gate three input nand gate to input north hello four by three into five by three into five by three 100 by 27 what is the electrical effort quickly pick so 45 by 8 45 by 8 very good what is branching effort 6 3 into 2 6. what is path effort then there are three stages so best stage effort is five we add parasitic delays so two three two seven total delay is three into five i know there are three stages each state has an effort of three three into five and plus seven twenty two hmm and therefore so the fan therefore the the uh what do you say the overall delay that we're talking about is 22 and what is this 4.4 cube root of 22 yeah okay so so what was how do we do that how do we now size y and x how do we now size y and x how do you know find y and x we know that f equal to 5 what is the g for a nor gate uh c out upon s into a course you see yaki so c out is 45 g is 4 by 3 upon 5 answer is 15 so why we know is 15 now so what about x what is the output load of x so we get x equal to 10 and now what we can do quickly is we can check if sax equal to 10 meets the requirement for this also or not i get c n equal to 8 for this or not okay so that we can verify and then we distribute this 15 and 10 and 8 into the pmos and nmos is that okay are you able to see this so here p p four means the width is like it is four times six yes okay yes okay so we've actually got even the gate sizing through this method without a single simulation do you realize this you've got an area estimate without a single simulation yes so now if i have to design let us say a driver to drive a capacitance of 64 i could have multiple number of stairs and if i follow the same topology same methodology you will realize that i could have one inverter like i have my input delay input capacitance fixed as one so i can have multiple ways to size or multiple site i can have multiple stage paths and i can size them according to the method that we just discussed huh and now can we estimate the delays across all of them can we estimate the delays hello so this for this first stage n equal to one one stage only what is f h what is h g is one what is h over here sixty-four c four plus parasitic just one inverter so one so my total delay is 65 okay now i said let's go to two stages so vaishnav would be very happy to say that oh see i was right the delay reduced we go to three stages the nice will be happier oh the debate reduced more let's go to four stages the delay should reduce more but you see it doesn't yes sir i'm sad no sir oh but do you realize that it is important to uh not jump back conclusions just trying to find conclusions just immediately observation evo that is just one observation and also look at it like this see to reduce delay from 65 to 18 what was the area loss one to nine and what is the area over here this is 21 what is the area over here the last driver itself is 23 look at it the last driver is 23 this is approximately 35. so going you you're continuously increasing area you are reducing delays the best less gain is over here then there is still more gain but at an area loss of almost 2.5 times 2.3 times and from here to here similar gain but an area loss of 4 times so you see you're able to estimate both delay and area through this method and then you can choose which could be the best option for your design i know while this is the fastest you may say that oh i am an area sensitive thing so i will keep this do you realize this are you able to see this any questions [Music] sorry so the slide in which 22 is equals to 4.4 was written what was that i was not able to hear that okay we will come to that let me just complete the topic then i will come to that again okay yes sir this part is clear any questions on this that we will be able to so this method immediately gives us a method to this method immediately gives me a comparison of different implementations both in terms of performance and area and i have not done a single simulation are you with me yes sir right"
vS6JQgBA_VU,so uh okay many times what would happen is there could be a very big load that could be there on the output but your logic stages the number of logic stages that you have is only say n1 but to get the least delay you would need n stages then what is recommended is that in the first few stages implement your logic and in the final n minus n month stages simply have inverters why do you think this is a recommendation so i mean can you uh just repeat what you're proposing here i mean why need to have end stages so let us say there is the swirling capacitance let us say it is a word line with a capacitance of 500 centifarads and you wanted to make a 8 input and gate to drive this the question is now one eighteen moon and gate cannot simply drive a five hundred twenty five capacitance it's a huge capacitance so you will put some status in between now the question is if i have to put total of n stages where should i put my nand gate in the beginning or in the end closer to the output or earlier early closer to the input okay is the question clear yes is the answer clear it's a logic at the beginning and then inverters yes now why so [Music] would be greater as compared to the inverter so the size is smaller i will make the w smaller okay see consider it like this in the previous example it says you see that the stages closer to the output have larger size so if i have to make a nand of this weight or a nand of this weight what would be the ratio in terms of area if i have to make a nand which has a f of i will need to size it very big is it not yes sir so i don't want to do that to save area all that logic is in the first few stages then you simply add inverters now what does this do this does that your overall delay equation becomes slightly complex and you will have to numerically solve it but you can still do it you can come to a rule of thumb or a you know back of the null of some number even then okay so i mean what kind of calculation are we doing here like after now how many inverters should i come to that is the calculation uh what should be the effort of each stage that is the first that is the first calculation yeah yeah yes i know so that will become slightly complex but that's okay sir yes as i can see the number of inverters should be an even number right sir so so that our output doesn't change uh i could actually have uh inverted output so that is just bubble shifting is it not ah okay okay i could do whatever don't worry about that so uh what we are doing is that we are just i'm not adding the number of stairs as we don't know at which stage we would get the minimum delay uh sorry in stage delay so we are adding those and we are differentiating it uh we are equating it to the first order deflation differential equation to zero so that we can get the uh maximum or minimum water yes yes so because of the presence of parasitics as i said it has no closed form solution if parasitics were zero then i know that rho that is uh stage effort for every state is e but if if i say that p in the parasitic is one unit then you will see that row would come out if each stages stage effort would come out to be around 3.6 okay now in fact what also is done is that just as we saw over here what did we see now the stage the stage effort of each stage over here is much larger than 3.6 is it not the stage effort is 8. over here it is four over here it is two point eight so this as soon as we were close to three point six we had the fastest delay but in a design i missed as i have already mentioned i am still want to go with this implementation because this has much lesser area and the delay is almost similar are you able to see this so while my optimal stage effort i have estimated it to be 3.6 i may want to have much larger stage effort just so that i save area some acknowledgement so this last but i mean stage effort of uh here it was number of area and delay right so what stage are you talking about each stage i'm talking about f the small f yeah is 8 over here yes sir what is the area of this block yeah nine this state effort is four over here which is close to three point six that we just calculated yes sir what is the area over here 25 20 yeah 21 27 yes huh so i increase my area more than double to get enough get a delay improvement of something like uh 15 15 right if i am going for a high density design i may rather say that okay i don't want the best optimal ratio i will go with this yeah yeah huh yes so logical effort over here is telling me what is the optimal thing but my design constraints may anyway push me to a different direction so i may decide differently yes like you said that we need to have in stages kind of thing yes so what we are essentially so and you know uh this that's you if you keep the stage ratio between 2.4 to 6 you will get a delay within a 15 of the optimal optimals optimally fifteen percent sixteen percent you saw that in this example the stage ratio is eight the state effort is eight but even then i'm getting a good result within 20 of that anna so do not get finicky or paranoid about keeping the stage ratio of 3.7 because that is 3.6 because that is what you found is the best in the logical effort analysis you will see depending on your design constraints you could keep a very wide range of stage ratios and you will still be almost optimal so mother you are so worried about kimura parasitic you see we wanted to get a you know a feeling an intuitiveness about all of this and that we are able to get are you able to see this yes sir so and this sensitivity analysis is rho greater than 2.1 distances this is we are talking about the exact simulation thing or we're talking about yeah this is a no this is the numerical analysis thing even now but simulation will give you something similar you will see,https://www.youtube.com/watch?v=vS6JQgBA_VU,"Link: https://www.youtube.com/watch?v=vS6JQgBA_VU
Transcript: so uh okay many times what would happen is there could be a very big load that could be there on the output but your logic stages the number of logic stages that you have is only say n1 but to get the least delay you would need n stages then what is recommended is that in the first few stages implement your logic and in the final n minus n month stages simply have inverters why do you think this is a recommendation so i mean can you uh just repeat what you're proposing here i mean why need to have end stages so let us say there is the swirling capacitance let us say it is a word line with a capacitance of 500 centifarads and you wanted to make a 8 input and gate to drive this the question is now one eighteen moon and gate cannot simply drive a five hundred twenty five capacitance it's a huge capacitance so you will put some status in between now the question is if i have to put total of n stages where should i put my nand gate in the beginning or in the end closer to the output or earlier early closer to the input okay is the question clear yes is the answer clear it's a logic at the beginning and then inverters yes now why so [Music] would be greater as compared to the inverter so the size is smaller i will make the w smaller okay see consider it like this in the previous example it says you see that the stages closer to the output have larger size so if i have to make a nand of this weight or a nand of this weight what would be the ratio in terms of area if i have to make a nand which has a f of i will need to size it very big is it not yes sir so i don't want to do that to save area all that logic is in the first few stages then you simply add inverters now what does this do this does that your overall delay equation becomes slightly complex and you will have to numerically solve it but you can still do it you can come to a rule of thumb or a you know back of the null of some number even then okay so i mean what kind of calculation are we doing here like after now how many inverters should i come to that is the calculation uh what should be the effort of each stage that is the first that is the first calculation yeah yeah yes i know so that will become slightly complex but that's okay sir yes as i can see the number of inverters should be an even number right sir so so that our output doesn't change uh i could actually have uh inverted output so that is just bubble shifting is it not ah okay okay i could do whatever don't worry about that so uh what we are doing is that we are just i'm not adding the number of stairs as we don't know at which stage we would get the minimum delay uh sorry in stage delay so we are adding those and we are differentiating it uh we are equating it to the first order deflation differential equation to zero so that we can get the uh maximum or minimum water yes yes so because of the presence of parasitics as i said it has no closed form solution if parasitics were zero then i know that rho that is uh stage effort for every state is e but if if i say that p in the parasitic is one unit then you will see that row would come out if each stages stage effort would come out to be around 3.6 okay now in fact what also is done is that just as we saw over here what did we see now the stage the stage effort of each stage over here is much larger than 3.6 is it not the stage effort is 8. over here it is four over here it is two point eight so this as soon as we were close to three point six we had the fastest delay but in a design i missed as i have already mentioned i am still want to go with this implementation because this has much lesser area and the delay is almost similar are you able to see this so while my optimal stage effort i have estimated it to be 3.6 i may want to have much larger stage effort just so that i save area some acknowledgement so this last but i mean stage effort of uh here it was number of area and delay right so what stage are you talking about each stage i'm talking about f the small f yeah is 8 over here yes sir what is the area of this block yeah nine this state effort is four over here which is close to three point six that we just calculated yes sir what is the area over here 25 20 yeah 21 27 yes huh so i increase my area more than double to get enough get a delay improvement of something like uh 15 15 right if i am going for a high density design i may rather say that okay i don't want the best optimal ratio i will go with this yeah yeah huh yes so logical effort over here is telling me what is the optimal thing but my design constraints may anyway push me to a different direction so i may decide differently yes like you said that we need to have in stages kind of thing yes so what we are essentially so and you know uh this that's you if you keep the stage ratio between 2.4 to 6 you will get a delay within a 15 of the optimal optimals optimally fifteen percent sixteen percent you saw that in this example the stage ratio is eight the state effort is eight but even then i'm getting a good result within 20 of that anna so do not get finicky or paranoid about keeping the stage ratio of 3.7 because that is 3.6 because that is what you found is the best in the logical effort analysis you will see depending on your design constraints you could keep a very wide range of stage ratios and you will still be almost optimal so mother you are so worried about kimura parasitic you see we wanted to get a you know a feeling an intuitiveness about all of this and that we are able to get are you able to see this yes sir so and this sensitivity analysis is rho greater than 2.1 distances this is we are talking about the exact simulation thing or we're talking about yeah this is a no this is the numerical analysis thing even now but simulation will give you something similar you will see"
LMeHv7zsxsA,so today we will we are going to in fact start with uh or we will start to look at the process variations we will also talk about projects and if time permits will also probably talk about you know start with power dissipation and power estimation methods so until now what you looked at is delay estimation methods am i right logical effort and all the delay models everything elmo delay everything was delay estimation so we have also looked at stick diagrams but stick diagrams do not give a very clear view of area yet it does give you some sense but not really a very clear view because the concept of width is not there in the stick diagrams so you will get the concept of area when you will work on your projects you already done assignments in which you have drawn in mutual drawn layout so you have some sense of how area is you know impacted when you change the size of devices and power is something that we will start next okay and uh after that we will go into different circuit design styles static cmos pseudo cmos pseudo pseudo nmos dynamic logic and so on so look into various design files for combinational circuit design after that we will look at sequential circuit design and then we will sign off you know this course and like i'm just giving you an overall uh you know a quick overview of what we expect in the second part of this course so later part we will sign off with uh some arithmetic circuits like adders multipliers and uh also memories okay so a quick glimpse of memories also will be there towards the end of this course okay so today we will start to look at uh parametric variations or process variations uh we will have a quick glimpse of why they happen and which we've already discussed so we'll move quickly around that then we will go go to the project part and then we'll start the power dissipation aspect so we designed a inverter such that this black line the black line now which i am overlaying with red now we designed an uh so how do i remove this i can simply remove this so we designed an inverter with this nominal curve of black line but if the pmos's design is faster than what we had anticipated or the n-mass is worse than what we had anticipated then the curve would move to this side on the other hand if the n mass is better than what we had anticipated and pmos is worse than what we had anticipated the curve would move to that side to the left side it is almost like you've changed the beta ratio of your design am i right if you change the beta ratio curve would move don't move on left to right stuff like that you remember yes yeah so if it so happens that pmos is manufactured fast or nmos is manufactured slow then the curve would move to right because it appears to this uh you know in the uh in the kirchhoff's law equation where we or how we determine the transfer characteristics of an inverter we see that pmos will now drive more current and therefore the curve would move to the right the output would stay one for a longer period of time but why is this happening how do we have a good pmos and a bad end moss or a good nmos and a bad female how do we get that and why do we get that it might be due to the manufacturing process yes it is due to manufacturing process runs it so so yes so like you are saying that if the curve is moving to the right or left it means the beta ratio is basically changing sort of so what beta is showing uh is related to the physical property physical characteristics okay so i mean so basically we are saying that whatever it is happening it is due to the physical uh that when the physical device is getting manufactured at that time something is happening which is leading to this kind of yeah you can say electrical beta ratio is changing would that be okay so electrical beta ratio what time what what the term would be yeah electrical beta ratio can be considered as the on current of the n mass upon on current of the p mass okay okay okay because if you have to equate them that is how you will come to the physical w by l beta ratio is it not uh yes sir right now you arrive at any beta ratio so that you get some ratio between the concurrent of the pmos and the nmos is it not yeah yes okay and that is the basis so we're talking about that basis that if the pmos current is more and the nmos current is lesser then it's almost like saying that the beta ratio of this device is such that pmos appears to be larger and nmos appears to be smaller okay it might be like uh the doping of uh pmos is much better than broken or feminist uh i mean so okay they're saying that doping could be one reason why this behavior can happen okay great what else uh so ultimately sir we can say all these factors are leading to change in the resistance of the devices all which factors like factors okay yeah beta resistance is the beta ratio is a consequence of something what can we say it is a mobility change why would mobility change no sudden mobility i i am saying that betas consist of these parameters but mobility will be very great so you are confusing between beta inside the model definition and beta ratio that we talk of as an inverter there are two very different things be careful okay okay so the beta as in model definition is something different from the beta ratio that we were just talking about so can this be due to variation in bt yes we just said no it could be due to vt with doping variations doping variations will lead to vt variations yeah in the chat window someone is saying t ox variations okay yes t ox variations will also lead to something like vp variation yes definitely there are direct impact on beta ratio either so does it have to do something with the temperature temperature means when we save yeah see in this situation when we are plotting them on the same graph we are assuming over here that the voltage of operation and temperature remain same okay but even then something has happened yes okay we are looking at why all those things could happen so yes you know uh for example if there is a variation in t ox that could be because of different duration for which oxide was grown if there was a is there is a variation in doping it could be because of a slightly different duration for which uh phosphine was run over the wafer for example so that phosphorus doping would be different so it could be because of all these little little variations that can happen in the manufacturing process so have we done this exercise in the class already where i asked you to write something 10 times on a piece of paper have it done that exercise yes so you know that they will when in a manufacturing process there can anyways be some variation that can happen however controlled however well controlled the process would be there would still be some variations and they lead to what we call as device variations and these device variations and then modeled into what is called as process slots these variations are due to as we just said vt oxide of an oxide thickness of nmos and p mass effective length effective width and so on so what we say is that we had targeted to make a particular device we call that typical this was the device that we wanted to make okay the center one but then what happened when i was uh let us say doping for the nmos then it happened in such a way that my device for the nmr side would go towards fast so this this dot started to move towards right so nmos doping was such that the device would go too fast then when i was doing doping for the pmos then again it was such that the device would go towards fast let us say so it would go up so i reached this particular place which is called as ff which is fast and mass fast p mass however if while doping for the p mass the doping went towards slow side for the p mass i would go here and i would arrive at a lot which is called as fast and mass slow pmos fs also written as snsp for more clarity okay nmos is fast emotions slow but typically if you say fs then people assume that nmos is being talked about first okay but you can always write it in fnst format so that it is more clear to anyone there okay so now let us say that uh not just so we said that the doping for nmos was towards fast doping for pmos was also towards fast so i reached here now we say that the etching of the poly when we were defining the gate that also happened for a few milliseconds more so what happened both n mass and p mass became a little faster then we say that the oxide thickness was also grown for a slightly lesser time so again both nmos and t mass became faster and we essentially moved from somewhere over here to this point where all the variations are then over overlaid over one over another and we arrived at the fast fast lot so you would add variations come here then add stuff and come somewhere here okay are you getting the sense there are some variations which are correlated and some variations which are independent for example nmos and p must do things happen in different steps so they are independent and most can be doped more and pmos can be doped less but some variations like length and t-oxide thickness they would be similar for both nmos and females are you with me on this any questions so if the body is etched more then it will lead to slower side right of the faster side why is the poly is etched more than the length is shorter if the length is shorter so in the ideas current equation if you just go to that equation for once uh how does the length appear in the equation w by l so but like you said uh that diffusion areas would be fixed for us uh when the mass would be made so if the polish edge move then we will not even get the gate itself not sorry the device itself uh even before we enter into this uh this business of how the drain drain what do you say capacitance etcetera would come into picture we had this lecture on manufacturing process yes what was the sequence of manufacturing steps i mean yes sir so first we destroy deposit the poly then we do a diffusion area so but like even before we are going towards the poly the mass that according to which the diffusion is happening they are they have been already manufactured so if they are polluted so let us review that one how do you make diffusion region in your layout so this man yes sir and then then you make poly yeah so diffusion mask is this is it not yes so now the poly length has reduced what happens the drain will formed it will still form along the gate yeah so this process is called as self-aligned gate and it's a very powerful process because then whatever variations happen to the length the poly may shift this side that side whatever it happens my transistor action will not be impacted my source and drain will be aligned to the gate at all times do you see that hello sir can you please repeat this you do not understand so you tell me what is the process of manufacturing what are the steps how we manufacture a transistor uh so first we'll have the substrate then uh we will introduce the end well after that we will uh deposit the field oxide along with the gate oxide and then we do the etching uh post that we do our implantation and after that after the implantation then yeah we we make the contact windows and then poster we will deposit the method what about the date when will the gate come oh sorry sir after after the uh depositing the gate upside we deposit the policy call okay so when we deposit the polysilicon then we etch the polysilicon after that yes so that is when the gate is formed yes and now after you've etched the polysilicon and you have etched the gate oxide in regions where there was no polysilicon you will now do the implant so that force and drain regions are formed yes so at all times gate will always be in touch with source and drain yes sir now if the sequence of designing source and drain was such that i would make source and drain first and then deposit poly something like this can happen do you see yes sir and this the transistor action will not happen or yes something like this can also happen the poly mass just got shifted by a few nanometers again transistor action would not happen yes sir but in the process that we are using the processes will deposit the poly first yes and when we will deposit the implants for source handling yes so transition action will always happen okay and this is what is called as self-aligned date okay unless that's it thank you okay um you will have to give me a minute my ppt kind of crashed so any other questions around this is this part clear about the self-aligned poly and stuff uh excuse me sir yes so sir the self-aligned gate is a property of the actual process itself it's not of the manufacturing process yes okay so like once we realize that our uh politics has shifted uh here and there we can just realign the entire deposition process it will automatically get realigned okay okay the way you defined the process do you see it will automatically get redefined no yes sir okay are you able to see this so what are we talking about we are saying that i will deposit the gate first now let us say the original position of gate was this but i deposited gate a little to the left after i have deposited the gate i will do the implant for source handling so what happens now the implant for source entering happens like this i still have source and drain there which are connected so the transistor action will still happen in this region even if my poly got misaligned,https://www.youtube.com/watch?v=LMeHv7zsxsA,"Link: https://www.youtube.com/watch?v=LMeHv7zsxsA
Transcript: so today we will we are going to in fact start with uh or we will start to look at the process variations we will also talk about projects and if time permits will also probably talk about you know start with power dissipation and power estimation methods so until now what you looked at is delay estimation methods am i right logical effort and all the delay models everything elmo delay everything was delay estimation so we have also looked at stick diagrams but stick diagrams do not give a very clear view of area yet it does give you some sense but not really a very clear view because the concept of width is not there in the stick diagrams so you will get the concept of area when you will work on your projects you already done assignments in which you have drawn in mutual drawn layout so you have some sense of how area is you know impacted when you change the size of devices and power is something that we will start next okay and uh after that we will go into different circuit design styles static cmos pseudo cmos pseudo pseudo nmos dynamic logic and so on so look into various design files for combinational circuit design after that we will look at sequential circuit design and then we will sign off you know this course and like i'm just giving you an overall uh you know a quick overview of what we expect in the second part of this course so later part we will sign off with uh some arithmetic circuits like adders multipliers and uh also memories okay so a quick glimpse of memories also will be there towards the end of this course okay so today we will start to look at uh parametric variations or process variations uh we will have a quick glimpse of why they happen and which we've already discussed so we'll move quickly around that then we will go go to the project part and then we'll start the power dissipation aspect so we designed a inverter such that this black line the black line now which i am overlaying with red now we designed an uh so how do i remove this i can simply remove this so we designed an inverter with this nominal curve of black line but if the pmos's design is faster than what we had anticipated or the n-mass is worse than what we had anticipated then the curve would move to this side on the other hand if the n mass is better than what we had anticipated and pmos is worse than what we had anticipated the curve would move to that side to the left side it is almost like you've changed the beta ratio of your design am i right if you change the beta ratio curve would move don't move on left to right stuff like that you remember yes yeah so if it so happens that pmos is manufactured fast or nmos is manufactured slow then the curve would move to right because it appears to this uh you know in the uh in the kirchhoff's law equation where we or how we determine the transfer characteristics of an inverter we see that pmos will now drive more current and therefore the curve would move to the right the output would stay one for a longer period of time but why is this happening how do we have a good pmos and a bad end moss or a good nmos and a bad female how do we get that and why do we get that it might be due to the manufacturing process yes it is due to manufacturing process runs it so so yes so like you are saying that if the curve is moving to the right or left it means the beta ratio is basically changing sort of so what beta is showing uh is related to the physical property physical characteristics okay so i mean so basically we are saying that whatever it is happening it is due to the physical uh that when the physical device is getting manufactured at that time something is happening which is leading to this kind of yeah you can say electrical beta ratio is changing would that be okay so electrical beta ratio what time what what the term would be yeah electrical beta ratio can be considered as the on current of the n mass upon on current of the p mass okay okay okay because if you have to equate them that is how you will come to the physical w by l beta ratio is it not uh yes sir right now you arrive at any beta ratio so that you get some ratio between the concurrent of the pmos and the nmos is it not yeah yes okay and that is the basis so we're talking about that basis that if the pmos current is more and the nmos current is lesser then it's almost like saying that the beta ratio of this device is such that pmos appears to be larger and nmos appears to be smaller okay it might be like uh the doping of uh pmos is much better than broken or feminist uh i mean so okay they're saying that doping could be one reason why this behavior can happen okay great what else uh so ultimately sir we can say all these factors are leading to change in the resistance of the devices all which factors like factors okay yeah beta resistance is the beta ratio is a consequence of something what can we say it is a mobility change why would mobility change no sudden mobility i i am saying that betas consist of these parameters but mobility will be very great so you are confusing between beta inside the model definition and beta ratio that we talk of as an inverter there are two very different things be careful okay okay so the beta as in model definition is something different from the beta ratio that we were just talking about so can this be due to variation in bt yes we just said no it could be due to vt with doping variations doping variations will lead to vt variations yeah in the chat window someone is saying t ox variations okay yes t ox variations will also lead to something like vp variation yes definitely there are direct impact on beta ratio either so does it have to do something with the temperature temperature means when we save yeah see in this situation when we are plotting them on the same graph we are assuming over here that the voltage of operation and temperature remain same okay but even then something has happened yes okay we are looking at why all those things could happen so yes you know uh for example if there is a variation in t ox that could be because of different duration for which oxide was grown if there was a is there is a variation in doping it could be because of a slightly different duration for which uh phosphine was run over the wafer for example so that phosphorus doping would be different so it could be because of all these little little variations that can happen in the manufacturing process so have we done this exercise in the class already where i asked you to write something 10 times on a piece of paper have it done that exercise yes so you know that they will when in a manufacturing process there can anyways be some variation that can happen however controlled however well controlled the process would be there would still be some variations and they lead to what we call as device variations and these device variations and then modeled into what is called as process slots these variations are due to as we just said vt oxide of an oxide thickness of nmos and p mass effective length effective width and so on so what we say is that we had targeted to make a particular device we call that typical this was the device that we wanted to make okay the center one but then what happened when i was uh let us say doping for the nmos then it happened in such a way that my device for the nmr side would go towards fast so this this dot started to move towards right so nmos doping was such that the device would go too fast then when i was doing doping for the pmos then again it was such that the device would go towards fast let us say so it would go up so i reached this particular place which is called as ff which is fast and mass fast p mass however if while doping for the p mass the doping went towards slow side for the p mass i would go here and i would arrive at a lot which is called as fast and mass slow pmos fs also written as snsp for more clarity okay nmos is fast emotions slow but typically if you say fs then people assume that nmos is being talked about first okay but you can always write it in fnst format so that it is more clear to anyone there okay so now let us say that uh not just so we said that the doping for nmos was towards fast doping for pmos was also towards fast so i reached here now we say that the etching of the poly when we were defining the gate that also happened for a few milliseconds more so what happened both n mass and p mass became a little faster then we say that the oxide thickness was also grown for a slightly lesser time so again both nmos and t mass became faster and we essentially moved from somewhere over here to this point where all the variations are then over overlaid over one over another and we arrived at the fast fast lot so you would add variations come here then add stuff and come somewhere here okay are you getting the sense there are some variations which are correlated and some variations which are independent for example nmos and p must do things happen in different steps so they are independent and most can be doped more and pmos can be doped less but some variations like length and t-oxide thickness they would be similar for both nmos and females are you with me on this any questions so if the body is etched more then it will lead to slower side right of the faster side why is the poly is etched more than the length is shorter if the length is shorter so in the ideas current equation if you just go to that equation for once uh how does the length appear in the equation w by l so but like you said uh that diffusion areas would be fixed for us uh when the mass would be made so if the polish edge move then we will not even get the gate itself not sorry the device itself uh even before we enter into this uh this business of how the drain drain what do you say capacitance etcetera would come into picture we had this lecture on manufacturing process yes what was the sequence of manufacturing steps i mean yes sir so first we destroy deposit the poly then we do a diffusion area so but like even before we are going towards the poly the mass that according to which the diffusion is happening they are they have been already manufactured so if they are polluted so let us review that one how do you make diffusion region in your layout so this man yes sir and then then you make poly yeah so diffusion mask is this is it not yes so now the poly length has reduced what happens the drain will formed it will still form along the gate yeah so this process is called as self-aligned gate and it's a very powerful process because then whatever variations happen to the length the poly may shift this side that side whatever it happens my transistor action will not be impacted my source and drain will be aligned to the gate at all times do you see that hello sir can you please repeat this you do not understand so you tell me what is the process of manufacturing what are the steps how we manufacture a transistor uh so first we'll have the substrate then uh we will introduce the end well after that we will uh deposit the field oxide along with the gate oxide and then we do the etching uh post that we do our implantation and after that after the implantation then yeah we we make the contact windows and then poster we will deposit the method what about the date when will the gate come oh sorry sir after after the uh depositing the gate upside we deposit the policy call okay so when we deposit the polysilicon then we etch the polysilicon after that yes so that is when the gate is formed yes and now after you've etched the polysilicon and you have etched the gate oxide in regions where there was no polysilicon you will now do the implant so that force and drain regions are formed yes so at all times gate will always be in touch with source and drain yes sir now if the sequence of designing source and drain was such that i would make source and drain first and then deposit poly something like this can happen do you see yes sir and this the transistor action will not happen or yes something like this can also happen the poly mass just got shifted by a few nanometers again transistor action would not happen yes sir but in the process that we are using the processes will deposit the poly first yes and when we will deposit the implants for source handling yes so transition action will always happen okay and this is what is called as self-aligned date okay unless that's it thank you okay um you will have to give me a minute my ppt kind of crashed so any other questions around this is this part clear about the self-aligned poly and stuff uh excuse me sir yes so sir the self-aligned gate is a property of the actual process itself it's not of the manufacturing process yes okay so like once we realize that our uh politics has shifted uh here and there we can just realign the entire deposition process it will automatically get realigned okay okay the way you defined the process do you see it will automatically get redefined no yes sir okay are you able to see this so what are we talking about we are saying that i will deposit the gate first now let us say the original position of gate was this but i deposited gate a little to the left after i have deposited the gate i will do the implant for source handling so what happens now the implant for source entering happens like this i still have source and drain there which are connected so the transistor action will still happen in this region even if my poly got misaligned"
TZ3aN2GsTdo,okay i got it okay thank you okay so now tell me one thing if lf if l effective is reduced that is police etched a little more what happens will i get a fast device or a slow device huh it will be fast it will be fast why because we know that the model is okay w by l into v g s minus v t the whole square stuff like that so l comes in the denominator if the length is lesser etching has happened a little more then the current will be more so i get a fast device so how should my vt change how should my vt change to get a fast device should vt reduce or should be increase it should reduce it should reduce why because of the vgs minus vt is down yes yes if vt reduces vgs minus vt term increases and therefore current increases great what about t ox uh t-offs also should reduce nominally uh uh also it should uh yeah because you need to increase the uh c off yes as the t-ox reduces it increases the c-ox which leads to more current uh but sir all of these like yeah that is happening but my device is on current is more yeah i know so that is what you're trying to find out how will the device become fast so all these things will lead to a fast device on the other side larger lengths high vt thicker gate oxide would meet to a slow device huh and while stuff like l effective and t ox is correlated for both nmos and p mass dopant implant is independent for example so it can happen that you will get fast fast lot also where just by chance both nmos and pmos move towards fast direction but you can also come to ss and fs slots where nmos move to one side and pmos move to the other is that part clear uh sir can you revisit the uh concept where the vt is dependent upon the doping i mean uh like how was bt changing i mean okay so svt if the doping is more let us say what happens so so we are talking of the diffusion doping right um no not just that we're talking of doping even under the gate the substrate doping also yeah okay so what happens if the doping in the under the gate changes because that is where the transistor action happens diffusion are just sources of current yes sir i know so it's under the date that the way you dope that will change the transistor behavior so if you increase the doping a bit what happens the depletion width reduces yeah under the diffusion the diffusion and the substrate is the gate the depletion width would reduce yes sir huh if the depletion which reduces then what happens so but when i am taking the transistor action i should not be talking about the depletion bit right because that is not that because then i'm not considering that what is vt after the inversion after depletion inversion player forms that is yes after the after the after the depletion maximum depletion width has happened then the inversion layer sets in so if i am saying that the maximum depletion layer will now happen faster so what will be t has come to vc will have come with vt will happen faster vt will be low okay yes pattern so i have doubt in the sweaty part if the doping is more so suppose we have a n well and the p plus doping on the source entry so if the if the doping is more in the substrate then the electrons in that the the region below the gate is gone now we need more vgs to remove those electron and get the uh get the holes from the p plus so i think vt will be more in that case so uh essentially what we are saying is that uh when we change the doping when we change the doping vt will get impacted yes there could be multiple directions in which my my system will move due to variations in doping in fact you will realize that in advance technologies there are retrograde implants there are super halo implants there are halo implants and so such complex doping that whatever picture we are talking about faizal is is largely hypothetical and just for ease of understanding okay the actual process is fairly complex with multiple multiple features figuring in yes yes so what is most important to arrive at so you can study all that in detail when we do ssd what is most important to arrive at is that doping for nmos and p mass is going to be different it will be independent steps yes yes so vt shift of nmos and pmos will happen in different directions what can happen in different directions that's the point we need to take back home okay okay okay because i agree you know we will uh i i i would have encouraged much more digressions but earlier in the course now we are you know we have to move fast towards our target of uh coming to circuits so yes you can study more reference material even in west a and harris you will have more material about how vt shift happens with doping and all that you will if you take ssd course you will read much more about how easy shifts happen and how it is impacted by doping yes so actually it was discussed in the ssd course uh that's why i'm asking yeah so uh there are so ssc must have also discussed halo and superhero implants uh no not yet not yet so you will see that in all the advanced technologies where these implants are in picture it is not so obvious to say doping it is also about the depth at which doping has happened the size of the hello so many things yes okay i understood your concept okay so what is important to understand is some some variation sources of variation are correlated others are independent and therefore you have et lot that is the target and ss slow and mass low pmos fs fast and most fast p mass and also sf and fast and more slow pmos kind of plots yes ma'am i didn't understand why would increasing the dopamine you know um you know decrease the maximum indication but that will take us completely off the phone so i'll just ask an officer yeah we can study that later or we can discuss this in the office is that okay so now if we know that my circuit can happen or can be or my wafer can be manufactured in any of these lots then it isn't it evident that i should verify all these lots when i do my design by lots of meaning the die complete die lot means a set of for 25 wafers okay all the 25 wafers that are in the lot for example would have one kind of doping because the doping happens uh the uh the doping happens in one go for for a set of 25 wafers substrate doping at least now when we talk about when we talk about halo and super hello then so this was how the lot the word lot had arrived at okay but in advanced technologies when you talk about complex uh substrate uh doping engineering then you would do that doping on a wafer wi-fi services so that would then appear as a lot then the lot variations are now limited to one wafer only okay but in older technologies the lot very the lot meant a set of 25 wafers that would go into the doping machine simultaneously so just the trivia uh if this lot you can see over 25 wafers so then this 25 all the wafers and all the dives will be corresponding to one process corner right yes okay now it is not so simple it can happen that so let us look at it like this when you doped them they all went towards let us say fs all of them but then what happened the substrate doping you had done and then what happened you started to deposit the gate and the gate deposition was towards the fast you know the etching of the gate happens a little more so you moved a little here then something has happened you could have moved a little here for example so there will be so many routes through which the lots could be manufactured anywhere in between these so this whole area this region is where your dyes will be manufactured these are just model representations you will get only these models so that you verify only these corner points so these are called pvt con vt corners or process corners that doesn't mean a lot will be manufactured only in these five points lot should be manufactured everywhere these are the corners of that distribution okay any questions okay so now coming to the next part which is that are these the only reasons why why delays or something would change or could delay change because of something else also temperature temperature temperature okay vdd used the voltage of operation yes let me show you have a question uh sir uh it was related to something earlier sir you said that a lot is a set of papers so sir um so uh i understood that there will be variations in the uh slots so uh if in multiple way person so there will be variations within the wafer also yes we'll come to that we'll come to that not just within a wafer you will see that there are variations within a diode there are die two diversions also very okay so okay i know yes so all that will happen don't worry we will we will discuss all that if you just give me a minute my ppt seems to be playing cranky today so we are also talking about the next thing that we need to look at is vp variations so what happens to the uh the variations and delays due to vdd and temperature uh mother you had a question uh yes sir in in virtuoso when we try to run simulation we either do it for so he said that our final device would be anywhere between in this region only so it doesn't necessarily have to be that any of the corners right so how do you decide corner is a corner corner is just one point in reality the device can be manufactured anywhere now so how do we simulate such that the origins that we simulate the behavior of the manufacture device and not just the converse do you really want to simulate intermediate points mother what would you achieve by that doesn't this mean that our transistor wouldn't work so this would mean that our transistor is not working uh exactly as we intended it to be it's not as the simulation so it is not as bad as slow as you had possibly designed it for it could be faster yes or it is not as fast as you had qualified the whole time or it could be slower than that yes okay but do you really want to check for those intermediate transistors also if it matters then we should check if it doesn't you tell me you tell me you tell me would it matter maybe something no it may it may matter no no maybe let us logically arrive at a solution because if i say that i have to test every point that could exist on that space you see there could be infinite points henna yes so that would mean that my verification effort would go like anything it would expand like anything so my design time my time to market will go for a toss as a designer we cannot simply say maybe not work okay so so we know beforehand that if we are using this manufacturing process that it will lie near fast near some of those corners and we say it will be within this rhombus okay,https://www.youtube.com/watch?v=TZ3aN2GsTdo,"Link: https://www.youtube.com/watch?v=TZ3aN2GsTdo
Transcript: okay i got it okay thank you okay so now tell me one thing if lf if l effective is reduced that is police etched a little more what happens will i get a fast device or a slow device huh it will be fast it will be fast why because we know that the model is okay w by l into v g s minus v t the whole square stuff like that so l comes in the denominator if the length is lesser etching has happened a little more then the current will be more so i get a fast device so how should my vt change how should my vt change to get a fast device should vt reduce or should be increase it should reduce it should reduce why because of the vgs minus vt is down yes yes if vt reduces vgs minus vt term increases and therefore current increases great what about t ox uh t-offs also should reduce nominally uh uh also it should uh yeah because you need to increase the uh c off yes as the t-ox reduces it increases the c-ox which leads to more current uh but sir all of these like yeah that is happening but my device is on current is more yeah i know so that is what you're trying to find out how will the device become fast so all these things will lead to a fast device on the other side larger lengths high vt thicker gate oxide would meet to a slow device huh and while stuff like l effective and t ox is correlated for both nmos and p mass dopant implant is independent for example so it can happen that you will get fast fast lot also where just by chance both nmos and pmos move towards fast direction but you can also come to ss and fs slots where nmos move to one side and pmos move to the other is that part clear uh sir can you revisit the uh concept where the vt is dependent upon the doping i mean uh like how was bt changing i mean okay so svt if the doping is more let us say what happens so so we are talking of the diffusion doping right um no not just that we're talking of doping even under the gate the substrate doping also yeah okay so what happens if the doping in the under the gate changes because that is where the transistor action happens diffusion are just sources of current yes sir i know so it's under the date that the way you dope that will change the transistor behavior so if you increase the doping a bit what happens the depletion width reduces yeah under the diffusion the diffusion and the substrate is the gate the depletion width would reduce yes sir huh if the depletion which reduces then what happens so but when i am taking the transistor action i should not be talking about the depletion bit right because that is not that because then i'm not considering that what is vt after the inversion after depletion inversion player forms that is yes after the after the after the depletion maximum depletion width has happened then the inversion layer sets in so if i am saying that the maximum depletion layer will now happen faster so what will be t has come to vc will have come with vt will happen faster vt will be low okay yes pattern so i have doubt in the sweaty part if the doping is more so suppose we have a n well and the p plus doping on the source entry so if the if the doping is more in the substrate then the electrons in that the the region below the gate is gone now we need more vgs to remove those electron and get the uh get the holes from the p plus so i think vt will be more in that case so uh essentially what we are saying is that uh when we change the doping when we change the doping vt will get impacted yes there could be multiple directions in which my my system will move due to variations in doping in fact you will realize that in advance technologies there are retrograde implants there are super halo implants there are halo implants and so such complex doping that whatever picture we are talking about faizal is is largely hypothetical and just for ease of understanding okay the actual process is fairly complex with multiple multiple features figuring in yes yes so what is most important to arrive at so you can study all that in detail when we do ssd what is most important to arrive at is that doping for nmos and p mass is going to be different it will be independent steps yes yes so vt shift of nmos and pmos will happen in different directions what can happen in different directions that's the point we need to take back home okay okay okay because i agree you know we will uh i i i would have encouraged much more digressions but earlier in the course now we are you know we have to move fast towards our target of uh coming to circuits so yes you can study more reference material even in west a and harris you will have more material about how vt shift happens with doping and all that you will if you take ssd course you will read much more about how easy shifts happen and how it is impacted by doping yes so actually it was discussed in the ssd course uh that's why i'm asking yeah so uh there are so ssc must have also discussed halo and superhero implants uh no not yet not yet so you will see that in all the advanced technologies where these implants are in picture it is not so obvious to say doping it is also about the depth at which doping has happened the size of the hello so many things yes okay i understood your concept okay so what is important to understand is some some variation sources of variation are correlated others are independent and therefore you have et lot that is the target and ss slow and mass low pmos fs fast and most fast p mass and also sf and fast and more slow pmos kind of plots yes ma'am i didn't understand why would increasing the dopamine you know um you know decrease the maximum indication but that will take us completely off the phone so i'll just ask an officer yeah we can study that later or we can discuss this in the office is that okay so now if we know that my circuit can happen or can be or my wafer can be manufactured in any of these lots then it isn't it evident that i should verify all these lots when i do my design by lots of meaning the die complete die lot means a set of for 25 wafers okay all the 25 wafers that are in the lot for example would have one kind of doping because the doping happens uh the uh the doping happens in one go for for a set of 25 wafers substrate doping at least now when we talk about when we talk about halo and super hello then so this was how the lot the word lot had arrived at okay but in advanced technologies when you talk about complex uh substrate uh doping engineering then you would do that doping on a wafer wi-fi services so that would then appear as a lot then the lot variations are now limited to one wafer only okay but in older technologies the lot very the lot meant a set of 25 wafers that would go into the doping machine simultaneously so just the trivia uh if this lot you can see over 25 wafers so then this 25 all the wafers and all the dives will be corresponding to one process corner right yes okay now it is not so simple it can happen that so let us look at it like this when you doped them they all went towards let us say fs all of them but then what happened the substrate doping you had done and then what happened you started to deposit the gate and the gate deposition was towards the fast you know the etching of the gate happens a little more so you moved a little here then something has happened you could have moved a little here for example so there will be so many routes through which the lots could be manufactured anywhere in between these so this whole area this region is where your dyes will be manufactured these are just model representations you will get only these models so that you verify only these corner points so these are called pvt con vt corners or process corners that doesn't mean a lot will be manufactured only in these five points lot should be manufactured everywhere these are the corners of that distribution okay any questions okay so now coming to the next part which is that are these the only reasons why why delays or something would change or could delay change because of something else also temperature temperature temperature okay vdd used the voltage of operation yes let me show you have a question uh sir uh it was related to something earlier sir you said that a lot is a set of papers so sir um so uh i understood that there will be variations in the uh slots so uh if in multiple way person so there will be variations within the wafer also yes we'll come to that we'll come to that not just within a wafer you will see that there are variations within a diode there are die two diversions also very okay so okay i know yes so all that will happen don't worry we will we will discuss all that if you just give me a minute my ppt seems to be playing cranky today so we are also talking about the next thing that we need to look at is vp variations so what happens to the uh the variations and delays due to vdd and temperature uh mother you had a question uh yes sir in in virtuoso when we try to run simulation we either do it for so he said that our final device would be anywhere between in this region only so it doesn't necessarily have to be that any of the corners right so how do you decide corner is a corner corner is just one point in reality the device can be manufactured anywhere now so how do we simulate such that the origins that we simulate the behavior of the manufacture device and not just the converse do you really want to simulate intermediate points mother what would you achieve by that doesn't this mean that our transistor wouldn't work so this would mean that our transistor is not working uh exactly as we intended it to be it's not as the simulation so it is not as bad as slow as you had possibly designed it for it could be faster yes or it is not as fast as you had qualified the whole time or it could be slower than that yes okay but do you really want to check for those intermediate transistors also if it matters then we should check if it doesn't you tell me you tell me you tell me would it matter maybe something no it may it may matter no no maybe let us logically arrive at a solution because if i say that i have to test every point that could exist on that space you see there could be infinite points henna yes so that would mean that my verification effort would go like anything it would expand like anything so my design time my time to market will go for a toss as a designer we cannot simply say maybe not work okay so so we know beforehand that if we are using this manufacturing process that it will lie near fast near some of those corners and we say it will be within this rhombus okay"
EH8zEetiYco,in this so do you know the concept of temperature inversion do you know the dependence of mobility on temperature yes sir so what happens to mobility as temperature increases be proportional to the power minus three by two is it nice yeah yeah okay is there anything else in terms of temperature that mobility is dependent on i mean there are two kinds of scattering we consider and it creates increases both plus and minus yes so as temperature increases the scattering also increases mobility actually overall current actually degrades okay this is at high voltages however when you are operating at low voltages the total number of carriers that you have in the in the conduction band they are not much so when you increase the temperature that carrier boost is much more than the scattering that would have happened because of uh lattice vibration and anything like that okay and therefore at lower voltages uh higher temperatures lead to a better current yes so can we your mobility is decreasing higher voltage is always better current is it not a higher voltage is better current but higher temperature was like reduced so what happens at low voltages the voltage is or the voltage is so low that the gate overdrive let us say is not sufficient even if the gate overdrive is sufficient we say that the number of carriers that you have in the conduction band to be able to conduct the current that is not much there are carriers inversion is already set and we know that but even then there is something missing as you increase the temperature more carriers come into picture carriers have more energy now so they move they move faster also sir i mean uh temperatures or also actually decreases the threshold voltage yeah so see threshold voltage reduction is also a consequence of this affects that number of carriers and all that yes looking at the different definitions of threshold you see all these are different ways of pointing at the same phenomena current increase on a vt reduce on all their they are you you one could say that because current has increased therefore vp has reduced because vt definition is one micron pair of current for a one micron with device anna so ah yeah is this part clear hello temperature and impact of temperature and voltage on circuit performance is that part clear does need to have a question say slide is not visible sir when this industry you have written that dvd is higher and the temperature is low so though our device is becoming faster sir but the that the sub threshold leakage will increase yeah on fast devices is known to be higher yes sir yes sir we have to compromise it yeah yeah that is known to be higher okay so now tell me uh if you have to verify then what will be the pvts at which you will design and verify your you know pvt means process temperature and voltage for which you will design and verify your circuits hello slow slow sir slow slow what about voltage uh slow slow with low voltage temperature high high high temperature so apne have you checked your assignment three i've asked you to characterize at multiple pvps yes yes so now can you identify and relate why so many pvts are being asked for yes sir they're all about these various corners and also what you will see is that for some parameters like for for timings delays slow everything putting everything to slow leads to worst case result but for some other parameters putting everything too fast would lead to worst case results and in terms of leakage it's a mix of slow and fast because you want high temperature to see worst case leakage are you able to see this like the worst case in case of so the worst case in k uh in case of fast pass will be for whole time likewise yes contamination delays will be worst in the fast fast low temperature and everything propagation delays will be worse than slow slow high low voltage and high temperature sub threshold leakage as as we rightly pointed out is is higher when you have fast and mass fast p mass when vdd is also high but for high leakage we need to have the higher temperature so the temperature is related to the slow temperature 125 degree celsius that is where you need mix of different pvts to overall characterize your designs that is why this long list of pvp is there so is that all is that all that we need to worry about or is there something else which line so just like important this one uh no sir i mean like the one you were currently on like last time after that so when i asked the doubt we were on important quarters like for [Music] okay so we just saw on our delay our first when n masses flow pmos is slow vdd is low and temperature is high it's just tabulating it in one pump that's it yeah power would also be higher also because of leakage being higher when uh your uh you know voltage of operation is higher it is cv square f so the capacitance is higher when the devices are fast v is higher vdd means we want to increase cv square f so we really have to be higher and we know frequency is highest when the temperature is low so cv square f is highest when uh or power is highest when everything is towards the fast side okay yes yeah so some of you already pointed out okay okay we can have all these lots so in reality what you get is not a rhombus what you get is actually an ellipse and on that ellipse you define what is called as uh you know one sigma ellipse two sigma ellipse and three sigma ellipse you say everything within this is considered as typical and this part is slow let us say okay so all models ssf all that rhombus that we looked at it is a fitting exercise you have to arrive at a rhombus over here which would be safe for designing purposes there may still be some lots which will be out of the humbles and you agree that on those lots you accept some extra heal loss okay in addition to that see whichever lot i have designed at suppose a lot is placed here you will see that there will be uh variations on that particular wafer itself these are called device variations so until now you are looking at lot variations now these are called device variations and to validate a design with device variations you go to the ss corner or ff corner or whatever corner you're talking about and you run monte carlo there what is monte carlo so if there are more number of inputs i will be using monte carlo analysis is an analysis in which you will vary different parameters which are known to exhibit variations so what are the parameters over here that we know will exhibit variations intrinsic parameter over here that will in the exhibit variation doping l effective w effective stuff like that so you vary all those parameters for different devices and randomly place those variations on different devices then when you simulate what you will get is a this red shaded circles around that lot point it is a sample of transistors that could be manufactured on that particular lot oh so can you explain this again actually i wasn't even getting this wow for a particular lot what we are doing exactly here so we were just talking that if there is a wafer even on that wafer there could be variations that could happen in a device which is manufactured towards the top of the wafer and then a device which is manufactured towards the right side of the wafer yes sir so it means that for even a lot there will be other device variations which will come into picture yes yes so how do you validate those so one part of validation we said okay we will we will uh test or characterize and design our stuff at circuits at ss 1.125 well ss low voltage high temperature and all that we just agreed that we will do that but for final circuit verification you also need to take into account device variations and that is what you will do by the means of running monte carlo simulations this is called as monte carlo analysis also in which different variations are applied to different transistors so that the example that we just saw that one pmos is fast and the nmos is flow those those situations can appear even in a fast pass lot or even in a slow slow lot where they were expected to both move in the same direction like when when the when it was starting i was taking the pbt variations in the law for the for a lot basically i said that okay my nmos will be slow slow slow and this vdd and temperature kind of way so by that i had considered the lot variations of the lord thing and now even i'm going uh once i pick up a certain corner rhombus then i'm going into that particular corner yeah and doing the same exercise of pain more slow pmos and more than vdd yes again again injecting variations in there okay and seeing how the devices in this particular lot can lead to the change in my circuit functionality okay so sir like when we have been for example in the virtuous itself when we are doing the simulation with the adel window so when we are selecting the sources that at that time we were selecting the slow slow and the temperature that are basically the uh not basically lot variations yes there are lot variations okay sir so in conclusion we can see that within this slot there are this this is the uh wafer and this wafer has this four corner devices that fast fast low slow and this four and there so this graph here is the lot variations so here basically there is four possibility of uh no there are infinite possibilities of devices that is why we have made this ellipse there so in this there is no fast fast low slow error the corner points we call them fast fast and slow slow okay some corner points of the cells we call them as fast fast and slow slow but there will only probably be a few lots in those exact those corners majority of lots will be enclosed in the in the in the rhombus there so okay okay okay excuse me sir yes so for this left graph so that was that is the lot variation yeah left and right both are lot variations only but then on the right one i've just made this red circle which is device variation so what is the y-axis in both of them for the for the left graph the y-axis are threshold voltages and for the right graph the x and y-axis are currents id okay so but we could run this monte carlo simulation on the left graph as well yeah yeah you just choose a lot and you run monte carlo variations and you will get a distribution of all these points okay sir okay okay yes sir uh we how my question is for tt uh so do we uh do the does the foundry provide us a real uh because uh we cannot be very sure that which is the most uh middle point always so every time you manufacture the middle point also might vary so um according to me that tt should be calculated theoretically and with reference to that we should uh decide ff and ss or or the foundry only provides every time the tt lord tt parameters the foundry will give you the lots always even the ss and the ff plots the foundry will give you you don't decide as a as a designer listen my question was like tt should be an averaged out value of all the corners right because every foundry may have a different uh way to arrive at ttd park some foundry may say that okay this pt will be my target okay okay i am i suppose today you want to design in three nanometers the technology is not even there or even if it is there it is in a prototype stage you do not even know what kind of variations will finally happen not happen so where you will finally place your tt you know you still not figured out the final devices or the final materials that you will use in your gate dielectric and stuff like that you have a prototype technology running so in such cases the models will be called paper model largely paper models where we're talking about specifications but as the technology matures for example if today you would want to talk about 18 nanometer or a 22 nanometer or 28 nanometer technology is very mature so now et is actually given by the lot by the by the process that okay there are majority of wafers which have been manufactured in this place so this is my teacher all right so my question is that yeah we like we were doing the simulations in eldor so we had the files with us but and they were tt also in that so but in the real life that ttu might change over the time yeah so in real life gap in the evolution of a technology it will definitely change okay sure that okay okay but uh once the technology is frozen once the process is well in control and the foundry has defined that this is my tt then that tt then remains constant then if you take a lot and it is towards fast you say it is it is not tt that's it sure you know but as the technology evolves tt would change yes sure thank you so much yeah so is the question clear to others also is the answer clear to others also so so like uh into both the graphs after we have uh the foundry has provided us with basically the lord corners then this red basically carves that we are doing by ourselves for the monte carlo for the device kind of analysis on that particular right yeah okay and what he was also asking was will tt always be constantly a hypothetical value or from driven from the process so what i responded was that when the technology is not very mature tt would be paper models in fact all the corners will also be paired by models but as the technology matures tt and all the other corners will be silicon divine models and the positions would change over time yes they breathe so just to confirm one thing in in both the graphs uh set the ff and ss would be reverse right uh yes on the left graph ff would be towards the bottom corner towards the origin side yes and on the right graph it will be the ss will be towards origin side okay yeah yeah thank you sir good observation so because saturation current is more on the right side exactly so i can confuse you in the in the mid sems and tell you you have to carefully look at the access and then decide okay okay so uh in addition to these tt ssf things we also have what is called as ffs and ssf lots or points they are essentially the result of when i run monte carlo on ff and ss i see that the worst case nmos and pmos combo can happen over here so when you are you know verifying small circuits you may want to verify them over these points also you do not characterize them because in characterization part usually a small circuit is not an end in itself you would have many circuits uh cascaded one after another and the overall delays would never be at fff or ssf but when you are just verifying your circuits you may want to verify them at these functional points also not all boundaries provided but quite a few foundries do provide these functional models okay so they may call this as ffg ssg sfg and fsg also but yeah they may also provide these functional models in addition to that okay so now yes sir how are we supposed to unlike uh uh do this montage on the simulation in in the simulator and like in in cadence yeah so you can look into the user manual you just have a command called dot mc okay okay you just use the command command dot mc you tell which parameters you want to vary and you tell how many number of simulations you want to do so it will run the monte carlo simulations for you it is available in the user manual okay so now see we know that the a device may be manufactured let us say fast but on fast we also know the leakage is very high and the delays are much lesser so you signed off you designed something for to operate at 2 gigahertz now a die is manufactured or a lot is manufactured which is operating at 3 gigahertz now overall ecosystem you cannot really operate the system at three gigahertz because there could be uh resonance issues there could be inductive effects which would come into picture and so on so you anyway want to operate the particular diet two gigahertz but uh the devices are fast so you say and my leakage is very high you say can i do something to arrive at two gigahertz instead of three gigahertz but i reduce the leakage so what would you do you can do multiple things you can for example apply body bias what happens when you apply reverse body bias devices start to move towards slow then vt starts to increase basically another thing that you can do is you can reduce the voltage of operation you can say see i wanted to operate at 2 gigahertz at 1.2 volts now at 1.2 volts i am already getting 3 gigahertz why not operate at 1.15 or 1.1 2 volts and i will come to 2 i will come to 2 gigahertz and now because i am operating at a lower voltage i will also consume lesser power so these two techniques so this is where you are changing the body bias is what called adaptive body wires and the other one which where i said that you could lower the vdd or if you are on the slow lot you want to improve the performance you could increase the vdd a bit because you know that at higher vdd performances are higher so that is called adaptive voltage scaling ok so these again are areas of active research there is lots of work happening uh in their even production these these technologies are even production where uh dyes are trimmed to operate at lower voltage or higher voltage depending on where they were manufactured at so at the time of test you see what is the operational frequency and you trim them what is the leakage and you trim them appropriately okay so so the body bias was applied for the fast pass and the voltage for this torso so i could apply voltage for fast fast also i could lower the voltage and reduce the overall power consumption okay right both these techniques are available for the corners [Music] yes i'm trying to bring the device back into my specification for say let us say leakage or power consumption or timing or whatever okay i process compensation you will see is used in a large number of products today already it's not a new concept that we're talking about any longer okay something is also raghav yeah i mean so this body bias thing was considering this body bias can basically further create more complications like i mean like i'm not able to exactly pinpoint but i think that like something things like you can glitch like further like uh because early when we are considering like when we're doing the substrate taping and tapping and we're connecting the source with the body we are sort of uh those latch up effects and many other things can pop up yes so very very good raga i'm so happy that you're able to anticipate the problems that can come with body bias so uh in terms of forward body bias you have to realize that you cannot really power body bias your pn junctions beyond anything beyond 0.2 or 0.3 volts because otherwise the leakage currents would kind of run off similarly on the side of reverse body bias there would be constraints on how much reverse body bias you can put again because otherwise a band-to-man tunneling will kind of enough there will be lots of current that will flow from the source to the substrate or drain to the substrate so you cannot really do a lot of body bias so very good and very interesting observation however in advanced technologies like fds soi fully depleted soi so there is no junction in the source and drain region there is simply a buried oxide so since there is no junction so there is no concept of junction leakage per se or and junction leakage cannot increase so you can apply whatever amount of powered body buyers or reverse body buyers that you want to you are talking about here the soi technology yes okay the fully depleted soi not even partially if you were on partially depleted soi then again you will face trouble because junction would be there only in fully depleted soi you can actually go to very large range of uh body bias voltages okay yes okay,https://www.youtube.com/watch?v=EH8zEetiYco,"Link: https://www.youtube.com/watch?v=EH8zEetiYco
Transcript: in this so do you know the concept of temperature inversion do you know the dependence of mobility on temperature yes sir so what happens to mobility as temperature increases be proportional to the power minus three by two is it nice yeah yeah okay is there anything else in terms of temperature that mobility is dependent on i mean there are two kinds of scattering we consider and it creates increases both plus and minus yes so as temperature increases the scattering also increases mobility actually overall current actually degrades okay this is at high voltages however when you are operating at low voltages the total number of carriers that you have in the in the conduction band they are not much so when you increase the temperature that carrier boost is much more than the scattering that would have happened because of uh lattice vibration and anything like that okay and therefore at lower voltages uh higher temperatures lead to a better current yes so can we your mobility is decreasing higher voltage is always better current is it not a higher voltage is better current but higher temperature was like reduced so what happens at low voltages the voltage is or the voltage is so low that the gate overdrive let us say is not sufficient even if the gate overdrive is sufficient we say that the number of carriers that you have in the conduction band to be able to conduct the current that is not much there are carriers inversion is already set and we know that but even then there is something missing as you increase the temperature more carriers come into picture carriers have more energy now so they move they move faster also sir i mean uh temperatures or also actually decreases the threshold voltage yeah so see threshold voltage reduction is also a consequence of this affects that number of carriers and all that yes looking at the different definitions of threshold you see all these are different ways of pointing at the same phenomena current increase on a vt reduce on all their they are you you one could say that because current has increased therefore vp has reduced because vt definition is one micron pair of current for a one micron with device anna so ah yeah is this part clear hello temperature and impact of temperature and voltage on circuit performance is that part clear does need to have a question say slide is not visible sir when this industry you have written that dvd is higher and the temperature is low so though our device is becoming faster sir but the that the sub threshold leakage will increase yeah on fast devices is known to be higher yes sir yes sir we have to compromise it yeah yeah that is known to be higher okay so now tell me uh if you have to verify then what will be the pvts at which you will design and verify your you know pvt means process temperature and voltage for which you will design and verify your circuits hello slow slow sir slow slow what about voltage uh slow slow with low voltage temperature high high high temperature so apne have you checked your assignment three i've asked you to characterize at multiple pvps yes yes so now can you identify and relate why so many pvts are being asked for yes sir they're all about these various corners and also what you will see is that for some parameters like for for timings delays slow everything putting everything to slow leads to worst case result but for some other parameters putting everything too fast would lead to worst case results and in terms of leakage it's a mix of slow and fast because you want high temperature to see worst case leakage are you able to see this like the worst case in case of so the worst case in k uh in case of fast pass will be for whole time likewise yes contamination delays will be worst in the fast fast low temperature and everything propagation delays will be worse than slow slow high low voltage and high temperature sub threshold leakage as as we rightly pointed out is is higher when you have fast and mass fast p mass when vdd is also high but for high leakage we need to have the higher temperature so the temperature is related to the slow temperature 125 degree celsius that is where you need mix of different pvts to overall characterize your designs that is why this long list of pvp is there so is that all is that all that we need to worry about or is there something else which line so just like important this one uh no sir i mean like the one you were currently on like last time after that so when i asked the doubt we were on important quarters like for [Music] okay so we just saw on our delay our first when n masses flow pmos is slow vdd is low and temperature is high it's just tabulating it in one pump that's it yeah power would also be higher also because of leakage being higher when uh your uh you know voltage of operation is higher it is cv square f so the capacitance is higher when the devices are fast v is higher vdd means we want to increase cv square f so we really have to be higher and we know frequency is highest when the temperature is low so cv square f is highest when uh or power is highest when everything is towards the fast side okay yes yeah so some of you already pointed out okay okay we can have all these lots so in reality what you get is not a rhombus what you get is actually an ellipse and on that ellipse you define what is called as uh you know one sigma ellipse two sigma ellipse and three sigma ellipse you say everything within this is considered as typical and this part is slow let us say okay so all models ssf all that rhombus that we looked at it is a fitting exercise you have to arrive at a rhombus over here which would be safe for designing purposes there may still be some lots which will be out of the humbles and you agree that on those lots you accept some extra heal loss okay in addition to that see whichever lot i have designed at suppose a lot is placed here you will see that there will be uh variations on that particular wafer itself these are called device variations so until now you are looking at lot variations now these are called device variations and to validate a design with device variations you go to the ss corner or ff corner or whatever corner you're talking about and you run monte carlo there what is monte carlo so if there are more number of inputs i will be using monte carlo analysis is an analysis in which you will vary different parameters which are known to exhibit variations so what are the parameters over here that we know will exhibit variations intrinsic parameter over here that will in the exhibit variation doping l effective w effective stuff like that so you vary all those parameters for different devices and randomly place those variations on different devices then when you simulate what you will get is a this red shaded circles around that lot point it is a sample of transistors that could be manufactured on that particular lot oh so can you explain this again actually i wasn't even getting this wow for a particular lot what we are doing exactly here so we were just talking that if there is a wafer even on that wafer there could be variations that could happen in a device which is manufactured towards the top of the wafer and then a device which is manufactured towards the right side of the wafer yes sir so it means that for even a lot there will be other device variations which will come into picture yes yes so how do you validate those so one part of validation we said okay we will we will uh test or characterize and design our stuff at circuits at ss 1.125 well ss low voltage high temperature and all that we just agreed that we will do that but for final circuit verification you also need to take into account device variations and that is what you will do by the means of running monte carlo simulations this is called as monte carlo analysis also in which different variations are applied to different transistors so that the example that we just saw that one pmos is fast and the nmos is flow those those situations can appear even in a fast pass lot or even in a slow slow lot where they were expected to both move in the same direction like when when the when it was starting i was taking the pbt variations in the law for the for a lot basically i said that okay my nmos will be slow slow slow and this vdd and temperature kind of way so by that i had considered the lot variations of the lord thing and now even i'm going uh once i pick up a certain corner rhombus then i'm going into that particular corner yeah and doing the same exercise of pain more slow pmos and more than vdd yes again again injecting variations in there okay and seeing how the devices in this particular lot can lead to the change in my circuit functionality okay so sir like when we have been for example in the virtuous itself when we are doing the simulation with the adel window so when we are selecting the sources that at that time we were selecting the slow slow and the temperature that are basically the uh not basically lot variations yes there are lot variations okay sir so in conclusion we can see that within this slot there are this this is the uh wafer and this wafer has this four corner devices that fast fast low slow and this four and there so this graph here is the lot variations so here basically there is four possibility of uh no there are infinite possibilities of devices that is why we have made this ellipse there so in this there is no fast fast low slow error the corner points we call them fast fast and slow slow okay some corner points of the cells we call them as fast fast and slow slow but there will only probably be a few lots in those exact those corners majority of lots will be enclosed in the in the in the rhombus there so okay okay okay excuse me sir yes so for this left graph so that was that is the lot variation yeah left and right both are lot variations only but then on the right one i've just made this red circle which is device variation so what is the y-axis in both of them for the for the left graph the y-axis are threshold voltages and for the right graph the x and y-axis are currents id okay so but we could run this monte carlo simulation on the left graph as well yeah yeah you just choose a lot and you run monte carlo variations and you will get a distribution of all these points okay sir okay okay yes sir uh we how my question is for tt uh so do we uh do the does the foundry provide us a real uh because uh we cannot be very sure that which is the most uh middle point always so every time you manufacture the middle point also might vary so um according to me that tt should be calculated theoretically and with reference to that we should uh decide ff and ss or or the foundry only provides every time the tt lord tt parameters the foundry will give you the lots always even the ss and the ff plots the foundry will give you you don't decide as a as a designer listen my question was like tt should be an averaged out value of all the corners right because every foundry may have a different uh way to arrive at ttd park some foundry may say that okay this pt will be my target okay okay i am i suppose today you want to design in three nanometers the technology is not even there or even if it is there it is in a prototype stage you do not even know what kind of variations will finally happen not happen so where you will finally place your tt you know you still not figured out the final devices or the final materials that you will use in your gate dielectric and stuff like that you have a prototype technology running so in such cases the models will be called paper model largely paper models where we're talking about specifications but as the technology matures for example if today you would want to talk about 18 nanometer or a 22 nanometer or 28 nanometer technology is very mature so now et is actually given by the lot by the by the process that okay there are majority of wafers which have been manufactured in this place so this is my teacher all right so my question is that yeah we like we were doing the simulations in eldor so we had the files with us but and they were tt also in that so but in the real life that ttu might change over the time yeah so in real life gap in the evolution of a technology it will definitely change okay sure that okay okay but uh once the technology is frozen once the process is well in control and the foundry has defined that this is my tt then that tt then remains constant then if you take a lot and it is towards fast you say it is it is not tt that's it sure you know but as the technology evolves tt would change yes sure thank you so much yeah so is the question clear to others also is the answer clear to others also so so like uh into both the graphs after we have uh the foundry has provided us with basically the lord corners then this red basically carves that we are doing by ourselves for the monte carlo for the device kind of analysis on that particular right yeah okay and what he was also asking was will tt always be constantly a hypothetical value or from driven from the process so what i responded was that when the technology is not very mature tt would be paper models in fact all the corners will also be paired by models but as the technology matures tt and all the other corners will be silicon divine models and the positions would change over time yes they breathe so just to confirm one thing in in both the graphs uh set the ff and ss would be reverse right uh yes on the left graph ff would be towards the bottom corner towards the origin side yes and on the right graph it will be the ss will be towards origin side okay yeah yeah thank you sir good observation so because saturation current is more on the right side exactly so i can confuse you in the in the mid sems and tell you you have to carefully look at the access and then decide okay okay so uh in addition to these tt ssf things we also have what is called as ffs and ssf lots or points they are essentially the result of when i run monte carlo on ff and ss i see that the worst case nmos and pmos combo can happen over here so when you are you know verifying small circuits you may want to verify them over these points also you do not characterize them because in characterization part usually a small circuit is not an end in itself you would have many circuits uh cascaded one after another and the overall delays would never be at fff or ssf but when you are just verifying your circuits you may want to verify them at these functional points also not all boundaries provided but quite a few foundries do provide these functional models okay so they may call this as ffg ssg sfg and fsg also but yeah they may also provide these functional models in addition to that okay so now yes sir how are we supposed to unlike uh uh do this montage on the simulation in in the simulator and like in in cadence yeah so you can look into the user manual you just have a command called dot mc okay okay you just use the command command dot mc you tell which parameters you want to vary and you tell how many number of simulations you want to do so it will run the monte carlo simulations for you it is available in the user manual okay so now see we know that the a device may be manufactured let us say fast but on fast we also know the leakage is very high and the delays are much lesser so you signed off you designed something for to operate at 2 gigahertz now a die is manufactured or a lot is manufactured which is operating at 3 gigahertz now overall ecosystem you cannot really operate the system at three gigahertz because there could be uh resonance issues there could be inductive effects which would come into picture and so on so you anyway want to operate the particular diet two gigahertz but uh the devices are fast so you say and my leakage is very high you say can i do something to arrive at two gigahertz instead of three gigahertz but i reduce the leakage so what would you do you can do multiple things you can for example apply body bias what happens when you apply reverse body bias devices start to move towards slow then vt starts to increase basically another thing that you can do is you can reduce the voltage of operation you can say see i wanted to operate at 2 gigahertz at 1.2 volts now at 1.2 volts i am 
already getting 3 gigahertz why not operate at 1.15 or 1.1 2 volts and i will come to 2 i will come to 2 gigahertz and now because i am operating at a lower voltage i will also consume lesser power so these two techniques so this is where you are changing the body bias is what called adaptive body wires and the other one which where i said that you could lower the vdd or if you are on the slow lot you want to improve the performance you could increase the vdd a bit because you know that at higher vdd performances are higher so that is called adaptive voltage scaling ok so these again are areas of active research there is lots of work happening uh in their even production these these technologies are even production where uh dyes are trimmed to operate at lower voltage or higher voltage depending on where they were manufactured at so at the time of test you see what is the operational frequency and you trim them what is the leakage and you trim them appropriately okay so so the body bias was applied for the fast pass and the voltage for this torso so i could apply voltage for fast fast also i could lower the voltage and reduce the overall power consumption okay right both these techniques are available for the corners [Music] yes i'm trying to bring the device back into my specification for say let us say leakage or power consumption or timing or whatever okay i process compensation you will see is used in a large number of products today already it's not a new concept that we're talking about any longer okay something is also raghav yeah i mean so this body bias thing was considering this body bias can basically further create more complications like i mean like i'm not able to exactly pinpoint but i think that like something things like you can glitch like further like uh because early when we are considering like when we're doing the substrate taping and tapping and we're connecting the source with the body we are sort of uh those latch up effects and many other things can pop up yes so very very good raga i'm so happy that you're able to anticipate the problems that can come with body bias so uh in terms of forward body bias you have to realize that you cannot really power body bias your pn junctions beyond anything beyond 0.2 or 0.3 volts because otherwise the leakage currents would kind of run off similarly on the side of reverse body bias there would be constraints on how much reverse body bias you can put again because otherwise a band-to-man tunneling will kind of enough there will be lots of current that will flow from the source to the substrate or drain to the substrate so you cannot really do a lot of body bias so very good and very interesting observation however in advanced technologies like fds soi fully depleted soi so there is no junction in the source and drain region there is simply a buried oxide so since there is no junction so there is no concept of junction leakage per se or and junction leakage cannot increase so you can apply whatever amount of powered body buyers or reverse body buyers that you want to you are talking about here the soi technology yes okay the fully depleted soi not even partially if you were on partially depleted soi then again you will face trouble because junction would be there only in fully depleted soi you can actually go to very large range of uh body bias voltages okay yes okay"
b2wwYMU-emI,okay okay so now we come to the uh today's session so so to say which is power distribution so what do you understand by the term power dissipation cv square cv square that is all about power dissipation but the first thing that comes into mind is that the first thing that comes to your mind is cv square okay so you say that there is some power that is consumed uh when the operation is happening so that essentially is dynamic power where you say okay this is something linked to cv square let us say hello okay and then what about uh short circuit currents what the short circuit current so is that we observed like with that observed during the in the uh static analysis analysis that there is a point when both are on both are in the saturation and there is a direction so it is this when the short circuit path exists between vdd and ground between the supply rails during the switching operation that is what is called as short circuit current and the third component of power is leakage the one that we were just happening about so dynamic power consumption if i said it is cv square huh so actually it's proportional to cv square it's not cv square but it's proportional to cv square so the power so but before we go into what it is let us just also have a look at power as it is drawn from the voltage source so power when you talk of it in terms of instantaneous power would be characterized as i t into vt that is current at any given point of time into the voltage at that point of time energy is integration of that power over time over the entire cycle and average power is then normalized energy over time what are you interested in as a designer what do you think is quoted on the data sheet so there are two questions after considering the complete so we should be more concerned about the dynamic power so this is all about dynamic so dynamic power is one component of it from it ibm those components that we are not even at those components yet we are saying amongst these three things instantaneous power energy and average power what are you most interested in sir uh i think it should be instantaneous power sir uh because we we must be much precise about the current which we are flowing at a particular instant in our transfer or something why because uh however in the average power we somehow get to reduce the whole value to a particular point but in instantaneous power uh it might happen like sometimes the voltage is low and the current is high so that this high current might not i mean like they uh totally collapse our circuit okay so what vaishnav is saying is that i'm also interested in instantaneous power in fact he's saying i'm only interested in instantaneous power because that gives me an estimate of what kind of current is flowing and with that i can design my power grid the current should not be so high that my power grid collapses so somewhere i am interested in instantaneous power because it will give me an estimate of what kind of ir drop can happen so i am interested in instantaneous power but when i am making a product i am also interested in energy that is what is the total energy consumed for example in one calculation so that i can then prolong the life of a calculator to run you know one million calculations before the battery dies off because i have a very small battery pencil battery there and filling button battery there and average power why do you think average power is important why is it even there on this screen there sir to calculate our consumptions at last i'm like at the end of the day i'm like okay for a laptop or something the consumption might be low but for uh high appliances then we are much like looking into the power so that yeah we don't depend up uh we don't end up consuming high amount of power on a device so when you turn a system on a circuit on let us say you just even turn your tube light on or you you know a light bulb on do you think it consumes the same power throughout closer what happens at the time when you're just turning it on there could be extra sparks extra power consumed because if it's a tungsten bulb the initial heating needs to happen something needs to do to be done some extra power may go initially but then you still quote one number that okay it will consume one watt this is a one watt bulb or six watt bulb or something like that is it not yes so that is average power i think yes that is average power for a user to make a decision on which component to use that user needs a value of average power a typical user a typical consumer is not interested in instantaneous power now since the specification is given in terms of average power a designer should also be concerned about average power also but a designer also needs to look at instantaneous power so that there are no serious eye drop issues in any part of your design sir yes sir but i'm not able to get the instantaneous power because when you're designing the power range then we basically give the voltages across we fix the voltages vdd and ground and the i drop is whatever is happening it is happening because of the interconnects because of the wires and the interconnects through which we are basically transferring that but so ultimately what exactly the power would be instantaneous part would be at a particular time would be basically defined by this speed level now because ultimately because of the transfer what all things is i dependent on let us look at that okay what are things is i dependent on sir i think if there's a capacitor then uh there might be a spike of icer i'm like it's possible right here at any point of time we might have a capacitor in between and it might have a spike might have a capacitor do you think there might there is a possibility of a capacitor do you know there are capacitors yeah there are capacitors but there are some places that are i'm not even we find some places where there are no capacitors so uh i mean the the variation of it which we have isn't i'm like isn't that linear which we think of and like so you tell me you've done simulations already done yes sir yes sir that's that's the reason why i'm like for suppose that miller capacitance effect in which we uh see pick up your simulations and you will have answers to all these questions right now yes so i am asking you a different question what does i depend on the resistance of wire the the current depends on okay these resistances and supply supply level okay and we're talking about the inverter cmos circuit the resistance of the channel the resistance of the channel okay and so the region of operation so width and the length yeah that would define the resistance of the channel so the region of operation the region of operation would move from all saturation to linear to everything no yes okay one very important thing slew okay that will say for how long the short circuit current will flow yes okay good what else very important thing include is we have included in the channel resistance because we talked about current already now you're talking about current in the channel resistance we have included vt and mobility both you see very important thing load yes something equally important charge so current means charge so tell me there what does what do you mean by charge integration of current over time leads to charge so charge is dependent on the kind of current flowing or what what do you mean to say with charge there your operating voltage yeah we already talked about operating voltage the number of times this inverter will toggle is it not yeah because power will be what is the unit of power it is about the kind of charge consumed per second is it not it could be some measure of what is consumed per unit time yes so what are we talking about we're talking about number of times the toggling is happening so frequency has a very important role to play and associated with it is something called activity factor so we'll just come to those aspects but instantaneous power is also dependent then on frequency of operation if you want to limit the instantaneous power so that your eye drops reduce you have to reduce the frequency of operation for example okay so as a designer you are interested in all three of them okay and in terms of how to represent power the power dissipated in the resistance is i square r and we know that the you know charge stored on a capacitor energy stored on a capacitor is 1 by 2 cv square this is basic electronics that all of you know am i right yes sir okay so for us we said that there are two primary sources of power dissipation dynamic and static the dynamic we said there are two components which which involve load capacitances and the other component which is short circuit current static power we said there are again multiple components sub threshold decays the ids kind of current gate leakage and then also junction leakage okay and now we will look into all these different parts in a little detail through this we will you know for both for dynamic power and for static power we will assume that we are talking about a chip with one billion transistors okay of these one billion transistors so this is a typical chip a typical digital chip let us say and of these one billion transistors you will notice that 950 million transistors are related to memory cells and 50 million transistors are logic transistors so in this course we are primarily talking about this part for the memory part we have this other course memory design and test that we will have in the next semester so but we are saying that there are 50 million logic transistors with an average width of 12 lambda lambda let us say is the minimum width or minimum size that you can make in a particular technology and we are also saying activity factor of 0.1 okay and then for the memory we are saying that memory devices because they are so large in number we want to keep them to be small memory array has devices which are averagely at four lambda size and because memory is so huge the activity factor is also actually lesser the probability that a particular memory would be accessed is actually lower then we are talking about 1 volt 6 65 nanometer process and we say that the gate capacitance is something like one fento farad per micron and diffusion capacitance is something like point eight centifarad per micron these are assumptions okay so when we do some uh calculations going further in the next few slides we will be going with these assumptions is that okay so it's exactly what so you assume that there are one one billion transistors on a chip we have assumed that 50 million of those are logic transistors we have assumed that the average width of those transistors logic transistors is 12 lambda and so on so all these are assumptions answers to c is what is capacity involving does it represent 65 nanometer uh you can't say that you you want to consider it like that then 2 lambda is 65 nanometer but it's not exactly the case today there's nothing like so in advanced technologies lambda has lost its significance so long back long long back lambda used to mean half the half the pitch so yes uh something like 65 nanometer for such dynamic technology but that may not be the case so just assume there is some lambda some constant okay the key point is that the logic transistors are typically three times bigger than the memory transistors just just uh consider this as an assumption that we have made it's not a very far-fetched assumption though it's a very realistic assumption but an assumption nevertheless,https://www.youtube.com/watch?v=b2wwYMU-emI,"Link: https://www.youtube.com/watch?v=b2wwYMU-emI
Transcript: okay okay so now we come to the uh today's session so so to say which is power distribution so what do you understand by the term power dissipation cv square cv square that is all about power dissipation but the first thing that comes into mind is that the first thing that comes to your mind is cv square okay so you say that there is some power that is consumed uh when the operation is happening so that essentially is dynamic power where you say okay this is something linked to cv square let us say hello okay and then what about uh short circuit currents what the short circuit current so is that we observed like with that observed during the in the uh static analysis analysis that there is a point when both are on both are in the saturation and there is a direction so it is this when the short circuit path exists between vdd and ground between the supply rails during the switching operation that is what is called as short circuit current and the third component of power is leakage the one that we were just happening about so dynamic power consumption if i said it is cv square huh so actually it's proportional to cv square it's not cv square but it's proportional to cv square so the power so but before we go into what it is let us just also have a look at power as it is drawn from the voltage source so power when you talk of it in terms of instantaneous power would be characterized as i t into vt that is current at any given point of time into the voltage at that point of time energy is integration of that power over time over the entire cycle and average power is then normalized energy over time what are you interested in as a designer what do you think is quoted on the data sheet so there are two questions after considering the complete so we should be more concerned about the dynamic power so this is all about dynamic so dynamic power is one component of it from it ibm those components that we are not even at those components yet we are saying amongst these three things instantaneous power energy and average power what are you most interested in sir uh i think it should be instantaneous power sir uh because we we must be much precise about the current which we are flowing at a particular instant in our transfer or something why because uh however in the average power we somehow get to reduce the whole value to a particular point but in instantaneous power uh it might happen like sometimes the voltage is low and the current is high so that this high current might not i mean like they uh totally collapse our circuit okay so what vaishnav is saying is that i'm also interested in instantaneous power in fact he's saying i'm only interested in instantaneous power because that gives me an estimate of what kind of current is flowing and with that i can design my power grid the current should not be so high that my power grid collapses so somewhere i am interested in instantaneous power because it will give me an estimate of what kind of ir drop can happen so i am interested in instantaneous power but when i am making a product i am also interested in energy that is what is the total energy consumed for example in one calculation so that i can then prolong the life of a calculator to run you know one million calculations before the battery dies off because i have a very small battery pencil battery there and filling button battery there and average power why do you think average power is important why is it even there on this screen there sir to calculate our consumptions at last i'm like at the end of the day i'm like okay for a laptop or something the consumption might be low but for uh high appliances then we are much like looking into the power so that yeah we don't depend up uh we don't end up consuming high amount of power on a device so when you turn a system on a circuit on let us say you just even turn your tube light on or you you know a light bulb on do you think it consumes the same power throughout closer what happens at the time when you're just turning it on there could be extra sparks extra power consumed because if it's a tungsten bulb the initial heating needs to happen something needs to do to be done some extra power may go initially but then you still quote one number that okay it will consume one watt this is a one watt bulb or six watt bulb or something like that is it not yes so that is average power i think yes that is average power for a user to make a decision on which component to use that user needs a value of average power a typical user a typical consumer is not interested in instantaneous power now since the specification is given in terms of average power a designer should also be concerned about average power also but a designer also needs to look at instantaneous power so that there are no serious eye drop issues in any part of your design sir yes sir but i'm not able to get the instantaneous power because when you're designing the power range then we basically give the voltages across we fix the voltages vdd and ground and the i drop is whatever is happening it is happening because of the interconnects because of the wires and the interconnects through which we are basically transferring that but so ultimately what exactly the power would be instantaneous part would be at a particular time would be basically defined by this speed level now because ultimately because of the transfer what all things is i dependent on let us look at that okay what are things is i dependent on sir i think if there's a capacitor then uh there might be a spike of icer i'm like it's possible right here at any point of time we might have a capacitor in between and it might have a spike might have a capacitor do you think there might there is a possibility of a capacitor do you know there are capacitors yeah there are capacitors but there are some places that are i'm not even we find some places where there are no capacitors so uh i mean the the variation of it which we have isn't i'm like isn't that linear which we think of and like so you tell me you've done simulations already done yes sir yes sir that's that's the reason why i'm like for suppose that miller capacitance effect in which we uh see pick up your simulations and you will have answers to all these questions right now yes so i am asking you a different question what does i depend on the resistance of wire the the current depends on okay these resistances and supply supply level okay and we're talking about the inverter cmos circuit the resistance of the channel the resistance of the channel okay and so the region of operation so width and the length yeah that would define the resistance of the channel so the region of operation the region of operation would move from all saturation to linear to everything no yes okay one very important thing slew okay that will say for how long the short circuit current will flow yes okay good what else very important thing include is we have included in the channel resistance because we talked about current already now you're talking about current in the channel resistance we have included vt and mobility both you see very important thing load yes something equally important charge so current means charge so tell me there what does what do you mean by charge integration of current over time leads to charge so charge is dependent on the kind of current flowing or what what do you mean to say with charge there your operating voltage yeah we already talked about operating voltage the number of times this inverter will toggle is it not yeah because power will be what is the unit of power it is about the kind of charge consumed per second is it not it could be some measure of what is consumed per unit time yes so what are we talking about we're talking about number of times the toggling is happening so frequency has a very important role to play and associated with it is something called activity factor so we'll just come to those aspects but instantaneous power is also dependent then on frequency of operation if you want to limit the instantaneous power so that your eye drops reduce you have to reduce the frequency of operation for example okay so as a designer you are interested in all three of them okay and in terms of how to represent power the power dissipated in the resistance is i square r and we know that the you know charge stored on a capacitor energy stored on a capacitor is 1 by 2 cv square this is basic electronics that all of you know am i right yes sir okay so for us we said that there are two primary sources of power dissipation dynamic and static the dynamic we said there are two components which which involve load capacitances and the other component which is short circuit current static power we said there are again multiple components sub threshold decays the ids kind of current gate leakage and then also junction leakage okay and now we will look into all these different parts in a little detail through this we will you know for both for dynamic power and for static power we will assume that we are talking about a chip with one billion transistors okay of these one billion transistors so this is a typical chip a typical digital chip let us say and of these one billion transistors you will notice that 950 million transistors are related to memory cells and 50 million transistors are logic transistors so in this course we are primarily talking about this part for the memory part we have this other course memory design and test that we will have in the next semester so but we are saying that there are 50 million logic transistors with an average width of 12 lambda lambda let us say is the minimum width or minimum size that you can make in a particular technology and we are also saying activity factor of 0.1 okay and then for the memory we are saying that memory devices because they are so large in number we want to keep them to be small memory array has devices which are averagely at four lambda size and because memory is so huge the activity factor is also actually lesser the probability that a particular memory would be accessed is actually lower then we are talking about 1 volt 6 65 nanometer process and we say that the gate capacitance is something like one fento farad per micron and diffusion capacitance is something like point eight centifarad per micron these are assumptions okay so when we do some uh calculations going further in the next few slides we will be going with these assumptions is that okay so it's exactly what so you assume that there are one one billion transistors on a chip we have assumed that 50 million of those are logic transistors we have assumed that the average width of those transistors logic transistors is 12 lambda and so on so all these are assumptions answers to c is what is capacity involving does it represent 65 nanometer uh you can't say that you you want to consider it like that then 2 lambda is 65 nanometer but it's not exactly the case today there's nothing like so in advanced technologies lambda has lost its significance so long back long long back lambda used to mean half the half the pitch so yes uh something like 65 nanometer for such dynamic technology but that may not be the case so just assume there is some lambda some constant okay the key point is that the logic transistors are typically three times bigger than the memory transistors just just uh consider this as an assumption that we have made it's not a very far-fetched assumption though it's a very realistic assumption but an assumption nevertheless"
aiJuk-YjTmY,uh we have such assumptions in place okay finally so we will simulate and we will characterize okay so let's come to Dynamic power so one thing that we need to understand is or what you already agreed on is that the energy stored in a capacitor is one by two cvd square am I right hello we've already agreed on this yes sir so however the energy drawn from the supply is if you want to charge this capacitor from 0 to vdd the energy that is drawn from the supply is something like this so what has happened only half the energy that was expended has been saved has been put on the capacitor has been conserved in the capacitor the remaining half has been dissipated in the resistance the tunnel resistance of the mosfet are you able to see this yes so now when this capacitor CS which is from 1 to 0 now that remaining 1 by 2 c v d d square will also get dissipated where will it get dissipated in the channel of the nbos are you able to see this hello foreign yes sir I into vdd into DT I should be input currents sorry I I of T should be input current right sir and like if you are if you are talking about the energy drawn from the supply yeah so we are we are modeling that input current as the the rate of charging of the capacitor it is rate of change of uh charge on the capacitor but the capacitor is our output capacitor itself yeah yeah but that is what you are charging now so here uh input input vdd is that vdd or our input V in because I can't see any connection between input and output directly so that my current can flow so does the current flow between input and output in a mosfet no sir why should there be a direct connection sir yes sir my doubt is that here the uh drawn from the supply Supply means VD directly yes okay okay okay sir thank you yeah that was my love yes yeah so if you look at the waveforms you know suppose you gave this kind of an input um so you've all done these inverter simulations all of you have done just now look at go back and look at your waveforms there if this is the kind of input you will see that the output is you know something not exactly that sharp you seen that yes and now if you plot the current through the pmos and the current through the nmos you will see that uh pmos and nmos have currents at the peaks of currents at different times over here there is a small short circuit current topic but largely then the current is Flowing from the nmos when the output is falling and from the pmos and the output is rising so most of the power dissipation is happening in the pmos on the rising side and nmos on the falling side huh and in terms of Uh current consumption you will see that uh the current consumption is following this kind of a purse where it is IP minus i n is being plotted over here okay and you will see that our from vdd will happen only during the price cycle but energy from vdd like because power power is consumed only during the rice cycle from vdd the vdd energy also gets consumed during the rice cycle and the energy stored in the capacitor first comes to half we did half CV Square then Falls to zero the yeah I am already there please tell me so this is below one uh the second row second column third row okay so what what is what we're plotting here is the current of the capacitor the current other capacitor is saying so this equation is not visible actually it's okay if IC is equal to IP minus i n current from the pmas minus current from the nmos nmos will take away the charge pmas will deposit the charge therefore current charging the capacitor just just the picture flow over here in this particular system we're just applying the job's law okay so so why the current is it should be maximum then should fall and then it should again fall price again why should we try if the direction has changed is it not the capacitor is discharging the direction of flow of current has changed so it will appear as negative current okay okay so it's like okay that plus M minus is charging it should be following the current should fall right because current will initially if it falling right yeah so current initially would rise and then fall okay it is once the capacitor starts to get charged the current would fall that is why current cell [Music] s so when it is dropping when it is what what that point is when the current curve is crossing the uh cutting the x axis for the first time what the point is basically when the current is in the third graph this is a second column third uh third row yeah so when it first cuts the x-axis the current curve only and then there's a time lapse and then it rises so I'm just wondering what this point is also the time lapse is the time gap between the fall and Rise of the input because at that time there is no current flowing anywhere the CMOS it's a static CMOS circuit um it's a static SEMA circuit you see that yes so in a static SEMA circuit when there is no transition happening we don't expect any current to flow yeah so that is what we are looking at there but there's no current flowing in that duration hmm is that okay let's light gone yeah it's coming give me a moment but are you able to see that in the static CMOS there is no current in the intermediate part when there is no struggling happening thank you hello so this is region I'm not able to get exciting I mean so you tell me what is happening here is there any any change in the output voltage Happening Here some voltage of capacitor voltage yeah this is the out now is there any change in output voltage happening here no sir so if there's no change in output voltage why should there be current flowing from either the pmos or the nmos yes that is what it is reflecting okay okay right okay that is zero okay okay yes okay so what essentially we are saying is that the total switching power is CVV square into frequency y frequency the number of times that the circuit switches that many toggles will happen one by two CV Square when the output Rises when the output Falls one by two will be CV square and the output Rises so per cycle CV Square and multiply it by number of times it would toggle in a in a second so frequency are you able to see this so this becomes the average Dynamic participated average switching power not Dynamic power Dynamic power will also have short circuits for internet okay so so this is what we have to do in our assignment right yes for dissipation you have to do this you have to also include the short circuit power in it but yeah okay so in a single uh clock means where we are going from 0 0 to 1 1 we have to take in account the whole current waveform and integrate with it by multiplying the voltage yes okay so what does this ssw represent so ssw represents the frequency multiplied by Alpha where Alpha is activity Factor okay for a signal that is a clock Alpha is equal to one because clock toggles 0 to 1 and 1 to 0 in every cycle but if there is a signal that switches only once per cycle Alpha would be one if there is a signal which has a glitch what would Alpha be so in one clock cycle yeah so there's a glitch in every clock cycle so what is Alpha for that particular circuit one by two as it's raising and falling uh for every rice so if any single switch any single any signal switching once meant Alpha is equal to one by two over here the signal is switching twice isn't it it is rising and then it's falling then it's one two one one let us say this glitch was spurious or not spurious and finally the output had to rise so what is Alpha 3x2 so do you realize the challenge that glitches cause so how come the 392 sir identity one transition second transition third transition yes sir all in one clock cycle so clock is here let us say this is your ideal circuit some node in your Adder circuit it had a glitch carry out let us say it had a glitch and then it Rose to one foreign what is the glitch leading to so basic Y2 Factor coming 3 is because three transition y two y will bring Y2 because every transition is one by two a clock we say Activity factor is one a clock has two transitions so every transition is one by two so see when we written if the clock signals the clock Alpha is the alpha is activity Factor but Alpha is one when we have two transitions that is yes and a clock has two transitions now in that clock period it has two transitions yes sir yeah so if I say that is Alpha that is one if I say Alpha for a clock is one then Alpha for a signal which is transitioning only once would be half yes sir and if it is a there's a signal which is transitioning thigh is because of a glitch Alpha would be if there are two Glitters then [Music] five by two okay every glitch is a is a drain on a lot of dynamic power so we do not want Glitters in our system okay glitches are a signal Integrity issue but they are also a much bigger power issue okay so looking at Short Circuit and what happens to the short circuit current when the input is toggling there is a time when both pmos and nmos are simultaneously on which is when some current would flow from vdd to ground directly that is short circuit current this current is no longer talk about we're not talking about CL over here we're talking about directly vdd to ground we are talking it calling out as ivd now if the rise and fall times are good then we can limit this short circuit power to less than 10 percent of total Dynamic power and therefore for back of the envelope calculations we can ignore this component but when you simulate you have to integrate you you will anyway integrate it it will get added there but for backup another calculations you can ignore this component is that okay rajneesh so sir when this V out is charging uh from vdd via the pmos this short circuit glitch will occur and similarly when V out is the CL is discharging via the below nmos then another this short circuit glitch will occur super transistor this um so what we learned in the previous slide in the activity Factor this that glist thing that this is the same thing now with activity Factor one so for every transition there will be the short circuit current also that will flow there is a charging current for load that we talked about in the previous section that will definitely be there but this short circuit current will also flow for every transition so uh so this short circuit glitch that Alpha c will delete that square that here for this glitch Alpha will be one so that this will be added in the total Direction this is this is independent of C uh on the capacitance yes yes sir the earlier formula will not be applied here that that is what I want to predict in your understanding that was a different topic we were talking about switching power there we are now talking about short circuit current bones together make Dynamic power okay a super transistor we have to add bison rate yes yes okay this is not dependent on capacitance it is dependent on Rise and Fall times yes okay okay yes uh Pfizer we need a rise time and fall time to be as low as possible to reduce the dissipation right yes to reduce this duration yes okay okay that is why you are given very tight specification when you were designing the first inverter in your assignment yeah yes okay so now let's look at that example we say that we look at that one billion times the chip we know that to calculate power we need to estimate some capacitance so we go ahead and do something like this for logic 50 million transistors into 12 Lambda and we said that there is this uh per Lambda the width that we're talking about is point zero to five microns that is a technology Factor and we said okay per Micron the gate capacitance was one pentofarad and dream capacitance was 0.8 so 1.8 went to farad per microns and I see that the logic capacitance is 27 nanometer nanofarad okay for the memory the devices do much more in number the size is smaller therefore the ratio is not as bad it is coming as 171 nanofarads and then we apply the dynamic power formula we are ignoring the short circuit currents as we just said we expect it to be within uh 10 percent of this Dynamic power and we say that okay overall power consumption will be around 6.1 Watts are you able to see this any questions so what is this factor of uh 25 nanometer uh per Lambda that is uh how much width do I associate with a Lambda one Lambda this is 25 nanometers so there was this question now what is this Lambda yes this is they are saying 25 nanometers is the Lambda okay okay just given the formula for that so what is this 0.1 and 0.02 in this calculation these are like equation kind of thing you tell me what were they what were we talking about when we introduced the subject uh some active factor of activity Factor the number of togglings to expect Hannah so so this 0.1 and 0.02 are the toggling factors for logic and memory separately right yes yes 0.1 is the activity factor for the logic and 0.02 is the activity factor for the sir yes sir uh as you said that if there was a glitch our activity Factor when two I'm like I'm like it increased sir but uh if we are eventually multiplying this activity factor with the frequency so sir uh if an activity if a glitch occurs then uh according according to what I can see on a graph my my time period should increase in that case sir because uh time period at a distinguished between a distinguished interval of time the waveform is repeating that you will talk about in terms of clock so how does a presence of a glitch depend on clock period like how does a glitch constrain a clock period sir frequency means I'm like a frequency I'm upgrading my my entire device at only one gigahertz now yes sir yes yes I'm operating my device at one gigahertz how much time do you think a glitch would take oh it would take okay it would take less time but okay I got confused okay sir I'll look into it sir,https://www.youtube.com/watch?v=aiJuk-YjTmY,"Link: https://www.youtube.com/watch?v=aiJuk-YjTmY
Transcript: uh we have such assumptions in place okay finally so we will simulate and we will characterize okay so let's come to Dynamic power so one thing that we need to understand is or what you already agreed on is that the energy stored in a capacitor is one by two cvd square am I right hello we've already agreed on this yes sir so however the energy drawn from the supply is if you want to charge this capacitor from 0 to vdd the energy that is drawn from the supply is something like this so what has happened only half the energy that was expended has been saved has been put on the capacitor has been conserved in the capacitor the remaining half has been dissipated in the resistance the tunnel resistance of the mosfet are you able to see this yes so now when this capacitor CS which is from 1 to 0 now that remaining 1 by 2 c v d d square will also get dissipated where will it get dissipated in the channel of the nbos are you able to see this hello foreign yes sir I into vdd into DT I should be input currents sorry I I of T should be input current right sir and like if you are if you are talking about the energy drawn from the supply yeah so we are we are modeling that input current as the the rate of charging of the capacitor it is rate of change of uh charge on the capacitor but the capacitor is our output capacitor itself yeah yeah but that is what you are charging now so here uh input input vdd is that vdd or our input V in because I can't see any connection between input and output directly so that my current can flow so does the current flow between input and output in a mosfet no sir why should there be a direct connection sir yes sir my doubt is that here the uh drawn from the supply Supply means VD directly yes okay okay okay sir thank you yeah that was my love yes yeah so if you look at the waveforms you know suppose you gave this kind of an input um so you've all done these inverter simulations all of you have done just now look at go back and look at your waveforms there if this is the kind of input you will see that the output is you know something not exactly that sharp you seen that yes and now if you plot the current through the pmos and the current through the nmos you will see that uh pmos and nmos have currents at the peaks of currents at different times over here there is a small short circuit current topic but largely then the current is Flowing from the nmos when the output is falling and from the pmos and the output is rising so most of the power dissipation is happening in the pmos on the rising side and nmos on the falling side huh and in terms of Uh current consumption you will see that uh the current consumption is following this kind of a purse where it is IP minus i n is being plotted over here okay and you will see that our from vdd will happen only during the price cycle but energy from vdd like because power power is consumed only during the rice cycle from vdd the vdd energy also gets consumed during the rice cycle and the energy stored in the capacitor first comes to half we did half CV Square then Falls to zero the yeah I am already there please tell me so this is below one uh the second row second column third row okay so what what is what we're plotting here is the current of the capacitor the current other capacitor is saying so this equation is not visible actually it's okay if IC is equal to IP minus i n current from the pmas minus current from the nmos nmos will take away the charge pmas will deposit the charge therefore current charging the capacitor just just the picture flow over here in this particular system we're just applying the job's law okay so so why the current is it should be maximum then should fall and then it should again fall price again why should we try if the direction has changed is it not the capacitor is discharging the direction of flow of current has changed so it will appear as negative current okay okay so it's like okay that plus M minus is charging it should be following the current should fall right because current will initially if it falling right yeah so current initially would rise and then fall okay it is once the capacitor starts to get charged the current would fall that is why current cell [Music] s so when it is dropping when it is what what that point is when the current curve is crossing the uh cutting the x axis for the first time what the point is basically when the current is in the third graph this is a second column third uh third row yeah so when it first cuts the x-axis the current curve only and then there's a time lapse and then it rises so I'm just wondering what this point is also the time lapse is the time gap between the fall and Rise of the input because at that time there is no current flowing anywhere the CMOS it's a static CMOS circuit um it's a static SEMA circuit you see that yes so in a static SEMA circuit when there is no transition happening we don't expect any current to flow yeah so that is what we are looking at there but there's no current flowing in that duration hmm is that okay let's light gone yeah it's coming give me a moment but are you able to see that in the static CMOS there is no current in the intermediate part when there is no struggling happening thank you hello so this is region I'm not able to get exciting I mean so you tell me what is happening here is there any any change in the output voltage Happening Here some voltage of capacitor voltage yeah this is the out now is there any change in output voltage happening here no sir so if there's no change in output voltage why should there be current flowing from either the pmos or the nmos yes that is what it is reflecting okay okay right okay that is zero okay okay yes okay so what essentially we are saying is that the total switching power is CVV square into frequency y frequency the number of times that the circuit switches that many toggles will happen one by two CV Square when the output Rises when the output Falls one by two will be CV square and the output Rises so per cycle CV Square and multiply it by number of times it would toggle in a in a second so frequency are you able to see this so this becomes the average Dynamic participated average switching power not Dynamic power Dynamic power will also have short circuits for internet okay so so this is what we have to do in our assignment right yes for dissipation you have to do this you have to also include the short circuit power in it but yeah okay so in a single uh clock means where we are going from 0 0 to 1 1 we have to take in account the whole current waveform and integrate with it by multiplying the voltage yes okay so what does this ssw represent so ssw represents the frequency multiplied by Alpha where Alpha is activity Factor okay for a signal that is a clock Alpha is equal to one because clock toggles 0 to 1 and 1 to 0 in every cycle but if there is a signal that switches only once per cycle Alpha would be one if there is a signal which has a glitch what would Alpha be so in one clock cycle yeah so there's a glitch in every clock cycle so what is Alpha for that particular circuit one by two as it's raising and falling uh for every rice so if any single switch any single any signal switching once meant Alpha is equal to one by two over here the signal is switching twice isn't it it is rising and then it's falling then it's one two one one let us say this glitch was spurious or not spurious and finally the output had to rise so what is Alpha 3x2 so do you realize the challenge that glitches cause so how come the 392 sir identity one transition second transition third transition yes sir all in one clock cycle so clock is here let us say this is your ideal circuit some node in your Adder circuit it had a glitch carry out let us say it had a glitch and then it Rose to one foreign what is the glitch leading to so basic Y2 Factor coming 3 is because three transition y two y will bring Y2 because every transition is one by two a clock we say Activity factor is one a clock has two transitions so every transition is one by two so see when we written if the clock signals the clock Alpha is the alpha is activity Factor but Alpha is one when we have two transitions that is yes and a clock has two transitions now in that clock period it has two transitions yes sir yeah so if I say that is Alpha that is one if I say Alpha for a clock is one then Alpha for a signal which is transitioning only once would be half yes sir and if it is a there's a signal which is transitioning thigh is because of a glitch Alpha would be if there are two Glitters then [Music] five by two okay every glitch is a is a drain on a lot of dynamic power so we do not want Glitters in our system okay glitches are a signal Integrity issue but they are also a much bigger power issue okay so looking at Short Circuit and what happens to the short circuit current when the input is toggling there is a time when both pmos and nmos are simultaneously on which is when some current would flow from vdd to ground directly that is short circuit current this current is no longer talk about we're not talking about CL over here we're talking about directly vdd to ground we are talking it calling out as ivd now if the rise and fall times are good then we can limit this short circuit power to less than 10 percent of total Dynamic power and therefore for back of the envelope calculations we can ignore this component but when you simulate you have to integrate you you will anyway integrate it it will get added there but for backup another calculations you can ignore this component is that okay rajneesh so sir when this V out is charging uh from vdd via the pmos this short circuit glitch will occur and similarly when V out is the CL is discharging via the below nmos then another this short circuit glitch will occur super transistor this um so what we learned in the previous slide in the activity Factor this that glist thing that this is the same thing now with activity Factor one so for every transition there will be the short circuit current also that will flow there is a charging current for load that we talked about in the previous section that will definitely be there but this short circuit current will also flow for every transition so uh so this short circuit glitch that Alpha c will delete that square that here for this glitch Alpha will be one so that this will be added in the total Direction this is this is independent of C uh on the capacitance yes yes sir the earlier formula will not be applied here that that is what I want to predict in your understanding that was a different topic we were talking about switching power there we are now talking about short circuit current bones together make Dynamic power okay a super transistor we have to add bison rate yes yes okay this is not dependent on capacitance it is dependent on Rise and Fall times yes okay okay yes uh Pfizer we need a rise time and fall time to be as low as possible to reduce the dissipation right yes to reduce this duration yes okay okay that is why you are given very tight specification when you were designing the first inverter in your assignment yeah yes okay so now let's look at that example we say that we look at that one billion times the chip we know that to calculate power we need to estimate some capacitance so we go ahead and do something like this for logic 50 million transistors into 12 Lambda and we said that there is this uh per Lambda the width that we're talking about is point zero to five microns that is a technology Factor and we said okay per Micron the gate capacitance was one pentofarad and dream capacitance was 0.8 so 1.8 went to farad per microns and I see that the logic capacitance is 27 nanometer nanofarad okay for the memory the devices do much more in number the size is smaller therefore the ratio is not as bad it is coming as 171 nanofarads and then we apply the dynamic power formula we are ignoring the short circuit currents as we just said we expect it to be within uh 10 percent of this Dynamic power and we say that okay overall power consumption will be around 6.1 Watts are you able to see this any questions so what is this factor of uh 25 nanometer uh per Lambda that is uh how much width do I associate with a Lambda one Lambda this is 25 nanometers so there was this question now what is this Lambda yes this is they are saying 25 nanometers is the Lambda okay okay just given the formula for that so what is this 0.1 and 0.02 in this calculation these are like equation kind of thing you tell me what were they what were we talking about when we introduced the subject uh some active factor of activity Factor the number of togglings to expect Hannah so so this 0.1 and 0.02 are the toggling factors for logic and memory separately right yes yes 0.1 is the activity factor for the logic and 0.02 is the activity factor for the sir yes sir uh as you said that if there was a glitch our activity Factor when two I'm like I'm like it increased sir but uh if we are eventually multiplying this activity factor with the frequency so sir uh if an activity if a glitch occurs then uh according according to what I can see on a graph my my time period should increase in that case sir because uh time period at a distinguished between a distinguished interval of time the waveform is repeating that you will talk about in terms of clock so how does a presence of a glitch depend on clock period like how does a glitch constrain a clock period sir frequency means I'm like a frequency I'm upgrading my my entire device at only one gigahertz now yes sir yes yes I'm operating my device at one gigahertz how much time do you think a glitch would take oh it would take okay it would take less time but okay I got confused okay sir I'll look into it sir"
2FF0fRRpP38,yes okay so we can estimate from back of the null calculations what kind of power we have if we have you know estimate of activity factor and something like that are you able to see this so here in this thing we are considering activity Factor 0.1 and 0.02 we had considered some kind of If this means glitches will only be there right and after that we have calculated the activity Factor right yeah and now suppose the 6.1 is beyond our power budget our power specification said 4 Watts what do you do of these all these things what can you reduce frequency can reduce actually all the three things you can reduce activity Factor how would you reduce activity Factor you will say I will get the devices I will put nand gates in some places and enable only parts of the circuit and not other parts of the circuit so if I reduce the activity Factor per circuit I will be able to reduce power I can reduce capacitances at least the capacitance is that toggle I can use smaller devices I can operate at a lower voltage I can operate at a lower frequency all these things I can reduce to be able to reduce Dynamic power and yeah please so how we are reducing the activity Factor can you please tell me okay uh let us look at activity factor in little more detail it will become abundantly evident to you how to reduce activity Factor yes so let us look at how activity factor is estimated so let us say that there is a probability p i of a node I being equal to 1. huh so the probability of a Pi Bar then is the that is the probability of node I being equal to 0 is 1 minus pi um and activity factor is p i into Pi Bar if there is a completely random data then what happens to p any node can be 0 or it can be 1. huh for a completely random data the probability of a node being at 1 is 0.5 are you with me yes it can be it can either be zero or one so the probability of a node being 1 is 0.5 so the alpha in a completely random data is 0.25 hmm however uh data is not completely random at all times huh so what we what do we say we say that many times a data will have for example if you're talking about bank accounts uh the msvs will largely be zeros if you're talking about something else again you know mostly msvs are something that you can fairly call as zeros and also because data will propagate through and Gates and or Gates they have which have lower activity Factor we'll just see why a typical design would have an activity factor of 0.1 so why do and and or Gates have lower activity Factor just look at this let us say it's and eight and two what is the probability of an output of and two being one it is a multiplication of probability of a being 1 and the probability of B being one am I right yes so the probability of and 2 being 1 is 1 by 4. and trees output being one as one by eight and you can calculate for all the gates hmm so now if I have a chain of gates let us say huh if I have a chain of gates and I say the inputs have an activity factor of 0.5 what will be the activity Factor at uh say N1 N2 and Y can you quickly calculate and tell me what is the activity Factor at N1 what is p at N1 so one by four three by four by one by four the probability of node N1 being one is actually three by four it's not an and gate it's a nand gate yeah yes so Alpha is 3 by 16. now given that what is the probability of this output the p over here y being 1. 1 by 16 . because both the inputs have to be zero see there is a bubble over here so the activity Factor at Y is 15 by 256. much less than 0.1 actually is it not so for an and four the activity factors less than point one clearly less than 0.1 and 3 is 1 by 8.125 and so on so yes say calculations so can you just go through this calculations once so it's not duplicated tell me what is the probability of uh so N1 will be 1 when a is 0 or B is 0. am I right yes yes sir so in how many cases is a or one of them zero there are four combinations of a possible A and B possible yes sir how many cases are there where one of them will be zero three so the probability is three by four yes if p is three by four then P bar is one by four yes then Alpha is 1 by 4 into 3 by 4 3 by 16 so Alpha was a p into P bar P bar okay right yes similarly what happens over here at the inputs whatever I had p over here is converted because there is a bubble so the inputs have a probability of one by four and one by four for this and gate for the and gate the output is one when both the inputs are 1. so 1 by 4 into 1 by 4 so the probability of the output over here being 1 is 1 by 16. and then okay hmm so P into P bar becomes 15 by 256. so yes so actually we have two bubbles like after that so we can just cancel them out right like for finding one directly we can just say like uh we are going directly and just it will be right so see we've gone through this because I can give you any circuit and you have to find the activity Factor there can I not yeah so I want you to get some practice on that that's why we did this okay sir okay yes sir what is the two input gates are different sir unless here we have an a nand gate so what if we have a nor gate or something yeah do it you will find out but it's not a hypothetical question just do it solve it in the second stacer when we get uh the probability over here would be different I'm like yeah the number would be 3 by 24 something would come let it come just do it no just solve it why are you worried is the method clear yes yes you apply the method so this will last me 15 minutes what is the probability of Y being zero 15 16 15. so P into P virus okay right okay there's niche sir uh sir suppose if in the top land after the top land we add a same two input nine after that means just the inverter after that so sir this three by four will become one by four just simple yeah yes that's what the bubble means no that's what the bubble represents okay okay yes yes but the activity Factor will still continue to be yes oh no yes sorry any node yes Alpha for any node is p into P bar always yes that is the formula probability of a node being equal to one has been called as p ragoff okay it would depend on its inputs yes Pfizer if it's an oriented in place of this you tell me yeah so for an or gate in how many cases will the output be one if a and b were three by four so yes that is what it is then I know you have the answer is yes okay okay Vishal so sir if we change like uh these and and nand gates to and Gates uh will the alpha change or I think it will be same right if I would remain actually same yeah there is just one inverter missing now yeah so sir it will verify is basically depending on the probability of it being and it not being associated as simple as it is as simple as the G concept The Logical effort Concepts that we looked at what is The Logical effort of a gate g is independent of the size of the gate yeah so if the topology if the functionality is of ending now whether you put an ad or not put an inverter there or not because the functionality is landing the kind of alpha Factor would be like this only okay okay so what do you do you say that to reduce the activity factor I will put an enable logic such that uh when the enable logic is let us say zero the output there will not double so if the output doesn't toggle I say power okay so Club gating is done to reduce so reduce activity Factor so that you save power then how do you reduce capacitance by you know the logical effort method we reduce uh the number of stages we use smaller Gates uh we do good floor planning so that wire capacitance reduces uh we also discussed that for long for large capacitances have the complex gates in the beginning and buffers or inverters in the end so that you do not toggle complex Gates too much or the complex gates are not very large in size hmm so all these things that we did for the logical effort method can be applied here again to reduce overall capacitances in your circuit,https://www.youtube.com/watch?v=2FF0fRRpP38,"Link: https://www.youtube.com/watch?v=2FF0fRRpP38
Transcript: yes okay so we can estimate from back of the null calculations what kind of power we have if we have you know estimate of activity factor and something like that are you able to see this so here in this thing we are considering activity Factor 0.1 and 0.02 we had considered some kind of If this means glitches will only be there right and after that we have calculated the activity Factor right yeah and now suppose the 6.1 is beyond our power budget our power specification said 4 Watts what do you do of these all these things what can you reduce frequency can reduce actually all the three things you can reduce activity Factor how would you reduce activity Factor you will say I will get the devices I will put nand gates in some places and enable only parts of the circuit and not other parts of the circuit so if I reduce the activity Factor per circuit I will be able to reduce power I can reduce capacitances at least the capacitance is that toggle I can use smaller devices I can operate at a lower voltage I can operate at a lower frequency all these things I can reduce to be able to reduce Dynamic power and yeah please so how we are reducing the activity Factor can you please tell me okay uh let us look at activity factor in little more detail it will become abundantly evident to you how to reduce activity Factor yes so let us look at how activity factor is estimated so let us say that there is a probability p i of a node I being equal to 1. huh so the probability of a Pi Bar then is the that is the probability of node I being equal to 0 is 1 minus pi um and activity factor is p i into Pi Bar if there is a completely random data then what happens to p any node can be 0 or it can be 1. huh for a completely random data the probability of a node being at 1 is 0.5 are you with me yes it can be it can either be zero or one so the probability of a node being 1 is 0.5 so the alpha in a completely random data is 0.25 hmm however uh data is not completely random at all times huh so what we what do we say we say that many times a data will have for example if you're talking about bank accounts uh the msvs will largely be zeros if you're talking about something else again you know mostly msvs are something that you can fairly call as zeros and also because data will propagate through and Gates and or Gates they have which have lower activity Factor we'll just see why a typical design would have an activity factor of 0.1 so why do and and or Gates have lower activity Factor just look at this let us say it's and eight and two what is the probability of an output of and two being one it is a multiplication of probability of a being 1 and the probability of B being one am I right yes so the probability of and 2 being 1 is 1 by 4. and trees output being one as one by eight and you can calculate for all the gates hmm so now if I have a chain of gates let us say huh if I have a chain of gates and I say the inputs have an activity factor of 0.5 what will be the activity Factor at uh say N1 N2 and Y can you quickly calculate and tell me what is the activity Factor at N1 what is p at N1 so one by four three by four by one by four the probability of node N1 being one is actually three by four it's not an and gate it's a nand gate yeah yes so Alpha is 3 by 16. now given that what is the probability of this output the p over here y being 1. 1 by 16 . because both the inputs have to be zero see there is a bubble over here so the activity Factor at Y is 15 by 256. much less than 0.1 actually is it not so for an and four the activity factors less than point one clearly less than 0.1 and 3 is 1 by 8.125 and so on so yes say calculations so can you just go through this calculations once so it's not duplicated tell me what is the probability of uh so N1 will be 1 when a is 0 or B is 0. am I right yes yes sir so in how many cases is a or one of them zero there are four combinations of a possible A and B possible yes sir how many cases are there where one of them will be zero three so the probability is three by four yes if p is three by four then P bar is one by four yes then Alpha is 1 by 4 into 3 by 4 3 by 16 so Alpha was a p into P bar P bar okay right yes similarly what happens over here at the inputs whatever I had p over here is converted because there is a bubble so the inputs have a probability of one by four and one by four for this and gate for the and gate the output is one when both the inputs are 1. so 1 by 4 into 1 by 4 so the probability of the output over here being 1 is 1 by 16. and then okay hmm so P into P bar becomes 15 by 256. so yes so actually we have two bubbles like after that so we can just cancel them out right like for finding one directly we can just say like uh we are going directly and just it will be right so see we've gone through this because I can give you any circuit and you have to find the activity Factor there can I not yeah so I want you to get some practice on that that's why we did this okay sir okay yes sir what is the two input gates are different sir unless here we have an a nand gate so what if we have a nor gate or something yeah do it you will find out but it's not a hypothetical question just do it solve it in the second stacer when we get uh the probability over here would be different I'm like yeah the number would be 3 by 24 something would come let it come just do it no just solve it why are you worried is the method clear yes yes you apply the method so this will last me 15 minutes what is the probability of Y being zero 15 16 15. so P into P virus okay right okay there's niche sir uh sir suppose if in the top land after the top land we add a same two input nine after that means just the inverter after that so sir this three by four will become one by four just simple yeah yes that's what the bubble means no that's what the bubble represents okay okay yes yes but the activity Factor will still continue to be yes oh no yes sorry any node yes Alpha for any node is p into P bar always yes that is the formula probability of a node being equal to one has been called as p ragoff okay it would depend on its inputs yes Pfizer if it's an oriented in place of this you tell me yeah so for an or gate in how many cases will the output be one if a and b were three by four so yes that is what it is then I know you have the answer is yes okay okay Vishal so sir if we change like uh these and and nand gates to and Gates uh will the alpha change or I think it will be same right if I would remain actually same yeah there is just one inverter missing now yeah so sir it will verify is basically depending on the probability of it being and it not being associated as simple as it is as simple as the G concept The Logical effort Concepts that we looked at what is The Logical effort of a gate g is independent of the size of the gate yeah so if the topology if the functionality is of ending now whether you put an ad or not put an inverter there or not because the functionality is landing the kind of alpha Factor would be like this only okay okay so what do you do you say that to reduce the activity factor I will put an enable logic such that uh when the enable logic is let us say zero the output there will not double so if the output doesn't toggle I say power okay so Club gating is done to reduce so reduce activity Factor so that you save power then how do you reduce capacitance by you know the logical effort method we reduce uh the number of stages we use smaller Gates uh we do good floor planning so that wire capacitance reduces uh we also discussed that for long for large capacitances have the complex gates in the beginning and buffers or inverters in the end so that you do not toggle complex Gates too much or the complex gates are not very large in size hmm so all these things that we did for the logical effort method can be applied here again to reduce overall capacitances in your circuit"
Nve0FZCx7gk,now this is the concept of dynamic voltage and frequency scaling so all of you have your cell phone with you am I right some of you might actually be attending this class on a cell phone any one of you attending the class on a cell phone as of now okay not here yet but someone would be at times so do you think the cell phone application processor here it has a rated frequency of 2.5 gigahertz do you think it always operates at 2.5 gigahertz huh so when you are playing a game on a cell phone when you are doing some really CPU intensive stuff at that point of time you need 2.5 gigahertz but if you're just reading some text message browsing the internet regular text pages you don't need that high performance the system does not need that so what does the system do system says that oh let us reduce the frequency of operation the load on my CPU is not as much instead of 2 gigahertz let me operate at only 200 megahertz I have reduced Dynamic power consumption by 10 times that is dynamic frequency scaling hmm now if I'm operating at 200 megahertz for let us say past one minute the system says that probably I don't really need to go into very high frequency for us for some more time now so let me also lower the voltage of operation because for 200 megahertz as you know at low voltages I can have larger delays but I at 200 megahertz I will still be able to meet my performance of 200 megahertz at let us say 0.7 volts I don't need 1.2 volts so I reduce vdd from 1.2 to something like 0.7 what happens so I first reduce frequency and then I reduce voltage also and I saved much more power because it was one by two CV Square f reduction in F led to linear reduction in power reduction in V additionally led to quadratic reduction in power and by managing both V and F I reduced power cubically so yes so this voltage killing I mean I get that if we reduce that we we save on power so but like how can I reduce that b in this figure what we are showing is that there is a voltage regulator that we add into our system by there is we add a controller in our system which we call as a dynamic voltage scaling controller which observes the workload and the temperature if the temperature goes very high it says my temperature is going very high my package May melt I need to reduce power consumption it would say Okay reduce frequency reduce voltage reduce voltage by telling the voltage regulator that you have to reduce the voltage huh now in another case when the workload is very less you're just browsing internet at a very slow pace you're reading some text periods it says I don't need to operate at a very high frequency the workload is very less reduce frequency reduce voltage so that is how we will be able to do it so sir when the situation kind of arises that I can reduce my frequency then only I can think of what is scaling right yes because the voltage will brought it in a single radio increase the delays also yeah yeah so that is where we said now we will start first reduce frequency we'll observe if we can operate at that low frequency for a reasonable amount of time then we will assume that okay if if we are not required to be at a higher frequency for the past to let us say uh one second I can also reduce voltage okay so but that will also impact our frequency in a certain way so I was already operating at a lower frequency is it not okay okay so earlier I had only scaled the frequency but not the voltage so I'm I'm basically making it so that is consistent with that frequency yes okay and to be able to do this you will need circuits which are called as level shifters because now there is a high voltage domain there is a low voltage domain and you will need to have level shifting happening between them otherwise there will be short circuit currents are you able to see this yes Michelle so sir if if somehow like we are using like we are doing something which needs more like which is more intensive which you need more so what will happen first we increase the voltage first or we increase the frequency first you tell me so I think uh it should be like we'll increase the voltage first and then we'll increase the frequency because if I directly increase the frequency without increasing the voltage what happens there will be some race conditions which will fail okay yeah so system will fail yeah okay okay so which conditions I'm sorry so when you raise the frequency before the voltage which conditions you create yourself race conditions set up time whole time something familiar will fail because their system is slow it's it's at low voltage but you want to operate at a much faster rate so something some outputs will not come in time something will go wrong okay yeah voltage and then the frequency okay so by increasing voltage we are making the device faster than the settings yes I know so you see you you realize why it was important to understand impact of voltage on delays before we talk about dvfs listen that was why that was the previous session and not this one okay so what we have done today we've looked at Dynamic power consumption being made of two components switching power and short circuit power and we have set that to reduce switching power you could use uh you could reduce all the various things you could reduce activity Factor by you know preventing glitches by propagating by using and nand Gates and so on we said that you can reduce capacitance by using smaller devices uh doing smarter placement so that wire capacitance is also reduce and so on and we said you could also do voltage and frequency scaling Dynamic voltage and frequency scaling okay and then to reduce short circuit power you would you would have good transition slopes is that okay so with that we will close today's session and the next session we will start with a static,https://www.youtube.com/watch?v=Nve0FZCx7gk,"Link: https://www.youtube.com/watch?v=Nve0FZCx7gk
Transcript: now this is the concept of dynamic voltage and frequency scaling so all of you have your cell phone with you am I right some of you might actually be attending this class on a cell phone any one of you attending the class on a cell phone as of now okay not here yet but someone would be at times so do you think the cell phone application processor here it has a rated frequency of 2.5 gigahertz do you think it always operates at 2.5 gigahertz huh so when you are playing a game on a cell phone when you are doing some really CPU intensive stuff at that point of time you need 2.5 gigahertz but if you're just reading some text message browsing the internet regular text pages you don't need that high performance the system does not need that so what does the system do system says that oh let us reduce the frequency of operation the load on my CPU is not as much instead of 2 gigahertz let me operate at only 200 megahertz I have reduced Dynamic power consumption by 10 times that is dynamic frequency scaling hmm now if I'm operating at 200 megahertz for let us say past one minute the system says that probably I don't really need to go into very high frequency for us for some more time now so let me also lower the voltage of operation because for 200 megahertz as you know at low voltages I can have larger delays but I at 200 megahertz I will still be able to meet my performance of 200 megahertz at let us say 0.7 volts I don't need 1.2 volts so I reduce vdd from 1.2 to something like 0.7 what happens so I first reduce frequency and then I reduce voltage also and I saved much more power because it was one by two CV Square f reduction in F led to linear reduction in power reduction in V additionally led to quadratic reduction in power and by managing both V and F I reduced power cubically so yes so this voltage killing I mean I get that if we reduce that we we save on power so but like how can I reduce that b in this figure what we are showing is that there is a voltage regulator that we add into our system by there is we add a controller in our system which we call as a dynamic voltage scaling controller which observes the workload and the temperature if the temperature goes very high it says my temperature is going very high my package May melt I need to reduce power consumption it would say Okay reduce frequency reduce voltage reduce voltage by telling the voltage regulator that you have to reduce the voltage huh now in another case when the workload is very less you're just browsing internet at a very slow pace you're reading some text periods it says I don't need to operate at a very high frequency the workload is very less reduce frequency reduce voltage so that is how we will be able to do it so sir when the situation kind of arises that I can reduce my frequency then only I can think of what is scaling right yes because the voltage will brought it in a single radio increase the delays also yeah yeah so that is where we said now we will start first reduce frequency we'll observe if we can operate at that low frequency for a reasonable amount of time then we will assume that okay if if we are not required to be at a higher frequency for the past to let us say uh one second I can also reduce voltage okay so but that will also impact our frequency in a certain way so I was already operating at a lower frequency is it not okay okay so earlier I had only scaled the frequency but not the voltage so I'm I'm basically making it so that is consistent with that frequency yes okay and to be able to do this you will need circuits which are called as level shifters because now there is a high voltage domain there is a low voltage domain and you will need to have level shifting happening between them otherwise there will be short circuit currents are you able to see this yes Michelle so sir if if somehow like we are using like we are doing something which needs more like which is more intensive which you need more so what will happen first we increase the voltage first or we increase the frequency first you tell me so I think uh it should be like we'll increase the voltage first and then we'll increase the frequency because if I directly increase the frequency without increasing the voltage what happens there will be some race conditions which will fail okay yeah so system will fail yeah okay okay so which conditions I'm sorry so when you raise the frequency before the voltage which conditions you create yourself race conditions set up time whole time something familiar will fail because their system is slow it's it's at low voltage but you want to operate at a much faster rate so something some outputs will not come in time something will go wrong okay yeah voltage and then the frequency okay so by increasing voltage we are making the device faster than the settings yes I know so you see you you realize why it was important to understand impact of voltage on delays before we talk about dvfs listen that was why that was the previous session and not this one okay so what we have done today we've looked at Dynamic power consumption being made of two components switching power and short circuit power and we have set that to reduce switching power you could use uh you could reduce all the various things you could reduce activity Factor by you know preventing glitches by propagating by using and nand Gates and so on we said that you can reduce capacitance by using smaller devices uh doing smarter placement so that wire capacitance is also reduce and so on and we said you could also do voltage and frequency scaling Dynamic voltage and frequency scaling okay and then to reduce short circuit power you would you would have good transition slopes is that okay so with that we will close today's session and the next session we will start with a static"
zFqb41NmdEU,on the previous class then we can take it upright away okay so what do you mean by static power dissipation so when input is stable nothing is changing and that at that point of time there might be some leakage so static power is when there is no change in input everything is stable even then some power is getting consumed see in cmos we said that uh so we will do it in much more detail later also but in cmos inverter we saw that in a stable state there is no on current neither from the nmos nor from the pmos because of the the fact that the nmos either one of the nmos or the pmos will be on both will not be on in a stable state during transition something would happen but otherwise in a stable state only one of them would be on so there is no direct variety to ground path and we do not expect any current to flow but some current still flows and that is called as static current or static power or leakage different ways to call it so what do you mean by that no change in input i mean why would that condition occur i mean so you tell me i just transition from zero to one and the next cycle will come after two nanoseconds yes so what happens in the in this duration okay uh so one of the inputs would be stable at least yeah one of them we're just talking about an inverter it only has one input so the input is stable no input is toggling but even then some current will flow okay so the amount of that current will be much larger in a cmos that current will be lesser but the current will flow okay and all right so that is called as static current but the path would be there any time the current some current would be flowing because of that uh whatever the store whatever the whatever was stored in the capacitor so that way that would flow then there is no change so let us say for example give me then let us say for example there is this inverter now let us say the stores are vdd now the input is 0 where is the path there is a path here but then uh this both the drain angles are on vdd so the current vds is zero current is zero there is no one current in the system as of now isn't it so okay we are talking terms of inverting right now yeah the meeting is getting recorded okay no sir we are talking in terms of the inverter lecture sir i did not get how are we reducing activity factor by uh putting our complex logic in the beginning because my idea was that because the clock will enter the complex logic at the beginning itself so most toggling would be faced at that point reducing activities after by putting the complex logic in the beginning with the function okay you're simply reducing the overall area and capacitances by doing that so that is already not related to activity factor at all no it's like anything i okay okay sorry okay yeah so coming to static power let us refresh about the uh you know one billion transactions that we were talking about where we said that uh there were one million 1 billion transistors of which 95 percent was memories and remaining was logic and so on remember that case then we studied for the dynamic power in the last session [Music] yes there we are nothing sir you were asking them i said yes okay okay so uh now we are just adding in some more details so that we can estimate the leakage of that chip also we are saying that uh the normal vt the leakage current in the normal vt device is hundred nano ampere 12 millimeter and that of a high vt device is 10 nanometers per millimeter and that hpt devices are used in all the memories and 95 percent of logic gates are also high vp there is some gate leakage which is 5 nano amperes per millimeter and then junction leakage which we say is negligible as of now because we are not applying any body bias or anything like that okay so just remember these things so that when we want to estimate the leakage accept level you will know where to and how to arrive at it is that okay so we said that width of normal v2 devices 50 million devices are normal vp their length is 12 lambda we know that lambda is 0.025 by lambda and uh we we just saw that uh the what was the 0.54 just give me a minute yeah these are total devices and 95 of devices were hvt so 5 of devices are normal vt so normal vt the total width that you get is 0.75 into 10 raised to power 6 microns similarly you calculate for high vt devices 15 50 50 million logic devices 12 lambda 95 of logic devices are high vt then all the memory devices are high vt and we multiply with the lambda factor so we get the overall width for the hpt devices also we've also been given the current per width for hpt on a svt device for a normal vt device and we can simply estimate that uh why do you think we are divided by two over here so to get the average no we don't need to do average of 5 et normal vt they are simply being added this 2 is because of something else so pmos and nmos will not have the same amount of leakage at same point of time so what we are saying is that in a cmos logic either pmos is off or nmos is off so only one of them is leaking the other one is not leaking at all because it is on so this doesn't make sense here i mean in an inverter one the one that we just saw in the over there uh when the input is zero and the output is one which of the two devices is leaking are both of them leaking nmos cannot leak i think suppose no inverse cannot be why will the envelopes not leak so i mean it is there is no path to ground so where will the current go in so what does leakage mean when there is no action happening then some current is flowing when a device is off yes when a device is off so there is no evident path for on current yeah but well then some current is flowing that is why it is called as off current yeah so which of the two devices is off over here nmos so in fact nmos is leaking yes and the b mass is not leaking so but pmos also there's no current going after it has reached that yeah but it is on you will not call that as leakage current okay okay anna so in a static condition the pmos will not govern the amount of current that is flowing through it the n mass will govern the amount of current that will flow through the pmos also is it not applying simple christopher's law i mean sir you're saying that uh when this end mass is off so though there is no on current path but still there is some path that will be the cause of leaking and that will provide the whole connection for the current from pmos also to sync through that uh npcmos is on pmos wants to sing this kind of current huge correct yes sir n mass is off yes nmr says no no current can flow from me i will uh i will flow only very small current from myself i'm not able to draw it on the screen so that is what the nmos would say yes what happens but due to some junction getting overlap with some kind of overlap there is some path provided by anyone there is some path but let us apply kirchhoff's law over there yes yes what happens uh the overall current that can flow from the p mass is limited to the current that will flow from the n mass yes we must cannot supply more current than the nmos constraint but behave we would be considering the current from the capacitor also right now or just see the capacitor is charged at vdd so if the pmos has to so if the capacitor cannot source current from itself can it no no so if nmos is to sink any current and pmos is ready to give so much of current will the current come from the capacitor or from the pmos okay yeah yeah vmos will not allow itself because it will maintain the world yeah okay yes sir either sub uh just appear just for the clarification when we are talking about the high vt devices those are the memory devices right like uh no logic devices can also be high vt so how we are how we are distributing between like 95 percent will be high vts and the five percent why is that that is uh that is the design of our chip okay okay okay okay and one more thing sir uh i am quite about confused between gate leakage and junction leakage [Music] that we have these many devices and these devices just give me a moment my system is slowing down a bit just give me a moment um sir yes sir so to find leakage currency it's enough to find the current flowing through idd at a point where my output is high uh what do you mean okay yes sir i i'll repeat it again so to find leakage current it's and then i can uh find the current i'm like in either or something i'll be finding that i'll be getting the wave of the current so uh i'll be just measuring this wave where my output is high that gives me my leakage current is is this statement correct sir why leakage will happen even when the output is low [Music] when my vdd is high i'll be making i'll take kcl over there and as my capacitance is fully charged and my pmos is ready to supply much more sir i'm sorry sir i can't hear you sorry i'm asking is will uh well will kcl apply only when the output is high or will kcl apply even when output is low even when output is closer so even an output is low input is high even then you will have the same method of calculating leakage does that when the output is low it means input is high it means pmos is off so pmos will govern the leakage not the nmos can't charge over vdd so will there be any kind of current over there because my output is at vdd it might be a tweeted or less than vdd but it won't go vts is zero if radius is zero there is no on current anna yes sir videos of the radius for the p mass is zero that is what you are saying output is vdd and supply is also vdd yes sir yes sir drainant source both are at zero hmm we did yeah so there is nowhere on current yes but the premise is it can offer as much current as you want okay so this is a generalization for only as much current as most things it will not be able to sync any more current okay this is a generalized statement but for inverter it uh inverter has when pmos is on and mass will be off so it will there won't arise a condition like that in any sigma circuit if the nmr stack is off the pmos track is on or vice versa yes cmos yes sir yes so sir like uh can i say that key uh the source for the though the path is provided by the off device but the source ultimately is the voltage source basically for the leakage current also even it is drawn from the source itself yeah yeah okay so yes the current current will always come from any current would always come from supply no yeah it couldn't come from anywhere else even if it was a capacitor that was charged some time back that current had also come from the supply yes sir yes sir yeah somebody yeah you will be able to link it to supply from somewhere anyways you will be able to do that yes yeah,https://www.youtube.com/watch?v=zFqb41NmdEU,"Link: https://www.youtube.com/watch?v=zFqb41NmdEU
Transcript: on the previous class then we can take it upright away okay so what do you mean by static power dissipation so when input is stable nothing is changing and that at that point of time there might be some leakage so static power is when there is no change in input everything is stable even then some power is getting consumed see in cmos we said that uh so we will do it in much more detail later also but in cmos inverter we saw that in a stable state there is no on current neither from the nmos nor from the pmos because of the the fact that the nmos either one of the nmos or the pmos will be on both will not be on in a stable state during transition something would happen but otherwise in a stable state only one of them would be on so there is no direct variety to ground path and we do not expect any current to flow but some current still flows and that is called as static current or static power or leakage different ways to call it so what do you mean by that no change in input i mean why would that condition occur i mean so you tell me i just transition from zero to one and the next cycle will come after two nanoseconds yes so what happens in the in this duration okay uh so one of the inputs would be stable at least yeah one of them we're just talking about an inverter it only has one input so the input is stable no input is toggling but even then some current will flow okay so the amount of that current will be much larger in a cmos that current will be lesser but the current will flow okay and all right so that is called as static current but the path would be there any time the current some current would be flowing because of that uh whatever the store whatever the whatever was stored in the capacitor so that way that would flow then there is no change so let us say for example give me then let us say for example there is this inverter now let us say the stores are vdd now the input is 0 where is the path there is a path here but then uh this both the drain angles are on vdd so the current vds is zero current is zero there is no one current in the system as of now isn't it so okay we are talking terms of inverting right now yeah the meeting is getting recorded okay no sir we are talking in terms of the inverter lecture sir i did not get how are we reducing activity factor by uh putting our complex logic in the beginning because my idea was that because the clock will enter the complex logic at the beginning itself so most toggling would be faced at that point reducing activities after by putting the complex logic in the beginning with the function okay you're simply reducing the overall area and capacitances by doing that so that is already not related to activity factor at all no it's like anything i okay okay sorry okay yeah so coming to static power let us refresh about the uh you know one billion transactions that we were talking about where we said that uh there were one million 1 billion transistors of which 95 percent was memories and remaining was logic and so on remember that case then we studied for the dynamic power in the last session [Music] yes there we are nothing sir you were asking them i said yes okay okay so uh now we are just adding in some more details so that we can estimate the leakage of that chip also we are saying that uh the normal vt the leakage current in the normal vt device is hundred nano ampere 12 millimeter and that of a high vt device is 10 nanometers per millimeter and that hpt devices are used in all the memories and 95 percent of logic gates are also high vp there is some gate leakage which is 5 nano amperes per millimeter and then junction leakage which we say is negligible as of now because we are not applying any body bias or anything like that okay so just remember these things so that when we want to estimate the leakage accept level you will know where to and how to arrive at it is that okay so we said that width of normal v2 devices 50 million devices are normal vp their length is 12 lambda we know that lambda is 0.025 by lambda and uh we we just saw that uh the what was the 0.54 just give me a minute yeah these are total devices and 95 of devices were hvt so 5 of devices are normal vt so normal vt the total width that you get is 0.75 into 10 raised to power 6 microns similarly you calculate for high vt devices 15 50 50 million logic devices 12 lambda 95 of logic devices are high vt then all the memory devices are high vt and we multiply with the lambda factor so we get the overall width for the hpt devices also we've also been given the current per width for hpt on a svt device for a normal vt device and we can simply estimate that uh why do you think we are divided by two over here so to get the average no we don't need to do average of 5 et normal vt they are simply being added this 2 is because of something else so pmos and nmos will not have the same amount of leakage at same point of time so what we are saying is that in a cmos logic either pmos is off or nmos is off so only one of them is leaking the other one is not leaking at all because it is on so this doesn't make sense here i mean in an inverter one the one that we just saw in the over there uh when the input is zero and the output is one which of the two devices is leaking are both of them leaking nmos cannot leak i think suppose no inverse cannot be why will the envelopes not leak so i mean it is there is no path to ground so where will the current go in so what does leakage mean when there is no action happening then some current is flowing when a device is off yes when a device is off so there is no evident path for on current yeah but well then some current is flowing that is why it is called as off current yeah so which of the two devices is off over here nmos so in fact nmos is leaking yes and the b mass is not leaking so but pmos also there's no current going after it has reached that yeah but it is on you will not call that as leakage current okay okay anna so in a static condition the pmos will not govern the amount of current that is flowing through it the n mass will govern the amount of current that will flow through the pmos also is it not applying simple christopher's law i mean sir you're saying that uh when this end mass is off so though there is no on current path but still there is some path that will be the cause of leaking and that will provide the whole connection for the current from pmos also to sync through that uh npcmos is on pmos wants to sing this kind of current huge correct yes sir n mass is off yes nmr says no no current can flow from me i will uh i will flow only very small current from myself i'm not able to draw it on the screen so that is what the nmos would say yes what happens but due to some junction getting overlap with some kind of overlap there is some path provided by anyone there is some path but let us apply kirchhoff's law over there yes yes what happens uh the overall current that can flow from the p mass is limited to the current that will flow from the n mass yes we must cannot supply more current than the nmos constraint but behave we would be considering the current from the capacitor also right now or just see the capacitor is charged at vdd so if the pmos has to so if the capacitor cannot source current from itself can it no no so if nmos is to sink any current and pmos is ready to give so much of current will the current come from the capacitor or from the pmos okay yeah yeah vmos will not allow itself because it will maintain the world yeah okay yes sir either sub uh just appear just for the clarification when we are talking about the high vt devices those are the memory devices right like uh no logic devices can also be high vt so how we are how we are distributing between like 95 percent will be high vts and the five percent why is that that is uh that is the design of our chip okay okay okay okay and one more thing sir uh i am quite about confused between gate leakage and junction leakage [Music] that we have these many devices and these devices just give me a moment my system is slowing down a bit just give me a moment um sir yes sir so to find leakage currency it's enough to find the current flowing through idd at a point where my output is high uh what do you mean okay yes sir i i'll repeat it again so to find leakage current it's and then i can uh find the current i'm like in either or something i'll be finding that i'll be getting the wave of the current so uh i'll be just measuring this wave where my output is high that gives me my leakage current is is this statement correct sir why leakage will happen even when the output is low [Music] when my vdd is high i'll be making i'll take kcl over there and as my capacitance is fully charged and my pmos is ready to supply much more sir i'm sorry sir i can't hear you sorry i'm asking is will uh well will kcl apply only when the output is high or will kcl apply even when output is low even when output is closer so even an output is low input is high even then you will have the same method of calculating leakage does that when the output is low it means input is high it means pmos is off so pmos will govern the leakage not the nmos can't charge over vdd so will there be any kind of current over there because my output is at vdd it might be a tweeted or less than vdd but it won't go vts is zero if radius is zero there is no on current anna yes sir videos of the radius for the p mass is zero that is what you are saying output is vdd and supply is also vdd yes sir yes sir drainant source both are at zero hmm we did yeah so there is nowhere on current yes but the premise is it can offer as much current as you want okay so this is a generalization for only as much current as most things it will not be able to sync any more current okay this is a generalized statement but for inverter it uh inverter has when pmos is on and mass will be off so it will there won't arise a condition like that in any sigma circuit if the nmr stack is off the pmos track is on or vice versa yes cmos yes sir yes so sir like uh can i say that key uh the source for the though the path is provided by the off device but the source ultimately is the voltage source basically for the leakage current also even it is drawn from the source itself yeah yeah okay so yes the current current will always come from any current would always come from supply no yeah it couldn't come from anywhere else even if it was a capacitor that was charged some time back that current had also come from the supply yes sir yes sir yeah somebody yeah you will be able to link it to supply from somewhere anyways you will be able to do that yes yeah"
BIbkHKBmrrQ,[Music] sir just one thing in the current part if we have let's say our two input nand gate then what will come in the denominator even then it will be two in a two input nand gate one of the p masses will be off suppose 0 1 is the state of input so one of the p masses is off the other one is on and one of the n masses is off and other one is on any time half the p masses and half the n mosses are on and off yes yeah so there was a question as to what what causes this leakage and so on so there are multiple sources of leakage the first and most important source is sub threshold conduction what does it mean it says that transistors cannot abruptly turn off as you so it does not happen that as soon as you go below vp transistor is completely off we saw that ids characteristics where we had talked about sub threshold slope and so on and this is log and we had said that the slope has to be 70 millivolts per decade and so on you remember that 60 millivolt per decade and all that stuff yes so what you're talking about there we were saying that it is not that vt can each a current goes to zero at once okay it reduces very very significantly there is a logarithmic exponential reduction in current as you go below vt but current will still flow and that is what is a threshold conduction okay then another set of leakage is gate leakage which is tunneling through ultra thin gate dielectrics so even though we are now using high k metal gate dielectrics which are physically not as thin as silicon dioxide based gates would be but even then the effective thickness of the gate is effectively the physical thickness of the gate is the order of uh you know two nanometers or three nanometers not more than that uh in in technologies where we do not have high k metal gates in those technologies because you want effective gate oxide thickness to be less than you know 20 angstroms 10 angstroms and so on uh there is a lot of tunnelling current that can flow and that is what is gate leakage and then we have junction leakage which is that there are reverse biased pn junctions in our devices so where where all do we have reverse biased pn junctions that's forced to body and drain two body junctions yes source to body drain to body both are reverse bias junctions and even though they are reverse bias functions reverse bias junctions do also conduct some current so that is where we have junction leakage we will look into these in a little more detail and their impact on how we design so sub threshold leakage as we just saw is uh is the current that is still flowing after vt has like after your device has gone below vt so this is what is defined as vt in this particular graph and you see there is still some current flowing even at zero value there is some current flowing so that is what we call as sub threshold current ids in a in a very very good transistor in a very very good transistor this sub threshold slope would tend to 60 to 65 millivolts per decade okay why why is this 60 millivolts per decade preferable over 100 millivolt per decade i'm sorry so it is the best that silicon can achieve and also my question is not why 60 i'm saying why lower is better sir decade the id will decrease per decade below we want current to decrease faster because current current will reduce much faster as you reduce the voltage there will be a decade of current reduction within whatever number we have if it's a hundred millivolts per decade then it requires 100 millivolts slower than vp to get one tenth the current whereas if it is 65 millivolt per decade it means my device has turned off very quickly and even 65 millivolts below vt i will have one tenth the current yeah welcome when we were discussing the boss capacitance and then we move to the there was when we were discussing the first time you told us about sub threshold you were seeing that one is that there is a depletion with under the gate and then there is a depletion of the pn junctions of the source and drain so somehow they get connected and that is basically providing a path so that is the path for that uh this sub threshold leakage i mean i just wanted to confirm yeah so let us go a little little beyond what we were talking on in the last class also or possibly in the last office hours uh where we were discussing about availability of electrons in the conduction band so do we realize that at all times at room temperature there will be some electrons in the conduction band yes sir so there's an electric field applied somewhere those electrons will flow yes so that is leakage even if the device is off there would be something in the conduction band okay anna so but i mean uh i'm not able to clearly visualize the path exactly what the though the band theory tells us me that they will be leakage because every any time point of time they would be conducting electrons but that part i'm i'm just just flexing about the path yeah subthreshold means source to drain path okay but that path is provided by the depletion connections and um no not exactly so depletion definitely depletion depletion region is a so what is the difference between a depletion region and a regular substrate so i mean depletion means that what the nature of the substrate was you have avoid the excess carriers from that region basically so in depletion region all the excess carriers have been depleted yes sir so if you if you inject some electrons from one side because there are no other carriers and there is an electric field across the depletion region these electrons will move very quickly across the depletion region that is one aspect but uh there may not be a complete depletion region also formed there okay okay okay so probably when we go into an accumulation mode then we can say that there is a different kind of a current flowing but uh so because like i am able to visualize depletion region as a like very very high resistance kind of region i mean it's a pistons are too much unlike creator so that may be the limiting factor i i can't comment okay okay yes yeah in the first formula can you repeat the terms in the exponential because i mean it's a little blurry uh the terms in the exponential are v g s minus v t naught minus eta vds minus a gamma uh vsb so you have all these things in the book available don't worry about it i'm not going to ask you these formulae in the exams or any and no one not you will not be asking someone even in the in the interview don't worry about that and so what's the difference between vt and vt not okay so v capital t v capital t is the kt by cube component oh okay right so pd knowledge is a sub threshold voltage vt naught is the threshold voltage at 0 vds okay so [Music] [Applause] again there is some issue so we are saying that there is a sub threshold current that is flowing and that sub threshold current is dependent on vp threshold voltage that is also if the threshold voltage is lower the sub threshold current will be higher we say we are also saying that this sub threshold current is also dependent on uh the the relationship between uh source and body uh the the body bias voltage that has been applied we're also saying that the sub threshold voltage this sub threshold current is also dependent on temperature by the virtue of this component 80 by q um as temperature increases kt by q also increases so we're also saying that this subthreshold current is dependent on temperature so uh when we say that the vt of the device has changed what has happened is that uh if if you for example you change vt from 0.4 to 0.1 the the same curve when it is shifted to the left would intersect the vt the vdd or the gate input vn equal to zero axis at a different place and therefore you can have multiple decades of difference between a high weighted the leakage of a highway device and the off current of a low vt device so this is just an exemplification that you you reduced in in 65 nanometers as you reduce vt by a hundred millivolts you increase the off current by a decade because we assume that the substantial slope is 100 intervals per decade okay now we come to some other effects which are slightly nuanced but are important so one effect is drain induced barrier lowering what does this mean this means that when i apply v when i change so see typically the leakage phenomena is dependent on gate pickup voltage what is the voltage at gate and when it is off even then some current is flowing from source to drain some electron flow is happening from source to drain so that is your typical leakage definition however what happens uh there is a voltage on drain and source also that is applied and we see that there is a dependence of on current and off current on current obviously but also off current on a leakage at we did equal to zero this happens because as you increase the drain voltage the electric field contours change in such a way that uh you know okay in a long channel device what i are why is this happening today just give me a moment so first tell me you understand the difference between a long channel device and a short channel device no yes sir so what is the difference so we uh i mean the uh we reach voltage i mean the velocity saturation more quickly quickly for channel devices so you have a lower current i mean in saturation so okay so as the technology scaling happens as you use shorter length what starts to happen is that your device behaves differently than the standard you know set of equations uh that we studied till now okay this deviation and behavior is referred to as short channel effects okay and uh why do these effects happen we will look at it in in and this explanation that i am just about to start with you so let us say this is a big long channel device and over here i have a short channel device okay now in a long channel device let us say vd is uh one or two volts and vs zero so what happens uh there is this barrier between drain and source so there is a depletion width over here there is a depletion width over here and in between there is a barrier if i try to draw that barrier that barrier would look like this so what is happening this two volts that i had over here is dropping across the channel so as i move from drain side to source side this barrier is increasing if i have a higher voltage over here current should be electrons will be attracted over here now in a long channel device this barrier so electrons have to jump from source into this region so this barrier remains high however in a short channel device what happens is that as drain tends to come closer we see that the barrier reduces when this barrier reduces what happens more electrons can now flow so for a short channel device let us look at it in a separate graph for a short center device the drain and source are closer and the barrier over here reduces than this value so electrons can now more easily jump and reach the drain this is called as drain induced barrier lowering this happens because over here we saw that depletion regions were far apart whereas in short channel devices depletion regions actually start to come very close to each other as they start to come close to each other the barrier starts to reduce questions so what is this is this some energy barrier or some physical barrier today yeah this is the energy this is the conduction band that i have shown uh so here we assume that the depletion of drain and the swords in long channel have reached their maximum depth even if how much ever the video is raised in long channel so the source and drain this junction this is the junction property this is not again talking about the gate over here i am talking about yeah i am talking about this the junction junction only for moga there will be some depletion wait form and uh uh then we have this voltage applied due to which this solution would have changed already yes we're talking about a static condition okay okay so we are not in okay i thought that if we increase vd maybe we can uh uh we can achieve the ibl in long term also uh no no never okay sir yes sir so this condition which you are we were we are speaking right now is in the uh is during my transistor is off right yes so sir if my transistor is off then obviously my depletion region would be above because there is no inversion inversion layer over there i didn't understand why this depletion region moved a bit up diffusion region there is no depletion region also here rashford depletion region there no but okay sorry yes sir i know [Music] we are getting from sir exactly is it due to drain and source yeah that is the pn junction okay okay let's go thank you okay this is the energy conduction band diagram but how is this a financial magnet which looks like some physical structure um so let me if i if i simply move this just a minute swat on it now and so are you able to see this now let me also put this here hello yeah are you able to see this that is what i am saying that's it because it's 2 volts over here the overall energy is lower over here and because uh it's high over there this this in fact the source source would be the since sources are zero this energy would be appearing higher but there is this barrier and we this vd over here the change in depletion width that is called that it causes does not impact anything on the values on the source side whereas when you apply a high vd over here it causes a change in depletion width in such a manner that the source also starts to get impacted and therefore the barrier reduces sir why did the vd become high sir because you charge the capacitor in an inverter you charge the capacitor to vdd yes sir yes right so you change the read and you change the vdna yes sir okay so so even when the like uh vgs was less than dt but still that there would be a depletion under the gate also now so but we have not considered that in this uh there would be a depletion another gate at all times there is some bgs i mean there will be some kind of yeah there will be some depletion but when so there would be a point where there will be no depletion also so we are not really talking about whether there is a depletion there or not what we are saying is that the drain voltage and the impact of drain voltage on the depletion layer starts to impact the starts to impact the barrier on the source side also so sir like it's like uh in short you're seeing that when uh in the short channel devices when we there is a change in the voltage on the vd so that changes depletion at the dairy but that also in effect changes at the source so the so it changes the barrier at the source and therefore leakage current changes and that is what is called as zone induced barrier lowering okay okay so high rain voltage causes current to increase and that is what you are seeing in this red region over here sir yes sir uh so now as uh someone already asked so we were speaking about nmos previously and my nmos will be off when my input will be zero yeah right sir so input is nothing but we are giving it to gate so i don't see any kind of depletion region forming over there because my gate voltage is zero uh but the voltage that i have applied at gate is zero but the doping that i could have done on the gate or the metal that i would have used for the gate can still pin it in such a value that there could be a depletion region yeah you can study so this is all ssd you can read that there and you will find out okay so now that was uh the ibl then there is another effect which is called as body effect where we,https://www.youtube.com/watch?v=BIbkHKBmrrQ,"Link: https://www.youtube.com/watch?v=BIbkHKBmrrQ
Transcript: [Music] sir just one thing in the current part if we have let's say our two input nand gate then what will come in the denominator even then it will be two in a two input nand gate one of the p masses will be off suppose 0 1 is the state of input so one of the p masses is off the other one is on and one of the n masses is off and other one is on any time half the p masses and half the n mosses are on and off yes yeah so there was a question as to what what causes this leakage and so on so there are multiple sources of leakage the first and most important source is sub threshold conduction what does it mean it says that transistors cannot abruptly turn off as you so it does not happen that as soon as you go below vp transistor is completely off we saw that ids characteristics where we had talked about sub threshold slope and so on and this is log and we had said that the slope has to be 70 millivolts per decade and so on you remember that 60 millivolt per decade and all that stuff yes so what you're talking about there we were saying that it is not that vt can each a current goes to zero at once okay it reduces very very significantly there is a logarithmic exponential reduction in current as you go below vt but current will still flow and that is what is a threshold conduction okay then another set of leakage is gate leakage which is tunneling through ultra thin gate dielectrics so even though we are now using high k metal gate dielectrics which are physically not as thin as silicon dioxide based gates would be but even then the effective thickness of the gate is effectively the physical thickness of the gate is the order of uh you know two nanometers or three nanometers not more than that uh in in technologies where we do not have high k metal gates in those technologies because you want effective gate oxide thickness to be less than you know 20 angstroms 10 angstroms and so on uh there is a lot of tunnelling current that can flow and that is what is gate leakage and then we have junction leakage which is that there are reverse biased pn junctions in our devices so where where all do we have reverse biased pn junctions that's forced to body and drain two body junctions yes source to body drain to body both are reverse bias junctions and even though they are reverse bias functions reverse bias junctions do also conduct some current so that is where we have junction leakage we will look into these in a little more detail and their impact on how we design so sub threshold leakage as we just saw is uh is the current that is still flowing after vt has like after your device has gone below vt so this is what is defined as vt in this particular graph and you see there is still some current flowing even at zero value there is some current flowing so that is what we call as sub threshold current ids in a in a very very good transistor in a very very good transistor this sub threshold slope would tend to 60 to 65 millivolts per decade okay why why is this 60 millivolts per decade preferable over 100 millivolt per decade i'm sorry so it is the best that silicon can achieve and also my question is not why 60 i'm saying why lower is better sir decade the id will decrease per decade below we want current to decrease faster because current current will reduce much faster as you reduce the voltage there will be a decade of current reduction within whatever number we have if it's a hundred millivolts per decade then it requires 100 millivolts slower than vp to get one tenth the current whereas if it is 65 millivolt per decade it means my device has turned off very quickly and even 65 millivolts below vt i will have one tenth the current yeah welcome when we were discussing the boss capacitance and then we move to the there was when we were discussing the first time you told us about sub threshold you were seeing that one is that there is a depletion with under the gate and then there is a depletion of the pn junctions of the source and drain so somehow they get connected and that is basically providing a path so that is the path for that uh this sub threshold leakage i mean i just wanted to confirm yeah so let us go a little little beyond what we were talking on in the last class also or possibly in the last office hours uh where we were discussing about availability of electrons in the conduction band so do we realize that at all times at room temperature there will be some electrons in the conduction band yes sir so there's an electric field applied somewhere those electrons will flow yes so that is leakage even if the device is off there would be something in the conduction band okay anna so but i mean uh i'm not able to clearly visualize the path exactly what the though the band theory tells us me that they will be leakage because every any time point of time they would be conducting electrons but that part i'm i'm just just flexing about the path yeah subthreshold means source to drain path okay but that path is provided by the depletion connections and um no not exactly so depletion definitely depletion depletion region is a so what is the difference between a depletion region and a regular substrate so i mean depletion means that what the nature of the substrate was you have avoid the excess carriers from that region basically so in depletion region all the excess carriers have been depleted yes sir so if you if you inject some electrons from one side because there are no other carriers and there is an electric field across the depletion region these electrons will move very quickly across the depletion region that is one aspect but uh there may not be a complete depletion region also formed there okay okay okay so probably when we go into an accumulation mode then we can say that there is a different kind of a current flowing but uh so because like i am able to visualize depletion region as a like very very high resistance kind of region i mean it's a pistons are too much unlike creator so that may be the limiting factor i i can't comment okay okay yes yeah in the first formula can you repeat the terms in the exponential because i mean it's a little blurry uh the terms in the exponential are v g s minus v t naught minus eta vds minus a gamma uh vsb so you have all these things in the book available don't worry about it i'm not going to ask you these formulae in the exams or any and no one not you will not be asking someone even in the in the interview don't worry about that and so what's the difference between vt and vt not okay so v capital t v capital t is the kt by cube component oh okay right so pd knowledge is a sub threshold voltage vt naught is the threshold voltage at 0 vds okay so [Music] [Applause] again there is some issue so we are saying that there is a sub threshold current that is flowing and that sub threshold current is dependent on vp threshold voltage that is also if the threshold voltage is lower the sub threshold current will be higher we say we are also saying that this sub threshold current is also dependent on uh the the relationship between uh source and body uh the the body bias voltage that has been applied we're also saying that the sub threshold voltage this sub threshold current is also dependent on temperature by the virtue of this component 80 by q um as temperature increases kt by q also increases so we're also saying that this subthreshold current is dependent on temperature so uh when we say that the vt of the device has changed what has happened is that uh if if you for example you change vt from 0.4 to 0.1 the the same curve when it is shifted to the left would intersect the vt the vdd or the gate input vn equal to zero axis at a different place and therefore you can have multiple decades of difference between a high weighted the leakage of a highway device and the off current of a low vt device so this is just an exemplification that you you reduced in in 65 nanometers as you reduce vt by a hundred millivolts you increase the off current by a decade because we assume that the substantial slope is 100 intervals per decade okay now we come to some other effects which are slightly nuanced but are important so one effect is drain induced barrier lowering what does this mean this means that when i apply v when i change so see typically the leakage phenomena is dependent on gate pickup voltage what is the voltage at gate and when it is off even then some current is flowing from source to drain some electron flow is happening from source to drain so that is your typical leakage definition however what happens uh there is a voltage on drain and source also that is applied and we see that there is a dependence of on current and off current on current obviously but also off current on a leakage at we did equal to zero this happens because as you increase the drain voltage the electric field contours change in such a way that uh you know okay in a long channel device what i are why is this happening today just give me a moment so first tell me you understand the difference between a long channel device and a short channel device no yes sir so what is the difference so we uh i mean the uh we reach voltage i mean the velocity saturation more quickly quickly for channel devices so you have a lower current i mean in saturation so okay so as the technology scaling happens as you use shorter length what starts to happen is that your device behaves differently than the standard you know set of equations uh that we studied till now okay this deviation and behavior is referred to as short channel effects okay and uh why do these effects happen we will look at it in in and this explanation that i am just about to start with you so let us say this is a big long channel device and over here i have a short channel device okay now in a long channel device let us say vd is uh one or two volts and vs zero so what happens uh there is this barrier between drain and source so there is a depletion width over here there is a depletion width over here and in between there is a barrier if i try to draw that barrier that barrier would look like this so what is happening this two volts that i had over here is dropping across the channel so as i move from drain side to source side this barrier is increasing if i have a higher voltage over here current should be electrons will be attracted over here now in a long channel device this barrier so electrons have to jump from source into this region so this barrier remains high however in a short channel device what happens is that as drain tends to come closer we see that the barrier reduces when this barrier reduces what happens more electrons can now flow so for a short channel device let us look at it in a separate graph for a short center device the drain and source are closer and the barrier over here reduces than this value so electrons can now more easily jump and reach the drain this is called as drain induced barrier lowering this happens because over here we saw that depletion regions were far apart whereas in short channel devices depletion regions actually start to come very close to each other as they start to come close to each other the barrier starts to reduce questions so what is this is this some energy barrier or some physical barrier today yeah this is the energy this is the conduction band that i have shown uh so here we assume that the depletion of drain and the swords in long channel have reached their maximum depth even if how much ever the video is raised in long channel so the source and drain this junction this is the junction property this is not again talking about the gate over here i am talking about yeah i am talking about this the junction junction only for moga there will be some depletion wait form and uh uh then we have this voltage applied due to which this solution would have changed already yes we're talking about a static condition okay okay so we are not in okay i thought that if we increase vd maybe we can uh uh we can achieve the ibl in long term also uh no no never okay sir yes sir so this condition which you are we were we are speaking right now is in the uh is during my transistor is off right yes so sir if my transistor is off then obviously my depletion region would be above because there is no inversion inversion layer over there i didn't understand why this depletion region moved a bit up diffusion region there is no depletion region also here rashford depletion region there no but okay sorry yes sir i know [Music] we are getting from sir exactly is it due to drain and source yeah that is the pn junction okay okay let's go thank you okay this is the energy conduction band diagram but how is this a financial magnet which looks like some physical structure um so let me if i if i simply move this just a minute swat on it now and so are you able to see this now let me also put this here hello yeah are you able to see this that is what i am saying that's it because it's 2 volts over here the overall energy is lower over here and because uh it's high over there this this in fact the source source would be the since sources are zero this energy would be appearing higher but there is this barrier and we this vd over here the change in depletion width that is called that it causes does not impact anything on the values on the source side whereas when you apply a high vd over here it causes a change in depletion width in such a manner that the source also starts to get impacted and therefore the barrier reduces sir why did the vd become high sir because you charge the capacitor in an inverter you charge the capacitor to vdd yes sir yes right so you change the read and you change the vdna yes sir okay so so even when the like uh vgs was less than dt but still that there would be a depletion under the gate also now so but we have not considered that in this uh there would be a depletion another gate at all times there is some bgs i mean there will be some kind of yeah there will be some depletion but when so there would be a point where there will be no depletion also so we are not really talking about whether there is a depletion there or not what we are saying is that the drain voltage and the impact of drain voltage on the depletion layer starts to impact the starts to impact the barrier on the source side also so sir like it's like uh in short you're seeing that when uh in the short channel devices when we there is a change in the voltage on the vd so that changes depletion at the dairy but that also in effect changes at the source so the so it changes the barrier at the source and therefore leakage current changes and that is what is called as zone induced barrier lowering okay okay so high rain voltage causes current to increase and that is what you are seeing in this red region over here sir yes sir uh so now as uh someone already asked so we were speaking about nmos previously and my nmos will be off when my input will be zero yeah right sir so input is nothing but we are giving it to gate so i don't see any kind of depletion region forming over there because my gate voltage is zero uh but the voltage that i have applied at gate is zero but the doping that i could have done on the gate or the metal that i would have used for the gate can still pin it in such a value that there could be a depletion region yeah you can study so this is all ssd you can read that there and you will find out okay so now that was uh the ibl then there is another effect which is called as body effect where we"
EavOMJjv87s,say that as you change the voltage of the body you will see that the VT would change and as DT changes you will also observe that leakage would change okay so when we apply any body bias there is an expected impact on leakage uh body bias or even when we do not apply body bias the very fact that my source and drain now let us talk of it in terms of the stack of an nmos of a nand gate now that this particular device look at this its body terminal is at Ground Hannah but what is the value of the source terminal if my this device is off what is the value on the source some finite value the value on the source could be could be vdd also if if my uh you know if a is on if a is uh if a is 1 and B is 0 then what happens this this starts to charge this node so this internal node could be ready also but if a is also off a is also 0 then this internal node would could be anything need not necessarily be ready but it could be some floating number are you able to see this so when a is when it can it will be vdd but otherwise we cannot Clearly say what it will be yeah some value VX would be there what that reacts will be we can again apply get off current law and voltage law on the uh uh you know on the stack of nmoses considering their off resistances everything we can find that value of VX but so we can find that out but we we clearly we say that it is not vdd it is somewhere intermediate exact value we do not know huh so what happens there is a voltage between source and body that is effectively getting applied huh and that is what we call as body effect it reads it leads to uh increasing or it increased in leads increasing in VT and therefore reduction in leakage it is also called as stack effect okay so what does this mean what does this entail for us yeah this is again Boxster could you please State what this stack effect against her I I got disconnected so sorry okay so when one of the inputs is off let us say B input is off yes the input is off and put us on we know that the the voltage at the intermediate node is vdd yes sir when a is also off that is a is also 0 then there will be some value at this particular node intermediate node yes sir yeah whatever it is one thing is clear that there is a supply or there is a vsb that this device will experience because body is definitely at zero yes and we are saying there's some voltage at the source yes sir so we will have a change in VT of the device the VT of the device would increase and what do we observe we observe a reduction in leakage this reduction in leakage is called as stack effect so how did the leakage reducer uh if DT increases what happens oh okay okay okay okay so I forgot yes thank you okay so that being said what else do we say we say that in a so what we do observe is that in a nand gate then as you change your inputs see the stack effect will happen differently when the inputs are 1 0 versus when they are zero zero are you able to see this yes sir so with that body effect happening differently over there uh we would actually observe that the leakage through a through a stack of two or three devices can actually reduce my orders of magnitude for example if all the inputs in the nmos stack are zero then the sub threshold leak it is 0.4 but when all of them are one then essentially the let us not say all of them are one let us say one one zero then the sub threshold leakage to the nmos side is 5.6 when all of them are one then the pmoses are leaking then the entirely different leakage mechanism has come into picture but until here we are looking at the effect of body body terminal only like the body effect only um overhead there's no body effect but over here there is a full body effect coming into picture both on VX and on VZ so why would there be leakage When A and B are 1 and C is zero because intermediate node will be connected to ground and so with the body yeah but leakage will happen from why to we said no yes sir so but SB is zero so VT will be yeah in that case there is no stack effect see did we take any stack effect there yes yes there is that is what we are saying that is exactly what we are saying that if so depending on which terminals are zero which ones are one we will have stack effect or not no stack effect Okay so I know that is exactly what we are saying yes so this is what you're also observing in your simulations am I right so when it when it is 1 0 0 then there is no stack effect it is showing okay Anna sir yeah yes no um yes sir how are we supposed to look into this specific term I'm like uh I substrate or I gate or I total how am I supposed to look into that leakage currency exactly in components of leakage you can you can measure the current at the gate terminal it will give you the gate leakage you can measure the current at the drain terminal it will give you the drain leakage of threshold leakage okay okay sir okay thank you this is probe and measure yes it is and do you see why deadly gate is changing so significantly when is deadly kit happening all inputs are high sir so their secret is happening in all those situations where the gate input is high and these inputs are zero so when all these are one ABC all are one then it is 0 at all the places so there is highest get leakage when all inputs are zero there is no gate leakage huh sir what is the first second column actually is what is written in the today's heading sir can you just it is blurry this is I sub this is okay so sir like we take we basically uh see the stack effect for every different node and better wherever we will see that the BSB is kind of uh greater than zero that will basically for that particular device that sub threshold will introduce yeah okay okay so this is so you will not really do it for every every gate and everything but yes to do an analysis you should be able to do it for example for a simple nor gate also How would how do you expect the leakage of a nor gate to change in different cases okay so depending on your input combination the gate leakage would change so but how do uh how do I say that how do I conclude any important reason I will give for change in grade teachers there is a voltage at gate and there is a voltage on the Source or drain due to which let us say just give me a minute so there is this so what is happening is this commitment so what we are saying that if the voltage over here is very different from the voltage over here then there will be direct leakage from gate to drain and Source let us say okay so what happens uh the voltage on the source and drain is also reflected across the channel region the body the transistor region and tunneling would happen let us say this is 1.2 volts and this is zero so the the channel region is also all at zero so 1.2 volts across a very thin gate oxide let us say 0.12 1.2 nanometers or 12 angstroms real angstrom device uh 1.2 volts across it there will there is bound to be gate leakage so tunneling happens funneling means electrons from one side of the dielectric so what is this let us say this is the date dielectric this is uh and these are your source and drain region this is gate and this is your Source slash drain region so what happens uh the the electron simply tunnel despite there being a barrier They Don't Really climb the barrier the simply tunnel by the Heisenberg's uncertainty principle yeah and uh you have some current flowing okay and that is why great leakage would change when you apply uh depending on inputs sir is it only with drain and Source or is it also with bodies tunneling also but that will rush into great those electrons that will enter into the body will rush into the source and drain region so it will be visible as source and only Pfizer so I am not able to get the stack when the stack effect is getting zero like okay so in this particular thing uh let us say oh so let us let us look at it over here what are we saying we are saying that when inputs are one zero zero let us say uh fifth row so a is one yes a is one means vs is equal to zero yes sir now what happens to v z v z can't be zero because you know there will be some stack effect yes sir okay enough now let us look at the 101 case C is one and a is one and C is transmitted to v z it becomes VD minus v t yes sir yes sir and since a is one therefore v x is equal to 0 we're not talking about stack effect anywhere okay okay because there is a deterministic voltage we know what it is yes yes sir stack effective we don't know the voltage we can find out but really we just simply saying there's a stack effects okay okay so but then why you have written the 0 over there I mean it should start effect is there right okay wizard is there okay fine I'm sorry okay I don't get your question rather yes sir so I mean uh in the case of zero one one be uh okay we are getting bdd minus DT okay right so there is a stack effect right okay yeah yes yeah so what does intermediate mean I mean what does intermediate a is reflecting this you tell me and it just analyze it yourself and tell me [Music] we are saying a0 B is 1 C 0. um so VD minus VT cannot come to either VX or v z yes but we actually some voltage which would appear at both VX and v z which is also again different from the stack effect as we are talking about it it could it could be similar but because there is some on resistance of N2 which also comes into picture now you cannot really say that stack effect um okay I mean it is not neither somebody talking about after the sensors over here now there is a non-resistance also that has come into picture okay so it is neither stack or neither will be minus fitting so it is okay okay so and these great leakage currents this 6.3 12.6 and 18.9 they are exact I mean multiples of 6.3 so does this mean that we can depending on the state I mean depending on the type of input we can determine some nodes Council notes that that's that are on or have some voltage and then we can determine the exact multiplication Factor yeah that was what we will look also in a way looking at now if the if this many gates are one and there is uh we did like uh look at case 0 1 1. hmm what is happening there in the case of zero one one my VX and v z are both are VD minus v t even for the devices where the gate is at one yeah the differential across the gate is just a VT so there is no tunneling that will happen but when the differential across the gate is full bdd that doesn't tunneling happens so as soon as you put for example v x equal to 0 you see currents are in the range of 6.3 Nano amperes okay enough as it becomes 0 for both VX and v z Uh current increased further yes and then in the last one it's the pmos leakage current that is coming into picture okay okay so I will have to reset it once again just give me a moment sir yes sir uh I don't know if this is a basic question or something but sir the nmos which is present in the center and between two pmosis and one and most first suppose we are we are considering an end game uh sir could you please uh explain why we are connecting our body to ground surface why we are connecting our body to ground directly you tell me what is the physical structure of the device physical structure yes sir to connect the body to Source somewhere let us say VX somewhere and uh to ground elsewhere what do you need can you have the same pvl in which the two devices can be made yes yes so can you make them in the same people if you have to keep different substrate voltages can the P well be same so uh or let us put it differently if the P well is same can there be different voltages on the body no there can't be sir yeah and why are you asking this question sir uh but okay okay so we just want to maintain the voltage why did we cover the layout part before this part so that you understand that something is not possible in terms of a layout hypothetically in a simulation you can put whatever value on your body but then if you have to design the layout of that and you design it the way we do then the body terminals will all be actually shorted is it not yes we do not have different bodies in which you will lay out those,https://www.youtube.com/watch?v=EavOMJjv87s,"Link: https://www.youtube.com/watch?v=EavOMJjv87s
Transcript: say that as you change the voltage of the body you will see that the VT would change and as DT changes you will also observe that leakage would change okay so when we apply any body bias there is an expected impact on leakage uh body bias or even when we do not apply body bias the very fact that my source and drain now let us talk of it in terms of the stack of an nmos of a nand gate now that this particular device look at this its body terminal is at Ground Hannah but what is the value of the source terminal if my this device is off what is the value on the source some finite value the value on the source could be could be vdd also if if my uh you know if a is on if a is uh if a is 1 and B is 0 then what happens this this starts to charge this node so this internal node could be ready also but if a is also off a is also 0 then this internal node would could be anything need not necessarily be ready but it could be some floating number are you able to see this so when a is when it can it will be vdd but otherwise we cannot Clearly say what it will be yeah some value VX would be there what that reacts will be we can again apply get off current law and voltage law on the uh uh you know on the stack of nmoses considering their off resistances everything we can find that value of VX but so we can find that out but we we clearly we say that it is not vdd it is somewhere intermediate exact value we do not know huh so what happens there is a voltage between source and body that is effectively getting applied huh and that is what we call as body effect it reads it leads to uh increasing or it increased in leads increasing in VT and therefore reduction in leakage it is also called as stack effect okay so what does this mean what does this entail for us yeah this is again Boxster could you please State what this stack effect against her I I got disconnected so sorry okay so when one of the inputs is off let us say B input is off yes the input is off and put us on we know that the the voltage at the intermediate node is vdd yes sir when a is also off that is a is also 0 then there will be some value at this particular node intermediate node yes sir yeah whatever it is one thing is clear that there is a supply or there is a vsb that this device will experience because body is definitely at zero yes and we are saying there's some voltage at the source yes sir so we will have a change in VT of the device the VT of the device would increase and what do we observe we observe a reduction in leakage this reduction in leakage is called as stack effect so how did the leakage reducer uh if DT increases what happens oh okay okay okay okay so I forgot yes thank you okay so that being said what else do we say we say that in a so what we do observe is that in a nand gate then as you change your inputs see the stack effect will happen differently when the inputs are 1 0 versus when they are zero zero are you able to see this yes sir so with that body effect happening differently over there uh we would actually observe that the leakage through a through a stack of two or three devices can actually reduce my orders of magnitude for example if all the inputs in the nmos stack are zero then the sub threshold leak it is 0.4 but when all of them are one then essentially the let us not say all of them are one let us say one one zero then the sub threshold leakage to the nmos side is 5.6 when all of them are one then the pmoses are leaking then the entirely different leakage mechanism has come into picture but until here we are looking at the effect of body body terminal only like the body effect only um overhead there's no body effect but over here there is a full body effect coming into picture both on VX and on VZ so why would there be leakage When A and B are 1 and C is zero because intermediate node will be connected to ground and so with the body yeah but leakage will happen from why to we said no yes sir so but SB is zero so VT will be yeah in that case there is no stack effect see did we take any stack effect there yes yes there is that is what we are saying that is exactly what we are saying that if so depending on which terminals are zero which ones are one we will have stack effect or not no stack effect Okay so I know that is exactly what we are saying yes so this is what you're also observing in your simulations am I right so when it when it is 1 0 0 then there is no stack effect it is showing okay Anna sir yeah yes no um yes sir how are we supposed to look into this specific term I'm like uh I substrate or I gate or I total how am I supposed to look into that leakage currency exactly in components of leakage you can you can measure the current at the gate terminal it will give you the gate leakage you can measure the current at the drain terminal it will give you the drain leakage of threshold leakage okay okay sir okay thank you this is probe and measure yes it is and do you see why deadly gate is changing so significantly when is deadly kit happening all inputs are high sir so their secret is happening in all those situations where the gate input is high and these inputs are zero so when all these are one ABC all are one then it is 0 at all the places so there is highest get leakage when all inputs are zero there is no gate leakage huh sir what is the first second column actually is what is written in the today's heading sir can you just it is blurry this is I sub this is okay so sir like we take we basically uh see the stack effect for every different node and better wherever we will see that the BSB is kind of uh greater than zero that will basically for that particular device that sub threshold will introduce yeah okay okay so this is so you will not really do it for every every gate and everything but yes to do an analysis you should be able to do it for example for a simple nor gate also How would how do you expect the leakage of a nor gate to change in different cases okay so depending on your input combination the gate leakage would change so but how do uh how do I say that how do I conclude any important reason I will give for change in grade teachers there is a voltage at gate and there is a voltage on the Source or drain due to which let us say just give me a minute so there is this so what is happening is this commitment so what we are saying that if the voltage over here is very different from the voltage over here then there will be direct leakage from gate to drain and Source let us say okay so what happens uh the voltage on the source and drain is also reflected across the channel region the body the transistor region and tunneling would happen let us say this is 1.2 volts and this is zero so the the channel region is also all at zero so 1.2 volts across a very thin gate oxide let us say 0.12 1.2 nanometers or 12 angstroms real angstrom device uh 1.2 volts across it there will there is bound to be gate leakage so tunneling happens funneling means electrons from one side of the dielectric so what is this let us say this is the date dielectric this is uh and these are your source and drain region this is gate and this is your Source slash drain region so what happens uh the the electron simply tunnel despite there being a barrier They Don't Really climb the barrier the simply tunnel by the Heisenberg's uncertainty principle yeah and uh you have some current flowing okay and that is why great leakage would change when you apply uh depending on inputs sir is it only with drain and Source or is it also with bodies tunneling also but that will rush into great those electrons that will enter into the body will rush into the source and drain region so it will be visible as source and only Pfizer so I am not able to get the stack when the stack effect is getting zero like okay so in this particular thing uh let us say oh so let us let us look at it over here what are we saying we are saying that when inputs are one zero zero let us say uh fifth row so a is one yes a is one means vs is equal to zero yes sir now what happens to v z v z can't be zero because you know there will be some stack effect yes sir okay enough now let us look at the 101 case C is one and a is one and C is transmitted to v z it becomes VD minus v t yes sir yes sir and since a is one therefore v x is equal to 0 we're not talking about stack effect anywhere okay okay because there is a deterministic voltage we know what it is yes yes sir stack effective we don't know the voltage we can find out but really we just simply saying there's a stack effects okay okay so but then why you have written the 0 over there I mean it should start effect is there right okay wizard is there okay fine I'm sorry okay I don't get your question rather yes sir so I mean uh in the case of zero one one be uh okay we are getting bdd minus DT okay right so there is a stack effect right okay yeah yes yeah so what does intermediate mean I mean what does intermediate a is reflecting this you tell me and it just analyze it yourself and tell me [Music] we are saying a0 B is 1 C 0. um so VD minus VT cannot come to either VX or v z yes but we actually some voltage which would appear at both VX and v z which is also again different from the stack effect as we are talking about it it could it could be similar but because there is some on resistance of N2 which also comes into picture now you cannot really say that stack effect um okay I mean it is not neither somebody talking about after the sensors over here now there is a non-resistance also that has come into picture okay so it is neither stack or neither will be minus fitting so it is okay okay so and these great leakage currents this 6.3 12.6 and 18.9 they are exact I mean multiples of 6.3 so does this mean that we can depending on the state I mean depending on the type of input we can determine some nodes Council notes that that's that are on or have some voltage and then we can determine the exact multiplication Factor yeah that was what we will look also in a way looking at now if the if this many gates are one and there is uh we did like uh look at case 0 1 1. hmm what is happening there in the case of zero one one my VX and v z are both are VD minus v t even for the devices where the gate is at one yeah the differential across the gate is just a VT so there is no tunneling that will happen but when the differential across the gate is full bdd that doesn't tunneling happens so as soon as you put for example v x equal to 0 you see currents are in the range of 6.3 Nano amperes okay enough as it becomes 0 for both VX and v z Uh current increased further yes and then in the last one it's the pmos leakage current that is coming into picture okay okay so I will have to reset it once again just give me a moment sir yes sir uh I don't know if this is a basic question or something but sir the nmos which is present in the center and between two pmosis and one and most first suppose we are we are considering an end game uh sir could you please uh explain why we are connecting our body to ground surface why we are connecting our body to ground directly you tell me what is the physical structure of the device physical structure yes sir to connect the body to Source somewhere let us say VX somewhere and uh to ground elsewhere what do you need can you have the same pvl in which the two devices can be made yes yes so can you make them in the same people if you have to keep different substrate voltages can the P well be same so uh or let us put it differently if the P well is same can there be different voltages on the body no there can't be sir yeah and why are you asking this question sir uh but okay okay so we just want to maintain the voltage why did we cover the layout part before this part so that you understand that something is not possible in terms of a layout hypothetically in a simulation you can put whatever value on your body but then if you have to design the layout of that and you design it the way we do then the body terminals will all be actually shorted is it not yes we do not have different bodies in which you will lay out those"
52kZoHsX--A,devices okay okay sir yes sir yes so from what we have seen till now if we want to reduce leakage what do we do we increase the vto devices high vt devices we say would have lesser leakage we use stacks and we decrease vb because we saw that in a stack effect there is some reverse body reverse or you know some source bias that is happening which is leading to reduction in leakage and we do that in terms of a body biasing also we say let us apply reverse body bias in sleep mode sleep means in inactive modes and forward body bias in active modes okay so last time there was this question i think in the office hours as to what is the difference between uh clock gating or power power gaiting uh clock dating and sleep so for example we could say that sleep mode involves much more than just enable signal on the clock dating path okay so gate leakage another a slide just to give you an estimate of how the gate leakage changes so when the physical gate oxide thickness was 19 angstroms uh and we were operating at a at a vdd in the range of 1.8 volts we had a gate leakage in the order of 10 raised to power minus 4 or something ok not really significant as we came to more finer you know advanced geometries then leakage started to become important and as as it is also said that in 65 nanometers and lower technologies where the silicon dioxide gate is used the t-ox is actually less than one nanometer and gate leakage you will notice increases very significantly it becomes a very significant part of overall leakage especially at room temperature see sub threshold uh leakage we already observed is dependent on temperature huh so at room temperature gate leakage becomes a very significant component and therefore we see that in advanced technologies gate leakage is something that we are worried about in the previous slide we also saw the stacked effect the stack effect and we saw that gate leakage over there is much uh much very predominant it was it was reasonably high component of the total leakage of that particular gate depending on the input combination huh you remember you said okay so yes so you said that to decrease the like leakage we can you decrease the body uh bias basically so but like when we were seeing the stack effect when we're seeing the stack thing so so we know that each of my basically inverses in the different pivots right now it's in same people yes sir all the n masses are in the same people okay all then masses are in the same table so their bodies are ground but their source is at vx or vz okay so effectively those transistors are in reverse bias because source voltage is higher than the body terminal voltage if i make any more devices in the in the same people the substrate region that is the common piece of set region is it not they're naturally connected sorry sorry so actually i was arguing about the like uh for the end well kind of thing like i was thinking even in this if you're if you're biasing all the involves through the same value and all envelopes are then connected okay i know so yes mother so this body by so this body was some place to our advantage when we talk about leakage but wouldn't it create uh non-uniform currents and that will lead to some unexpected behavior of the device so because substrate is not directly connected to the source then this means that for if i stack my transistors then they will all have different vts at different point of times at different point of operations so wouldn't that change the current through each of those devices in the stack effect the leakage changes to the current to the devices is changing so now the current is not uniform like for e for modeling will still be followed yes yes sir it will be followed so whichever is resisted device whichever can sink the lowest current that will define the total current in the system okay okay so okay okay so don't assume there is any current accumulation anywhere casey will still be followed yes sir there is no accumulation but as you said that the current the device that can sync lowest current will now be the limiting factor now since the top stacks will uh as we stack the transistors the above transistors will become bad things so wouldn't that change my delays and all those when we will move to the combinational or combinational logic design you will see that there is a way to design around the delays due to stacks you will see that that is called tapered design okay it will impact yes for sure it will impact but there is a way to handle it we will handle it okay so yes all nmos sir i i understood that there is a common uh p p substrate that's the reason why uh we are grounding all the bodies to ground sir but uh why why is the cadence giving us an option to uh connect the body to somewhere for an nmos to be specific okay i do understand that for pmos we uh we have that but for nmoser why does the cadence even give an option why can't it directly uh ground ground around all the uh ground all the bodies of nmos because there is a there is a possibility in the technology to have a have what is called as buried and well or deep and well that deep envelope is used to separate evils yes sir and when you can separate those people by using that buried and well then what happens you can actually give it yes also separately so for rf circuits or for some specific designs designers may want to give that kind of area and therefore technology has to give you an option to connect the body terminal to different levels okay so as a designer you have all the flexibility but the device which i select is nsvt lp or psvtlp in cadence for suppose so all rf designs also the same devices will be used okay so the design methodology is different so there would be an option where i could enable a deep and well yes you will have to draw it you'll have to draw it on the um in the layout layout okay then your pls will be separated okay okay okay sir thank you okay like if you had a question so yes sir i mean why would i be needing to like separate the p wells i mean actually the whole point was that only right because by doing one deeper like now suppose you do not want the stack effect as mother was saying that the performance would change so like i as i could as i could understand that the stack effect was coming into play uh because of our design only because we had designing the nand gates such that like three there will be the cause of so what happened because of that vx became higher than substrate voltage yes that is why a reason that is the reason why your leakage is reduced is it not now you do not want vt to change what will you do you will need to connect the substrate also to vx yes so then you will need deep and so i can do that in d in every p l we can connect to ground and it's it's a huge area of penalty huge okay yeah so you do not do it for digital circuits okay this is if done it is only done for analog rf circuits not for digital circuits at all it's a huge area penalty okay so but cadence would always give you option to have that body terminal and you may also want at some time to connect the body terminals as a designer you should have all the flexibility okay so so like for example in the digital circuit i would by default be observing the track effect i would get by the virtue of my design only because i'm designed like they would be tmosset animosity one so so like then why basically uh do i have to basic uh then buy should it buy should i basically select the low bt devices because because you want speed yes yes sir i mean because because static effect because which is stack effect i am getting the kind of the reduction in leakage so why should i go because only the side you're saying that 95 are basically high weight devices but for the digital circuit i can go for the low beating yeah so it means that you will have to use in more transistors if you do not go to high vt you only use stacking to reduce leakage then uh you will not be able so for for even an inverter you will do stack off two n mosses and stack off to the muscles to reduce leakage yeah your waist area okay instead you you do it like hpt devices okay actually i'm considering only the static cmos implementation yeah okay so let's quickly look at junction leakage junction leakage has three components basic you know ordinary diode leakage because there are diodes everywhere then band to band tunneling what happens in banter and tunneling so this is the diode leakage thing where since there is a source and drain region and there is a depletion region there there is some diode current that will flow reverse reverse biased pn junctions will have some leakage then we're talking about band to band tunneling what is this let us say that i apply so you know we're talking about halo doping and all those things over here let us say that i have applied a reverse body bias on my body so that i reduce leakage what happens the conduction band of one side starts to become aligned with the valence band of the other sides okay and if uh the the depletion width is small enough then electrons will simply tunnel from the valence band on one side to the conduction band on the other that is called band-to-band tunneling sir why are these getting aligned sir align means so initially they were like this you applied reverse body bias initially they were like this then you applied reverse body wires and they went low so now electrons will directly move from here to here sorry from here to here because you applied a reverse body bias that is where it can happen you expected that by applying reverse body bias i will remove the sub threshold leakage which you will you will definitely reduce sub threshold leakage but you will introduce band to band tunneling okay focus yeah then there is also something called as gate induced rain leakage what does this mean this means that due to some so let us say there is this device huh let us say there is this device on the drain side let us go to whiteboard so what happens is there is slight overlap between source drain and gate regions so when you apply some voltage on the gate when you apply some voltage on the gate there is some change in potential the the depletion region over here in this region such that there is higher leakage in the drain why why are we only talking about the rain because rain is at a higher voltage source and body are typically connected shorted but drain and body are at different potentials so because of the electrostatic contours changing shape near the drain region when you apply gate voltage you see that the drain leakage increases and that is reflected by this curve there that is reflected by this red red shaded region in the curve there okay this is called as gate induced drain leakage so we've looked at different kinds of leakages till now now if i now if i say that i want to uh how do i put it if i say that i want to now reduce overall leakage in the system what all levers do you think we have hello just start effect huh can you start basically stacking okay you can stack the body of it due to which the body effect will come okay what else so i mean we can connect the body to different voltages if it is possible we can connect the body to different voltages if possible for the p pmosses it may be possible by again losing a lot of area and mosses you will need to lose a lot lot more area to be able to do that but let us say we we still are able to create some voltage islands where we say that substrate voltages for inactive islands you would want to keep at a different level so that leakage reduces so that is body biasing across uh clustered body biasing across different uh circuit regions huh yes okay what else can you do maybe may be thicker oxides thicker oxides okay but super oxides you will see that it will lead to change in speed the speed would be great so long channel devices and high cadillacs yes long channel devices high k dielectrics yes so that gate leakage reduces but a very important technique that you use is what is called as power gating so when your entire circuit when your entire circuit you know that is not going to be operated you put a set of these sleep transistors or header switch transistors on vdd so your power gated block does not directly get vdd it gets a new supply which is virtual vdd or vddv okay when you know that this particular block is is going to be off or not operational you can simply switch off these pmoses you can take sleep to one and when you take sleep to one what happens the supply the vdd supply is cut off okay what it does necessarily require it that at the output again you put a gating with sleep bar so that outputs do not lead to very high currents in the subsequent stages because the output as you cut off the vdd what happens the outputs of this block will start to vary between 0 and vdd will no longer be at 0 or vdd they will be anywhere which can lead to high short circuit currents in the subsequent stages to prevent that what do you do you put these and gates how do you isolate the outputs okay now it appears that this would reduce leakage yes it will reduce leakage but you should activate sleep modes only when you are doing it for a sufficient amount of time because toggling the sleep pin will in itself is at the heat it's a huge capacitance the sleep would be running all over the place it is a huge capacitance and toggling the sleep pin in itself will consume some current so that should not exceed the current that you are saving okay so what is this output what output i am taking here out from here i mean this would be the power gated block would be my pdn or the pdf pull up or to pull down it so let us say the power gated block only had the nand gate okay okay completely so like we're saying in terms of the complete gate not like the pull down on the pull up i'm talking about a power gated block which means i am talking about the full processor okay okay i'm talking about a full memory there for example okay okay okay so that is where we did not say a circuit we set a block yeah yes uh details okay yeah if there was a question so even after i found it i will still some previous stage will still be providing some inputs right here let the inputs come so i am not using the outputs of this block i anyway i'm not using the outputs of this block so let the inputs come if my vdd is not connected it will not lead to any power consumption is it still gate leakage will still be there because yeah you cannot control this so full memory inputs are just going to 20 gates if we are putting a condition on immediately then even we are removing our stack effect right sir we are adding a stack effect this vdd v is something like v x is it not yes sir we are adding a stack effect we will need to size our circuits slightly differently so that this or we'll have to have a huge capacitance on vddv so that after power up when you want to actually operate the circuit stack effect doesn't appear in the delays [Music] okay okay so that this vddv is almost equal to vdd in active mods okay so okay so what we looked at today was three kinds of leakages static power being governed by sub threshold leakage gate leakage and junction leakage we looked at uh scaling effects like uh dibl gidl and we talked about high k dielectrics also that we use high k dielectrics so that physical gate oxide thickness can be higher and gate leakage can be reduced and to reduce leakage we discussed about using high vt lowering vdd we already discussed in the last class also body effect large lengths you mentioned and then we also talked about sleep transistors towards the end okay so yes so i have a doubt in the previous slide okay yeah so uh we we are adding this p moses to uh cut off the connection between vdd and the power we are our logic right yeah now when these female p masses are turned off so there would be some sub threshold leakage also in those pmoses so yeah and that will come but overall leakage will reduce now for our logic the leakage will reduce but that uh threshold leakage of those p masses so it is again the same thing look at it like this there will be a kcl that will apply yes sir so if the power gated block does not does not allow syncing more current how will more current go okay okay okay equilibrium limit,https://www.youtube.com/watch?v=52kZoHsX--A,"Link: https://www.youtube.com/watch?v=52kZoHsX--A
Transcript: devices okay okay sir yes sir yes so from what we have seen till now if we want to reduce leakage what do we do we increase the vto devices high vt devices we say would have lesser leakage we use stacks and we decrease vb because we saw that in a stack effect there is some reverse body reverse or you know some source bias that is happening which is leading to reduction in leakage and we do that in terms of a body biasing also we say let us apply reverse body bias in sleep mode sleep means in inactive modes and forward body bias in active modes okay so last time there was this question i think in the office hours as to what is the difference between uh clock gating or power power gaiting uh clock dating and sleep so for example we could say that sleep mode involves much more than just enable signal on the clock dating path okay so gate leakage another a slide just to give you an estimate of how the gate leakage changes so when the physical gate oxide thickness was 19 angstroms uh and we were operating at a at a vdd in the range of 1.8 volts we had a gate leakage in the order of 10 raised to power minus 4 or something ok not really significant as we came to more finer you know advanced geometries then leakage started to become important and as as it is also said that in 65 nanometers and lower technologies where the silicon dioxide gate is used the t-ox is actually less than one nanometer and gate leakage you will notice increases very significantly it becomes a very significant part of overall leakage especially at room temperature see sub threshold uh leakage we already observed is dependent on temperature huh so at room temperature gate leakage becomes a very significant component and therefore we see that in advanced technologies gate leakage is something that we are worried about in the previous slide we also saw the stacked effect the stack effect and we saw that gate leakage over there is much uh much very predominant it was it was reasonably high component of the total leakage of that particular gate depending on the input combination huh you remember you said okay so yes so you said that to decrease the like leakage we can you decrease the body uh bias basically so but like when we were seeing the stack effect when we're seeing the stack thing so so we know that each of my basically inverses in the different pivots right now it's in same people yes sir all the n masses are in the same people okay all then masses are in the same table so their bodies are ground but their source is at vx or vz okay so effectively those transistors are in reverse bias because source voltage is higher than the body terminal voltage if i make any more devices in the in the same people the substrate region that is the common piece of set region is it not they're naturally connected sorry sorry so actually i was arguing about the like uh for the end well kind of thing like i was thinking even in this if you're if you're biasing all the involves through the same value and all envelopes are then connected okay i know so yes mother so this body by so this body was some place to our advantage when we talk about leakage but wouldn't it create uh non-uniform currents and that will lead to some unexpected behavior of the device so because substrate is not directly connected to the source then this means that for if i stack my transistors then they will all have different vts at different point of times at different point of operations so wouldn't that change the current through each of those devices in the stack effect the leakage changes to the current to the devices is changing so now the current is not uniform like for e for modeling will still be followed yes yes sir it will be followed so whichever is resisted device whichever can sink the lowest current that will define the total current in the system okay okay so okay okay so don't assume there is any current accumulation anywhere casey will still be followed yes sir there is no accumulation but as you said that the current the device that can sync lowest current will now be the limiting factor now since the top stacks will uh as we stack the transistors the above transistors will become bad things so wouldn't that change my delays and all those when we will move to the combinational or combinational logic design you will see that there is a way to design around the delays due to stacks you will see that that is called tapered design okay it will impact yes for sure it will impact but there is a way to handle it we will handle it okay so yes all nmos sir i i understood that there is a common uh p p substrate that's the reason why uh we are grounding all the bodies to ground sir but uh why why is the cadence giving us an option to uh connect the body to somewhere for an nmos to be specific okay i do understand that for pmos we uh we have that but for nmoser why does the cadence even give an option why can't it directly uh ground ground around all the uh ground all the bodies of nmos because there is a there is a possibility in the technology to have a have what is called as buried and well or deep and well that deep envelope is used to separate evils yes sir and when you can separate those people by using that buried and well then what happens you can actually give it yes also separately so for rf circuits or for some specific designs designers may want to give that kind of area and therefore technology has to give you an option to connect the body terminal to different levels okay so as a designer you have all the flexibility but the device which i select is nsvt lp or psvtlp in cadence for suppose so all rf designs also the same devices will be used okay so the design methodology is different so there would be an option where i could enable a deep and well yes you will have to draw it you'll have to draw it on the um in the layout layout okay then your pls will be separated okay okay okay sir thank you okay like if you had a question so yes sir i mean why would i be needing to like separate the p wells i mean actually the whole point was that only right because by doing one deeper like now suppose you do not want the stack effect as mother was saying that the performance would change so like i as i could as i could understand that the stack effect was coming into play uh because of our design only because we had designing the nand gates such that like three there will be the cause of so what happened because of that vx became higher than substrate voltage yes that is why a reason that is the reason why your leakage is reduced is it not now you do not want vt to change what will you do you will need to connect the substrate also to vx yes so then you will need deep and so i can do that in d in every p l we can connect to ground and it's it's a huge area of penalty huge okay yeah so you do not do it for digital circuits okay this is if done it is only done for analog rf circuits not for digital circuits at all it's a huge area penalty okay so but cadence would always give you option to have that body terminal and you may also want at some time to connect the body terminals as a designer you should have all the flexibility okay so so like for example in the digital circuit i would by default be observing the track effect i would get by the virtue of my design only because i'm designed like they would be tmosset animosity one so so like then why basically uh do i have to basic uh then buy should it buy should i basically select the low bt devices because because you want speed yes yes sir i mean because because static effect because which is stack effect i am getting the kind of the reduction in leakage so why should i go because only the side you're saying that 95 are basically high weight devices but for the digital circuit i can go for the low beating yeah so it means that you will have to use in more transistors if you do not go to high vt you only use stacking to reduce leakage then uh you will not be able so for for even an inverter you will do stack off two n mosses and stack off to the muscles to reduce leakage yeah your waist area okay instead you you do it like hpt devices okay actually i'm considering only the static cmos implementation yeah okay so let's quickly look at junction leakage junction leakage has three components basic you know ordinary diode leakage because there are diodes everywhere then band to band tunneling what happens in banter and tunneling so this is the diode leakage thing where since there is a source and drain region and there is a depletion region there there is some diode current that will flow reverse reverse biased pn junctions will have some leakage then we're talking about band to band tunneling what is this let us say that i apply so you know we're talking about halo doping and all those things over here let us say that i have applied a reverse body bias on my body so that i reduce leakage what happens the conduction band of one side starts to become aligned with the valence band of the other sides okay and if uh the the depletion width is small enough then electrons will simply tunnel from the valence band on one side to the conduction band on the other that is called band-to-band tunneling sir why are these getting aligned sir align means so initially they were like this you applied reverse body bias initially they were like this then you applied reverse body wires and they went low so now electrons will directly move from here to here sorry from here to here because you applied a reverse body bias that is where it can happen you expected that by applying reverse body bias i will remove the sub threshold leakage which you will you will definitely reduce sub threshold leakage but you will introduce band to band tunneling okay focus yeah then there is also something called as gate induced rain leakage what does this mean this means that due to some so let us say there is this device huh let us say there is this device on the drain side let us go to whiteboard so what happens is there is slight overlap between source drain and gate regions so when you apply some voltage on the gate when you apply some voltage on the gate there is some change in potential the the depletion region over here in this region such that there is higher leakage in the drain why why are we only talking about the rain because rain is at a higher voltage source and body are typically connected shorted but drain and body are at different potentials so because of the electrostatic contours changing shape near the drain region when you apply gate voltage you see that the drain leakage increases and that is reflected by this curve there that is reflected by this red red shaded region in the curve there okay this is called as gate induced drain leakage so we've looked at different kinds of leakages till now now if i now if i say that i want to uh how do i put it if i say that i want to now reduce overall leakage in the system what all levers do you think we have hello just start effect huh can you start basically stacking okay you can stack the body of it due to which the body effect will come okay what else so i mean we can connect the body to different voltages if it is possible we can connect the body to different voltages if possible for the p pmosses it may be possible by again losing a lot of area and mosses you will need to lose a lot lot more area to be able to do that but let us say we we still are able to create some voltage islands where we say that substrate voltages for inactive islands you would want to keep at a different level so that leakage reduces so that is body biasing across uh clustered body biasing across different uh circuit regions huh yes okay what else can you do maybe may be thicker oxides thicker oxides okay but super oxides you will see that it will lead to change in speed the speed would be great so long channel devices and high cadillacs yes long channel devices high k dielectrics yes so that gate leakage reduces but a very important technique that you use is what is called as power gating so when your entire circuit when your entire circuit you know that is not going to be operated you put a set of these sleep transistors or header switch transistors on vdd so your power gated block does not directly get vdd it gets a new supply which is virtual vdd or vddv okay when you know that this particular block is is going to be off or not operational you can simply switch off these pmoses you can take sleep to one and when you take sleep to one what happens the supply the vdd supply is cut off okay what it does necessarily require it that at the output again you put a gating with sleep bar so that outputs do not lead to very high currents in the subsequent stages because the output as you cut off the vdd what happens the outputs of this block will start to vary between 0 and vdd will no longer be at 0 or vdd they will be anywhere which can lead to high short circuit currents in the subsequent stages to prevent that what do you do you put these and gates how do you isolate the outputs okay now it appears that this would reduce leakage yes it will reduce leakage but you should activate sleep modes only when you are doing it for a sufficient amount of time because toggling the sleep pin will in itself is at the heat it's a huge capacitance the sleep would be running all over the place it is a huge capacitance and toggling the sleep pin in itself will consume some current so that should not exceed the current that you are saving okay so what is this output what output i am taking here out from here i mean this would be the power gated block would be my pdn or the pdf pull up or to pull down it so let us say the power gated block only had the nand gate okay okay completely so like we're saying in terms of the complete gate not like the pull down on the pull up i'm talking about a power gated block which means i am talking about the full processor okay okay i'm talking about a full memory there for example okay okay okay so that is where we did not say a circuit we set a block yeah yes uh details okay yeah if there was a question so even after i found it i will still some previous stage will still be providing some inputs right here let the inputs come so i am not using the outputs of this block i anyway i'm not using the outputs of this block so let the inputs come if my vdd is not connected it will not lead to any power consumption is it still gate leakage will still be there because yeah you cannot control this so full memory inputs are just going to 20 gates if we are putting a condition on immediately then even we are removing our stack effect right sir we are adding a stack effect this vdd v is something like v x is it not yes sir we are adding a stack effect we will need to size our circuits slightly differently so that this or we'll have to have a huge capacitance on vddv so that after power up when you want to actually operate the circuit stack effect doesn't appear in the delays [Music] okay okay so that this vddv is almost equal to vdd in active mods okay so okay so what we looked at today was three kinds of leakages static power being governed by sub threshold leakage gate leakage and junction leakage we looked at uh scaling effects like uh dibl gidl and we talked about high k dielectrics also that we use high k dielectrics so that physical gate oxide thickness can be higher and gate leakage can be reduced and to reduce leakage we discussed about using high vt lowering vdd we already discussed in the last class also body effect large lengths you mentioned and then we also talked about sleep transistors towards the end okay so yes so i have a doubt in the previous slide okay yeah so uh we we are adding this p moses to uh cut off the connection between vdd and the power we are our logic right yeah now when these female p masses are turned off so there would be some sub threshold leakage also in those pmoses so yeah and that will come but overall leakage will reduce now for our logic the leakage will reduce but that uh threshold leakage of those p masses so it is again the same thing look at it like this there will be a kcl that will apply yes sir so if the power gated block does not does not allow syncing more current how will more current go okay okay okay equilibrium 
limit"
whDILV2AOyQ,to our next section which is where your project also is we're talking about combinational logic design so in this combination of circuit design let us first understand what is the difference between combinational circuit and sequential circuit who will tell me sir output of combinational circuit only depends on the present inputs and the output of a sequential circuit depends upon present input as well as the previous input zones okay which which what is an example of a sequential circuit any fsm uh that we design sequence detector maybe no let us say circuits that you know of already you know you use them already flip flop latch and flip flop flip flops they're all sequential circuits and combinational circuit any basic comparator normal gate and gate better universal all these gates they are all combinational circuits so we'll first look at combinational logic design in this class and the next one then we will move to sequential circuit design in the in the class after that okay so in terms of combination but in the combination of circuit design then you have two different design styles most common two different design styles we'll look at other design styles also but most common styles are static cmos and dynamic so static cmos all of us know yes what is dynamic logic said in this logic we use a clock and we do not we do not use a pmos uh circuit here we use only nmos and use the pmos and nmos for giving a clock uh above and below the end logic after we can do it in two ways we can have a pull-up network or we can have a pull-down network we'll be changing our output position however regarding that uh and the main issue with this dynamic logic is that okay advantage is that area gets reduced at first and issue is that we'll have some rays around conditions and uh cascading conditions okay so we'll anyways look into much more detail in dynamic logic later but whenever we call dynamic logic whether it is even you know memory cell for example if it's a static memory then you have a 60 transistor memory cell if it's a dynamic memory then you have dynamic ram then you have a capacitor on which you will store charge so in dynamic logic there will be some some time some input combinational state where the output is not driven by anything else but is dependent on some charge stored on some capacitance so i mean the output logic will depend upon the char stone and capacitor at some point yeah output will be output will be driven because of some charge stored on some capacitor now if by some reason either because of leakage or because of crosstalk or because of some other reason that charge gets dissipated there is no way to recover that charge during the cycle and you lose data you lose you get incorrect output but during the static also the voltage the ca output is observing that only will transfer the logic to the other stage in a static cmos let us say a nand gate if there is some noise on one of the inputs will the output change okay it may have a glitch output may have a glitch but it will again come back to the original correct state is it not let us say i gave a small glitch on the input a of a nand gate there would be small glitch on the output but it will only be a glitch for a dynamic logic gate it will not get a glitch you give a glitch on the input and you will have a permanent voltage loss at the output don't worry we will see we will see this in much more detail and probably the next class but for now just remember just remember that and static cmos we are not depending we are not leaving anything to chance we actually always have a pull-up network or a pull-down network that is on so the output is always driven and dynamic logic the output may not always be driven and there will be times when the output is driven is is only because of some charge stored on some capacitor is this okay so so the charge so the capacitance drives the output or the capacitance just defines what the output state is yeah it could be it could be anything so you may have a series of inverters after this capacitance so we say okay the capacitance only drives the output but this capacitance could be the output directly so like there could be an amplifier that uh that define that actually drives some other output based on the capacity in the value stored on charge stored on capacitance yeah so is it something like that or it can directly drive let's say an inverter without any amplifier in between yeah it can directly have an inverter your dynamic gate could be could be input it could be an input to an inverter yes okay so in that case as soon as inverter reads there is a chance that this dynamic logic will discharge uh where in a cmos gate does the gate consume any power leak itself leakage will take years lots of time gate leakage is relatively much lesser than any other form of leakage [Music] so good good that you're thinking on those lines but yes i understand that you do not have the the the order of magnitude of these different components yet readily available to you so you can assume this i'm fine so don't feel bad key i gave you a different answer it's fine but that really is not that big of a botheration mother gate leakage is not really that big a moderate botheration so dynamic logic is still very widely used okay sir so i can drive a static logic by our dynamic output as well yes okay you can write static logic with a dynamic input but dynamic and dynamic logic itself has some weaknesses we will look at that in the next session it has some weaknesses and then you will need to take care of them so how many of you are actually designing a dynamic aoi or oi in your in your project put a plus one in the chat window if you are oh okay someone yeah so you will see that you will have to take care of this capacitance and you will have to check the noise immunity of your gate we will look at various various failure modes of dynamic logics you will need to just analyze your circuit accordingly okay sir i was asking that uh if even if the dram cell is not an object it is still called dynamic one it's called dynamic ram cell yes not logic dynamic dynamic because it's storing something on a capacitor and you need to refresh it you need to ensure that some leakage or whatever has happened it is kind of recovered on a regular basis yes ok so this much you know that in a static cmos there is a pull-up network and a pull-down network and that pull-up network and pull-down network are duals of each other all of you even in your assignment or somewhere else you must have seen this you already checked this in the in your exam also am i right so pull up network and pull down network are duals of each other what does this mean when one is on method okay when the pull-up network is driving then the pull-down network will be off and vice versa yes sir but how how do you make a dual sir the series transistor in n was parallel uh in in the pmos that is dual so uh the dual of a series transistor would be uh parallel transistors on the pmos side and vice versa for example in a nand gate you have n moses in series and you get a and b on the pmo side you have a parallel b and a two input nand gate you remember how is the two input nand gate made bit so in a two input nand gate you have pmos is in parallel and nmos is in series what has happened here something is happening so when when this uh so this is called a dual where the same logic is implemented as it is implemented in series in the inverses it is implemented as parallel in the pmoses and vice versa something which is implemented as uh parallel in the moses will be implemented as series in the p masses this part is clear friends yes sir okay so if i use if i connect uh n masses in the pull-up network then what happens vt drop happens and output cannot go up a vdd minus vt yes vg-dops happens and output cannot go above vdd minus vt similarly if i put a pmos on the pull down network what happens it cannot drive a proper zero it cannot drive a proper zero it will drive it only down to bt vt so this vt drop is something that you should always be alert about especially when you're driving even you are designing ptl logic so pto voters ptl we will see but when you're designing pass transistor logic uh ptl logic these uh voltage drops is something that you need to be extremely careful about okay we will look into it in detail later okay so bt drop means that we should not put the nmos in the vdn pull up network the nmos will have will have to be put in the pull-down network when the n-mast is in the pull-down network your output will go to zero otherwise the output will only go to vtp it will not be able to go down to full zero but but then why would you call it dt drop the threshold i mean because that is what happened now zero was expected to be transferred here but zero could not be transferred it got limited by the vt of this pmos okay is that okay so i need to do something with the ppt it kind of gets hanged every now and then i am not able to move there so this is one thing that we need to be alert about that there will be vt drops across the enos and pmos when they are used to transmit vdd and ground respectively okay because the p mass cannot transmit a a good ground a good zero and n mass cannot transmit a good one okay so just give me a moment if it is again opening up so when we talk of complementary cmos oh you're not able to see the slide yet am i right is my slide visible now it's visible okay so we say that pull up network is a dual of the pull-down network in a complementary cmos type and cmos is always an inverting gate if you want to implement an and gate you will have to first implement implement a nand gate and only then you will be able to implement the and gate okay so you will have you can implement inverted gates in one gate in one stage but non-inverting gates require two stages okay so this much we know i will quickly move forward any doubt in this one how to make an and gate we've already done so much of it nor gate we know nor get all of us know yes sir so if i talk of a complex cmos gate like this how would my dual the pmos network look like quickly this also i know you know sir b and c in series sir it's in parallel with a and the whole structure is parallel with anyone else has a different view or is vaishnav correct is it clear so the dual the pima site would mean that since d is parallel over here d goes in series a which was in series earlier comes in parallel and b and c which were in parallel in the nmos stack come in series okay so this would be the complex cmos gate this is like the aoys and ois that you are going to design so how to construct a complex gate first design the pull down network and then after by looking at the pull-down network you design the pull-up network okay and uh logical effort of complex gates uh are you able to see we've already done this we've already seen this slide earlier also you remember we have seen this slide and we're looking at uh the first time when we looked at the g and the h thing huh yes hello yeah so the logical effort of these gates can also be calculated in exactly the same manner as we did for the first complex gate so who will give me the value of gc or gd now 6 by 3 6 by 3 again what about p 12 by 3 12 by 3 12 by 3 great uh what about now ga over here five but what about gb eight by three what are you doing the sizing has been done yeah okay so we've ensured that the equivalent resistance of the inverter is same come whatever be the case okay so how do you estimate the delay of a complex gate like if i make a complex gate versus i make a two uh other thing what do you expect in terms of delay yeah so for this the overall h let us say is 10 b is 1 there are no branching happening anywhere and number of states is 2 in both the cases so what would be the different delays can you find out by using a logical effort analysis so this is possible only if we give our output of c load right the load has been told now 160 units okay okay okay sorry yes so we see okay p is two plus two g we know nand gates four by three four by three uh nor gate on the other side and then gbh is something like this and i get the delay to be 12.4 tau i am going quickly because this is already done what about this one in this case there is a four input first gate and one input second gate so four plus one five what about g you can quickly make this gate and find out find out its g you will see that g is equal to 2 f is gbh so 20 because h is h is 10 over here and what about total delay now total delay has increased a little appears to increase a little 14 top then why are we talking about complex gates if the delay has increased a little why are we talking about complex gates so the area reduces very significantly area reduces very significantly huh and how do we see that in the first case you say that eight eight eight eight eight eight eight eight and 25 25 25 25 you just do this analysis and what about the second one see the area is reduced to 36 ah no no no sorry area is not reduced to 36 the second stage is 36 the first stage is uh 40 plus 24 that is input capacitance right yeah input capacitance you're saying is also a measure of area now no okay sorry yes is it not yes sir yeah so in the first first case what is the area eight and eight devices of eight microns each to sixty four plus four of twenty five eight so one sixty four in the second case what is the area 16 into 4 plus 36 64 36 100 so area has reduced so significantly 164 versus 100 so even if delay increase by that little amount in reality because my area is so much lesser the parasitics and everything will be lesser so in fact delay of a complex gate is also lesser okay so this is one thing in reality so this is one thing you have to prove in your projects you know this man should have a question yes sir if we if i have a gate at the complex gate which has a different g value for different uh different inputs so which which one will i take the worst g or the best g for the calculation of delay oh yeah so for calculation of propagation delay you will take the first g okay then contain elimination the best g yes ana now this is anyways calculations yes sir in project you are saying that okay we are supposed to compare this both so are we supposed to make the layout of both or only one is enough sir so how will you prove to me that area is okay yeah you can still say numbers are higher but how will you prove to me that delay is lesser delay is also lesser in the complex gate if you don't make the layout that i can say that only parasitic is small so i'll click that and peel out between how will you prove to me how will you prove to me i am also saying now okay yes yes sir one small thing so for making the layouts of non-complex gates so if you are cascading one nand gate after the other so i think metal layers would get blocked right again so atmos you may need one method to to make those connections use then only for that purpose use metal tool okay yes only for that purpose so you should be evident in that like when you show the layout it should be evident there yes okay so do you think this input order matters yes it matters so where will the propagation delay be highest which input to output delay will be highest a2 a2 or b2y if b arrives later if b has an input so see your nand gate is being driven by some other logic somewhere so if b arrives later then should b be connected to the lower and most or the upper end mass uppercut then you should connect b to the upper end mass so that what happens we can buy the output yes okay so input order we understand matters then uh okay this we already discussed yes please so why was the delay for b2 by the highest i mean wouldn't it depend on is it falling delay or raising daily yeah we were looking at the nmr stack rising for i mean when the output is rising now or when the output is falling we will have for different delays for a and b for different stimuli we will get the worst case stage even then let us look at it like this even if it is a rising delay it was zero earlier you took a to zero so now what is the capacitance that needs to be charged only the capacitance on y input by output am i right now so what's the stimuli that you're given it was output was zero initially so both a and b were one yes now i took a to 0 so that y charges to 1 that is what you want to see now price delay yes so now what is the delay what is the rc emas 2 and output is in this case b will give b will give the worst case in that case okay so let us say the output is to fall yes sir then what is the worst case this means that if a was only already one or if b was already one the other input now goes to one yes sir which one has more delay so if a changes then if a was already one then what has happened so now also vdd x is also charged to vdd or we really minus vt in fact yes okay so in both cases b is the most case yeah okay is that clear yes sir uh sir uh just to add up on this the input order also matters because uh if i consider a function a y is equal to a to b plus c then we'll have if we attach the parallel connection of v and c to the output then we'll have more capacitive capacitive loading with output so that has to be connected to the ground whereas a should be connected to the output right so method uh runs it what i'm saying is that even in a two input gate so input simple to input nand gate even there the input which is closer to the output should be the one that is arriving late yes yes sir in a simple circuit like a nand gate i'm telling you this that order demand order matters yes sir in a complex circuit you're absolutely right bang on output definitely matters yes sir okay all of us understand why it matters any questions around that please yes sign me what exactly was uh being discussed i was not able to get ranjit was if it's a complex gate it matters still more because then that will change the intermediate like suppose if it's a and b parallel and c in series in the nmo stack so if i put c above on y if y is directly connected like the first the series in transistor c is connected to the output and a r b are in parallel connected to ground then there would be one delay and if i have a different structure where a and b are in parallel connected to y and c is in series connected to ground that will have a different delay for different like there will be different delays for a b and c to output in these two structures and you have to design appropriately experiment you will see so and you are saying that the closest the input closer to the output should arrive the latest right for a nand gate yes whichever input has shortest delay should be designed to be arriving last in your path in this particular example if you have if you know that there are two inputs a and b if you know that the first input is arriving faster that first input should be connected to b but in that case if you are considering the propagation thing so the capacitance between these two uh that will discharge if it arrives fast and yeah i'm gonna get the propagate will not get the verse delay then basically yeah yeah we're not characterizing now now we are designing a path you want the delays to reduce in a past month okay okay fine okay we've moved we have graduated from characterization to designing okay so now we are ordering the input such that we get the least delays least delay in my path just like for logical effort the intent was to get least delay unless the least area in the path okay so but then in that case we will also be ha the specification will also specify okay how the signals are arriving right yeah yeah so for example if i ask you to make an adder you will know how the signals will arrive first which will arrive late yes okay you are a designer it is not about designing one gate knight is then designing a path similarly you can actually make gates asymmetric so that the non critical input may have higher load for example in this case reset bar has higher load and a critical input a has lower load so overall load of this gate would increase but the delay for signal a would reduce significantly are you able to see this see my a signal was arriving late a signal is on a critical path reset is something which like sleep in or something which already is there static signal already there so you let the reset bar come and then for a because that is the actual critical path the critical input you reduce the delay very significantly by reducing the size of the cent mass are you able to see this so if you're making full custom paths then you may want to design asymmetric gates also so that you reduce total delays are you with me any questions and this critical thing wasn't clear like the path of critical path for over here would mean path which has the largest delay so a was coming from a path which had the largest delay yes so okay a was coming last so i wanted to put a closer to the output that i already did now i want to improve performance further okay what i did was i reduced the load on load on a also so that a can arrive a little faster and i increase the load on reset bar sir how did you share the load between a and reset sir share the load i reduce the load i reduced the load of a so resistance of a increased i then said okay let me increase the size of b so that i still get the same equivalent resistance as an inverter or a regular nand gate okay okay sir yes okay yes sir sir if this is fine that you reduce the load for a but sir now y node will also take more time to discharge to the by three uh nmos which could which could be a faster discharge through four and more so wait wait wait look at it like this had it not been four by three i would have designed two and moses of resistance uh off of size 2 is so my overall resistance would have been r now what is the overall resistance now 3 by 4 r plus r by four it still is r okay so you have upsized the reset also and uh fine yes otherwise it would happen too no to yes size two so the overall area you have increased but the delay you have reduced huh and you could actually also have symmetric gates designed so you had two n masses each was two microns but your both the inputs were coming randomly at same time so you said oh i want to give equals equal delay from a to y and b to y so you make a symmetric gate like this one micron of a is closer to the output one micron of b is closer to the output the other one micron is far farther from the output you able to see this any questions on this this also so we are just reducing the load over here right we've not reduced the load over here and must be was supposed to go to a nmos which was total size 2 it is still going to total size 2. i've just changed rearrange the envelopes in such a way that equal strength of an a and b n masses is closer to y and equal strength of a and b and masses is closer to ground that's all i've done okay and you can actually also make skewed gates and i'm just taking this through because this is kind of uh very simple and the last slide on cmos okay you can also make skewed gates if you want to say that i want to favor rising outputs over because you know for example in an adder carry out carry equal to one you want to bring up faster carry goes to zero you can come bring it down later also so you know that one path is faster or let us say even a comparator a 20-bit comparator so zorgates connected to one another you know that falling would anyway be fast rising is something that will take time so i want tries to be faster so you can actually skew the sizing so that when you screw the sizing what happens your transfer characteristics shift to the left or to the right i'm not able to draw this on my screen i'm surprised by so questions here what happens when i ask you are you able to see the benefit of skewed logic any questions around that sir but this brings an overhead with a noise merging being affected right yes yes yes yes so even you know when i went to asymmetric gates noise margin could have been impacted but this increases uh the effect on the noise margin with a greater direction right so because any glitch can change the output attaining itself yes yes yes but for my preferred side i get a faster output for example if there is a signal which is which is continuously recharged to one and i want to sense when it falls yeah this can get that way first of all i want to sense it and i want to have this kind of a skewed logic yes sir i know yes sir sir okay so actually i'm not able to get this concept actually can you this of skewed gates like exactly what in here early i was able to get like an earlier we were reducing the load so now let us say let us say that i am in the first gate i am interested in output going to one output falling i am not bothered about in my state machine output going to one has a very significant role to play we're talking about a state machine here where one transition is more important than the other charging basically is more important for me than this yeah let us say that y rising is more important than by falling in the first case so what happens now the total load of a has reduced are you able to see this total load of a has reduced can you see this instead of 3 that is 2 of pmos and 1 of n mass i now have 2.5 total load additionally i said that because this load has reduced a will now transition faster and therefore my output will also transition faster i've also skewed so nmos will now have lesser on current and i will be able to take y to one level much faster so two ways i am benefiting in terms of rising of y so one was that the load was getting reduced so transitions faster but what's the other benefit to you so in the in the transfer characteristic i have shifted this i have because i have made nmos smaller than the strength of n was smaller than the strength of the p mass so my switching will happen faster now earlier at a lower value of in fact at a still higher level of a i will start to have y rising because nmos will not be able to conduct as much current as the pmos will be able to sync provide do you remember the skew the skewed invertebrates yes uh you mean that uh shift that kind of shift exactly that's it that would happen yeah but that was impacting for the noise margins i mean that is also impacting the delays that is what i am telling you okay so how will that impact the noise margin because it will just shift but not change the slow now a very small disturbance on a will also cause output y to double [Music] y is more i mean so we define noise margin as 45 degree slope for that around region c so that region c is only shifting but it is not changing its slope so what was the noise margin the noise margin was 45 degree slope while a point two zero or one so again if you repeat that please it was the point where you get that 45 degree slope just let's go to the white board we were saying that we set this point and this point yes they define my noise margin points so what is the noise margin this is the noise margin so if i have shifted this curve here if i have shifted this curve here this 45 degree or a point has shifted here so the noise margin has reduced now okay got it i understood noise margin wrong okay so when you skew when you use q gates the noise margin gets degraded okay and you could have high skew lowest q but you could you could design both the sides okay so we will stop here we have covered these concepts today we talked about uh uh static cmos where pull-up network is a dual of pull-down network we talked that complex gates are denser they are low power and they have equivalent speed we blocked about the importance of input orders symmetric and asymmetric gates and also skewed gates next class will start to talk about different logic styles ratio logic pass transistor logic and other styles okay so we will close the class today it's already beyond the class time i know this i'm sorry for that but we had more discussion and there were that was an important discussion so we didn't stop that there okay thank you guys all the best stop the recording so just before even uh when we were uh when you're saying that the input ordering when we're considered when you explain the input ordering concept we were basically more focused towards we were basically in the concept of the critical part critical delays we were discussing yes but when we were discussing the secured one it was in the context of like favoring like if that yeah now you're talking about critical path not just in terms of path but also in terms of this direction we want the transition to happen they're being very very specific so like it will be over and above that yes yes okay,https://www.youtube.com/watch?v=whDILV2AOyQ,"Link: https://www.youtube.com/watch?v=whDILV2AOyQ
Transcript: to our next section which is where your project also is we're talking about combinational logic design so in this combination of circuit design let us first understand what is the difference between combinational circuit and sequential circuit who will tell me sir output of combinational circuit only depends on the present inputs and the output of a sequential circuit depends upon present input as well as the previous input zones okay which which what is an example of a sequential circuit any fsm uh that we design sequence detector maybe no let us say circuits that you know of already you know you use them already flip flop latch and flip flop flip flops they're all sequential circuits and combinational circuit any basic comparator normal gate and gate better universal all these gates they are all combinational circuits so we'll first look at combinational logic design in this class and the next one then we will move to sequential circuit design in the in the class after that okay so in terms of combination but in the combination of circuit design then you have two different design styles most common two different design styles we'll look at other design styles also but most common styles are static cmos and dynamic so static cmos all of us know yes what is dynamic logic said in this logic we use a clock and we do not we do not use a pmos uh circuit here we use only nmos and use the pmos and nmos for giving a clock uh above and below the end logic after we can do it in two ways we can have a pull-up network or we can have a pull-down network we'll be changing our output position however regarding that uh and the main issue with this dynamic logic is that okay advantage is that area gets reduced at first and issue is that we'll have some rays around conditions and uh cascading conditions okay so we'll anyways look into much more detail in dynamic logic later but whenever we call dynamic logic whether it is even you know memory cell for example if it's a static memory then you have a 60 transistor memory cell if it's a dynamic memory then you have dynamic ram then you have a capacitor on which you will store charge so in dynamic logic there will be some some time some input combinational state where the output is not driven by anything else but is dependent on some charge stored on some capacitance so i mean the output logic will depend upon the char stone and capacitor at some point yeah output will be output will be driven because of some charge stored on some capacitor now if by some reason either because of leakage or because of crosstalk or because of some other reason that charge gets dissipated there is no way to recover that charge during the cycle and you lose data you lose you get incorrect output but during the static also the voltage the ca output is observing that only will transfer the logic to the other stage in a static cmos let us say a nand gate if there is some noise on one of the inputs will the output change okay it may have a glitch output may have a glitch but it will again come back to the original correct state is it not let us say i gave a small glitch on the input a of a nand gate there would be small glitch on the output but it will only be a glitch for a dynamic logic gate it will not get a glitch you give a glitch on the input and you will have a permanent voltage loss at the output don't worry we will see we will see this in much more detail and probably the next class but for now just remember just remember that and static cmos we are not depending we are not leaving anything to chance we actually always have a pull-up network or a pull-down network that is on so the output is always driven and dynamic logic the output may not always be driven and there will be times when the output is driven is is only because of some charge stored on some capacitor is this okay so so the charge so the capacitance drives the output or the capacitance just defines what the output state is yeah it could be it could be anything so you may have a series of inverters after this capacitance so we say okay the capacitance only drives the output but this capacitance could be the output directly so like there could be an amplifier that uh that define that actually drives some other output based on the capacity in the value stored on charge stored on capacitance yeah so is it something like that or it can directly drive let's say an inverter without any amplifier in between yeah it can directly have an inverter your dynamic gate could be could be input it could be an input to an inverter yes okay so in that case as soon as inverter reads there is a chance that this dynamic logic will discharge uh where in a cmos gate does the gate consume any power leak itself leakage will take years lots of time gate leakage is relatively much lesser than any other form of leakage [Music] so good good that you're thinking on those lines but yes i understand that you do not have the the the order of magnitude of these different components yet readily available to you so you can assume this i'm fine so don't feel bad key i gave you a different answer it's fine but that really is not that big of a botheration mother gate leakage is not really that big a moderate botheration so dynamic logic is still very widely used okay sir so i can drive a static logic by our dynamic output as well yes okay you can write static logic with a dynamic input but dynamic and dynamic logic itself has some weaknesses we will look at that in the next session it has some weaknesses and then you will need to take care of them so how many of you are actually designing a dynamic aoi or oi in your in your project put a plus one in the chat window if you are oh okay someone yeah so you will see that you will have to take care of this capacitance and you will have to check the noise immunity of your gate we will look at various various failure modes of dynamic logics you will need to just analyze your circuit accordingly okay sir i was asking that uh if even if the dram cell is not an object it is still called dynamic one it's called dynamic ram cell yes not logic dynamic dynamic because it's storing something on a capacitor and you need to refresh it you need to ensure that some leakage or whatever has happened it is kind of recovered on a regular basis yes ok so this much you know that in a static cmos there is a pull-up network and a pull-down network and that pull-up network and pull-down network are duals of each other all of you even in your assignment or somewhere else you must have seen this you already checked this in the in your exam also am i right so pull up network and pull down network are duals of each other what does this mean when one is on method okay when the pull-up network is driving then the pull-down network will be off and vice versa yes sir but how how do you make a dual sir the series transistor in n was parallel uh in in the pmos that is dual so uh the dual of a series transistor would be uh parallel transistors on the pmos side and vice versa for example in a nand gate you have n moses in series and you get a and b on the pmo side you have a parallel b and a two input nand gate you remember how is the two input nand gate made bit so in a two input nand gate you have pmos is in parallel and nmos is in series what has happened here something is happening so when when this uh so this is called a dual where the same logic is implemented as it is implemented in series in the inverses it is implemented as parallel in the pmoses and vice versa something which is implemented as uh parallel in the moses will be implemented as series in the p masses this part is clear friends yes sir okay so if i use if i connect uh n masses in the pull-up network then what happens vt drop happens and output cannot go up a vdd minus vt yes vg-dops happens and output cannot go above vdd minus vt similarly if i put a pmos on the pull down network what happens it cannot drive a proper zero it cannot drive a proper zero it will drive it only down to bt vt so this vt drop is something that you should always be alert about especially when you're driving even you are designing ptl logic so pto voters ptl we will see but when you're designing pass transistor logic uh ptl logic these uh voltage drops is something that you need to be extremely careful about okay we will look into it in detail later okay so bt drop means that we should not put the nmos in the vdn pull up network the nmos will have will have to be put in the pull-down network when the n-mast is in the pull-down network your output will go to zero otherwise the output will only go to vtp it will not be able to go down to full zero but but then why would you call it dt drop the threshold i mean because that is what happened now zero was expected to be transferred here but zero could not be transferred it got limited by the vt of this pmos okay is that okay so i need to do something with the ppt it kind of gets hanged every now and then i am not able to move there so this is one thing that we need to be alert about that there will be vt drops across the enos and pmos when they are used to transmit vdd and ground respectively okay because the p mass cannot transmit a a good ground a good zero and n mass cannot transmit a good one okay so just give me a moment if it is again opening up so when we talk of complementary cmos oh you're not able to see the slide yet am i right is my slide visible now it's visible okay so we say that pull up network is a dual of the pull-down network in a complementary cmos type and cmos is always an inverting gate if you want to implement an and gate you will have to first implement implement a nand gate and only then you will be able to implement the and gate okay so you will have you can implement inverted gates in one gate in one stage but non-inverting gates require two stages okay so this much we know i will quickly move forward any doubt in this one how to make an and gate we've already done so much of it nor gate we know nor get all of us know yes sir so if i talk of a complex cmos gate like this how would my dual the pmos network look like quickly this also i know you know sir b and c in series sir it's in parallel with a and the whole structure is parallel with anyone else has a different view or is vaishnav correct is it clear so the dual the pima site would mean that since d is parallel over here d goes in series a which was in series earlier comes in parallel and b and c which were in parallel in the nmos stack come in series okay so this would be the complex cmos gate this is like the aoys and ois that you are going to design so how to construct a complex gate first design the pull down network and then after by looking at the pull-down network you design the pull-up network okay and uh logical effort of complex gates uh are you able to see we've already done this we've already seen this slide earlier also you remember we have seen this slide and we're looking at uh the first time when we looked at the g and the h thing huh yes hello yeah so the logical effort of these gates can also be calculated in exactly the same manner as we did for the first complex gate so who will give me the value of gc or gd now 6 by 3 6 by 3 again what about p 12 by 3 12 by 3 12 by 3 great uh what about now ga over here five but what about gb eight by three what are you doing the sizing has been done yeah okay so we've ensured that the equivalent resistance of the inverter is same come whatever be the case okay so how do you estimate the delay of a complex gate like if i make a complex gate versus i make a two uh other thing what do you expect in terms of delay yeah so for this the overall h let us say is 10 b is 1 there are no branching happening anywhere and number of states is 2 in both the cases so what would be the different delays can you find out by using a logical effort analysis so this is possible only if we give our output of c load right the load has been told now 160 units okay okay okay sorry yes so we see okay p is two plus two g we know nand gates four by three four by three uh nor gate on the other side and then gbh is something like this and i get the delay to be 12.4 tau i am going quickly because this is already done what about this one in this case there is a four input first gate and one input second gate so four plus one five what about g you can quickly make this gate and find out find out its g you will see that g is equal to 2 f is gbh so 20 because h is h is 10 over here and what about total delay now total delay has increased a little appears to increase a little 14 top then why are we talking about complex gates if the delay has increased a little why are we talking about complex gates so the area reduces very significantly area reduces very significantly huh and how do we see that in the first case you say that eight eight eight eight eight eight eight eight and 25 25 25 25 you just do this analysis and what about the second one see the area is reduced to 36 ah no no no sorry area is not reduced to 36 the second stage is 36 the first stage is uh 40 plus 24 that is input capacitance right yeah input capacitance you're saying is also a measure of area now no okay sorry yes is it not yes sir yeah so in the first first case what is the area eight and eight devices of eight microns each to sixty four plus four of twenty five eight so one sixty four in the second case what is the area 16 into 4 plus 36 64 36 100 so area has reduced so significantly 164 versus 100 so even if delay increase by that little amount in reality because my area is so much lesser the parasitics and everything will be lesser so in fact delay of a complex gate is also lesser okay so this is one thing in reality so this is one thing you have to prove in your projects you know this man should have a question yes sir if we if i have a gate at the complex gate which has a different g value for different uh different inputs so which which one will i take the worst g or the best g for the calculation of delay oh yeah so for calculation of propagation delay you will take the first g okay then contain elimination the best g yes ana now this is anyways calculations yes sir in project you are saying that okay we are supposed to compare this both so are we supposed to make the layout of both or only one is enough sir so how will you prove to me that area is okay yeah you can still say numbers are higher but how will you prove to me that delay is lesser delay is also lesser in the complex gate if you don't make the layout that i can say that only parasitic is small so i'll click that and peel out between how will you prove to me how will you prove to me i am also saying now okay yes yes sir one small thing so for making the layouts of non-complex gates so if you are cascading one nand gate after the other so i think metal layers would get blocked right again so atmos you may need one method to to make those connections use then only for that purpose use metal tool okay yes only for that purpose so you should be evident in that like when you show the layout it should be evident there yes okay so do you think this input order matters yes it matters so where will the propagation delay be highest which input to output delay will be highest a2 a2 or b2y if b arrives later if b has an input so see your nand gate is being driven by some other logic somewhere so if b arrives later then should b be connected to the lower and most or the upper end mass uppercut then you should connect b to the upper end mass so that what happens we can buy the output yes okay so input order we understand matters then uh okay this we already discussed yes please so why was the delay for b2 by the highest i mean wouldn't it depend on is it falling delay or raising daily yeah we were looking at the nmr stack rising for i mean when the output is rising now or when the output is falling we will have for different delays for a and b for different stimuli we will get the worst case stage even then let us look at it like this even if it is a rising delay it was zero earlier you took a to zero so now what is the capacitance that needs to be charged only the capacitance on y input by output am i right now so what's the stimuli that you're given it was output was 
zero initially so both a and b were one yes now i took a to 0 so that y charges to 1 that is what you want to see now price delay yes so now what is the delay what is the rc emas 2 and output is in this case b will give b will give the worst case in that case okay so let us say the output is to fall yes sir then what is the worst case this means that if a was only already one or if b was already one the other input now goes to one yes sir which one has more delay so if a changes then if a was already one then what has happened so now also vdd x is also charged to vdd or we really minus vt in fact yes okay so in both cases b is the most case yeah okay is that clear yes sir uh sir uh just to add up on this the input order also matters because uh if i consider a function a y is equal to a to b plus c then we'll have if we attach the parallel connection of v and c to the output then we'll have more capacitive capacitive loading with output so that has to be connected to the ground whereas a should be connected to the output right so method uh runs it what i'm saying is that even in a two input gate so input simple to input nand gate even there the input which is closer to the output should be the one that is arriving late yes yes sir in a simple circuit like a nand gate i'm telling you this that order demand order matters yes sir in a complex circuit you're absolutely right bang on output definitely matters yes sir okay all of us understand why it matters any questions around that please yes sign me what exactly was uh being discussed i was not able to get ranjit was if it's a complex gate it matters still more because then that will change the intermediate like suppose if it's a and b parallel and c in series in the nmo stack so if i put c above on y if y is directly connected like the first the series in transistor c is connected to the output and a r b are in parallel connected to ground then there would be one delay and if i have a different structure where a and b are in parallel connected to y and c is in series connected to ground that will have a different delay for different like there will be different delays for a b and c to output in these two structures and you have to design appropriately experiment you will see so and you are saying that the closest the input closer to the output should arrive the latest right for a nand gate yes whichever input has shortest delay should be designed to be arriving last in your path in this particular example if you have if you know that there are two inputs a and b if you know that the first input is arriving faster that first input should be connected to b but in that case if you are considering the propagation thing so the capacitance between these two uh that will discharge if it arrives fast and yeah i'm gonna get the propagate will not get the verse delay then basically yeah yeah we're not characterizing now now we are designing a path you want the delays to reduce in a past month okay okay fine okay we've moved we have graduated from characterization to designing okay so now we are ordering the input such that we get the least delays least delay in my path just like for logical effort the intent was to get least delay unless the least area in the path okay so but then in that case we will also be ha the specification will also specify okay how the signals are arriving right yeah yeah so for example if i ask you to make an adder you will know how the signals will arrive first which will arrive late yes okay you are a designer it is not about designing one gate knight is then designing a path similarly you can actually make gates asymmetric so that the non critical input may have higher load for example in this case reset bar has higher load and a critical input a has lower load so overall load of this gate would increase but the delay for signal a would reduce significantly are you able to see this see my a signal was arriving late a signal is on a critical path reset is something which like sleep in or something which already is there static signal already there so you let the reset bar come and then for a because that is the actual critical path the critical input you reduce the delay very significantly by reducing the size of the cent mass are you able to see this so if you're making full custom paths then you may want to design asymmetric gates also so that you reduce total delays are you with me any questions and this critical thing wasn't clear like the path of critical path for over here would mean path which has the largest delay so a was coming from a path which had the largest delay yes so okay a was coming last so i wanted to put a closer to the output that i already did now i want to improve performance further okay what i did was i reduced the load on load on a also so that a can arrive a little faster and i increase the load on reset bar sir how did you share the load between a and reset sir share the load i reduce the load i reduced the load of a so resistance of a increased i then said okay let me increase the size of b so that i still get the same equivalent resistance as an inverter or a regular nand gate okay okay sir yes okay yes sir sir if this is fine that you reduce the load for a but sir now y node will also take more time to discharge to the by three uh nmos which could which could be a faster discharge through four and more so wait wait wait look at it like this had it not been four by three i would have designed two and moses of resistance uh off of size 2 is so my overall resistance would have been r now what is the overall resistance now 3 by 4 r plus r by four it still is r okay so you have upsized the reset also and uh fine yes otherwise it would happen too no to yes size two so the overall area you have increased but the delay you have reduced huh and you could actually also have symmetric gates designed so you had two n masses each was two microns but your both the inputs were coming randomly at same time so you said oh i want to give equals equal delay from a to y and b to y so you make a symmetric gate like this one micron of a is closer to the output one micron of b is closer to the output the other one micron is far farther from the output you able to see this any questions on this this also so we are just reducing the load over here right we've not reduced the load over here and must be was supposed to go to a nmos which was total size 2 it is still going to total size 2. i've just changed rearrange the envelopes in such a way that equal strength of an a and b n masses is closer to y and equal strength of a and b and masses is closer to ground that's all i've done okay and you can actually also make skewed gates and i'm just taking this through because this is kind of uh very simple and the last slide on cmos okay you can also make skewed gates if you want to say that i want to favor rising outputs over because you know for example in an adder carry out carry equal to one you want to bring up faster carry goes to zero you can come bring it down later also so you know that one path is faster or let us say even a comparator a 20-bit comparator so zorgates connected to one another you know that falling would anyway be fast rising is something that will take time so i want tries to be faster so you can actually skew the sizing so that when you screw the sizing what happens your transfer characteristics shift to the left or to the right i'm not able to draw this on my screen i'm surprised by so questions here what happens when i ask you are you able to see the benefit of skewed logic any questions around that sir but this brings an overhead with a noise merging being affected right yes yes yes yes so even you know when i went to asymmetric gates noise margin could have been impacted but this increases uh the effect on the noise margin with a greater direction right so because any glitch can change the output attaining itself yes yes yes but for my preferred side i get a faster output for example if there is a signal which is which is continuously recharged to one and i want to sense when it falls yeah this can get that way first of all i want to sense it and i want to have this kind of a skewed logic yes sir i know yes sir sir okay so actually i'm not able to get this concept actually can you this of skewed gates like exactly what in here early i was able to get like an earlier we were reducing the load so now let us say let us say that i am in the first gate i am interested in output going to one output falling i am not bothered about in my state machine output going to one has a very significant role to play we're talking about a state machine here where one transition is more important than the other charging basically is more important for me than this yeah let us say that y rising is more important than by falling in the first case so what happens now the total load of a has reduced are you able to see this total load of a has reduced can you see this instead of 3 that is 2 of pmos and 1 of n mass i now have 2.5 total load additionally i said that because this load has reduced a will now transition faster and therefore my output will also transition faster i've also skewed so nmos will now have lesser on current and i will be able to take y to one level much faster so two ways i am benefiting in terms of rising of y so one was that the load was getting reduced so transitions faster but what's the other benefit to you so in the in the transfer characteristic i have shifted this i have because i have made nmos smaller than the strength of n was smaller than the strength of the p mass so my switching will happen faster now earlier at a lower value of in fact at a still higher level of a i will start to have y rising because nmos will not be able to conduct as much current as the pmos will be able to sync provide do you remember the skew the skewed invertebrates yes uh you mean that uh shift that kind of shift exactly that's it that would happen yeah but that was impacting for the noise margins i mean that is also impacting the delays that is what i am telling you okay so how will that impact the noise margin because it will just shift but not change the slow now a very small disturbance on a will also cause output y to double [Music] y is more i mean so we define noise margin as 45 degree slope for that around region c so that region c is only shifting but it is not changing its slope so what was the noise margin the noise margin was 45 degree slope while a point two zero or one so again if you repeat that please it was the point where you get that 45 degree slope just let's go to the white board we were saying that we set this point and this point yes they define my noise margin points so what is the noise margin this is the noise margin so if i have shifted this curve here if i have shifted this curve here this 45 degree or a point has shifted here so the noise margin has reduced now okay got it i understood noise margin wrong okay so when you skew when you use q gates the noise margin gets degraded okay and you could have high skew lowest q but you could you could design both the sides okay so we will stop here we have covered these concepts today we talked about uh uh static cmos where pull-up network is a dual of pull-down network we talked that complex gates are denser they are low power and they have equivalent speed we blocked about the importance of input orders symmetric and asymmetric gates and also skewed gates next class will start to talk about different logic styles ratio logic pass transistor logic and other styles okay so we will close the class today it's already beyond the class time i know this i'm sorry for that but we had more discussion and there were that was an important discussion so we didn't stop that there okay thank you guys all the best stop the recording so just before even uh when we were uh when you're saying that the input ordering when we're considered when you explain the input ordering concept we were basically more focused towards we were basically in the concept of the critical part critical delays we were discussing yes but when we were discussing the secured one it was in the context of like favoring like if that yeah now you're talking about critical path not just in terms of path but also in terms of this direction we want the transition to happen they're being very very specific so like it will be over and above that yes yes okay"
8QtpUhabV-A,our combinational logic where we talk about what kind of combinational logic we would be interested to look at for example ratio logic so long back so see one thing is one thing one challenge is static cmos is that for n number of inputs you have two n number of devices huh and of those two hand devices also the pmos that is the half of those two end devices and devices are also larger are you able to see this in a nand gate two input nand gate how many devices do we have two input nand gate how many devices do we have what is four devices in a nor gate how many do we have to input nor gate again four so at least two n devices are there in static cmos and what about the size of nmos and pmos there and the nor gate the pmos size is four times that of the nmr size and an and gate is it is equivalent to nmr size in a two input nand gate so what do we do now we want to look for ah is there a way to reduce the total number of devices why do we want to reduce the total number of devices what's the importance of reducing number of devices area reductions yes and in vlsi area is we want to save gold so we want to reduce area come whatever may so now we will look at a few methods a few techniques to reduce area by for example in this particular slide you will see completely doing away with the pull-up network for example so what do i do instead of all those p mosses i will just put one resistive load what's the problem with one resistive load fabrication is difficult okay so when you say that instead of static cmos i will put any other load whether it is resistive load or depletion load or pmos load since that load is always on since that load is always on what happens we will observe leakage we will observe continuous static current from vdd to vss and different types of designs were proposed resistive loads so in technologies when pmosses were not available then resistive loads or depletion loads were the only options to be used once the pmoses started to become available then pmos loads were used but these pmos loads were always on now we just saw that by using these always on loads or resistances and depletion loads what is the challenge that we expect that the output will not go to pure zero it cannot because pmos is always on some current some current will come either from rl or the pmos or the diffusion load that we have put are you with me on this any questions still here hello you can put a plus one or something in the chat window if you don't want to unmute and speak now i will not move forward until i get a feedback is that one thing sir if the load is big enough then we can obtain kind of a clear zero yes so what will be the challenge then if the road is suppose this resistive load is very resistant then i will get an almost good zero but what is the challenge i said current will be low charging would be charging current will be less so when i have to take f to one that will be very slow are you able to see this the charging will be very slow then so you cannot really keep the resistance to be extremely high also and moreover if you want to keep the resistance to be very high if you have a real resistance there then that resistance will take a lot of area if you have a pmos there or a depletion load there okay area may not be that much impacted but you will have in all the three cases whether it is resistance or transistors you will have much larger rise times so one thing we already discussed that the noise margin would degrade the low voltage will not be zero low voltage will be in the ratio of a resistance of the p network upon resistance of the the resistance of the resistance of the pull down network upon resistance of the pull down network plus rl huh and the propagation delay will also in the in the case of uh rising be dependent on rl so if you make very large resistance then the rise time will be very very large so this is not really a good way to design but you see we save lots of area so we may want to design it somewhere so these are the active loads where we have in this case nmos only technology and in this case a pmos load so in our technologies we always have pmos so we may want to do it like this but we see that there are obvious challenges if for example i have a pseudo pima pseudo nmos design where they have a pmos load because it is small and everything i have a pmos load then what happens then when just one of these inputs is on the other three are off at that point of time the current that is sunk from here will be or you know the ratio of current sunk from here or the resistance of the pmos stack and the ratio of the nmos stack resistance of the nmr stack will be such that my vol will be different so you will see that uh as my more and more transistors in that uh nor gate turn on huh i will get a no this i will get a better zero so are you able to see this not exactly why v is changing here okay so let us say the pmos resistance is 10k huh and nmos resistance is uh also 10k let us say 10k angle let us say nmos resistance is 2k each of these nmoses has resistance 2k so when all four of my n masses are on what is the effective and mass resistance [Music] so what is the value of uh vol approximately okay yes approximately vdd by 19. uh we need by 21. almost even more than 5 percent of vdd taken now let us say only one of them is on then what is happening are you able to see this yes hello but why won't we for example if we know that we are using a pseudo nmos then we can design our females also to be that equivalent resistance like happiness tell me your value how much would you want the pmos resistance to be finally ideally you would want equivalent to equal resistance on pmos and nmr so that you have almost equal delays for rise and fall yes sir so manitoba i have made it 10k whereas nmoses are 2k so my rise time will be 5 times more than fall time already [Music] you propose what number would you want to use let us use that i have no problem let us find out what that number tell me so if we use 2k for the pinocchio yes let us use 2k for the pmos then what happens when all the four outputs are one okay it will not work for you okay are you able to see this yes so when we do so what this also means is that when we do ratio logic design pseudo nmr pseudo pmos the way we size the nmos and pmos how does a very significant impact on vol and all those things and that is what is shown in this slide that as you size your pmos up what happens you reduce the pmos resistance but my vol reduced my fault time increased significantly are you able to see this this is exactly the same discussion you were having just now yes so uh not very interesting very complex you know in the sense that if while we save area we save a lot of area actually all the p mosses are gone anna so in that nor gate imagine the p mosses would have if the nmos is sized one the pmos would have been sized it's a four input thing huh what would happen the size of the p moses hello four times the size four times eight times sixteen times six four fifteen sixteen four input thing yeah anna so 16 into four you have saved how much 64 units out of total 68 units yeah huge area saving but much much more complex much less noise immune so what do we do we say okay and much less noise immune additionally uh the rise time and fall times are very very skewed and everything so then the idea was okay let us do one thing where we say that during an active cycle i will have an additional pmos which would turn on so what does this cmos do during the rise time it would take it up fast but when the system is falling after the so initially it will fall to only say uh let us say vdd by f4 but then once this pmos goes off enable goes high again then this would fall to zero almost zero because this is very resistive huh we can do that hello yeah so what do you want in the earlier case we saw that first if i keep the pmos to be very resistance my rise time would be very bad okay the 16 percent and five percent is fine i am not worried so to get a good rise time what do i want i wanted the pmos to be 2k but with 2k this was the kind of values i was getting on my output unacceptable so what to do so the idea is that in parallel to this nk resistance put another resistance and put another p mass which is slightly larger so that effective pmos resistance is now 2k okay now when the evaluation is on so this pmos will be on only during the evaluation period when the evaluation is on it will my effective pmos resistance is only 2k so the rise will also be fast but once the evaluation closes i would come to this 10k scenario huh and then my output would be at five percent vdd and sixteen percent degree so i get the best of both worlds are you able to see this now so what we would have to add some logic for any equal signal also yes but that you can you know my circuit is to be evaluated i am now evaluating my combinational circuit so at a global level you can add one signal okay at a global level you add one signal but overall you're safe so at the vo at the output i want the exact video to appear so this 16 and five percent i shouldn't get now i mean i should get the exact bdd no but uh vdd you will get yeah but i'm getting with this variation like five percent and 16 percent yeah that is dependent on inputs that is the that is the challenge with ratio logic but even 16 of vdd which means it will still be considered as zero much lower than vd by two okay and are much lower than vdd by two and the other case is where the problem is so what do you mean by a validation phase exactly sir now what do you think i mean [Music] should it be when uh when should my nmos be at higher logic when do we sorry when do we want our output to change i don't know imagine logically i have not used a term which you do not know in english you know and english meaning evaluation whenever we want our output to be 0 or 1 according to the circuit definition i want my output to be zero and one at all times right now because otherwise there will be large amounts of current flowing yes so something else what else could be enabled for what else would this evaluation mean anyone else who can help fashion of their what do you think evaluation would mean the charging discharging phase the transition time of the like the charging and the discharging when it's happening okay that is the evaluation that is the time when your gate is and getting transitions at inputs and you want to evaluate what is the output yes i think so i know so in a synchronous system when the clock comes that is when most of the gates toggle that is in most of the inputs will travel because the flip flop will give the outputs only at that time otherwise flip-flops should also have their output stable is it not yes yes yes so you can say after the clock comes i will have a 20 or 200 pico second enable pulse so that all the combinational gates in my system would evaluate can it be done yes so that is what we mean yes thank you so adaptive load means that during the evaluation phase you have additional pmos which is turned on so that rise wherever signals have to rise they can rise quickly because the output of this signal s this gate s has to go elsewhere also is it not so there is a path we're just not designing one gate we are designing a path so wherever this goes then it will do its own action there so i have a doubt that we are switching the enable pmos right and we are saying that it is it has to be much larger than m2 but i thought that since m2 is the one which is always on and during the the falling phase to save the leakage m2 should be larger since m1 will be off then during the static phase when nothing is working no when the m when we need the low output then so you do not know what the inputs are now because if you do not know the inputs how can you tell the outputs you can always tell whether it is an evaluation phase or not no sir my doubt is suppose uh a one of the input is high and back step back uh this is a nor gate for input nor gate if you have to make the control of this pmos based on the inputs itself then you are actually going for a static cmos implementation aren't you right you will have to put a gate to generate enable signal now okay the entire effort is to save area right irrespective of any input change okay clock comes you generate input you generate enables because you know now evaluations have to happen so we just need to save the rise delay in this case and saving area also yeah not leakage liquid is not the focus here no leakage is saved because in the static case now only m2 is on see if why wouldn't you have gotten too much larger okay had you made m2 much larger static power would have increased significantly light ship now you actually save leakage by this method without compromising on rise time you've done both now right right got it good okay thank you is this point clear to everyone so so in effect we are trying to basically uh with this effort we are trying to uh make the delays again seem like the rise to the equal to the following year this is what yes yes yes yes that is what our attempt is that is what our attempt is that rise time and fall rise delay and fall delay should be almost equal because if they are not then at a system level you have to you put in a huge penalty in terms of managing setups and holds yes so because earlier the fault was already less so we had to make yes okay so this is the adaptive load then this is very interesting this is same kind of circuit but instead of putting this pmos to be always on you you are making a differential output logic huh you're making a differential output logic where you say that instead of pmos being controlled statically by a uh at zero or something and then me putting two p mosses in parallel adaptive load vegeta whatever if i anyway need both the polarities of an input of an output huh if i already need both the polarities of an output then let me use this dc vsl logic where what happens we actually get full zero and we we actually get full ones and also full zeros because why suppose out bar has to go to one when our bar has to go to one what happens uh this pmos will turn off so out will go to a clean zero outgoing to clean zero means this p mass is fully on and this one will be strengthened so noise immunity is also recovered and you also save area you can have these m1 and m2 large enough so that delays for rising and falling are similar are you able to see this,https://www.youtube.com/watch?v=8QtpUhabV-A,"Link: https://www.youtube.com/watch?v=8QtpUhabV-A
Transcript: our combinational logic where we talk about what kind of combinational logic we would be interested to look at for example ratio logic so long back so see one thing is one thing one challenge is static cmos is that for n number of inputs you have two n number of devices huh and of those two hand devices also the pmos that is the half of those two end devices and devices are also larger are you able to see this in a nand gate two input nand gate how many devices do we have two input nand gate how many devices do we have what is four devices in a nor gate how many do we have to input nor gate again four so at least two n devices are there in static cmos and what about the size of nmos and pmos there and the nor gate the pmos size is four times that of the nmr size and an and gate is it is equivalent to nmr size in a two input nand gate so what do we do now we want to look for ah is there a way to reduce the total number of devices why do we want to reduce the total number of devices what's the importance of reducing number of devices area reductions yes and in vlsi area is we want to save gold so we want to reduce area come whatever may so now we will look at a few methods a few techniques to reduce area by for example in this particular slide you will see completely doing away with the pull-up network for example so what do i do instead of all those p mosses i will just put one resistive load what's the problem with one resistive load fabrication is difficult okay so when you say that instead of static cmos i will put any other load whether it is resistive load or depletion load or pmos load since that load is always on since that load is always on what happens we will observe leakage we will observe continuous static current from vdd to vss and different types of designs were proposed resistive loads so in technologies when pmosses were not available then resistive loads or depletion loads were the only options to be used once the pmoses started to become available then pmos loads were used but these pmos loads were always on now we just saw that by using these always on loads or resistances and depletion loads what is the challenge that we expect that the output will not go to pure zero it cannot because pmos is always on some current some current will come either from rl or the pmos or the diffusion load that we have put are you with me on this any questions still here hello you can put a plus one or something in the chat window if you don't want to unmute and speak now i will not move forward until i get a feedback is that one thing sir if the load is big enough then we can obtain kind of a clear zero yes so what will be the challenge then if the road is suppose this resistive load is very resistant then i will get an almost good zero but what is the challenge i said current will be low charging would be charging current will be less so when i have to take f to one that will be very slow are you able to see this the charging will be very slow then so you cannot really keep the resistance to be extremely high also and moreover if you want to keep the resistance to be very high if you have a real resistance there then that resistance will take a lot of area if you have a pmos there or a depletion load there okay area may not be that much impacted but you will have in all the three cases whether it is resistance or transistors you will have much larger rise times so one thing we already discussed that the noise margin would degrade the low voltage will not be zero low voltage will be in the ratio of a resistance of the p network upon resistance of the the resistance of the resistance of the pull down network upon resistance of the pull down network plus rl huh and the propagation delay will also in the in the case of uh rising be dependent on rl so if you make very large resistance then the rise time will be very very large so this is not really a good way to design but you see we save lots of area so we may want to design it somewhere so these are the active loads where we have in this case nmos only technology and in this case a pmos load so in our technologies we always have pmos so we may want to do it like this but we see that there are obvious challenges if for example i have a pseudo pima pseudo nmos design where they have a pmos load because it is small and everything i have a pmos load then what happens then when just one of these inputs is on the other three are off at that point of time the current that is sunk from here will be or you know the ratio of current sunk from here or the resistance of the pmos stack and the ratio of the nmos stack resistance of the nmr stack will be such that my vol will be different so you will see that uh as my more and more transistors in that uh nor gate turn on huh i will get a no this i will get a better zero so are you able to see this not exactly why v is changing here okay so let us say the pmos resistance is 10k huh and nmos resistance is uh also 10k let us say 10k angle let us say nmos resistance is 2k each of these nmoses has resistance 2k so when all four of my n masses are on what is the effective and mass resistance [Music] so what is the value of uh vol approximately okay yes approximately vdd by 19. uh we need by 21. almost even more than 5 percent of vdd taken now let us say only one of them is on then what is happening are you able to see this yes hello but why won't we for example if we know that we are using a pseudo nmos then we can design our females also to be that equivalent resistance like happiness tell me your value how much would you want the pmos resistance to be finally ideally you would want equivalent to equal resistance on pmos and nmr so that you have almost equal delays for rise and fall yes sir so manitoba i have made it 10k whereas nmoses are 2k so my rise time will be 5 times more than fall time already [Music] you propose what number would you want to use let us use that i have no problem let us find out what that number tell me so if we use 2k for the pinocchio yes let us use 2k for the pmos then what happens when all the four outputs are one okay it will not work for you okay are you able to see this yes so when we do so what this also means is that when we do ratio logic design pseudo nmr pseudo pmos the way we size the nmos and pmos how does a very significant impact on vol and all those things and that is what is shown in this slide that as you size your pmos up what happens you reduce the pmos resistance but my vol reduced my fault time increased significantly are you able to see this this is exactly the same discussion you were having just now yes so uh not very interesting very complex you know in the sense that if while we save area we save a lot of area actually all the p mosses are gone anna so in that nor gate imagine the p mosses would have if the nmos is sized one the pmos would have been sized it's a four input thing huh what would happen the size of the p moses hello four times the size four times eight times sixteen times six four fifteen sixteen four input thing yeah anna so 16 into four you have saved how much 64 units out of total 68 units yeah huge area saving but much much more complex much less noise immune so what do we do we say okay and much less noise immune additionally uh the rise time and fall times are very very skewed and everything so then the idea was okay let us do one thing where we say that during an active cycle i will have an additional pmos which would turn on so what does this cmos do during the rise time it would take it up fast but when the system is falling after the so initially it will fall to only say uh let us say vdd by f4 but then once this pmos goes off enable goes high again then this would fall to zero almost zero because this is very resistive huh we can do that hello yeah so what do you want in the earlier case we saw that first if i keep the pmos to be very resistance my rise time would be very bad okay the 16 percent and five percent is fine i am not worried so to get a good rise time what do i want i wanted the pmos to be 2k but with 2k this was the kind of values i was getting on my output unacceptable so what to do so the idea is that in parallel to this nk resistance put another resistance and put another p mass which is slightly larger so that effective pmos resistance is now 2k okay now when the evaluation is on so this pmos will be on only during the evaluation period when the evaluation is on it will my effective pmos resistance is only 2k so the rise will also be fast but once the evaluation closes i would come to this 10k scenario huh and then my output would be at five percent vdd and sixteen percent degree so i get the best of both worlds are you able to see this now so what we would have to add some logic for any equal signal also yes but that you can you know my circuit is to be evaluated i am now evaluating my combinational circuit so at a global level you can add one signal okay at a global level you add one signal but overall you're safe so at the vo at the output i want the exact video to appear so this 16 and five percent i shouldn't get now i mean i should get the exact bdd no but uh vdd you will get yeah but i'm getting with this variation like five percent and 16 percent yeah that is dependent on inputs that is the that is the challenge with ratio logic but even 16 of vdd which means it will still be considered as zero much lower than vd by two okay and are much lower than vdd by two and the other case is where the problem is so what do you mean by a validation phase exactly sir now what do you think i mean [Music] should it be when uh when should my nmos be at higher logic when do we sorry when do we want our output to change i don't know imagine logically i have not used a term which you do not know in english you know and english meaning evaluation whenever we want our output to be 0 or 1 according to the circuit definition i want my output to be zero and one at all times right now because otherwise there will be large amounts of current flowing yes so something else what else could be enabled for what else would this evaluation mean anyone else who can help fashion of their what do you think evaluation would mean the charging discharging phase the transition time of the like the charging and the discharging when it's happening okay that is the evaluation that is the time when your gate is and getting transitions at inputs and you want to evaluate what is the output yes i think so i know so in a synchronous system when the clock comes that is when most of the gates toggle that is in most of the inputs will travel because the flip flop will give the outputs only at that time otherwise flip-flops should also have their output stable is it not yes yes yes so you can say after the clock comes i will have a 20 or 200 pico second enable pulse so that all the combinational gates in my system would evaluate can it be done yes so that is what we mean yes thank you so adaptive load means that during the evaluation phase you have additional pmos which is turned on so that rise wherever signals have to rise they can rise quickly because the output of this signal s this gate s has to go elsewhere also is it not so there is a path we're just not designing one gate we are designing a path so wherever this goes then it will do its own action there so i have a doubt that we are switching the enable pmos right and we are saying that it is it has to be much larger than m2 but i thought that since m2 is the one which is always on and during the the falling phase to save the leakage m2 should be larger since m1 will be off then during the static phase when nothing is working no when the m when we need the low output then so you do not know what the inputs are now because if you do not know the inputs how can you tell the outputs you can always tell whether it is an evaluation phase or not no sir my doubt is suppose uh a one of the input is high and back step back uh this is a nor gate for input nor gate if you have to make the control of this pmos based on the inputs itself then you are actually going for a static cmos implementation aren't you right you will have to put a gate to generate enable signal now okay the entire effort is to save area right irrespective of any input change okay clock comes you generate input you generate enables because you know now evaluations have to happen so we just need to save the rise delay in this case and saving area also yeah not leakage liquid is not the focus here no leakage is saved because in the static case now only m2 is on see if why wouldn't you have gotten too much larger okay had you made m2 much larger static power would have increased significantly light ship now you actually save leakage by this method without compromising on rise time you've done both now right right got it good okay thank you is this point clear to everyone so so in effect we are trying to basically uh with this effort we are trying to uh make the delays again seem like the rise to the equal to the following year this is what yes yes yes yes that is what our attempt is that is what our attempt is that rise time and fall rise delay and fall delay should be almost equal because if they are not then at a system level you have to you put in a huge penalty in terms of managing setups and holds yes so because earlier the fault was already less so we had to make yes okay so this is the adaptive load then this is very interesting this is same kind of circuit but instead of putting this pmos to be always on you you are making a differential output logic huh you're making a differential output logic where you say that instead of pmos being controlled statically by a uh at zero or something and then me putting two p mosses in parallel adaptive load vegeta whatever if i anyway need both the polarities of an input of an output huh if i already need both the polarities of an output then let me use this dc vsl logic where what happens we actually get full zero and we we actually get full ones and also full zeros because why suppose out bar has to go to one when our bar has to go to one what happens uh this pmos will turn off so out will go to a clean zero outgoing to clean zero means this p mass is fully on and this one will be strengthened so noise immunity is also recovered and you also save area you can have these m1 and m2 large enough so that delays for rising and falling are similar are you able to see this"
vtWsWSdbqmI,or gate let us say a is equal to one b is equal to one both are one so this is zero this is one this is zero this is zero okay so what happens this stacks these two this stack is completely off there is a discharge path from here so what is happening out will go to 0 want to go to 0 at least yes as out wants to go to 0 let's discharge from here what happens it turns this pmos fully on but just starts to turn it on let us look at it like that only what happens this node goes to one because the nmr stack of this node is off you see here it is zero so it is off and over here here it is 0 so it is off so because this goes to 1 it can easily go to 1 now this tmos turns off if this pmos turns off then this nmr stack will fully discharge out to zero okay because they would there would be only this charging thing happening nothing changed see why was it not able to go to zero because the pmos was also on now it was static on yes now we have removed that so but like how we will be able to ensure that the rise and the fall time is equal here there i mean discharge will happen but would that be there would be difference in the rise important you can size the p moses accordingly okay right then fall time is a rise and fall delays are a measure of your delays no of your uh uh what do you say no yes sir see one thing is clear the rise will happen only after the 0 has been written that is evident am i right unless a 0 is there 1 cannot be written are you able to see this debris do you have a question yes sir sir this in this differential cascode thing sir i think this example is very favorable to this particular design right because uh i was thinking of let's say nand gate in that case pdn1 and pdm 2 designing would be very tough right um no there will largely be duals of each other but then rice time fall time matching would be difficult but yeah but but you are absolutely right it is for xnor xor gate this is the idea as the inputs are complement so yeah yeah yeah any other gate it takes more renovation to design them but yeah that's okay are these kind of gates that are like complementary are designed in this fashion because before mid sum i was very trying hard to let's design a complex grid using static cmos and i was neither was able to match the logic means take out the value of logical efforts of every input means it was means very different so yeah if you look at it the logical effort of a and b is very different yes b logical effort is twice that of a yes sir yes sir b is connected to force yeah no b is connected to 2 and a is connected to 1. there is b bar and a bar yes sir enough so logical effort is not matched over here ok but you saved lots of areas you wanted both the polarities you saved lots of area yes sir yes if you want to make a logical effort analysis on this should we take a and a bar as separate teacher or can i take a connected to an inverter but what are we supposed to do exactly so than that are we supposed to take two in a and a bar has two different inputs or as a same input for this particular gate there are two different inputs now yes sir and in some other gate we might we might end up using a bar even in a complex gate even in that we are supposed to take a and a bar as different right if there are two different signals they are different okay okay thank you now what's the confusion there no sir i thought i will be using an inverter gate to from a to get an a bar that will become a few if you would design that inside your uh gate itself if you will design that inverter also inside your system then yes you have to consider it otherwise no for example in a flip flop you will have to put some inverters on clock pen so those inverters load has to be considered when you consider logical effort of a flip flop on clock for nx xor gates will be giving it as a x or b i will be writing it as such so uh in the equation i can't see any a bar or b bar okay if we expand that equation then definitely we'll get an a bar and b bar yeah so uh yeah are you are you putting an equation on silicon or are you putting a circuit on silicon circuit sir so yes sir yeah yes sir yeah okay thank you so and you see this is the response the zero as i said will always come first and only then the one thing would rise okay now after this ratio logic thing we move to the next design style which is called past,https://www.youtube.com/watch?v=vtWsWSdbqmI,"Link: https://www.youtube.com/watch?v=vtWsWSdbqmI
Transcript: or gate let us say a is equal to one b is equal to one both are one so this is zero this is one this is zero this is zero okay so what happens this stacks these two this stack is completely off there is a discharge path from here so what is happening out will go to 0 want to go to 0 at least yes as out wants to go to 0 let's discharge from here what happens it turns this pmos fully on but just starts to turn it on let us look at it like that only what happens this node goes to one because the nmr stack of this node is off you see here it is zero so it is off and over here here it is 0 so it is off so because this goes to 1 it can easily go to 1 now this tmos turns off if this pmos turns off then this nmr stack will fully discharge out to zero okay because they would there would be only this charging thing happening nothing changed see why was it not able to go to zero because the pmos was also on now it was static on yes now we have removed that so but like how we will be able to ensure that the rise and the fall time is equal here there i mean discharge will happen but would that be there would be difference in the rise important you can size the p moses accordingly okay right then fall time is a rise and fall delays are a measure of your delays no of your uh uh what do you say no yes sir see one thing is clear the rise will happen only after the 0 has been written that is evident am i right unless a 0 is there 1 cannot be written are you able to see this debris do you have a question yes sir sir this in this differential cascode thing sir i think this example is very favorable to this particular design right because uh i was thinking of let's say nand gate in that case pdn1 and pdm 2 designing would be very tough right um no there will largely be duals of each other but then rice time fall time matching would be difficult but yeah but but you are absolutely right it is for xnor xor gate this is the idea as the inputs are complement so yeah yeah yeah any other gate it takes more renovation to design them but yeah that's okay are these kind of gates that are like complementary are designed in this fashion because before mid sum i was very trying hard to let's design a complex grid using static cmos and i was neither was able to match the logic means take out the value of logical efforts of every input means it was means very different so yeah if you look at it the logical effort of a and b is very different yes b logical effort is twice that of a yes sir yes sir b is connected to force yeah no b is connected to 2 and a is connected to 1. there is b bar and a bar yes sir enough so logical effort is not matched over here ok but you saved lots of areas you wanted both the polarities you saved lots of area yes sir yes if you want to make a logical effort analysis on this should we take a and a bar as separate teacher or can i take a connected to an inverter but what are we supposed to do exactly so than that are we supposed to take two in a and a bar has two different inputs or as a same input for this particular gate there are two different inputs now yes sir and in some other gate we might we might end up using a bar even in a complex gate even in that we are supposed to take a and a bar as different right if there are two different signals they are different okay okay thank you now what's the confusion there no sir i thought i will be using an inverter gate to from a to get an a bar that will become a few if you would design that inside your uh gate itself if you will design that inverter also inside your system then yes you have to consider it otherwise no for example in a flip flop you will have to put some inverters on clock pen so those inverters load has to be considered when you consider logical effort of a flip flop on clock for nx xor gates will be giving it as a x or b i will be writing it as such so uh in the equation i can't see any a bar or b bar okay if we expand that equation then definitely we'll get an a bar and b bar yeah so uh yeah are you are you putting an equation on silicon or are you putting a circuit on silicon circuit sir so yes sir yeah yes sir yeah okay thank you so and you see this is the response the zero as i said will always come first and only then the one thing would rise okay now after this ratio logic thing we move to the next design style which is called past"
i7zDhLsk9i4,transistor logic some of you are designing your gates projects in pass transistor logic who all are doing it in ptl put a plus five in the chat window no one huh no one is designing using ptr that is of the few people who are in class today why is the clustering so low today any ideas midsummer ended last week so we can probably have a surprise quiz in the class sometime let us see so uh maybe there is some documentary notification today for some people um is it the case for some of you so some of you are expected to be on campus today am i right is that the expectation because even on even on wednesday the class strength was low okay no problems so uh a past transistor logic says that we'd so you know in the static cmos and in this ratio logic also we had these d masses and we had these constraints of how big the pmos should be what should be the ratio of the pmos stack under nmr stack and so on we had all these things the questions comes can i design only within most transistors no pmos at all especially you know in 1970s and 80s the mosses were not even there so everything had to be designed with an unmasked logic so what do i do if i have to design with nmos logic because if i have only nmos logic then there is no vdd to ground connection also so there will be no static power consumption and that is where we talk about past transistor logic where n masses are used as switches n masses are used as switches you may say so what do you do you make a switch network and then you simply buffer the output okay so in in this kind of a network an and gate would be designed simply like this are you able to see this that this is and functionality can you work it out for yourself hello this is okay and functionality is clear now the beauty of pass transistor logic is that you can have and functionality also and you can have nand functionality also so you no longer are limited to inverted output suppose in as in a static cmos or even studio cmos if you wanted a and gate to be implemented you will first implement a nand gate and then you will implement then we will add an inverter over here that is not required at all just two nmoses and you have and functionality then what is the challenge the challenge so as we said you put something and then add the output you put a buffer the challenge is that now this in let us say this n goes from 0 to 1 if n goes from 0 to 1 this nmos turns on it charges up vx and output goes to zero so you get the output as zero but what about x x is at what value what will be the value that x will be at so when n is going to be minus gravity minus v v d minus v t so what happens to this the current of this inverter now what happens to the current of this inverter now sir what do you mean by current exactly sir output current sir what do you mean by current of an inverter it's a load which it supplies the current to the load which is only that do you mean only that when you talk of current current from the vdd yeah so what happens to the current from vdd over here that is what my question is so sub threshold starts from pmos and something more maybe now the pmos is not slowly off yes so the pmos current or the sub threshold current or the static current that will flow will not be zero you tell me i have this inverter the input is less so what is happening this is vdd minus vt so you're just at the boundary of threshold voltage for the p mass v mass is off but there is still static power and a significant amount of static current happening nmos is fully on that you are able to see so nmos is fully on pmos is off but not fully off so there is a significant amount of static current coming from here which would be sunk here now the ratio of this just off pmos resistance of just of pmos and the resistance of a fully on nmos that ratio is such that you are still getting an almost zero at the output that is a different thing but do you realize that there will be that that will be a very high sub threshold current flowing over here are you able to see that sir how can we say that my nmos is fully answered you tell me that as my input is not when uh touching the one position when does nmos enter into saturation region when my uh okay video should be greater than vs minus vtc is it greater than vgs minus vp what is the vt that you see in this photo vt is the between things uh x2 output between gap what is that value that's vt uh there is about x axis is labeled and one one almost one i think yeah so let us say 1 yes so what is vds minus vt then when x is equal to 1.5 x equal to 1.5 it's pointless so vds minus vp is greater than zero okay okay sir yeah yes yeah it is in saturation yes it is i know see you have to okay so this is one thing that i am observing in the class uh you're not using your uh you know the logic that you that has already been taught to you earlier to arrive at a analysis to do some analysis you're waiting for either me to analyze it for you or someone else to analyze it for you this is not right please use your knowledge that already you have to quickly do this mental estimation now i have no problem in helping you but the problem is if you continuously look at me whenever you become independent you are more than halfway through the class through the course at this point this value that is this greater than vds minus vp should i be helping you solve this no sir so please at least try to become independent again you make mistakes you ask questions no problems unless you make mistakes how will you learn i have no problems with you making mistakes but at least this analysis you do and then say sir point five off the credit why are you saying it is on instead of saying why are you saying it is on you tell me why do you think it is off and then we will review again but you ask me to arrive it for you that is not right when will you become independent so ask as many questions no problems validate as many doubts clarify as many doubts but this is not a doubt this is something you not even tried to solve something and you are asking a question this is not right are you able to see this yes so if we have if you have uh nmrs only logic while we started now you remember when we started the ptl we said there will be no static currents you remember this on that slide we had written no static current but what did we just see there is all of us are done all the static current that is happening there are you able to see this so we started ptl with no static current hypothesis but we just realized there is going to be static current in ptl also so what to do now so like i was thinking like instead of like we are implementing our combinational logic using ptl and then we are using this inverter for the buffer uh but if we okay but can't we implement this uh inverter also like in ptl logic itself like if we put this simple nmos and then connect the x to that gate also like okay how will you take it to vdd then output to be ready then i mean like so then that x is on so vddt will be basically it will fight we will try let us try why why not you know no this is a good question because this is still exploratory this is a good question no problems in handling this question let us see i see easy example may let us see what happens when uh i want to make inverter through a pass gate so what are we saying we are saying uh for an inverter you would put the input over here or no for an for an inverter then what you would need to do you would need to say that either i will put input over here so input is 1 output should be 0 and i will put 0 over here it got stuck let me go to whiteboards i'm able to do something not able to write i am not able to write on the screen um so what are we saying we are saying that there is a and put vdd now over here it was a vx and we now say that this vx will put somewhere so that i get the inversion there i get a full vdu to ground swing there that is the purpose of putting an inverter are you are you with me on this why do we put an inverter in the first place because i want a full zero to vdd swing yes now tell me how to design a ptl based inverter i can take this vx to a gate of an nmos yes and i will store a 0 over here so my output will go to zero over like this but when the output has to go to one how how will i put this nmos how do i what configuration should i use yeah then we have to put the vdd but then also it will be introduced okay you're saying vdd so what is the benefit now if i put vdd over here what happens now the gate is at vx yes what will i get over here vdd minus the two threshold yes yeah so can you do it so one more special drop because the earlier and this okay are you able to see this so 2 y 2 is coming exactly so one vt drop because of this yes sir yeah one vt drop had already happened here yeah yes so you see this doesn't work you will have to use an inverter there,https://www.youtube.com/watch?v=i7zDhLsk9i4,"Link: https://www.youtube.com/watch?v=i7zDhLsk9i4
Transcript: transistor logic some of you are designing your gates projects in pass transistor logic who all are doing it in ptl put a plus five in the chat window no one huh no one is designing using ptr that is of the few people who are in class today why is the clustering so low today any ideas midsummer ended last week so we can probably have a surprise quiz in the class sometime let us see so uh maybe there is some documentary notification today for some people um is it the case for some of you so some of you are expected to be on campus today am i right is that the expectation because even on even on wednesday the class strength was low okay no problems so uh a past transistor logic says that we'd so you know in the static cmos and in this ratio logic also we had these d masses and we had these constraints of how big the pmos should be what should be the ratio of the pmos stack under nmr stack and so on we had all these things the questions comes can i design only within most transistors no pmos at all especially you know in 1970s and 80s the mosses were not even there so everything had to be designed with an unmasked logic so what do i do if i have to design with nmos logic because if i have only nmos logic then there is no vdd to ground connection also so there will be no static power consumption and that is where we talk about past transistor logic where n masses are used as switches n masses are used as switches you may say so what do you do you make a switch network and then you simply buffer the output okay so in in this kind of a network an and gate would be designed simply like this are you able to see this that this is and functionality can you work it out for yourself hello this is okay and functionality is clear now the beauty of pass transistor logic is that you can have and functionality also and you can have nand functionality also so you no longer are limited to inverted output suppose in as in a static cmos or even studio cmos if you wanted a and gate to be implemented you will first implement a nand gate and then you will implement then we will add an inverter over here that is not required at all just two nmoses and you have and functionality then what is the challenge the challenge so as we said you put something and then add the output you put a buffer the challenge is that now this in let us say this n goes from 0 to 1 if n goes from 0 to 1 this nmos turns on it charges up vx and output goes to zero so you get the output as zero but what about x x is at what value what will be the value that x will be at so when n is going to be minus gravity minus v v d minus v t so what happens to this the current of this inverter now what happens to the current of this inverter now sir what do you mean by current exactly sir output current sir what do you mean by current of an inverter it's a load which it supplies the current to the load which is only that do you mean only that when you talk of current current from the vdd yeah so what happens to the current from vdd over here that is what my question is so sub threshold starts from pmos and something more maybe now the pmos is not slowly off yes so the pmos current or the sub threshold current or the static current that will flow will not be zero you tell me i have this inverter the input is less so what is happening this is vdd minus vt so you're just at the boundary of threshold voltage for the p mass v mass is off but there is still static power and a significant amount of static current happening nmos is fully on that you are able to see so nmos is fully on pmos is off but not fully off so there is a significant amount of static current coming from here which would be sunk here now the ratio of this just off pmos resistance of just of pmos and the resistance of a fully on nmos that ratio is such that you are still getting an almost zero at the output that is a different thing but do you realize that there will be that that will be a very high sub threshold current flowing over here are you able to see that sir how can we say that my nmos is fully answered you tell me that as my input is not when uh touching the one position when does nmos enter into saturation region when my uh okay video should be greater than vs minus vtc is it greater than vgs minus vp what is the vt that you see in this photo vt is the between things uh x2 output between gap what is that value that's vt uh there is about x axis is labeled and one one almost one i think yeah so let us say 1 yes so what is vds minus vt then when x is equal to 1.5 x equal to 1.5 it's pointless so vds minus vp is greater than zero okay okay sir yeah yes yeah it is in saturation yes it is i know see you have to okay so this is one thing that i am observing in the class uh you're not using your uh you know the logic that you that has already been taught to you earlier to arrive at a analysis to do some analysis you're waiting for either me to analyze it for you or someone else to analyze it for you this is not right please use your knowledge that already you have to quickly do this mental estimation now i have no problem in helping you but the problem is if you continuously look at me whenever you become independent you are more than halfway through the class through the course at this point this value that is this greater than vds minus vp should i be helping you solve this no sir so please at least try to become independent again you make mistakes you ask questions no problems unless you make mistakes how will you learn i have no problems with you making mistakes but at least this analysis you do and then say sir point five off the credit why are you saying it is on instead of saying why are you saying it is on you tell me why do you think it is off and then we will review again but you ask me to arrive it for you that is not right when will you become independent so ask as many questions no problems validate as many doubts clarify as many doubts but this is not a doubt this is something you not even tried to solve something and you are asking a question this is not right are you able to see this yes so if we have if you have uh nmrs only logic while we started now you remember when we started the ptl we said there will be no static currents you remember this on that slide we had written no static current but what did we just see there is all of us are done all the static current that is happening there are you able to see this so we started ptl with no static current hypothesis but we just realized there is going to be static current in ptl also so what to do now so like i was thinking like instead of like we are implementing our combinational logic using ptl and then we are using this inverter for the buffer uh but if we okay but can't we implement this uh inverter also like in ptl logic itself like if we put this simple nmos and then connect the x to that gate also like okay how will you take it to vdd then output to be ready then i mean like so then that x is on so vddt will be basically it will fight we will try let us try why why not you know no this is a good question because this is still exploratory this is a good question no problems in handling this question let us see i see easy example may let us see what happens when uh i want to make inverter through a pass gate so what are we saying we are saying uh for an inverter you would put the input over here or no for an for an inverter then what you would need to do you would need to say that either i will put input over here so input is 1 output should be 0 and i will put 0 over here it got stuck let me go to whiteboards i'm able to do something not able to write i am not able to write on the screen um so what are we saying we are saying that there is a and put vdd now over here it was a vx and we now say that this vx will put somewhere so that i get the inversion there i get a full vdu to ground swing there that is the purpose of putting an inverter are you are you with me on this why do we put an inverter in the first place because i want a full zero to vdd swing yes now tell me how to design a ptl based inverter i can take this vx to a gate of an nmos yes and i will store a 0 over here so my output will go to zero over like this but when the output has to go to one how how will i put this nmos how do i what configuration should i use yeah then we have to put the vdd but then also it will be introduced okay you're saying vdd so what is the benefit now if i put vdd over here what happens now the gate is at vx yes what will i get over here vdd minus the two threshold yes yeah so can you do it so one more special drop because the earlier and this okay are you able to see this so 2 y 2 is coming exactly so one vt drop because of this yes sir yeah one vt drop had already happened here yeah yes so you see this doesn't work you will have to use an inverter there"
Db9HZv9Wc8s,you can anything else that is not clear yet hello so what is the challenge now we said that there will be no leakage but there is leakage happening huh so what to do we need to design something differently so we say that uh so this vt loss thing we just now saw okay you're able to see this this vt losses is exactly what we saw just now any questions on the vt loss part so like uh for the static only for example we are you are saying that uh we are saying the vdd here as 2.5 volt but as we for example scale to low technology nodes this leakage would reduce because this vdd is decreasing so on that also if we are basically so you tell me you're reducing the voltage okay so you're reducing the voltage to let us say one volt yes sir threshold voltage would be 0.5 yes sir so at b you will have 0.5 which is v d by 2 what would you make of that yeah so in advanced technologies it actually becomes burst yeah okay so now what we say is so let us put a level restorer so after the inverter we put a pmos a small p mass and we have a level restorer and this what does this level restorer do it ensures that vx goes to vdd when v out is 0 vx goes to 0 to vdd and therefore there is no static current from the inverter but what has happened to make this gate you already now have four transistors are you able to see this so you already have two v moses now you wanted to do away with the team of three monsters all together but already you have two p mosses now additionally uh this additional transistor mr is a like and load on the output and you again have the same problem of ratio of the strength of mr versus mn you want to try something from a but this mr is on it will not let your v x to go zero go to zero are you able to see this suppose you want to drive x to zero it was initially one if x was initially one then out was zero outbound zero means mr is fully on now you want to drive x to one x to zero you want to sing that current through a what happens the amount of current you sing through a a much more amount or some amount would be coming from mr so this is again the same ratio problem that you were looking at in the earlier ratio logic paradigm are you able to see this any questions so the principle of uh clearly solder is basically the positive feedback kind of kind of half latch yes so what if we change sizes of mrna so now you have to do the sizing none you have see in static cmos did you ever have to do sizing for your vol or voh purpose no no you only did sizing for your delay purpose over here we are saying we need to do sizing for functionality itself are you able to see this yes sir so now i will uh somewhat decrease size of mr yes now you want mr to be resistive yes huh so mr has to be as result just like over there pmos had to the pmos and the ratio logic had to be as small as possible so that you could take as close to 0 as possible over here mr has to be as resistive as possible it just is there to restore from vx to vdd take from vx to vdd that is the only purpose so keep it as small as possible typically this restorer device would be the smallest pmos that you could design in a technology smallest and that too with large length okay so having different links doesn't have any problem with having different lengths length yeah if the length is minimum then the current from mr will be high oh i am reducing the width you've already reduced the width yes you are the minimum width but if you want it to be still more resistive what do you do you increase the length yeah so what i am saying is size it appropriately you may not need to increase the rent but yes so what length are you using there here i am talking digital like most people are talking about so has anyone tied your hands that you don't have to touch length then it is an assumption you are making i am telling you increase the length i think that opening the length would not only be like uh we are not going to deliver many things will change i think yeah let them what all will change let's look at that what always change if you increase the length first of all everything the power also will change which power i mean dissipation participation also will get impacted i think so yeah which power dissipation static or dynamic we know everything now we know all the different static power is gate leakage brain leakage junction leakage we know all those components also so tell me which one if you increase the length which power would increase switching with switching in this particular circuit with switching power would increase the switching of out because you've added an additional capacitor on out am i right yes so that will increase so what how what has length got to do with it anyways it was this mr you are putting you increase the length by 10 percent that capacitance increased by further 10 so it's a minuscule change in overall power but probably you are not now worried about ratio logic design your overall delay may reduce that can happen yes if you make mr more resistors then a to x transition a to x movement will be much faster because now mr is not really playing much role it is only playing a role very slowly so that vx does not remain at the at vdd minus vt level vx gets recharged to vdd and that it can do at leisure output is already there are you able to see this sir one thing just i wanted to ask that from x to the gate of mr there would be always some inherent delay because there is an inverter now let's let's say my input was a one then i suddenly switched to zero and for some time won't we be observing a shot between vdd why do we want mr to be small this is exactly what we are talking about certain dynamic power would be increasing again yeah it would increase it would take some extra time to because mr current has to be sung through a that is not just dynamic power all the current of mr in that period will have to be sung through it okay so if this mr is very large then you will never be able to write 0 on x instead the thing is actually in static cmos we never observed a short between input pin and supply pin yes so see the challenge here so this is a big challenge over here now your input pin you cannot control it also you see he affected my supply yes yes you see this is such a big challenge so later you will see as we move forward you will see that inputs at least trip level inputs or block level inputs can never come to pass transistor logic not allowed because some other circuit is driving and over here you have put ppl and this ptl logic because of the virtue of it being ptl starts to back drive the inputs the system would go no macro level inputs can ever be driven uh or can ever be taken to a ttl logic simply not allowed you will see you will see this in detail later but so i'm happy that you've taken us to that point but uh is this level restorer concept here because we will use this in dynamic gates also so just here so for example all the techniques that we have studied like the logical effort they won't be we won't be able to apply here also no right no logical effort is for static schemas these are techniques we are just trying to save area once you've done everything else now you say okay let me recover area so some places you say okay i will use this ptl some places you will say i will use this dc vsl and all those things but here we are saving the area equivalent to only two transistors yeah moving on so but see in this particular you're just talking about one gate then yes but if you think of a mux so this is the impact of restorating if the restorer is very large then this is where your output is but if the restorer is small enough then it it works okay so this is okay what you need to really look for is that if you have two inverters for example driving this this particular gate there could be current paths that could form between them okay so it's not it's not easy you have to be extremely careful when you use ptl that is why i said these inputs cannot be coming from outside the macro if you really have these two inverters the input should be like coming here then whatever current it is you will be able to characterize within your valid verification process itself okay so what do you do we had this vt drop and everything to avoid vt drop you instead of pass gates you use transmission gates now what happens whether the input is zero or one you will be able to transmit a to b at one point of time nmos will be on at another point of time pmos will be on are you able to see this instead of etl use transmission gate logic hello so now you know you no longer need this is by adding one more transistor yeah but you no longer need the level restorer do you see that yes huh you no longer read the revolver restorer and just to get you do not even actually need to put the inverters there if you do not have to drive a very large load you just wanted to put the inverter just so that you have a clear zero and one output you no longer need that inverter also so this is better so then why choose pasta and sister nausea i'm sorry then why juice why do we choose past time system we can because in some places would work no but transmission is better yeah but at some places in some places you only need to transmit a zero for example in the bit lines of a of a memory when you want to write into the memory you only transmit a 0 that is the only transition that you are interested in when you want to write into the memory so why then user transmission get why waste area area is gold are you able to see this yes so it depends on application which i mean yes so all these exotic styles uh skewed gates uh asymmetric dates symmetric gates all these exotic styles this ratio logic ptl all these exotic styles are to be used only on specific use cases but when you have those specific use cases you should have the library you should have the mental space to say okay i have studied about this let me use this logic here that is why we are discussing this in the class are you able to see this hello yes it is if you have a transmission gate multiple base multiplexer you can actually get a very good multiplexer out of it very quickly no challenges a transmission gate zord is also very dense just look at it be careful this is not ground this is b bar this is not vdd this is b huh these are these appear to be very nice designs but realize that these a and b are now signals so this b is not stable b bar is not stable at zero this b bar might also be rising or might just be falling so the delays are not in your control at all this looks to be a very dense design for his or gate but try implementing it try characterizing it and you're in for a toss unless you have the world of time you can't use this design so even if this file if it is in the middle of some design then i can control the signals i can control my launcher okay so transmission gate okay let us assume that there is a huge series of transmission gates that i have what do i essentially have then i have a large rc network and my delays degrade humongously so what do we need to do we need to put buffers intermittently okay we need to put these buffers intermittently otherwise this is a very huge r equivalent that you will see see each r in itself is small but because you have a multitude of these hours it's like a you know stack of p mosses or a stack of nmoses so you either need to size these transmission gates up significantly or you just simply put buffers after say five stages or ten stages or whatever is appropriate for you for that particular technology okay so transmission getting both eye problem solved but not everything are you with me yes this will be a regular cmos for two inverters but you still save lots of cmos lots of logic area any questions here hmm not participating not speaking nothing is happening friends you see what happening no response today so if you have this kind of a if you have this kind of a transmission gate chain then what do you do you can actually calculate the delay so if there is no buffer then this will be the kind of delay because the total number of resistance will be n into you know you add all those resistances but if you put in a buffer then you will come to some optimal number there is some delay of the buffer and then limited delay of the chain so you arrive at an m optimal total number of stages after which you should put a buffer okay are you able to see this i mean like uh i think that most where exactly are we using this like kind of these esoteric like kind of circuits because yes the transmission database circuits transmission gateway circuits could be used at many places because they will help you implement even complex logic with lesser number of transistors okay it's like instead of etl you're using uh switches of transmission gates but then the early issue was that a signal that that is a very very big issue and i think yeah but that was for this or gate no no don't get confused that was only for this all gate for other gates it will not be like that it can be but not much zorg it was a challenge solve it was designed like this or gate as design like that appears to be very dense but it's a pin it's a pain to design it now but like for the other gates itself for example my uh suppose the b signal and the device signal it would be coming from some other kind of logic so then it would also be facing some kind of degradation and this view of that signal would change and so how would i be able to characterize that theo in terms of [Music] what do you say when you're talking about it in terms of uh that is a different thing all other gates will still be able to manage okay fairly well okay so um if we if we go to a buffered transmission gate chain do you realize that there is a may a simple method to arrive at what is the optimal number of stages after which you want to put a buffer is this thing evident to you yes sir great so with that we kind of come to a close of this ptl kind of logic design also okay and now we start with what is called as dynamic logic so what do you understand by dynamic logic so i was i was just into,https://www.youtube.com/watch?v=Db9HZv9Wc8s,"Link: https://www.youtube.com/watch?v=Db9HZv9Wc8s
Transcript: you can anything else that is not clear yet hello so what is the challenge now we said that there will be no leakage but there is leakage happening huh so what to do we need to design something differently so we say that uh so this vt loss thing we just now saw okay you're able to see this this vt losses is exactly what we saw just now any questions on the vt loss part so like uh for the static only for example we are you are saying that uh we are saying the vdd here as 2.5 volt but as we for example scale to low technology nodes this leakage would reduce because this vdd is decreasing so on that also if we are basically so you tell me you're reducing the voltage okay so you're reducing the voltage to let us say one volt yes sir threshold voltage would be 0.5 yes sir so at b you will have 0.5 which is v d by 2 what would you make of that yeah so in advanced technologies it actually becomes burst yeah okay so now what we say is so let us put a level restorer so after the inverter we put a pmos a small p mass and we have a level restorer and this what does this level restorer do it ensures that vx goes to vdd when v out is 0 vx goes to 0 to vdd and therefore there is no static current from the inverter but what has happened to make this gate you already now have four transistors are you able to see this so you already have two v moses now you wanted to do away with the team of three monsters all together but already you have two p mosses now additionally uh this additional transistor mr is a like and load on the output and you again have the same problem of ratio of the strength of mr versus mn you want to try something from a but this mr is on it will not let your v x to go zero go to zero are you able to see this suppose you want to drive x to zero it was initially one if x was initially one then out was zero outbound zero means mr is fully on now you want to drive x to one x to zero you want to sing that current through a what happens the amount of current you sing through a a much more amount or some amount would be coming from mr so this is again the same ratio problem that you were looking at in the earlier ratio logic paradigm are you able to see this any questions so the principle of uh clearly solder is basically the positive feedback kind of kind of half latch yes so what if we change sizes of mrna so now you have to do the sizing none you have see in static cmos did you ever have to do sizing for your vol or voh purpose no no you only did sizing for your delay purpose over here we are saying we need to do sizing for functionality itself are you able to see this yes sir so now i will uh somewhat decrease size of mr yes now you want mr to be resistive yes huh so mr has to be as result just like over there pmos had to the pmos and the ratio logic had to be as small as possible so that you could take as close to 0 as possible over here mr has to be as resistive as possible it just is there to restore from vx to vdd take from vx to vdd that is the only purpose so keep it as small as possible typically this restorer device would be the smallest pmos that you could design in a technology smallest and that too with large length okay so having different links doesn't have any problem with having different lengths length yeah if the length is minimum then the current from mr will be high oh i am reducing the width you've already reduced the width yes you are the minimum width but if you want it to be still more resistive what do you do you increase the length yeah so what i am saying is size it appropriately you may not need to increase the rent but yes so what length are you using there here i am talking digital like most people are talking about so has anyone tied your hands that you don't have to touch length then it is an assumption you are making i am telling you increase the length i think that opening the length would not only be like uh we are not going to deliver many things will change i think yeah let them what all will change let's look at that what always change if you increase the length first of all everything the power also will change which power i mean dissipation participation also will get impacted i think so yeah which power dissipation static or dynamic we know everything now we know all the different static power is gate leakage brain leakage junction leakage we know all those components also so tell me which one if you increase the length which power would increase switching with switching in this particular circuit with switching power would increase the switching of out because you've added an additional capacitor on out am i right yes so that will increase so what how what has length got to do with it anyways it was this mr you are putting you increase the length by 10 percent that capacitance increased by further 10 so it's a minuscule change in overall power but probably you are not now worried about ratio logic design your overall delay may reduce that can happen yes if you make mr more resistors then a to x transition a to x movement will be much faster because now mr is not really playing much role it is only playing a role very slowly so that vx does not remain at the at vdd minus vt level vx gets recharged to vdd and that it can do at leisure output is already there are you able to see this sir one thing just i wanted to ask that from x to the gate of mr there would be always some inherent delay because there is an inverter now let's let's say my input was a one then i suddenly switched to zero and for some time won't we be observing a shot between vdd why do we want mr to be small this is exactly what we are talking about certain dynamic power would be increasing again yeah it would increase it would take some extra time to because mr current has to be sung through a that is not just dynamic power all the current of mr in that period will have to be sung through it okay so if this mr is very large then you will never be able to write 0 on x instead the thing is actually in static cmos we never observed a short between input pin and supply pin yes so see the challenge here so this is a big challenge over here now your input pin you cannot control it also you see he affected my supply yes yes you see this is such a big challenge so later you will see as we move forward you will see that inputs at least trip level inputs or block level inputs can never come to pass transistor logic not allowed because some other circuit is driving and over here you have put ppl and this ptl logic because of the virtue of it being ptl starts to back drive the inputs the system would go no macro level inputs can ever be driven uh or can ever be taken to a ttl logic simply not allowed you will see you will see this in detail later but so i'm happy that you've taken us to that point but uh is this level restorer concept here because we will use this in dynamic gates also so just here so for example all the techniques that we have studied like the logical effort they won't be we won't be able to apply here also no right no logical effort is for static schemas these are techniques we are just trying to save area once you've done everything else now you say okay let me recover area so some places you say okay i will use this ptl some places you will say i will use this dc vsl and all those things but here we are saving the area equivalent to only two transistors yeah moving on so but see in this particular you're just talking about one gate then yes but if you think of a mux so this is the impact of restorating if the restorer is very large then this is where your output is but if the restorer is small enough then it it works okay so this is okay what you need to really look for is that if you have two inverters for example driving this this particular gate there could be current paths that could form between them okay so it's not it's not easy you have to be extremely careful when you use ptl that is why i said these inputs cannot be coming from outside the macro if you really have these two inverters the input should be like coming here then whatever current it is you will be able to characterize within your valid verification process itself okay so what do you do we had this vt drop and everything to avoid vt drop you instead of pass gates you use transmission gates now what happens whether the input is zero or one you will be able to transmit a to b at one point of time nmos will be on at another point of time pmos will be on are you able to see this instead of etl use transmission gate logic hello so now you know you no longer need this is by adding one more transistor yeah but you no longer need the level restorer do you see that yes huh you no longer read the revolver restorer and just to get you do not even actually need to put the inverters there if you do not have to drive a very large load you just wanted to put the inverter just so that you have a clear zero and one output you no longer need that inverter also so this is better so then why choose pasta and sister nausea i'm sorry then why juice why do we choose past time system we can because in some places would work no but transmission is better yeah but at some places in some places you only need to transmit a zero for example in the bit lines of a of a memory when you want to write into the memory you only transmit a 0 that is the only transition that you are interested in when you want to write into the memory so why then user transmission get why waste area area is gold are you able to see this yes so it depends on application which i mean yes so all these exotic styles uh skewed gates uh asymmetric dates symmetric gates all these exotic styles this ratio logic ptl all these exotic styles are to be used only on specific use cases but when you have those specific use cases you should have the library you should have the mental space to say okay i have studied about this let me use this logic here that is why we are discussing this in the class are you able to see this hello yes it is if you have a transmission gate multiple base multiplexer you can actually get a very good multiplexer out of it very quickly no challenges a transmission gate zord is also very dense just look at it be careful this is not ground this is b bar this is not vdd this is b huh these are these appear to be very nice designs but realize that these a and b are now signals so this b is not stable b bar is not stable at zero this b bar might also be rising or might just be falling so the delays are not in your control at all this looks to be a very dense design for his or gate but try implementing it try characterizing it and you're in for a toss unless you have the world of time you can't use this design so even if this file if it is in the middle of some design then i can control the signals i can control my launcher okay so transmission gate okay let us assume that there is a huge series of transmission gates that i have what do i essentially have then i have a large rc network and my delays degrade humongously so what do we need to do we need to put buffers intermittently okay we need to put these buffers intermittently otherwise this is a very huge r equivalent that you will see see each r in itself is small but because you have a multitude of these hours it's like a you know stack of p mosses or a stack of nmoses so you either need to size these transmission gates up significantly or you just simply put buffers after say five stages or ten stages or whatever is appropriate for you for that particular technology okay so transmission getting both eye problem solved but not everything are you with me yes this will be a regular cmos for two inverters but you still save lots of cmos lots of logic area any questions here hmm not participating not speaking nothing is happening friends you see what happening no response today so if you have this kind of a if you have this kind of a transmission gate chain then what do you do you can actually calculate the delay so if there is no buffer then this will be the kind of delay because the total number of resistance will be n into you know you add all those resistances but if you put in a buffer then you will come to some optimal number there is some delay of the buffer and then limited delay of the chain so you arrive at an m optimal total number of stages after which you should put a buffer okay are you able to see this i mean like uh i think that most where exactly are we using this like kind of these esoteric like kind of circuits because yes the transmission database circuits transmission gateway circuits could be used at many places because they will help you implement even complex logic with lesser number of transistors okay it's like instead of etl you're using uh switches of transmission gates but then the early issue was that a signal that that is a very very big issue and i think yeah but that was for this or gate no no don't get confused that was only for this all gate for other gates it will not be like that it can be but not much zorg it was a challenge solve it was designed like this or gate as design like that appears to be very dense but it's a pin it's a pain to design it now but like for the other gates itself for example my uh suppose the b signal and the device signal it would be coming from some other kind of logic so then it would also be facing some kind of degradation and this view of that signal would change and so how would i be able to characterize that theo in terms of [Music] what do you say when you're talking about it in terms of uh that is a different thing all other gates will still be able to manage okay fairly well okay so um if we if we go to a buffered transmission gate chain do you realize that there is a may a simple method to arrive at what is the optimal number of stages after which you want to put a buffer is this thing evident to you yes sir great so with that we kind of come to a close of this ptl kind of logic design also okay and now we start with what is called as dynamic logic so what do you understand by dynamic logic so i was i was just into"
fz09Zx1PLOg,it's almost time so we'll close the class but what do you mean by dynamic logic dynamic means something is moving something is i think something is moving something there's movement it's not right so when we are using the clock then we are using a clock yes so the dynamic circuits for example since let us look at it like this in static circuits what are you doing at every point of time except when switching output is connected to either vdd or ground why a low resistance path because there is a pull up stack and a pull down stack in dynamic logic the output may actually be connected or lefty left floating so you are depending on storage of output on some capacitance okay so what does this mean this means that you have for example a dynamic gate and you have a clock also going to it now when ck is equal to 0 then what happens this pmos is on this nmos is off output goes to 1. this phase is called the pre-charge phase now when you want to evaluate the output of a b and c of this combinational gate when a b and c values are fixed then what happens ck goes to 1 ck goes to 1 means what would happen the pmos would turn off the nmos would turn on m e would turn on m evaluate would turn on and now you will evaluate the the dynamic gate and once evaluated suppose let us say that c is equal to 0 and b is also equal to 0. so the evaluation says that out has to be 1 but clk is 1 so out is now being left floating are you able to see this out is not any longer driven to one out is left floating that is where it is called as dynamic logic are you able to see this so when clock was one then the lower end mosque will will be like open switch so the close switch and so i will have a path yeah and if abc are one then i am saying when c is equal to zero and b is equal to zero okay and abc are one then zero so we consider so as designers we have to look at the worst case what is the worst case the worst case is that your is 1 b 0 c 0 so there is some charge sharing that has happened between these two nodes and there is no way to even recover that charge are you able to see that faulty takedown yes fault delay there was no change in output expected if b is 0 and c 0 there was no change in output expected yes sir but out is now floating out is not driven to 1 because the clk is 1. and there's no path to ground it was not meant to be because if if b is equal to 0 and c is equal to 0 then there was no path to ground there was no it was not meant to be there so what are we saying if let us say there is a glitch on b b was zero but there is a glitch that comes on b a is one what happens now now until the clock goes back to zero again until my recharge phase starts again there is no way to recover out are you able to see this so what are we saying we are saying that there are few conditions that are there on the output that once the output of a gate is discharged it cannot be charged again the inputs to the gate can make at most one transition during an evaluation so if you're talking about a glitch that glitch input going to one it discharged the gate and now the zero input going back to zero will not charge it again so inputs so glitches are absolutely unacceptable in dynamic gates huh then it may not go to zero afternoon if my glitch is very small my output might reduce but it not go to zero directly so what do you mean by a glitch for a short pulse i have a one two zero it goes to one and zero the short is an assumption for me glitch is any spurious transition okay consider adder in the adder ripple carry adders huh these ci is just keep on getting evaluated yes so the ci can go to one for a reasonable amount of time yes but it is still a glitch yes so short was your assumption is it not yes sir i have a very big device even a short glitch can lead to dispatch yes so again as a designer always look at the worst case failure mode when you are designing when you are verifying are you able to see this so we don't we don't want to keep it floating we have to make it somehow to not keep it yes so that is a challenge that we as designers have so what do you think we can do we did something in the static dates what what can we do we had the signals vx going to vdd minus dt or something like that to do it to connect it to vdd we added something what did we do output buffer auto buffer vx clear restorer we made a half latch so the level wrestler restored the level from vx to vdd over here what can we do we can also put a restorer over here so that if there is some charge that has gone because of a glitch or something it can be recovered are you able to see this so what are the properties of dynamic gates first is that the total number of transistors is n plus 2 versus 2n for static c mass huh then you get full swing outputs we're not talking worried about ratio logic just yet you will get full zero and full ones so non-ratio sizing and do you realize that as soon as you reduce the number of transistors that an input goes to you reduce the logical effort since you've reduced the logical effort of the design the overall path delays reduce very very significantly so there is reduced input capacitance there is reduced output capacitance also huh and therefore overall delays are expected to be less additionally now these are positives what is also happening is that even if there is no static paths the problem is that power consumption and these gates will be higher why let us consider a case that let's consider the case of a static nand huh [Music] so this is the last thing that we are doing so let's consider the case of a static nand static a two input map now in the previous cycles a and b were both one so what they had done this output y was discharged but when c k went to zero what happened this output got recharged a and b did not toggle when the next clock came this output will discharge again now there was no toggle in a and b had it been a static inverter a static nand gate would there have been any power consumption but over here i consume power so my activity factor has at once increased very significantly are you able to see this in every cycle i'm discharging and charging the charging and charging so i mean because uh activity factor of the clock is the highest and here it is controlled by the clock itself so yeah with the more spectrum yes massive yes hannah so are you able to see this area uh as soon as there is some glitch on the input signals even a small glitch on the input signals as we just saw the output the the the reliability of the output starts to suffer because once it discharges there is no way to bring it back so in the next class we will look at these restorer concepts and the other concepts which are used so that we are able to use dynamic gates appropriately in our designs okay we'll close the class here you're already at 130. okay sir yes sir can we keep that clock no nmos first and then bdn network okay because because at the output capacitance will be reduced i think okay no problem you can do that we don't usually do that because uh we don't want uh clock see as soon as clock toggles there will be noise on the output again so we don't want that also to happen but it's okay you can do that that's not usually done though so we have the path delegate in that case because my clock is getting in between yeah see in this gate clock has to come first and then other signals will be evaluated okay but if you put it like that a clock on the top even then it's okay because as soon as clock comes other inputs have already been evaluated on the nmr stack and you would give an output you can try that it's not usually done think why what could be the failure,https://www.youtube.com/watch?v=fz09Zx1PLOg,"Link: https://www.youtube.com/watch?v=fz09Zx1PLOg
Transcript: it's almost time so we'll close the class but what do you mean by dynamic logic dynamic means something is moving something is i think something is moving something there's movement it's not right so when we are using the clock then we are using a clock yes so the dynamic circuits for example since let us look at it like this in static circuits what are you doing at every point of time except when switching output is connected to either vdd or ground why a low resistance path because there is a pull up stack and a pull down stack in dynamic logic the output may actually be connected or lefty left floating so you are depending on storage of output on some capacitance okay so what does this mean this means that you have for example a dynamic gate and you have a clock also going to it now when ck is equal to 0 then what happens this pmos is on this nmos is off output goes to 1. this phase is called the pre-charge phase now when you want to evaluate the output of a b and c of this combinational gate when a b and c values are fixed then what happens ck goes to 1 ck goes to 1 means what would happen the pmos would turn off the nmos would turn on m e would turn on m evaluate would turn on and now you will evaluate the the dynamic gate and once evaluated suppose let us say that c is equal to 0 and b is also equal to 0. so the evaluation says that out has to be 1 but clk is 1 so out is now being left floating are you able to see this out is not any longer driven to one out is left floating that is where it is called as dynamic logic are you able to see this so when clock was one then the lower end mosque will will be like open switch so the close switch and so i will have a path yeah and if abc are one then i am saying when c is equal to zero and b is equal to zero okay and abc are one then zero so we consider so as designers we have to look at the worst case what is the worst case the worst case is that your is 1 b 0 c 0 so there is some charge sharing that has happened between these two nodes and there is no way to even recover that charge are you able to see that faulty takedown yes fault delay there was no change in output expected if b is 0 and c 0 there was no change in output expected yes sir but out is now floating out is not driven to 1 because the clk is 1. and there's no path to ground it was not meant to be because if if b is equal to 0 and c is equal to 0 then there was no path to ground there was no it was not meant to be there so what are we saying if let us say there is a glitch on b b was zero but there is a glitch that comes on b a is one what happens now now until the clock goes back to zero again until my recharge phase starts again there is no way to recover out are you able to see this so what are we saying we are saying that there are few conditions that are there on the output that once the output of a gate is discharged it cannot be charged again the inputs to the gate can make at most one transition during an evaluation so if you're talking about a glitch that glitch input going to one it discharged the gate and now the zero input going back to zero will not charge it again so inputs so glitches are absolutely unacceptable in dynamic gates huh then it may not go to zero afternoon if my glitch is very small my output might reduce but it not go to zero directly so what do you mean by a glitch for a short pulse i have a one two zero it goes to one and zero the short is an assumption for me glitch is any spurious transition okay consider adder in the adder ripple carry adders huh these ci is just keep on getting evaluated yes so the ci can go to one for a reasonable amount of time yes but it is still a glitch yes so short was your assumption is it not yes sir i have a very big device even a short glitch can lead to dispatch yes so again as a designer always look at the worst case failure mode when you are designing when you are verifying are you able to see this so we don't we don't want to keep it floating we have to make it somehow to not keep it yes so that is a challenge that we as designers have so what do you think we can do we did something in the static dates what what can we do we had the signals vx going to vdd minus dt or something like that to do it to connect it to vdd we added something what did we do output buffer auto buffer vx clear restorer we made a half latch so the level wrestler restored the level from vx to vdd over here what can we do we can also put a restorer over here so that if there is some charge that has gone because of a glitch or something it can be recovered are you able to see this so what are the properties of dynamic gates first is that the total number of transistors is n plus 2 versus 2n for static c mass huh then you get full swing outputs we're not talking worried about ratio logic just yet you will get full zero and full ones so non-ratio sizing and do you realize that as soon as you reduce the number of transistors that an input goes to you reduce the logical effort since you've reduced the logical effort of the design the overall path delays reduce very very significantly so there is reduced input capacitance there is reduced output capacitance also huh and therefore overall delays are expected to be less additionally now these are positives what is also happening is that even if there is no static paths the problem is that power consumption and these gates will be higher why let us consider a case that let's consider the case of a static nand huh [Music] so this is the last thing that we are doing so let's consider the case of a static nand static a two input map now in the previous cycles a and b were both one so what they had done this output y was discharged but when c k went to zero what happened this output got recharged a and b did not toggle when the next clock came this output will discharge again now there was no toggle in a and b had it been a static inverter a static nand gate would there have been any power consumption but over here i consume power so my activity factor has at once increased very significantly are you able to see this in every cycle i'm discharging and charging the charging and charging so i mean because uh activity factor of the clock is the highest and here it is controlled by the clock itself so yeah with the more spectrum yes massive yes hannah so are you able to see this area uh as soon as there is some glitch on the input signals even a small glitch on the input signals as we just saw the output the the the reliability of the output starts to suffer because once it discharges there is no way to bring it back so in the next class we will look at these restorer concepts and the other concepts which are used so that we are able to use dynamic gates appropriately in our designs okay we'll close the class here you're already at 130. okay sir yes sir can we keep that clock no nmos first and then bdn network okay because because at the output capacitance will be reduced i think okay no problem you can do that we don't usually do that because uh we don't want uh clock see as soon as clock toggles there will be noise on the output again so we don't want that also to happen but it's okay you can do that that's not usually done though so we have the path delegate in that case because my clock is getting in between yeah see in this gate clock has to come first and then other signals will be evaluated okay but if you put it like that a clock on the top even then it's okay because as soon as clock comes other inputs have already been evaluated on the nmr stack and you would give an output you can try that it's not usually done think why what could be the failure"
WrZ2leirJl8,the last class so just started the dynamic we we were introduced we hadn't used the dynamic logic so what is dynamic logic why is it called so because the output is not driven and like always driven and we get a floating kind of output and it depends upon the charge that is stored on the capacitor not always driven so while in static gates we say that uh the output or all the nodes are always driven you do not leave things non-floating in static cmos case in dynamic logic we realized that there is only n stack and on the pima side you have a clock based header and on the at the end of the bottom of the nmr stack you have a clock based footer and you said that this this system uh will lead to a floating gate condition when the remaining nmos stack is off uh the pmos will go off and clock goes high and you will end up having floating output so since that kind of and then at that point of time you are dependent on the charge stored on that floating output to ensure that you are stable that you are robust so that is where it is called as a dynamic due to leakage you will you may need to refresh this so at the end of every clock cycle this this capacitor whether it had discharged or not will again be charged up to vdd okay so we also looked i started to look at the challenges or limitations around dynamic gates what were they sir there is very less noise immunity there is very less noise immunity okay for a particular uh within a single cycle of the clock the inputs can be changed at most once um so the inputs can can change only at most once input can go from zero to one only once if it if there is a glitch then i have a problem okay what else to charge and discharge this the power consumption is high so activity factor is very high so yes activity effect is also very that's something different but yeah activity factor is very high because in in terms of uh when you compare it with a static date even if the even if the inputs have not toggled a static gate would not consume any power but a dynamic gate will always consume power you know because at the end of every evaluation phase there is a precharge phase and in that recharge phase whatever capacitances you had discharged would get recharged all over again what else so we also saw that in dynamic gates the total number of transistors would be something like n plus 2 versus 2 n for the static cmos you're able to see this n plus two the plus two things yes sir the header clock the the pmos with the header clock and the n mass with the footer clock then the good thing about this is so we have lesser number of transistors but much much better situation than let us say ptl or pseudo and mass because the outputs are fulfilling outputs are full string the output is either full vdd and when it has to be zero it will be taken to full ground so outputs are full swing and because outputs are full swing and the nmr stack or pmos stack will is not you know there is no race condition or fight back between the two nmos and pmos traps like in uh pseudo nmos kind of a case the sizing does not really affect the logic levels the sizing affects the delays but it does not affect the logic levels and what also has happened we discussed this also in the last class we've reduced the capacitance with all capacitances have they reduced input all the pmos the most one we reduce the input capacitances because uh there is no pmos you know the the the signals now no longer need to go to the pmos so if i would make a inverter a dynamic inverter the pmos would have a clock on it there would be one n mass with a clock on it and then there will be the other end mass so the effective logical effort of this dynamic inverter would be can you quickly tell me hello so one third one third so wait a minute i seem to have lost control over my powerpoint slideshow why one third just just uh correct me two for the device two for the input gate and two for the clock so what is the total load that the input gate is seeing now two minutes two n so what what do we do then what is the uh uh what is this thing then the logical effort is two-thirds well logical effort is two by three hannah so do we still divide by the static yeah we can divide by the static uh like that is the reference for us as of now is it not so enough yes so how it has become two by three can please explain that again what is the input load of a regular inverter it's a three and what is the input load of this inverter that we talked about so we have a nmos in between that will be of size one why someone one he wanna say you know we have a footer two so uh so if you look at it just give me a moment your system would look like this am i right yes converter so the logical effort is two by three okay fine yes sir okay so then what do we do if we say that this is the kind of logical effort that we have uh what no logical efforts are what other constraints do you see would be happening with this kind of a dynamic gate now your circuit designers what kind of things would you see in the dynamic gate now so i mean i i can see that we cannot use like cascades like stages in stage kind stuff here like dynamic interesting why do you say so so because we have that constraint now because that input can go from only zero to one and suppose in we have cascaded it so if that is going the one is going there so in that for the subsequent state it will disrupt that the same kind of uh problem we will face that we didn't want to face with this same kind of problem so i mean like uh if we go if we have inputs other than going from 0 to 1 then we see that if the capacitor discharge then we don't have any option it will and that logic then will basically we will get different kind of uh we will get basically wrong outputs basically a dynamic then always have one to zero transit a transition at output right yes because at the end of the cycle you have to charge it to one well and uh so if the output has to transition it will always be from 1 to 0 there is no other transition possible and it was already 1 it can only go to 0 now or it will remain as 1. when it remains as 1 what do we say it is floating when it remains as one we say that it is floating are you with me because the pmos is off in the evaluation phase ck equal to 1 so pmos is off and we say it is floating i know this this p mass on which ck goes will be off friends i want feedback yes sir yes yes sir okay so uh once we look into this aspect then then we say that let me show my slides again just give me a moment so then we come to other properties of dynamic gates where we say that overall power dissipation is higher we do not want glitching to happen and we already said higher transition probabilities and clock has very high load are you able to see this but in a static cmos logic style there is hardly any load on clock lock only goes to the flip flops whereas over here clock goes to every combination of gate so the load on clock is very high and we know that for clock alpha is equal to activity factor is equal to 1 1 so that is another reason why overall power of a dynamic logic system is very very high one is that there is any all additional toggling on the inputs also higher transition probabilities but extra load on clock is also there then uh the pull down network starts to work as soon as the input signals exceed vtn so uh you know the transition level v i m and v h are equal vtn as soon as uh the input touches vtn you you now know that okay my my uh output is starting to discharge so there is a noise of more than vtn your output starts to get corrupted so we talked about low noise martin already pre-charged okay we already know so one other important issue so we talked about the floating floating output so what does why is that an issue that is an issue because see there is this diode leakage over here due to this what happens is that you wanted the output to remain one but it is floating due to this leakage this output will discharge yes and this then needs to be restored there is no way to restore this so what you need to do what you need to do otherwise is you need to give the next clock pulse so clock goes to zero then again it recharges back so you need to give this refresh kind of a pulse over and over again this also leads to extra power consumption so yes so i mean like we can say that we can also do we can also like reduce this period for this this discharging is happening then also we can limit that then yeah but it is so okay how is the clock period of a pipeline or or any logic uh determined it is based on that overall evaluation time of that combinational block now yes sir so if you need some period then you need that period are you able to see this that is constrained it will depend upon the critical input as well right uh the input which is most delayed uh yes i know so there will be lots of signals which are coming to your combinational logic and the last one and how much time it takes to evaluate that one that will finally determine how much you need so how do we correct the char the charge leakage problem by using something very similar to what we call as level restorer in the transmission gate or power transistor logic we call it a keeper over here okay this transistor that we put as a half latch back there is called keeper and now what you get is you get out bar at the output are you able to see this oh so actually this keeper here will only prevent the charge from the cl to prevent the cl charge yes sir so i mean in effect it is preventing the charge from taking from that load basically or restoring that mass does not leak from the capacitor man because now it will be from the directly from the vdd that starts does not leak from a capacitor charge leaks from a and b the transistors are that have a and b connected to their gates yeah so now uh so but ineffectively the power that was lost due to leakage that will lose but now the source is different basically yeah yeah so leakage you cannot reduce you're not reducing leakage just saying that the impact of leakage on the gate and its reliability has been mitigated okay okay rajneesh you have a question sir can you move back to one slideshow yes but then there are there's a stack effect also coming now ck is also zero see when this this device is fully on then anyway there is something that will provide charge to this node i don't have a problem now yes whatever leakage happens that that it will follow this path not this path okay are you able to see that yes okay so anything else so this inverter that i used would be static this inverter that i used yeah this will be static [Laughter] yes otherwise it becomes tricky it will not you cannot really cascade it like this uh sir that out bar is meant only for keepers if i want to transfer the output to next stage i will be using the out the on one on the cl right no not necessary in fact we use the out so uh as we as we talk about cascading gates so there is a complexity in cascading the gate someone pointed that thing out we will talk about it in a little so as we will talk about it you will realize that we cannot have a gate uh or we cannot have input transitions going from one to zero in a dynamic gate see we said only one transition is accepted what is also important to realize is that that transition has to be a rising transition it cannot be a falling transition are you able to see this yes so if it has to be a rising transition then the output has to be inverted from whatever you got from the dynamic gate so actually you will use out bar at all the places where you need to use this the output of this combinational gate okay sir yes sir so uh the inverter which i am placing after my uh position of my load circuit that should be sized according to my keeper right so uh or am i thinking of it output load that should be sized according to the load that you want to put on this so but the output of my inverter is connected to my keeper and i should make sure that my keeper works fine whenever my output the main output is uh going down so in this sense i think my keeper should be uh sorry my inverter should be sized according to the keeper yes it has to be sized according to the keeper and also on the load that you put on out bar that is what i am saying okay the load that you put on out bar will be much much larger than this keeper this keeper is going to be very small just like we thought of talked about level restorer in the ptl this keeper has to be very small so that it does not fight back the input transitions okay sir sir and one more small question sir so sir in project we are supposed to place our load at this position only input before the inverter position 25 m2 farad which we were talking in the domino logic yeah i just answered this question now not necessary in fact i don't ask exactly this question i said no you will have to put it on the output of the inverter okay if you have static gate following it then it can be different but if we have dynamic gates following it it has to be an out bar okay okay so uh okay sir understood thank you okay now sir this level restorer you said that this livery store has to be small but we are keeping it so that it can reach uh it can restore the level of cl but if it is small then you can have higher only leakage so it's only leaking the leakage currents are much smaller than on current so that not yes sir so you need a very small keeper okay so so even small keeper will restore the charge even if it has a high resistance yeah because this keeper will be fully on see the keeper is on output is expected to be zero out bar is expected to be zero so the keeper is fully on pmos is in saturation region no yes okay so saturation current of the pmos versus off current of the nmos so keeper can be fairly small it will extend depend on the size it's a saturation current yes but you will see use if you have if you're working on the project with the dynamic gate you will see the skipper will actually be very very small not only will the width be 0.135 you will also keep length much larger than 0.6 106. okay okay and so one more thing is that in all these restorer circuits we are actually creating a feedback so wouldn't wouldn't that feedback i mean how will we ensure that this feedback is that we actually get out of this feedback by keeping this keeper and level restore is very small that's the purpose if we keep these small then even uh even the regular strength and mosque will be able to fight partner okay yeah that's the primary purpose so see the functionality is only to recover the leakage charge so you don't need much current anyways then another constraint is you do not want it to fight back the forward paths yes sir so you keep it small both the constraints lead to you lead you to keeping this keeper very very small as small as possible okay okay okay yes sir uh raghav sir with this keeper you said that earlier in the dynamic center it is a non-ratio like logic so it to maintain that then also like we have to maintain the keeper like to be like zero point one three five we cannot increase from that keeper is as as mother also mentioned keeper as a feedback as soon as you have feedback ratio logics comes in again yes sir yes sir so until there was this until there was there's no keeper there the everything was fully logical as soon as you have this keeper a sizing constraint comes in the keeper has to be as small as possible so but you said that legal we can also increase the velocity is the length like to maintain that yeah okay because other if you cannot reduce the width less than 0.135 in your technology and you want to still make it weaker the easiest way is to increase the length okay so but like my point first i understand that we had to keep it to the minimum side but exactly what exactly will be that uh sweet spot like how do i know about that okay i cannot get the liquid of your device okay of your device at ff125 okay you should do it at fs fast enough slow pmos at fs 125 highest voltage uh the keeper should be able to because pmos is now slow the pmos should still the pmos keeper should still be able to compensate for the charge loss through the inverses which are fast temperature is also high so leakage is high i know so why shouldn't i prefer the ff 125.32 and ss and you will make the keeper also fast it will anyway be able to offer more current okay right yes for the worst case sizing you have to test a tab you have to size the keeper at fast n mass slope mass and at high temperatures and at high voltage the leakage is maximum and at high voltages at higher temperatures the drive strength of the pmos will also reduce yes so that is the pace so you will size the keeper yes sir,https://www.youtube.com/watch?v=WrZ2leirJl8,"Link: https://www.youtube.com/watch?v=WrZ2leirJl8
Transcript: the last class so just started the dynamic we we were introduced we hadn't used the dynamic logic so what is dynamic logic why is it called so because the output is not driven and like always driven and we get a floating kind of output and it depends upon the charge that is stored on the capacitor not always driven so while in static gates we say that uh the output or all the nodes are always driven you do not leave things non-floating in static cmos case in dynamic logic we realized that there is only n stack and on the pima side you have a clock based header and on the at the end of the bottom of the nmr stack you have a clock based footer and you said that this this system uh will lead to a floating gate condition when the remaining nmos stack is off uh the pmos will go off and clock goes high and you will end up having floating output so since that kind of and then at that point of time you are dependent on the charge stored on that floating output to ensure that you are stable that you are robust so that is where it is called as a dynamic due to leakage you will you may need to refresh this so at the end of every clock cycle this this capacitor whether it had discharged or not will again be charged up to vdd okay so we also looked i started to look at the challenges or limitations around dynamic gates what were they sir there is very less noise immunity there is very less noise immunity okay for a particular uh within a single cycle of the clock the inputs can be changed at most once um so the inputs can can change only at most once input can go from zero to one only once if it if there is a glitch then i have a problem okay what else to charge and discharge this the power consumption is high so activity factor is very high so yes activity effect is also very that's something different but yeah activity factor is very high because in in terms of uh when you compare it with a static date even if the even if the inputs have not toggled a static gate would not consume any power but a dynamic gate will always consume power you know because at the end of every evaluation phase there is a precharge phase and in that recharge phase whatever capacitances you had discharged would get recharged all over again what else so we also saw that in dynamic gates the total number of transistors would be something like n plus 2 versus 2 n for the static cmos you're able to see this n plus two the plus two things yes sir the header clock the the pmos with the header clock and the n mass with the footer clock then the good thing about this is so we have lesser number of transistors but much much better situation than let us say ptl or pseudo and mass because the outputs are fulfilling outputs are full string the output is either full vdd and when it has to be zero it will be taken to full ground so outputs are full swing and because outputs are full swing and the nmr stack or pmos stack will is not you know there is no race condition or fight back between the two nmos and pmos traps like in uh pseudo nmos kind of a case the sizing does not really affect the logic levels the sizing affects the delays but it does not affect the logic levels and what also has happened we discussed this also in the last class we've reduced the capacitance with all capacitances have they reduced input all the pmos the most one we reduce the input capacitances because uh there is no pmos you know the the the signals now no longer need to go to the pmos so if i would make a inverter a dynamic inverter the pmos would have a clock on it there would be one n mass with a clock on it and then there will be the other end mass so the effective logical effort of this dynamic inverter would be can you quickly tell me hello so one third one third so wait a minute i seem to have lost control over my powerpoint slideshow why one third just just uh correct me two for the device two for the input gate and two for the clock so what is the total load that the input gate is seeing now two minutes two n so what what do we do then what is the uh uh what is this thing then the logical effort is two-thirds well logical effort is two by three hannah so do we still divide by the static yeah we can divide by the static uh like that is the reference for us as of now is it not so enough yes so how it has become two by three can please explain that again what is the input load of a regular inverter it's a three and what is the input load of this inverter that we talked about so we have a nmos in between that will be of size one why someone one he wanna say you know we have a footer two so uh so if you look at it just give me a moment your system would look like this am i right yes converter so the logical effort is two by three okay fine yes sir okay so then what do we do if we say that this is the kind of logical effort that we have uh what no logical efforts are what other constraints do you see would be happening with this kind of a dynamic gate now your circuit designers what kind of things would you see in the dynamic gate now so i mean i i can see that we cannot use like cascades like stages in stage kind stuff here like dynamic interesting why do you say so so because we have that constraint now because that input can go from only zero to one and suppose in we have cascaded it so if that is going the one is going there so in that for the subsequent state it will disrupt that the same kind of uh problem we will face that we didn't want to face with this same kind of problem so i mean like uh if we go if we have inputs other than going from 0 to 1 then we see that if the capacitor discharge then we don't have any option it will and that logic then will basically we will get different kind of uh we will get basically wrong outputs basically a dynamic then always have one to zero transit a transition at output right yes because at the end of the cycle you have to charge it to one well and uh so if the output has to transition it will always be from 1 to 0 there is no other transition possible and it was already 1 it can only go to 0 now or it will remain as 1. when it remains as 1 what do we say it is floating when it remains as one we say that it is floating are you with me because the pmos is off in the evaluation phase ck equal to 1 so pmos is off and we say it is floating i know this this p mass on which ck goes will be off friends i want feedback yes sir yes yes sir okay so uh once we look into this aspect then then we say that let me show my slides again just give me a moment so then we come to other properties of dynamic gates where we say that overall power dissipation is higher we do not want glitching to happen and we already said higher transition probabilities and clock has very high load are you able to see this but in a static cmos logic style there is hardly any load on clock lock only goes to the flip flops whereas over here clock goes to every combination of gate so the load on clock is very high and we know that for clock alpha is equal to activity factor is equal to 1 1 so that is another reason why overall power of a dynamic logic system is very very high one is that there is any all additional toggling on the inputs also higher transition probabilities but extra load on clock is also there then uh the pull down network starts to work as soon as the input signals exceed vtn so uh you know the transition level v i m and v h are equal vtn as soon as uh the input touches vtn you you now know that okay my my uh output is starting to discharge so there is a noise of more than vtn your output starts to get corrupted so we talked about low noise martin already pre-charged okay we already know so one other important issue so we talked about the floating floating output so what does why is that an issue that is an issue because see there is this diode leakage over here due to this what happens is that you wanted the output to remain one but it is floating due to this leakage this output will discharge yes and this then needs to be restored there is no way to restore this so what you need to do what you need to do otherwise is you need to give the next clock pulse so clock goes to zero then again it recharges back so you need to give this refresh kind of a pulse over and over again this also leads to extra power consumption so yes so i mean like we can say that we can also do we can also like reduce this period for this this discharging is happening then also we can limit that then yeah but it is so okay how is the clock period of a pipeline or or any logic uh determined it is based on that overall evaluation time of that combinational block now yes sir so if you need some period then you need that period are you able to see this that is constrained it will depend upon the critical input as well right uh the input which is most delayed uh yes i know so there will be lots of signals which are coming to your combinational logic and the last one and how much time it takes to evaluate that one that will finally determine how much you need so how do we correct the char the charge leakage problem by using something very similar to what we call as level restorer in the transmission gate or power transistor logic we call it a keeper over here okay this transistor that we put as a half latch back there is called keeper and now what you get is you get out bar at the output are you able to see this oh so actually this keeper here will only prevent the charge from the cl to prevent the cl charge yes sir so i mean in effect it is preventing the charge from taking from that load basically or restoring that mass does not leak from the capacitor man because now it will be from the directly from the vdd that starts does not leak from a capacitor charge leaks from a and b the transistors are that have a and b connected to their gates yeah so now uh so but ineffectively the power that was lost due to leakage that will lose but now the source is different basically yeah yeah so leakage you cannot reduce you're not reducing leakage just saying that the impact of leakage on the gate and its reliability has been mitigated okay okay rajneesh you have a question sir can you move back to one slideshow yes but then there are there's a stack effect also coming now ck is also zero see when this this device is fully on then anyway there is something that will provide charge to this node i don't have a problem now yes whatever leakage happens that that it will follow this path not this path okay are you able to see that yes okay so anything else so this inverter that i used would be static this inverter that i used yeah this will be static [Laughter] yes otherwise it becomes tricky it will not you cannot really cascade it like this uh sir that out bar is meant only for keepers if i want to transfer the output to next stage i will be using the out the on one on the cl right no not necessary in fact we use the out so uh as we as we talk about cascading gates so there is a complexity in cascading the gate someone pointed that thing out we will talk about it in a little so as we will talk about it you will realize that we cannot have a gate uh or we cannot have input transitions going from one to zero in a dynamic gate see we said only one transition is accepted what is also important to realize is that that transition has to be a rising transition it cannot be a falling transition are you able to see this yes so if it has to be a rising transition then the output has to be inverted from whatever you got from the dynamic gate so actually you will use out bar at all the places where you need to use this the output of this combinational gate okay sir yes sir so uh the inverter which i am placing after my uh position of my load circuit that should be sized according to my keeper right so uh or am i thinking of it output load that should be sized according to the load that you want to put on this so but the output of my inverter is connected to my keeper and i should make sure that my keeper works fine whenever my output the main output is uh going down so in this sense i think my keeper should be uh sorry my inverter should be sized according to the keeper yes it has to be sized according to the keeper and also on the load that you put on out bar that is what i am saying okay the load that you put on out bar will be much much larger than this keeper this keeper is going to be very small just like we thought of talked about level restorer in the ptl this keeper has to be very small so that it does not fight back the input transitions okay sir sir and one more small question sir so sir in project we are supposed to place our load at this position only input before the inverter position 25 m2 farad which we were talking in the domino logic yeah i just answered this question now not necessary in fact i don't ask exactly this question i said no you will have to put it on the output of the inverter okay if you have static gate following it then it can be different but if we have dynamic gates following it it has to be an out bar okay okay so uh okay sir understood thank you okay now sir this level restorer you said that this livery store has to be small but we are keeping it so that it can reach uh it can restore the level of cl but if it is small then you can have higher only leakage so it's only leaking the leakage currents are much smaller than on current so that not yes sir so you need a very small keeper okay so so even small keeper will restore the charge even if it has a high resistance yeah because this keeper will be fully on see the keeper is on output is expected to be zero out bar is expected to be zero so the keeper is fully on pmos is in saturation region no yes okay so saturation current of the pmos versus off current of the nmos so keeper can be fairly small it will extend depend on the size it's a saturation current yes but you will see use if you have if you're working on the project with the dynamic gate you will see the skipper will actually be very very small not only will the width be 0.135 you will also keep length much larger than 0.6 106. okay okay and so one more thing is that in all these restorer circuits we are actually creating a feedback so wouldn't wouldn't that feedback i mean how will we ensure that this feedback is that we actually get out of this feedback by keeping this keeper and level restore is very small that's the purpose if we keep these small then even uh even the regular strength and mosque will be able to fight partner okay yeah that's the primary purpose so see the functionality is only to recover the leakage charge so you don't need much current anyways then another constraint is you do not want it to fight back the forward paths yes sir so you keep it small both the constraints lead to you lead you to keeping this keeper very very small as small as possible okay okay okay yes sir uh raghav sir with this keeper you said that earlier in the dynamic center it is a non-ratio like logic so it to maintain that then also like we have to maintain the keeper like to be like zero point one three five we cannot increase from that keeper is as as mother also mentioned keeper as a feedback as soon as you have feedback ratio logics comes in again yes sir yes sir so until there was this until there was there's no keeper there the everything was fully logical as soon as you have this keeper a sizing constraint comes in the keeper has to be as small as possible so but you said that legal we can also increase the velocity is the length like to maintain that yeah okay because other if you cannot reduce the width less than 0.135 in your technology and you want to still make it weaker the easiest way is to increase the length okay so but like my point first i understand that we had to keep it to the minimum side but exactly what exactly will be that uh sweet spot like how do i know about that okay i cannot get the liquid of your device okay of your device at ff125 okay you should do it at fs fast enough slow pmos at fs 125 highest voltage uh the keeper should be able to because pmos is now slow the pmos should still the pmos keeper should still be able to compensate for the charge loss through the inverses which are fast temperature is also high so leakage is high i know so why shouldn't i prefer the ff 125.
32 and ss and you will make the keeper also fast it will anyway be able to offer more current okay right yes for the worst case sizing you have to test a tab you have to size the keeper at fast n mass slope mass and at high temperatures and at high voltage the leakage is maximum and at high voltages at higher temperatures the drive strength of the pmos will also reduce yes so that is the pace so you will size the keeper yes sir"
1s96L4B1Nrk,um sir in the layout of uh domino logic if i am using a standard cell template then i am able to see that if i am using four to five uh input uh a y then i have seven to it n was and only three b mos there i'll see that recording so what we do is at the edges we keep the envelopes to be as much as we wanted hannah so we make our t masses here you make the output p masses here all that you do then you take this up and then what you do is you put your n masses here so now you have more space for your end losses okay but this minimum width of envelope has to be maintained this minimum width of n well has to be maintained and uh this has to be maintained so ab drc sorry maintain kirk you can always do this okay thank you okay uh sir i just wanted to confirm that only the rising transition accepted because uh when the clock is high that would only be yeah that would only be the transition which would help the output to discharge and there is nothing and other no special reason for other other changes you tell me if the clock is high that is when the evaluation phase is on yes let us say a and b were initially one and you say only one transition is allowed now b goes to zero after some time after clock has come b goes to 0 after some time and you say oh this is only one transition allow this will it work no that is why only one transition and that to a rising transition yes exactly okay okay thanks sir so one small question regarding the c load thing says this c load should be attached after one more inverter after outbound right because uh what the cl is in their case they've put the c load there but if you have to so if you have to cascade uh so after this dynamic gate the dynamic nand gate if you were to use static gates then all that c load can come on this place where they have put this here however if it has to be dynamic gates then you will just see raw vm battery at a debunk also has exactly the same thing that you only accept zero to one rising transitions so you have to have this inverter in place without this inverter you cannot connect the next dynamic gate stage because if you connect the dynamic gate stage over here let us say let us say you put another dynamic gate stage over here what will happen so this is one clock comes this this one would discharge now this was already one but over here also a and b were one so they also discharge now this goes to zero what will you do now okay so the next pdn network could be off but it is already discharged the capacitance over here no yes and nothing we could do to uh now you lost this information now this is not usable therefore what we do is we instead modify the logic in such a way that it will put put out bar at your gate okay yes sir cl so one more small question is that suppose we are making we are suppose not cascading and only making one aoi only complex state then to represent the correct output we need to put an inverter right because which trip are we talking about which chip are we talking about can there be a list which has only one gate just give me a moment okay yeah i'm sorry so see you cannot really make just one static gate somewhere can you no sir i know so you will always have more designs some you cannot have a chip with only one gate so let's not talk of a hypothetical situation when there are gates cascaded one after the other if the gate cascaded after a dynamic gate is a dynamic gate then that gate has to come after this inverter it cannot come before the inverter if it comes then we have to design that gate in a different manner we will just see that also so let's just hold these questions of cascading gates for a little while is that okay we'll cover that part in just a little bit please sir i have a general question sir so my clock will be running all over the uh all over my layout so uh my doubt was that so i should make sure that my clock should be a lcm of these both gate but both inputs a and b for suppose in this lcm least common multiple of period of both inputs so that i can get all my outs a and b are not a and b are not clocks they do not have a period they are they are just like uh let us say uh i am i'm adding two numbers so there could be 0 1 1 0 1 1 1 0 anything that could be it is not a clock so what do you mean by period of a and b okay that actually that was my doubt sir actually as my a and b signals are not sure uh then uh how am i supposed to know that my clock which i give to this system uh should make sure that i should be uh i should be capable of doing every method for a and b there are four combinations zero zero zero one one zero and one one i should be capable of doing all this all these combinations in that case uh now if i if i look into the system then for for this zero zero zero one one zero one one kind of thing uh i'll have some specific value specific time period of a and time period of b uh if i if i give it uh first suppose then uh my clock in this condition should be the lcm of this both time periods uh in in a specific condition then but do you have a time period for a non non uh recurring signal no sir this was made out i i got it clarified just now okay there's no time period of a and b there is a timing constraint between a and b and clock that a and b should be settled before clock arrives that timing constraint you can't talk about but time period is there's nothing like a time period for a and b okay okay sir thank you okay so you want that if the a and b have to be one then they should arrive some sometime before block arrives sir uh the clock frequency here must be of one particular one it should not vary with if we are doing some different operation so if the clock frequency is varying denser [Music] means our this time period must be constant measure for a particular sizing of circuits yeah for a particular processor for a particular design you will have you will arrive at some clock frequency at which you will operate yes okay i know so all the combinational gates will will get the same clock whether it is a nand gate or a y or whatever it is so another problem that happens we just now looked at the leakage problem now consider this case clk is already one let us say and now a goes to one b remains at zero what happens c c l will charge c a there will be charge redistribution between cl and ca and what does this do to cl so its logic level basically gets speakers and there is no way to recharge it back yes sir so what do you do then again you put level resource now in this particular case it does not look very complex but look at this gate there is some cl which is 50 central farads and there are this internal capacitances also so if you really end up using the 50 cent of farad capacitor to distrib and distributed starch all over the place you may actually come to as low a value as vdd by 2 are you able to see this yes yes sir so what do you do what can you do over here recharge the internal nodes sorry so uh yes you will put some precharge somewhere so just like the level restorer the keeper that we had put there we would put some keepers over here also so we will actually end up putting keepers at suppose if you have this so you can always you know find out how the charge distribution would happen this this is very basic you can find this out i can assume that you can find this out friends server is it not increasing the area of our circuit like if we are putting keepers yeah it is so uh and keepers usually we put an inverter which is of a larger size because look at look at this complex kit that we just saw this was so this is a four input aoi kind of a gate huh now area is increasing yes because you put one keeper let us say you you end up putting keepers at at all these big capacitances you will put one keeper over here one keeper over here whatever okay so you put some but these are very small p masses now if for this if for this nmos pull down network you have to make a pull up network what was the area that you were looking into okay so i i got confused because the keepers i'm not only about the area but i'm seeing that the clock is also getting we have to provide more power clock power and then also the parasitics also is increasing at the point we are providing the keepers right there so i mean clock has to drive then more kind of uh devices right because uh the pmos that would be using for the keeper that will be also driven by the clock so if we add more and more keepers need not be that can be driven by this output also now can be clocked even the output because you finally you wanted this to be if this was one and you had a you want to maintain it as one you do not want to disagree you just use it like that okay yes so we can [Music] combine recharge will happen from the clock precast will happen from mp over here right so another third transistor for keypad yeah a keeper is to be added yes okay okay sir will be uh sir will we add a single keeper for single node or one keeper can take care of many nodes you tell me how many source and drain does one keeper have said if i attach one source too many so it means you're shorting all those notes they become one note then oh sorry yes see look at it like this yes it appears to be inefficient but it is much much faster yes yes at cost of increasing yes no not increased area area as we just discussed is also lesser keepers are very small the pmos is that you will need to put with this pulldown network will be very large comparatively okay i know sir even if my output capacitance charge has been discharged by the parasitics in between uh even uh but i have my keeper above for my output capacitance so uh is this keeper is it not sufficient to drive my output to vdd back again uh depends vaishnav just as we looked in that example if the output has gone to vdd by two then the inverter must have also gone too high so keeper would have turned off okay so in that case my keeper is inefficient to get back that is where you will then need the clocks or you will need keepers also in those internal places and not just on the top okay okay okay so that there is minimal charge sharing okay yeah uh raghav uh yes sir sir like as rajneesh asked that we can get some uh positive thing with the advantage with the tph pizza i think that theoretically tpl is zero right i mean because the rising thing that the clock is taking care of the p charge phase is taking care of that the reset phase no no there is a reset phase recharge time we said the reset time would reduce yes fine okay and so like here you would you talking like with the extra keeper that is hacking we don't necessarily need to connect it with the clock we can connect it directly with the output like inverter right okay it thank you what is the problem with when we do that so we can do that yes in specific cases we can't do that but what is the problem when will we not be able to do that okay uh currently out yeah output voltage which we have we are dead sorting it with the node which is in between a and b why my keeper is connected to output however and this same same position is being connected in between of my a and b no so we said we have to add an extra keeper now yes so okay so the here can i just add one keeper and charge all the nodes with that and we realize no that is not possible okay so this keeper which you are showing is only for an internal node in this diagram you see this has clock going this has clock going to it the one on the output the keeper that i put here for that we had this inverted output going there now my question is that inverted output could also go to some of these keepers what will be the problem or how do you avoid how to avoid that problem if you connect this out bar like what do you do can you always do it or do you always need clock so clock is needed because else the pull the footer would be on and there would be a shot between vdd and ground at some places yes at some places it could happen that out is let us say sometimes it could happen that let us say in this particular case for example uh let us say a was 0 b was 1 now what happens as soon as clock goes to 1 this node is expected to discharge but a is 0 so a will not let the out node to disarch so if i had this inverter coming and then connecting what would happen this remains one this goes to zero so there is a direct path from vdg to ground so we can use output also for such intermediate keepers but you have to be extremely careful that the connectivity is such that there is no direct path if you want to play very very safe use the clock clock load would increase and uh yeah keepers are much smaller than these three charge transistors but but even then clock load would increase sir one small thing just can i uh ask this is the last class someone asks that footer can we place over a or b or not same thing could occur here also uh because clock will would be changing from one to zero and therefore zero to one so uh direct short path could exist again here if we place footer above a and b so uh the switching leakage would increase right i mean switching current would increase right you could place footer above dnb right because uh sir a direct longer direct path would exist where both the footer and free charge would be on at the same time uh during the clock transiting period why let us say this is how i put it and then i put a and b over here now where is this extra current going there's nothing supposed to be a and b is zero okay then nothing no if a and b were one then anyway there were three even then in this case also three devices were one so they were expected to discharge out okay you know okay sorry i know so why do we still keep the ck on the bottom we could put ck on up there also but why do we still keep it on the bottom so maybe due to that we want to like uh keep the clock signals away from uh internal metal or internal interconnects or that because that can lead to like some kind of capacitive effect coupling so it essentially becomes an inverter and in in water layout or making we saw whenever the inverter switches there is some kink at the uh output that we observed so some noise could be introduced i think okay something else we just decided is the footer larger than other internal can be and that doesn't matter that is not where the answer is we discussed about this you know in the static gates we talked about inputs coming late should be closer to the output so over here in the evaluation phase the output will discharge when a and b will go to one so what is coming after c has gone to one a and b hello so therefore we need the c k to be on the bottom so that your output still comes fast rather this yes but like one was the input ordering but uh could that be also reason that uh because clock activity is very high so in between we have like different kind of interconnects running through that and if it is other you know let us forget that even if you do not look at the layout aspects you want stills the ck to be at the bottom because once whenever a and b whichever of them when both of them go to one you want the output to be discharged as quickly as possible yes sir yes that is that is the reason okay if you are always sure that this a and b will arrive before ck arrives it will always be set up then it's a different thing but that's not usually the case you will not be able to ascertain that so now the next problem that we are looking at is uh back gate coupling so we said that you could you could uh couple uh you could couple static dates directly at the output of the dynamic gate without the inverter and then because static gates can take both kind of transition zero to one and one to zero so static gate script will challenge but when you couple a static gate right after the write down out one what can happen yeah so back gate coupling starts to happen now let us say that your out one was something and uh out two or something and all that in goes to 1 from 0 from 0 in goes to 1 out 1 was already 1 what will happen at once out 2 will discharge now yes sir when out two discharges what will happen due to miller coupling out one will also see some discharge happening so this back gate coupling is also an issue that you will have in dynamic gates so even when you are coupling a static gate next to a dynamic gate there could be such challenges that can appear are you able to see this sir yes so when the outpour is getting discharged out one will also see a discharge can you please explain this line duty miller coupling yeah this is the capacitance this is the miller coupling yes sir so out 2 went to zero psn now this coupling capacitance is also between out two and out one okay yes sir okay another problem that we have is clock feed through so dynamic gates when you want to use okay they are very very fast very very high speed but they suffer from lots of these problems there is another problem of clock feed through this is something like what are you talking about we thought that pelican when the clock comes there will be some feed through between clock and the output this is what we discussed you know this this part you remember yes sir you discussed this earlier so this is also a problem because unnecessarily your clock your output is going up and low and all that we don't want that also so and and these cannot be avoided and there are other problems also capacitive coupling as we know that this node is floating this output node will be floating when ck is equal to one so any crosstalk that will lead to noise and injection of a charge injection over here substrate coupling any any any noise on the substrate over here when the output is floating again that will couple on to the output so uh supply noise so many things linked to dynamic gates but even then you will see they are used fairly much more often than pass transistor logic and transmission gate logic they're used much more often than those two places why because they're very high speed very very high speed power is higher but speed is also very high which is what people love yes but theoretically if i say i think you see that but pseudo nmos would be even faster should be than this dynamic right so it almost cannot go to zero no yeah that is the challenge so you don't want that anna rajneesh sir can you move to the clock feed through slide voltage reliability becomes an issue okay so sorry we will write that if we did increase the gate reliability decreases yeah at higher variety the gate is gate areas faster so the gate reliability degrades yes okay okay i know yes yes,https://www.youtube.com/watch?v=1s96L4B1Nrk,"Link: https://www.youtube.com/watch?v=1s96L4B1Nrk
Transcript: um sir in the layout of uh domino logic if i am using a standard cell template then i am able to see that if i am using four to five uh input uh a y then i have seven to it n was and only three b mos there i'll see that recording so what we do is at the edges we keep the envelopes to be as much as we wanted hannah so we make our t masses here you make the output p masses here all that you do then you take this up and then what you do is you put your n masses here so now you have more space for your end losses okay but this minimum width of envelope has to be maintained this minimum width of n well has to be maintained and uh this has to be maintained so ab drc sorry maintain kirk you can always do this okay thank you okay uh sir i just wanted to confirm that only the rising transition accepted because uh when the clock is high that would only be yeah that would only be the transition which would help the output to discharge and there is nothing and other no special reason for other other changes you tell me if the clock is high that is when the evaluation phase is on yes let us say a and b were initially one and you say only one transition is allowed now b goes to zero after some time after clock has come b goes to 0 after some time and you say oh this is only one transition allow this will it work no that is why only one transition and that to a rising transition yes exactly okay okay thanks sir so one small question regarding the c load thing says this c load should be attached after one more inverter after outbound right because uh what the cl is in their case they've put the c load there but if you have to so if you have to cascade uh so after this dynamic gate the dynamic nand gate if you were to use static gates then all that c load can come on this place where they have put this here however if it has to be dynamic gates then you will just see raw vm battery at a debunk also has exactly the same thing that you only accept zero to one rising transitions so you have to have this inverter in place without this inverter you cannot connect the next dynamic gate stage because if you connect the dynamic gate stage over here let us say let us say you put another dynamic gate stage over here what will happen so this is one clock comes this this one would discharge now this was already one but over here also a and b were one so they also discharge now this goes to zero what will you do now okay so the next pdn network could be off but it is already discharged the capacitance over here no yes and nothing we could do to uh now you lost this information now this is not usable therefore what we do is we instead modify the logic in such a way that it will put put out bar at your gate okay yes sir cl so one more small question is that suppose we are making we are suppose not cascading and only making one aoi only complex state then to represent the correct output we need to put an inverter right because which trip are we talking about which chip are we talking about can there be a list which has only one gate just give me a moment okay yeah i'm sorry so see you cannot really make just one static gate somewhere can you no sir i know so you will always have more designs some you cannot have a chip with only one gate so let's not talk of a hypothetical situation when there are gates cascaded one after the other if the gate cascaded after a dynamic gate is a dynamic gate then that gate has to come after this inverter it cannot come before the inverter if it comes then we have to design that gate in a different manner we will just see that also so let's just hold these questions of cascading gates for a little while is that okay we'll cover that part in just a little bit please sir i have a general question sir so my clock will be running all over the uh all over my layout so uh my doubt was that so i should make sure that my clock should be a lcm of these both gate but both inputs a and b for suppose in this lcm least common multiple of period of both inputs so that i can get all my outs a and b are not a and b are not clocks they do not have a period they are they are just like uh let us say uh i am i'm adding two numbers so there could be 0 1 1 0 1 1 1 0 anything that could be it is not a clock so what do you mean by period of a and b okay that actually that was my doubt sir actually as my a and b signals are not sure uh then uh how am i supposed to know that my clock which i give to this system uh should make sure that i should be uh i should be capable of doing every method for a and b there are four combinations zero zero zero one one zero and one one i should be capable of doing all this all these combinations in that case uh now if i if i look into the system then for for this zero zero zero one one zero one one kind of thing uh i'll have some specific value specific time period of a and time period of b uh if i if i give it uh first suppose then uh my clock in this condition should be the lcm of this both time periods uh in in a specific condition then but do you have a time period for a non non uh recurring signal no sir this was made out i i got it clarified just now okay there's no time period of a and b there is a timing constraint between a and b and clock that a and b should be settled before clock arrives that timing constraint you can't talk about but time period is there's nothing like a time period for a and b okay okay sir thank you okay so you want that if the a and b have to be one then they should arrive some sometime before block arrives sir uh the clock frequency here must be of one particular one it should not vary with if we are doing some different operation so if the clock frequency is varying denser [Music] means our this time period must be constant measure for a particular sizing of circuits yeah for a particular processor for a particular design you will have you will arrive at some clock frequency at which you will operate yes okay i know so all the combinational gates will will get the same clock whether it is a nand gate or a y or whatever it is so another problem that happens we just now looked at the leakage problem now consider this case clk is already one let us say and now a goes to one b remains at zero what happens c c l will charge c a there will be charge redistribution between cl and ca and what does this do to cl so its logic level basically gets speakers and there is no way to recharge it back yes sir so what do you do then again you put level resource now in this particular case it does not look very complex but look at this gate there is some cl which is 50 central farads and there are this internal capacitances also so if you really end up using the 50 cent of farad capacitor to distrib and distributed starch all over the place you may actually come to as low a value as vdd by 2 are you able to see this yes yes sir so what do you do what can you do over here recharge the internal nodes sorry so uh yes you will put some precharge somewhere so just like the level restorer the keeper that we had put there we would put some keepers over here also so we will actually end up putting keepers at suppose if you have this so you can always you know find out how the charge distribution would happen this this is very basic you can find this out i can assume that you can find this out friends server is it not increasing the area of our circuit like if we are putting keepers yeah it is so uh and keepers usually we put an inverter which is of a larger size because look at look at this complex kit that we just saw this was so this is a four input aoi kind of a gate huh now area is increasing yes because you put one keeper let us say you you end up putting keepers at at all these big capacitances you will put one keeper over here one keeper over here whatever okay so you put some but these are very small p masses now if for this if for this nmos pull down network you have to make a pull up network what was the area that you were looking into okay so i i got confused because the keepers i'm not only about the area but i'm seeing that the clock is also getting we have to provide more power clock power and then also the parasitics also is increasing at the point we are providing the keepers right there so i mean clock has to drive then more kind of uh devices right because uh the pmos that would be using for the keeper that will be also driven by the clock so if we add more and more keepers need not be that can be driven by this output also now can be clocked even the output because you finally you wanted this to be if this was one and you had a you want to maintain it as one you do not want to disagree you just use it like that okay yes so we can [Music] combine recharge will happen from the clock precast will happen from mp over here right so another third transistor for keypad yeah a keeper is to be added yes okay okay sir will be uh sir will we add a single keeper for single node or one keeper can take care of many nodes you tell me how many source and drain does one keeper have said if i attach one source too many so it means you're shorting all those notes they become one note then oh sorry yes see look at it like this yes it appears to be inefficient but it is much much faster yes yes at cost of increasing yes no not increased area area as we just discussed is also lesser keepers are very small the pmos is that you will need to put with this pulldown network will be very large comparatively okay i know sir even if my output capacitance charge has been discharged by the parasitics in between uh even uh but i have my keeper above for my output capacitance so uh is this keeper is it not sufficient to drive my output to vdd back again uh depends vaishnav just as we looked in that example if the output has gone to vdd by two then the inverter must have also gone too high so keeper would have turned off okay so in that case my keeper is inefficient to get back that is where you will then need the clocks or you will need keepers also in those internal places and not just on the top okay okay okay so that there is minimal charge sharing okay yeah uh raghav uh yes sir sir like as rajneesh asked that we can get some uh positive thing with the advantage with the tph pizza i think that theoretically tpl is zero right i mean because the rising thing that the clock is taking care of the p charge phase is taking care of that the reset phase no no there is a reset phase recharge time we said the reset time would reduce yes fine okay and so like here you would you talking like with the extra keeper that is hacking we don't necessarily need to connect it with the clock we can connect it directly with the output like inverter right okay it thank you what is the problem with when we do that so we can do that yes in specific cases we can't do that but what is the problem when will we not be able to do that okay uh currently out yeah output voltage which we have we are dead sorting it with the node which is in between a and b why my keeper is connected to output however and this same same position is being connected in between of my a and b no so we said we have to add an extra keeper now yes so okay so the here can i just add one keeper and charge all the nodes with that and we realize no that is not possible okay so this keeper which you are showing is only for an internal node in this diagram you see this has clock going this has clock going to it the one on the output the keeper that i put here for that we had this inverted output going there now my question is that inverted output could also go to some of these keepers what will be the problem or how do you avoid how to avoid that problem if you connect this out bar like what do you do can you always do it or do you always need clock so clock is needed because else the pull the footer would be on and there would be a shot between vdd and ground at some places yes at some places it could happen that out is let us say sometimes it could happen that let us say in this particular case for example uh let us say a was 0 b was 1 now what happens as soon as clock goes to 1 this node is expected to discharge but a is 0 so a will not let the out node to disarch so if i had this inverter coming and then connecting what would happen this remains one this goes to zero so there is a direct path from vdg to ground so we can use output also for such intermediate keepers but you have to be extremely careful that the connectivity is such that there is no direct path if you want to play very very safe use the clock clock load would increase and uh yeah keepers are much smaller than these three charge transistors but but even then clock load would increase sir one small thing just can i uh ask this is the last class someone asks that footer can we place over a or b or not same thing could occur here also uh because clock will would be changing from one to zero and therefore zero to one so uh direct short path could exist again here if we place footer above a and b so uh the switching leakage would increase right i mean switching current would increase right you could place footer above dnb right because uh sir a direct longer direct path would exist where both the footer and free charge would be on at the same time uh during the clock transiting period why let us say this is how i put it and then i put a and b over here now where is this extra current going there's nothing supposed to be a and b is zero okay then nothing no if a and b were one then anyway there were three even then in this case also three devices were one so they were expected to discharge out okay you know okay sorry i know so why do we still keep the ck on the bottom we could put ck on up there also but why do we still keep it on the bottom so maybe due to that we want to like uh keep the clock signals away from uh internal metal or internal interconnects or that because that can lead to like some kind of capacitive effect coupling so it essentially becomes an inverter and in in water layout or making we saw whenever the inverter switches there is some kink at the uh output that we observed so some noise could be introduced i think okay something else we just decided is the footer larger than other internal can be and that doesn't matter that is not where the answer is we discussed about this you know in the static gates we talked about inputs coming late should be closer to the output so over here in the evaluation phase the output will discharge when a and b will go to one so what is coming after c has gone to one a and b hello so therefore we need the c k to be on the bottom so that your output still comes fast rather this yes but like one was the input ordering but uh could that be also reason that uh because clock activity is very high so in between we have like different kind of interconnects running through that and if it is other you know let us forget that even if you do not look at the layout aspects you want stills the ck to be at the bottom because once whenever a and b whichever of them when both of them go to one you want the output to be discharged as quickly as possible yes sir yes that is that is the reason okay if you are always sure that this a and b will arrive before ck arrives it will always be set up then it's a different thing but that's not usually the case you will not be able to ascertain that so now the next problem that we are looking at is uh back gate coupling so we said that you could you could uh couple uh you could couple static dates directly at the output of the dynamic gate without the inverter and then because static gates can take both kind of transition zero to one and one to zero so static gate script will challenge but when you couple a static gate right after the write down out one what can happen yeah so back gate coupling starts to happen now let us say that your out one was something and uh out two or something and all that in goes to 1 from 0 from 0 in goes to 1 out 1 was already 1 what will happen at once out 2 will discharge now yes sir when out two discharges what will happen due to miller coupling out one will also see some discharge happening so this back gate coupling is also an issue that you will have in dynamic gates so even when you are coupling a static gate next to a dynamic 
gate there could be such challenges that can appear are you able to see this sir yes so when the outpour is getting discharged out one will also see a discharge can you please explain this line duty miller coupling yeah this is the capacitance this is the miller coupling yes sir so out 2 went to zero psn now this coupling capacitance is also between out two and out one okay yes sir okay another problem that we have is clock feed through so dynamic gates when you want to use okay they are very very fast very very high speed but they suffer from lots of these problems there is another problem of clock feed through this is something like what are you talking about we thought that pelican when the clock comes there will be some feed through between clock and the output this is what we discussed you know this this part you remember yes sir you discussed this earlier so this is also a problem because unnecessarily your clock your output is going up and low and all that we don't want that also so and and these cannot be avoided and there are other problems also capacitive coupling as we know that this node is floating this output node will be floating when ck is equal to one so any crosstalk that will lead to noise and injection of a charge injection over here substrate coupling any any any noise on the substrate over here when the output is floating again that will couple on to the output so uh supply noise so many things linked to dynamic gates but even then you will see they are used fairly much more often than pass transistor logic and transmission gate logic they're used much more often than those two places why because they're very high speed very very high speed power is higher but speed is also very high which is what people love yes but theoretically if i say i think you see that but pseudo nmos would be even faster should be than this dynamic right so it almost cannot go to zero no yeah that is the challenge so you don't want that anna rajneesh sir can you move to the clock feed through slide voltage reliability becomes an issue okay so sorry we will write that if we did increase the gate reliability decreases yeah at higher variety the gate is gate areas faster so the gate reliability degrades yes okay okay i know yes yes"
ouihedF07RY,okay so now we formally come to the topic of cascading dynamic gates so we see that this is not this is not the right way to cascade anna what would happen here out transition is from one to zero then i will have some discharge and that will not be refreshed yes so out one goes to zero after ck comes but even before out out one has goes to zero out two has discharged earlier so you cannot really cascade dynamic gate just like this so what do we do we can have other ways to cascade gates so which is like first we already talked about put an inverter in between then what will solve the problem because transitions are now always zero to equal to one zero to one transitions are safe no problems there this is called domino logic why is it called domino you've seen dominoes yes sir the circuit is being evaluated one after the another stage by stage yeah so dominoes are are stacks of cards one false it touches the other one the other one falls the other one falls over and falls and the whole chain activate gets activated uh during the corona times there was this ad you know that you have to break the chain so we are the mask so one person wears a mask that person comes out of this domino chain and the overall chain breaks otherwise everyone gets infected you remember that ad what's up they bought circulatory seen that yes sir so domino this is called domino because until out one goes to one tdn the second period will not evaluate so only after first pdn has evaluated will the second pdn evaluate then the third pd and evaluate then the fourth pdn evaluate that is why it is called as domino logic okay yeah questions so tarun uh hello sir it's more of an open-ended question so as we go more and more towards low power design so shouldn't uh the the dynamic circuits will be like very little use yeah but they're still much more as i said they're still much more often used than ptl and uh pseudo pseudonymous is not used almost anywhere you will still see dynamic circuits used fairly often much often than pseudo nmos and ptl okay so learning all these all the different designs is fine but with so much variety of designs that are possible and how do we even decide what a particular how to probably design a particular thing like in a processor there will be thousands of different components like address multipliers and so many different kinds of things and so many different kinds of constraints if this is fast then this has to be slow and all these things have to be made so how do we even decide on this default so mother the default would be static cmos okay now if you want higher speed than static cmos then you go to dynamic okay if in the static cmos you know that there are places where you could save area by going to ppl and that those those movements are always you know 0 0 0 0 output to be transmitted from one side to the other then you could go to ptl also okay for example now this will be ptl varieties would be in in places like implementing muxes in memories okay so there are some very specific use cases for all these other design styles default is always static cmos and that too whatever is best for your layout all those skewed cmos gates and high skew low q and all those they are also very specifically used in data paths you really want to speed up exactly one or two critical paths otherwise even they are not used even though they are static cmos okay but all these levers you should know as designers because tomorrow when you go and design somewhere you should know that okay if my manager or my customer is asking for much higher speed there is one this additional lever that i have which is domino logic i can try that and you can experiment with it and you can see okay now with domino static cmos i can go to 500 megahertz domino i can go to 800 but with static cmos the power was let us say 2 milliwatts and the domino it is 3.8 i've got much higher speed but power has also increased so let the customer choose okay okay so like in embedded systems like application i will prefer to use static because it consumes lower power and not typically you will only use static mother status is a mainstay that is why it is also taught in second third year okay okay there's being an advanced course you're talking about more advanced things also okay okay yes sir those are not the main step don't confuse it with that they are not the mainstay all this dc vsl and all those so we discussed the cvsr for example is only only used for xor nor combination almost nowhere else the very specific uh ideas and they are being shared so that after you go home and if you come up with you know you you get inspired by these specific games and you can propose something new yourself also okay so okay yeah yes sir sir one confusion that i'm getting over here is uh sir how we are preserving the means uh total means logic actually total input to output logic how do you preserve that in a regular static cmos gate sir my confusion here is suppose we are implementing an sop suppose a b plus c d the first stage would be and gate next stage should be or gate so now here we are press if you are placing an inverter in between so means that no they are there demorgan's theorem you know that now so some kind of bubble pushing need to be made and land and representation something like that yes what's the big deal there that is a simpler part the other challenges that we discussed just now they are the more complex ones they breathe well pushing is so logical it is so simple so suppose you you have given me to design aoi in non-complex form in a uh where individual gates need to be also a dynamic gate so you will not ask me that uh suppose this is a and gate why we implement it using a nand gate we will just simply now input an output right yeah answer one more question here after we create the truth table that's it uh yes a truth table should be preserved input and output and one more thing here is that uh it's a keeper circuit how will how we can place that can we just show in the diagram keep a circuit in the character in the first level okay why why was this question there sir output capacitance increase over there at 0.135 by 0.2 it's a very small keeper so turning on the keeper would be not a problem or challenge anywhere that's and that is why you also design it to be very small huh yes sir you should understand thank you yeah so can we here also prefer that in this inverter can we prefer a high screen water here because we are only interested in the zero you tell me uh what was the if this inverter was not there what was the default state of input coming to this second pdf if this inverter was not there what would be this input's default state in the pre-charge state zero to one clockwise so if it is one then what happens after as soon as clock comes even before this one discharges this one would discharge yes sir we don't want that yes okay yes okay okay okay because inverter changes the default state to zero yes sir okay okay so yeah this is also explained in the animation over here now domino we just discussed why it is domino because only after the first one is evaluated the second one will be evaluated and the third one then the fourth one okay and uh again properties of domino only non-inverted logic can be can be implemented and because it is dynamic gate based and capacitances are reduced there is smaller logical effort this is much much faster and as one of you already pointed out inverter can be skewed because only one transition is important for us the other one is not even important so domino can be designed very very fast now look at it like this over here if i know that only after this comes here will this gate be evaluated do i even need a clock over here so what we say is okay let us remove the footer of the subsequent stages and when we remove the footer of the subsequent stages we are able to uh reduce some end masses also we can reduce the size of the n masses in this stack also and therefore gain further area are you able to see this yes but this can be done only if there is no static output coming to life this can be done only if this out one is going something like this and then there is other whatever now out one is coming here if out one was also in parallel with some other stuff then you can't do this then the ck has to be there are you able to see this sorry can you explain this point again yeah so why did we say that we will we will remove this footer transistor because we said that okay this this will get evaluated here and only after this gets evaluated can this output get discharged i know yes sir what does that mean that this first out one is in the same situation as a footer there is nothing in parallel to out one which would allow this logic to discharge the the capacitance over here yes sir yes now let us say if in parallel to out one there was some other signal also let us say e that was coming then you still need this okay right yes sir otherwise this this the output load over here will start to get discharged through this other part is basically i need to ensure that output out is the latest signal that is arriving yes so this footless domino this is called as footless domino uh can be uh has to be used only very carefully cannot be just uh or remove all the footer then go ahead it cannot work okay yes so carefully but you know what is being said is there is a scope of further optimization we were talking about n plus two we could possibly do with only n plus one then there is also this differential or dual rail domino where you have uh you know again possibly used for axar and xor kind of a thing where a and b and a bar and b bar all are used okay and you get the differential output also again as i said differential gates where you need that differential output to be driven okay so but here we can also get the inverting outputs right so yes and that is where we did not put in we did not bring the keeper uh input from after this inverter we said okay we will use it from here itself okay because the outputs are inverted one of the keepers is going to be on the other one is going to be off hmm,https://www.youtube.com/watch?v=ouihedF07RY,"Link: https://www.youtube.com/watch?v=ouihedF07RY
Transcript: okay so now we formally come to the topic of cascading dynamic gates so we see that this is not this is not the right way to cascade anna what would happen here out transition is from one to zero then i will have some discharge and that will not be refreshed yes so out one goes to zero after ck comes but even before out out one has goes to zero out two has discharged earlier so you cannot really cascade dynamic gate just like this so what do we do we can have other ways to cascade gates so which is like first we already talked about put an inverter in between then what will solve the problem because transitions are now always zero to equal to one zero to one transitions are safe no problems there this is called domino logic why is it called domino you've seen dominoes yes sir the circuit is being evaluated one after the another stage by stage yeah so dominoes are are stacks of cards one false it touches the other one the other one falls the other one falls over and falls and the whole chain activate gets activated uh during the corona times there was this ad you know that you have to break the chain so we are the mask so one person wears a mask that person comes out of this domino chain and the overall chain breaks otherwise everyone gets infected you remember that ad what's up they bought circulatory seen that yes sir so domino this is called domino because until out one goes to one tdn the second period will not evaluate so only after first pdn has evaluated will the second pdn evaluate then the third pd and evaluate then the fourth pdn evaluate that is why it is called as domino logic okay yeah questions so tarun uh hello sir it's more of an open-ended question so as we go more and more towards low power design so shouldn't uh the the dynamic circuits will be like very little use yeah but they're still much more as i said they're still much more often used than ptl and uh pseudo pseudonymous is not used almost anywhere you will still see dynamic circuits used fairly often much often than pseudo nmos and ptl okay so learning all these all the different designs is fine but with so much variety of designs that are possible and how do we even decide what a particular how to probably design a particular thing like in a processor there will be thousands of different components like address multipliers and so many different kinds of things and so many different kinds of constraints if this is fast then this has to be slow and all these things have to be made so how do we even decide on this default so mother the default would be static cmos okay now if you want higher speed than static cmos then you go to dynamic okay if in the static cmos you know that there are places where you could save area by going to ppl and that those those movements are always you know 0 0 0 0 output to be transmitted from one side to the other then you could go to ptl also okay for example now this will be ptl varieties would be in in places like implementing muxes in memories okay so there are some very specific use cases for all these other design styles default is always static cmos and that too whatever is best for your layout all those skewed cmos gates and high skew low q and all those they are also very specifically used in data paths you really want to speed up exactly one or two critical paths otherwise even they are not used even though they are static cmos okay but all these levers you should know as designers because tomorrow when you go and design somewhere you should know that okay if my manager or my customer is asking for much higher speed there is one this additional lever that i have which is domino logic i can try that and you can experiment with it and you can see okay now with domino static cmos i can go to 500 megahertz domino i can go to 800 but with static cmos the power was let us say 2 milliwatts and the domino it is 3.8 i've got much higher speed but power has also increased so let the customer choose okay okay so like in embedded systems like application i will prefer to use static because it consumes lower power and not typically you will only use static mother status is a mainstay that is why it is also taught in second third year okay okay there's being an advanced course you're talking about more advanced things also okay okay yes sir those are not the main step don't confuse it with that they are not the mainstay all this dc vsl and all those so we discussed the cvsr for example is only only used for xor nor combination almost nowhere else the very specific uh ideas and they are being shared so that after you go home and if you come up with you know you you get inspired by these specific games and you can propose something new yourself also okay so okay yeah yes sir sir one confusion that i'm getting over here is uh sir how we are preserving the means uh total means logic actually total input to output logic how do you preserve that in a regular static cmos gate sir my confusion here is suppose we are implementing an sop suppose a b plus c d the first stage would be and gate next stage should be or gate so now here we are press if you are placing an inverter in between so means that no they are there demorgan's theorem you know that now so some kind of bubble pushing need to be made and land and representation something like that yes what's the big deal there that is a simpler part the other challenges that we discussed just now they are the more complex ones they breathe well pushing is so logical it is so simple so suppose you you have given me to design aoi in non-complex form in a uh where individual gates need to be also a dynamic gate so you will not ask me that uh suppose this is a and gate why we implement it using a nand gate we will just simply now input an output right yeah answer one more question here after we create the truth table that's it uh yes a truth table should be preserved input and output and one more thing here is that uh it's a keeper circuit how will how we can place that can we just show in the diagram keep a circuit in the character in the first level okay why why was this question there sir output capacitance increase over there at 0.135 by 0.2 it's a very small keeper so turning on the keeper would be not a problem or challenge anywhere that's and that is why you also design it to be very small huh yes sir you should understand thank you yeah so can we here also prefer that in this inverter can we prefer a high screen water here because we are only interested in the zero you tell me uh what was the if this inverter was not there what was the default state of input coming to this second pdf if this inverter was not there what would be this input's default state in the pre-charge state zero to one clockwise so if it is one then what happens after as soon as clock comes even before this one discharges this one would discharge yes sir we don't want that yes okay yes okay okay okay because inverter changes the default state to zero yes sir okay okay so yeah this is also explained in the animation over here now domino we just discussed why it is domino because only after the first one is evaluated the second one will be evaluated and the third one then the fourth one okay and uh again properties of domino only non-inverted logic can be can be implemented and because it is dynamic gate based and capacitances are reduced there is smaller logical effort this is much much faster and as one of you already pointed out inverter can be skewed because only one transition is important for us the other one is not even important so domino can be designed very very fast now look at it like this over here if i know that only after this comes here will this gate be evaluated do i even need a clock over here so what we say is okay let us remove the footer of the subsequent stages and when we remove the footer of the subsequent stages we are able to uh reduce some end masses also we can reduce the size of the n masses in this stack also and therefore gain further area are you able to see this yes but this can be done only if there is no static output coming to life this can be done only if this out one is going something like this and then there is other whatever now out one is coming here if out one was also in parallel with some other stuff then you can't do this then the ck has to be there are you able to see this sorry can you explain this point again yeah so why did we say that we will we will remove this footer transistor because we said that okay this this will get evaluated here and only after this gets evaluated can this output get discharged i know yes sir what does that mean that this first out one is in the same situation as a footer there is nothing in parallel to out one which would allow this logic to discharge the the capacitance over here yes sir yes now let us say if in parallel to out one there was some other signal also let us say e that was coming then you still need this okay right yes sir otherwise this this the output load over here will start to get discharged through this other part is basically i need to ensure that output out is the latest signal that is arriving yes so this footless domino this is called as footless domino uh can be uh has to be used only very carefully cannot be just uh or remove all the footer then go ahead it cannot work okay yes so carefully but you know what is being said is there is a scope of further optimization we were talking about n plus two we could possibly do with only n plus one then there is also this differential or dual rail domino where you have uh you know again possibly used for axar and xor kind of a thing where a and b and a bar and b bar all are used okay and you get the differential output also again as i said differential gates where you need that differential output to be driven okay so but here we can also get the inverting outputs right so yes and that is where we did not put in we did not bring the keeper uh input from after this inverter we said okay we will use it from here itself okay because the outputs are inverted one of the keepers is going to be on the other one is going to be off hmm"
w0ZmNIo7A0Y,another way to cascade is using npc mass what does this mean that the first cooldown network if it is made out of nmos is then you cascade it with another gate which has not pulled down network but pull up network and this out 2 is recharged to 0 instead of 1. so this is a flipped dynamic gate and what is happening over here clock is coming so over here clock bar is coming you're working in two phases are you able to see this just looking at how to make this dynamic gate stuff more usable huh why we are doing this in pc mask thing you tell me inverter is not there anymore we've avoided the inverter because now we say if there is a pull up network it can accept one to zero transition see when the when pull down network was driving another pull down network then only zero to one transitions were allowed for that i had to put an inverter there now if i put a pull up network on the next gate then what happens one to zero transitions are also allowed are in fact only one to zero transitions are allowed so you don't you don't need those inverters in between so but we have removed an inverter and uh we are considering a circuit with uh with the p bosses so what about the area then yeah but think about the delay because inverters were adding delay now that delay is avoided okay okay okay so according to the application we have to decide yes according to the application you choose because at some places because you're using dynamic only for speed you may want more seats and then you can do this yes sir okay so yes i am so happy that all of you are now thinking like designers oh i have improved speed so what happened through area what is happening to power you have to continuously keep all the three things in mind when you design you cannot just design for speed and now over here if you are giving away that you know more area because of implementing it in pull up network you you realize that what is happening the speed is the speed is gaining you're consciously doing it yes sir okay so this saves you all those inverters there now this is nora logic which said that okay np to heihei i may want to couple this pdn with another pdn so i will also have an inverter over here and drive other pdns and similarly i may drive pdns from out to but i can have an inverter and drive other pums so this is further extension of the np logic that we talked over here are you able to see this so can we explain this once again let this load so what was there in np logic in np logic only this part was there anna listen now it may happen that for some particular gate implementation through p1 could be really very large area and due to that very large area itself you will not be able to gain speed yes can happen so you say okay let me use that that signal as pdn only for other signals that it drives i will use a pun so this is maximum flexible you have pdn driving a pdn in a domino format you have pdn driving a pun in an np format again even driving a pdn in an np format and p when driving a p1 in a domino format so this is a mix of domino and np but you also realize this is so much more complex to design is it not so many puns pdns everything to be designed so here even though my area is increasing i am able to drive three other outputs at a time so that you could have done earlier also that you could have done earlier also without saying that in the np in the previous slide when i was showing np i was saying that pdn is always followed by a pun yes sir over here i am saying in nora i am saying ok bring in an inverter and i can actually draw a pdn also in this case i'll be i should be increasing the size of my pdn in my first stage right because as it's depending on the logical effort you know yeah yeah we don't we don't go back to that thing again this is basics we already discussed they were fundamental you will naturally do that i expect you to do that sizing is now trivial sizing it is not trivial it is important but we've already understood sizing in much much detail earlier so let's not get bogged down by that over and over again at least in the class yes sir yes so yes i think you will have to do we will do anna it's not about the sizing it's about the increase of areas are exactly that's what i would area increase if there is no change in sizing sir obviously we are connecting a pdn to our output then i am supposed to increase my sizing accordingly of my previous stage okay yeah because you change the sizes that is where area increase now well actually i've got this concept but why i'm like integrating both kind of like in the nora like np also insecurity and the dynamic also integrating what exactly and benefit i'm not able to get clearly up on that let us say that you know the exact same doubt that uh faizal had asked uh that uh if you're using a p u n then the area of this p u n is increased yes sir huh so now let us say this p n is really complex and the area increases so much that those internal capacitances on the p masses they delay much more than an inverter would have delayed okay yes possible then you use a pdn only you say okay then an inverter plus pdn will be faster and also lesser area let me use a pdn button so one one gate is driving two different logics for one logic a pdn work better for another pu and work better and nora allows you to use both but how will the functionality uh how will the basically the internal connections will be made because i'm getting both connections right i bought to the point also the np connection also and the dynamic recognition also metal one that you have over here you will just take it somewhere else also yes sir so that is not the issue i'm asking that if i'm implementing a layout so i have implemented both i am dynamic dynamic and then and npc mos why i am integrating both kind of in the same itself i can pre-evaluate my key okay uh this kept this p1 could be more complex so i will not even implement it in the same design i will not that is where i will go to the pdn okay so you're not working at a standard cell now you're working at a cascading of these standard cells okay okay okay okay okay yes i've already moved to the cascading domino gates now dynamic gates section okay this is one this is one standard cell this is the other standard cell there would be another planet over here okay okay so i was getting confused with that okay okay thank you sir yeah anything else they did yes or one small question regarding the non-complex implementation only so sir we can do it in two ways right using the domino logic or the footless domino or uh dynamic cascaded after dynamic where we might need two inverters in between two inverters no two inverters again the terms the challenge comes with the transition they breathe your delay increases season not the delay the transitions you only want zero to one transitions happening zero to one transition that is the chapter so between domino and focus domino uh yes sir yes so between the domino and footless domino sir means what we should do in means in our project for non-complex influence domino because you're making only one cell you're not making a path so for the other stage dweller paths you can use footless also in the second stage but just see if it works for you if it doesn't then don't sir my domino is only expected right so if someone may oh yes okay tell you so class we will close now and uh next class there is this presentation monday we have the quiz we'll meet on next wednesday now we'll meet on monday also office hours and then next wednesday okay sir yes uh actually i need to talk to you regarding something else okay we can wait i will stop the recording so regarding first presentation can i ask one more thing sir so for non-complex implementation just said that just the functionality and schematic would be enough and for complex if we do the till the layout simulation so see all these instructions are already clarified on the classroom now let's go with that only okay okay if there is some further clarification in it ask on the classroom everyone will get to know abi there are only 33 students in the class it was not fair okay uh sir yes yeah [Music] you have a question yes sir i have my question is related to project finding dynamo actually what i did is as you said in the office server i remove the minimum drc to raise the maximum and most sizes in that uh in that space i got the possibility of the nmos somewhere i can place the minimum and mass somewhere i can place the maximum and and as you said the footer should be a maximum one so that the delays will be lesser and what i planned is that the the nmos which is near to the output i'll try to keep it as a minimum one so what i am seeing is that when these transistors are coming in series they see the current capabilities will be different like the smallest one which should be the one with the limiting one yeah so uh the the size which i increase the footer that i am not using actually it won't change anything for you yeah so keeping the footer maximum is not useful anything like no if i make it as as similar as the one which is near to the output then i can use the lesser area yes even if area doesn't change at least your leakage will reduce gate capacitances will reduce clock load will reduce but the delays uh the alias will be increasing the list will be almost similar because there is something which is equivalent resistance already there okay one more question is there sir as i trace the animal sizes and all now i'll simulate on all things to know the maximum frequency at what the maximum frequency i can do and the voltages but i think the designing process should be the reverse like you should have given us the frequency and the vdd based on that we should design right no you're designing a standard cell so you just i told you one thing that no more area loss so every time the design should be start for the dynamo i think the design should be start from the layout are the standard cells for the standard cells you know this is a template this is the size if you were designing free flow circuits you know not standard cells and then you would do all that oh this is my load then let's go back and see what should be the size of the driver or what should be the size of the penalty my driver and so on then you go that way otherwise you simply drop okay so whenever the standard cell is made so we have to first made it and then the layout is the one which determines the sizes primarily then if you want better speed you use those uh buffers after your complex gate yeah one more question is you have given 70 for the annual i didn't understand why you are giving this because when i am choosing uh pmos as small as possible then in and most uh the some area is still left in the annual area which i am using for the rooting purpose so i think if if that 70 constraint is removed the area so that is the standard cell so that is the standard cell constraint we can't remove that thank you so much thank you okay that is the standard cell constraint that we have set for our library okay because we also are going to design static seam updates that is where we have kept that as,https://www.youtube.com/watch?v=w0ZmNIo7A0Y,"Link: https://www.youtube.com/watch?v=w0ZmNIo7A0Y
Transcript: another way to cascade is using npc mass what does this mean that the first cooldown network if it is made out of nmos is then you cascade it with another gate which has not pulled down network but pull up network and this out 2 is recharged to 0 instead of 1. so this is a flipped dynamic gate and what is happening over here clock is coming so over here clock bar is coming you're working in two phases are you able to see this just looking at how to make this dynamic gate stuff more usable huh why we are doing this in pc mask thing you tell me inverter is not there anymore we've avoided the inverter because now we say if there is a pull up network it can accept one to zero transition see when the when pull down network was driving another pull down network then only zero to one transitions were allowed for that i had to put an inverter there now if i put a pull up network on the next gate then what happens one to zero transitions are also allowed are in fact only one to zero transitions are allowed so you don't you don't need those inverters in between so but we have removed an inverter and uh we are considering a circuit with uh with the p bosses so what about the area then yeah but think about the delay because inverters were adding delay now that delay is avoided okay okay okay so according to the application we have to decide yes according to the application you choose because at some places because you're using dynamic only for speed you may want more seats and then you can do this yes sir okay so yes i am so happy that all of you are now thinking like designers oh i have improved speed so what happened through area what is happening to power you have to continuously keep all the three things in mind when you design you cannot just design for speed and now over here if you are giving away that you know more area because of implementing it in pull up network you you realize that what is happening the speed is the speed is gaining you're consciously doing it yes sir okay so this saves you all those inverters there now this is nora logic which said that okay np to heihei i may want to couple this pdn with another pdn so i will also have an inverter over here and drive other pdns and similarly i may drive pdns from out to but i can have an inverter and drive other pums so this is further extension of the np logic that we talked over here are you able to see this so can we explain this once again let this load so what was there in np logic in np logic only this part was there anna listen now it may happen that for some particular gate implementation through p1 could be really very large area and due to that very large area itself you will not be able to gain speed yes can happen so you say okay let me use that that signal as pdn only for other signals that it drives i will use a pun so this is maximum flexible you have pdn driving a pdn in a domino format you have pdn driving a pun in an np format again even driving a pdn in an np format and p when driving a p1 in a domino format so this is a mix of domino and np but you also realize this is so much more complex to design is it not so many puns pdns everything to be designed so here even though my area is increasing i am able to drive three other outputs at a time so that you could have done earlier also that you could have done earlier also without saying that in the np in the previous slide when i was showing np i was saying that pdn is always followed by a pun yes sir over here i am saying in nora i am saying ok bring in an inverter and i can actually draw a pdn also in this case i'll be i should be increasing the size of my pdn in my first stage right because as it's depending on the logical effort you know yeah yeah we don't we don't go back to that thing again this is basics we already discussed they were fundamental you will naturally do that i expect you to do that sizing is now trivial sizing it is not trivial it is important but we've already understood sizing in much much detail earlier so let's not get bogged down by that over and over again at least in the class yes sir yes so yes i think you will have to do we will do anna it's not about the sizing it's about the increase of areas are exactly that's what i would area increase if there is no change in sizing sir obviously we are connecting a pdn to our output then i am supposed to increase my sizing accordingly of my previous stage okay yeah because you change the sizes that is where area increase now well actually i've got this concept but why i'm like integrating both kind of like in the nora like np also insecurity and the dynamic also integrating what exactly and benefit i'm not able to get clearly up on that let us say that you know the exact same doubt that uh faizal had asked uh that uh if you're using a p u n then the area of this p u n is increased yes sir huh so now let us say this p n is really complex and the area increases so much that those internal capacitances on the p masses they delay much more than an inverter would have delayed okay yes possible then you use a pdn only you say okay then an inverter plus pdn will be faster and also lesser area let me use a pdn button so one one gate is driving two different logics for one logic a pdn work better for another pu and work better and nora allows you to use both but how will the functionality uh how will the basically the internal connections will be made because i'm getting both connections right i bought to the point also the np connection also and the dynamic recognition also metal one that you have over here you will just take it somewhere else also yes sir so that is not the issue i'm asking that if i'm implementing a layout so i have implemented both i am dynamic dynamic and then and npc mos why i am integrating both kind of in the same itself i can pre-evaluate my key okay uh this kept this p1 could be more complex so i will not even implement it in the same design i will not that is where i will go to the pdn okay so you're not working at a standard cell now you're working at a cascading of these standard cells okay okay okay okay okay yes i've already moved to the cascading domino gates now dynamic gates section okay this is one this is one standard cell this is the other standard cell there would be another planet over here okay okay so i was getting confused with that okay okay thank you sir yeah anything else they did yes or one small question regarding the non-complex implementation only so sir we can do it in two ways right using the domino logic or the footless domino or uh dynamic cascaded after dynamic where we might need two inverters in between two inverters no two inverters again the terms the challenge comes with the transition they breathe your delay increases season not the delay the transitions you only want zero to one transitions happening zero to one transition that is the chapter so between domino and focus domino uh yes sir yes so between the domino and footless domino sir means what we should do in means in our project for non-complex influence domino because you're making only one cell you're not making a path so for the other stage dweller paths you can use footless also in the second stage but just see if it works for you if it doesn't then don't sir my domino is only expected right so if someone may oh yes okay tell you so class we will close now and uh next class there is this presentation monday we have the quiz we'll meet on next wednesday now we'll meet on monday also office hours and then next wednesday okay sir yes uh actually i need to talk to you regarding something else okay we can wait i will stop the recording so regarding first presentation can i ask one more thing sir so for non-complex implementation just said that just the functionality and schematic would be enough and for complex if we do the till the layout simulation so see all these instructions are already clarified on the classroom now let's go with that only okay okay if there is some further clarification in it ask on the classroom everyone will get to know abi there are only 33 students in the class it was not fair okay uh sir yes yeah [Music] you have a question yes sir i have my question is related to project finding dynamo actually what i did is as you said in the office server i remove the minimum drc to raise the maximum and most sizes in that uh in that space i got the possibility of the nmos somewhere i can place the minimum and mass somewhere i can place the maximum and and as you said the footer should be a maximum one so that the delays will be lesser and what i planned is that the the nmos which is near to the output i'll try to keep it as a minimum one so what i am seeing is that when these transistors are coming in series they see the current capabilities will be different like the smallest one which should be the one with the limiting one yeah so uh the the size which i increase the footer that i am not using actually it won't change anything for you yeah so keeping the footer maximum is not useful anything like no if i make it as as similar as the one which is near to the output then i can use the lesser area yes even if area doesn't change at least your leakage will reduce gate capacitances will reduce clock load will reduce but the delays uh the alias will be increasing the list will be almost similar because there is something which is equivalent resistance already there okay one more question is there sir as i trace the animal sizes and all now i'll simulate on all things to know the maximum frequency at what the maximum frequency i can do and the voltages but i think the designing process should be the reverse like you should have given us the frequency and the vdd based on that we should design right no you're designing a standard cell so you just i told you one thing that no more area loss so every time the design should be start for the dynamo i think the design should be start from the layout are the standard cells for the standard cells you know this is a template this is the size if you were designing free flow circuits you know not standard cells and then you would do all that oh this is my load then let's go back and see what should be the size of the driver or what should be the size of the penalty my driver and so on then you go that way otherwise you simply drop okay so whenever the standard cell is made so we have to first made it and then the layout is the one which determines the sizes primarily then if you want better speed you use those uh buffers after your complex gate yeah one more question is you have given 70 for the annual i didn't understand why you are giving this because when i am choosing uh pmos as small as possible then in and most uh the some area is still left in the annual area which i am using for the rooting purpose so i think if if that 70 constraint is removed the area so that is the standard cell so that is the standard cell constraint we can't remove that thank you so much thank you okay that is the standard cell constraint that we have set for our library okay because we also are going to design static seam updates that is where we have kept that as"
aa14b6AXSzg,sequential circuits yes so today we will start with sequential circuits this is uh as you will notice later when you will appear for interviews or anything this is one of the most uh how do i put it one of the most widely asked topics in your interviews so please pay sufficient attention to this topic ask as many questions as you wish to not exactly on the basics of these circuits but finally you know probably today or in the next session and we will work on the timing diagrams on the timing constraints linked to sequential circuits then there will be you know those kind of questions are usually asked in the interviews in the interviews and the written tests and all that so that you should really be very clear of so sequential circuits is a very important topic we use sequential circuits in our designs very very regularly so what are sequential circuits and how are they different from combinational circuits anyone so the output of a sequential circuit should depend upon the previous input and present input as on the other hand the combination only depends on the present input okay any other ideas suggestions so gandhi said that output of a sequential circuit depends on previous input and present input both or previous output and present input both whereas output of a combinational circuit is dependent only on present input so that is the key difference between sequential circuits and combinational circuits and this you know what this also means is that we need to because there is a sense of previous state and current state and let us say a future state what will be the output and how will the next uh state be dependent on it and so on because it requires that kind of a thing we need something which is called as state or tokens this is uh these these this previous set of inputs and current set of inputs and the future outputs all this is clubbed and called as a state or also a token in some texts you will see the word token also used somewhere and where do we see them finite state machines all of us know we've seen melee machine mode machine and all that you remember on at state machines and pipelines also you must have heard hello yes yes so pipelines finite state machines these are some common places where you will you will have to use sequential circuits sequential circuits or the sequencing when i say that there is uh some input uh dependence on uh you know that the there is a com so this combinational logic over here uh and there is this flop over here so whatever happened in the previous cycle will define what will happen in the next cycle over here so all that all this dependence is uh comes with an overhead or with comes with a with a penalty so what happens is that if let us say in this particular pipeline if if or how do i put it let us say that if there are combinational paths and we know that the slowest path or let me show the slowest path in a different way let me say this is the slowest path and the fastest path would never intersect then we are safe however if the slowest path and the fastest path for example are going to converge into some cone or something like that then it may happen that we may have glitches on the output of this nand gate are you able to see this what i am saying let us see there are two inputs one input comes very fast the other input comes very slowly then what can happen is that in an intermediate state when this input has reached but the other one has not reached i could get glitters and these glitters or we may not really call it glitches we may get spurious transitions are you able to see this so so when we are considering the combinational logic only then i don't exactly control key how the inputs are going to be arriving or when they're going right in another like in an adder there is some path which is longer so it will take longer time to come yes sir okay there are some paths which are longer some paths which are shorter so shorter paths will come to the nand gate longer paths will come later so there will be some states that will appear these fourier states not only mean more power consumption but also extra toggling and and possibly corruption of state machine elsewhere so if we cannot ensure that the flow of information will be uh will be always synchronized we use what is called as tokens or we use what is called as flip flops so when when for example in a fiber optic cable you know that you send this pulse okay this pulse and any other pulse will all travel at same speed which is the speed of light am i right there are light pulses just the amplitude of the pulses higher or lower the speed of the pulse will exactly be the same so you do not need to put any sequencing elements in in a optical fiber you say it's fine my light will always travel with the speed c it is only the dispersion between the pulses that defines how what is the minimum time between two pulses however in terms of uh hardware in terms of our circuits we cannot always ensure that the slow paths will be able to catch up with the fast path and so on and therefore we need to break the hardware path and use what we call as flip flops or latches to delay these fast signals this fast path we say okay before entering this and gate i will have a series of flip flops,https://www.youtube.com/watch?v=aa14b6AXSzg,"Link: https://www.youtube.com/watch?v=aa14b6AXSzg
Transcript: sequential circuits yes so today we will start with sequential circuits this is uh as you will notice later when you will appear for interviews or anything this is one of the most uh how do i put it one of the most widely asked topics in your interviews so please pay sufficient attention to this topic ask as many questions as you wish to not exactly on the basics of these circuits but finally you know probably today or in the next session and we will work on the timing diagrams on the timing constraints linked to sequential circuits then there will be you know those kind of questions are usually asked in the interviews in the interviews and the written tests and all that so that you should really be very clear of so sequential circuits is a very important topic we use sequential circuits in our designs very very regularly so what are sequential circuits and how are they different from combinational circuits anyone so the output of a sequential circuit should depend upon the previous input and present input as on the other hand the combination only depends on the present input okay any other ideas suggestions so gandhi said that output of a sequential circuit depends on previous input and present input both or previous output and present input both whereas output of a combinational circuit is dependent only on present input so that is the key difference between sequential circuits and combinational circuits and this you know what this also means is that we need to because there is a sense of previous state and current state and let us say a future state what will be the output and how will the next uh state be dependent on it and so on because it requires that kind of a thing we need something which is called as state or tokens this is uh these these this previous set of inputs and current set of inputs and the future outputs all this is clubbed and called as a state or also a token in some texts you will see the word token also used somewhere and where do we see them finite state machines all of us know we've seen melee machine mode machine and all that you remember on at state machines and pipelines also you must have heard hello yes yes so pipelines finite state machines these are some common places where you will you will have to use sequential circuits sequential circuits or the sequencing when i say that there is uh some input uh dependence on uh you know that the there is a com so this combinational logic over here uh and there is this flop over here so whatever happened in the previous cycle will define what will happen in the next cycle over here so all that all this dependence is uh comes with an overhead or with comes with a with a penalty so what happens is that if let us say in this particular pipeline if if or how do i put it let us say that if there are combinational paths and we know that the slowest path or let me show the slowest path in a different way let me say this is the slowest path and the fastest path would never intersect then we are safe however if the slowest path and the fastest path for example are going to converge into some cone or something like that then it may happen that we may have glitches on the output of this nand gate are you able to see this what i am saying let us see there are two inputs one input comes very fast the other input comes very slowly then what can happen is that in an intermediate state when this input has reached but the other one has not reached i could get glitters and these glitters or we may not really call it glitches we may get spurious transitions are you able to see this so so when we are considering the combinational logic only then i don't exactly control key how the inputs are going to be arriving or when they're going right in another like in an adder there is some path which is longer so it will take longer time to come yes sir okay there are some paths which are longer some paths which are shorter so shorter paths will come to the nand gate longer paths will come later so there will be some states that will appear these fourier states not only mean more power consumption but also extra toggling and and possibly corruption of state machine elsewhere so if we cannot ensure that the flow of information will be uh will be always synchronized we use what is called as tokens or we use what is called as flip flops so when when for example in a fiber optic cable you know that you send this pulse okay this pulse and any other pulse will all travel at same speed which is the speed of light am i right there are light pulses just the amplitude of the pulses higher or lower the speed of the pulse will exactly be the same so you do not need to put any sequencing elements in in a optical fiber you say it's fine my light will always travel with the speed c it is only the dispersion between the pulses that defines how what is the minimum time between two pulses however in terms of uh hardware in terms of our circuits we cannot always ensure that the slow paths will be able to catch up with the fast path and so on and therefore we need to break the hardware path and use what we call as flip flops or latches to delay these fast signals this fast path we say okay before entering this and gate i will have a series of flip flops"
zow_CFimPxs,then in that case you will get outputs which are not correct intermittently that much is clear we just looked at the example of a nand gate we don't even go into a complex gate like an adder or something like that even in a simple nand gate do you realize that if one input comes much later than the other there will be a differential there will be a spurious output there for some time so why am calling that spurious because whatever becomes i will get the according functionality in me yeah because i have now and now i will say that i wanted the addition of two words to be done okay just so so anything that is intermediate is spurious for me now what is it that i want i want there is one correct output and then there is directly a next correct output any intermediate state has spurious states for me okay right okay yes okay that is what i mean by spurious okay i'm only concerned with some kind of outputs not all yes yeah so okay and so one more thing so one thing also said the concept of token exactly what exactly you were trying to say is that is it the value that is the whole being held or the the data that might be coming in going out token could be okay token could be something which is like uh when the state of this signal is zero only then i will proceed forward it is like a you've seen a relay race sir in which what happens the first first first runner carries a baton with him and puts it on to the uh gives it on to the second runner after some time yes yes sir i know so this uh this is like a token that only after my previous set of results are there only then i will start my second operation so in asynchronous circuit you call it as tokens in uh synchronous circuits you call of it as state where flip flop the way the clock would come and say okay now next now let's move to the next stage in asynchronous circuits you call it as token okay so somehow it's linked to the inputs and output like when i achieve this kind of output i can move to the next set of inputs something like that yes so there is one okay now let us look at it like this there could be a special output that your circuit would give which says that okay now i am ready for the next input okay when all the calculations have done have been completed it says now i'm ready for the next input now once this ready input ready signal goes high then you will give the next set of inputs so this ready signal is a token now okay okay okay so like it's like the concept of moving from one competition to the next that kind of okay yeah it is managing that okay yes so it is about sequencing that was what you were talking about in the last slide also yes you were talking about sequencing where we said that uh in an optical fiber that in an optical fiber we said that things would move in a in a wave format anna whereas uh it may not happen so in the uh it may not happen so in the hardware that we're talking about yes so when that is what we're talking about then we say that this is about sequencing delays does this help so sir we are moving towards sequencing because we want to avoid those kind of spurious kind of that yeah transitions token to something like a acknowledgement signal yes sir uh what i know about the pipelines so what uh according to whatever we have read also basically to make the overall circuit faster so what we do is to separate two blocks of circuit and put flip flops in between so that the output of previous one is not able to interact with the input of the next stage until i send the clock signal so sir even even if the delays of all the transitions of input for both the circuit the stage 1 and state 2 are are similar or or let's say are constant even then to make the circuit faster i will like to put flip flops or not even then i would want to do that yes even then i would want to do that so how are we saying that okay constant if it is constant then i can rema remove the flip flops uh if it is constant i will remove the flip flops because even after removing the flip flops i will get the correct functionality the speed will be slower okay so for speed i will still need to put them and yeah functionality so then you are using flip flops only for speed purposes otherwise you're using pipelining also for sequencing purposes is that clear yes it is so what we are saying is there are two purposes of uh of using these sequencing circuits first is to ensure sequencing second is to improve overall system throughput system throughput need would still remain but in wave pipelining you can say that okay i do not need to uh no i do not need to give this keep these flip flops or sequencing elements in between because i am always safe so yes rather so i am mean i am improving the speed of the circuit because i'm able to achieve kind of parallelism kind of thing that is why i'm able to achieve it yeah right okay yes so are all of you doing the computer architecture course anyone who's not doing the ca course okay at least those who are present in the class okay leap is not oh some people are not doing c a course so those of you doing cf codes you would see that cma this concept is discussed in in much detail why pipelining is used why it is important and so on so pipelining is used for two purposes as we are discussing over here first is to ensure sequencing that the earlier inputs don't mix with the with the present set of inputs or vice versa and we also saying that sequential elements of pipelining is used to improve overall throughput of the system okay now when we use these sequencing elements in our paths what do we do we inevitably add flip flops and latches and they will inevitably lead to additional delays even on the slower paths see there was a slow path you wanted to slow down only the fast path but you do not know which path is slow which path is fast when you are doing a system synthesis in that case what happens in that case finally we say that we simply insert a flop on all the paths and even the slow paths we'll see some delay this additional delay that is that this flip flop would take or this latch would take is called as clocking overhead or sequencing overhead so actually it is called last sequencing overhead but a few people erroneously call it as clocking overhead clocking over it is not the correct term because as i just mentioned a little while back this kind of overhead even occurs in the token system if you have tokens so even in token systems there is going to be some overhead so it is better to call it as sequencing overhead and not clocking overhead is that okay any questions till here so suppose we are putting uh one flip flop in the path uh so the clocking overhead will be one clock period so i've just now said pfizer we will not use the term clocking over it we will use the term sequence string overhead sequencing overhead would be one clock period like eight o'clock at the flip flop they take output no the sequencing overhead will be the the the delay of the flop that is ck to q delay of the flop c q to q okay okay because that is the additional delay that your logic now has to travel now yes yes sir yes understood okay okay so that becomes the delay that is the sequencing overhead we will talk about sequencing overhead in much detail after we introduce these sequencing elements to you we'll talk about the sequencing overhead and much detail in a little while yes sir um so you were saying that typically we don't know the slower and faster path uh when we synthesize the circuit but again that's i think at system level we typically do know right that yeah at the time of synthesis we would know but at the time of writing an rtl we may not know so you would put the flop everywhere and then you synthesize so what i meant was that before synthesis we do not we may not really know which circuits which paths are fast which paths are slow because during synthesis also some paths will be converted to faster paths by using faster cells and slower cells and all that so we the in rtl itself will put the flops at all the places okay okay okay so,https://www.youtube.com/watch?v=zow_CFimPxs,"Link: https://www.youtube.com/watch?v=zow_CFimPxs
Transcript: then in that case you will get outputs which are not correct intermittently that much is clear we just looked at the example of a nand gate we don't even go into a complex gate like an adder or something like that even in a simple nand gate do you realize that if one input comes much later than the other there will be a differential there will be a spurious output there for some time so why am calling that spurious because whatever becomes i will get the according functionality in me yeah because i have now and now i will say that i wanted the addition of two words to be done okay just so so anything that is intermediate is spurious for me now what is it that i want i want there is one correct output and then there is directly a next correct output any intermediate state has spurious states for me okay right okay yes okay that is what i mean by spurious okay i'm only concerned with some kind of outputs not all yes yeah so okay and so one more thing so one thing also said the concept of token exactly what exactly you were trying to say is that is it the value that is the whole being held or the the data that might be coming in going out token could be okay token could be something which is like uh when the state of this signal is zero only then i will proceed forward it is like a you've seen a relay race sir in which what happens the first first first runner carries a baton with him and puts it on to the uh gives it on to the second runner after some time yes yes sir i know so this uh this is like a token that only after my previous set of results are there only then i will start my second operation so in asynchronous circuit you call it as tokens in uh synchronous circuits you call of it as state where flip flop the way the clock would come and say okay now next now let's move to the next stage in asynchronous circuits you call it as token okay so somehow it's linked to the inputs and output like when i achieve this kind of output i can move to the next set of inputs something like that yes so there is one okay now let us look at it like this there could be a special output that your circuit would give which says that okay now i am ready for the next input okay when all the calculations have done have been completed it says now i'm ready for the next input now once this ready input ready signal goes high then you will give the next set of inputs so this ready signal is a token now okay okay okay so like it's like the concept of moving from one competition to the next that kind of okay yeah it is managing that okay yes so it is about sequencing that was what you were talking about in the last slide also yes you were talking about sequencing where we said that uh in an optical fiber that in an optical fiber we said that things would move in a in a wave format anna whereas uh it may not happen so in the uh it may not happen so in the hardware that we're talking about yes so when that is what we're talking about then we say that this is about sequencing delays does this help so sir we are moving towards sequencing because we want to avoid those kind of spurious kind of that yeah transitions token to something like a acknowledgement signal yes sir uh what i know about the pipelines so what uh according to whatever we have read also basically to make the overall circuit faster so what we do is to separate two blocks of circuit and put flip flops in between so that the output of previous one is not able to interact with the input of the next stage until i send the clock signal so sir even even if the delays of all the transitions of input for both the circuit the stage 1 and state 2 are are similar or or let's say are constant even then to make the circuit faster i will like to put flip flops or not even then i would want to do that yes even then i would want to do that so how are we saying that okay constant if it is constant then i can rema remove the flip flops uh if it is constant i will remove the flip flops because even after removing the flip flops i will get the correct functionality the speed will be slower okay so for speed i will still need to put them and yeah functionality so then you are using flip flops only for speed purposes otherwise you're using pipelining also for sequencing purposes is that clear yes it is so what we are saying is there are two purposes of uh of using these sequencing circuits first is to ensure sequencing second is to improve overall system throughput system throughput need would still remain but in wave pipelining you can say that okay i do not need to uh no i do not need to give this keep these flip flops or sequencing elements in between because i am always safe so yes rather so i am mean i am improving the speed of the circuit because i'm able to achieve kind of parallelism kind of thing that is why i'm able to achieve it yeah right okay yes so are all of you doing the computer architecture course anyone who's not doing the ca course okay at least those who are present in the class okay leap is not oh some people are not doing c a course so those of you doing cf codes you would see that cma this concept is discussed in in much detail why pipelining is used why it is important and so on so pipelining is used for two purposes as we are discussing over here first is to ensure sequencing that the earlier inputs don't mix with the with the present set of inputs or vice versa and we also saying that sequential elements of pipelining is used to improve overall throughput of the system okay now when we use these sequencing elements in our paths what do we do we inevitably add flip flops and latches and they will inevitably lead to additional delays even on the slower paths see there was a slow path you wanted to slow down only the fast path but you do not know which path is slow which path is fast when you are doing a system synthesis in that case what happens in that case finally we say that we simply insert a flop on all the paths and even the slow paths we'll see some delay this additional delay that is that this flip flop would take or this latch would take is called as clocking overhead or sequencing overhead so actually it is called last sequencing overhead but a few people erroneously call it as clocking overhead clocking over it is not the correct term because as i just mentioned a little while back this kind of overhead even occurs in the token system if you have tokens so even in token systems there is going to be some overhead so it is better to call it as sequencing overhead and not clocking overhead is that okay any questions till here so suppose we are putting uh one flip flop in the path uh so the clocking overhead will be one clock period so i've just now said pfizer we will not use the term clocking over it we will use the term sequence string overhead sequencing overhead would be one clock period like eight o'clock at the flip flop they take output no the sequencing overhead will be the the the delay of the flop that is ck to q delay of the flop c q to q okay okay because that is the additional delay that your logic now has to travel now yes yes sir yes understood okay okay so that becomes the delay that is the sequencing overhead we will talk about sequencing overhead in much detail after we introduce these sequencing elements to you we'll talk about the sequencing overhead and much detail in a little while yes sir um so you were saying that typically we don't know the slower and faster path uh when we synthesize the circuit but again that's i think at system level we typically do know right that yeah at the time of synthesis we would know but at the time of writing an rtl we may not know so you would put the flop everywhere and then you synthesize so what i meant was that before synthesis we do not we may not really know which circuits which paths are fast which paths are slow because during synthesis also some paths will be converted to faster paths by using faster cells and slower cells and all that so we the in rtl itself will put the flops at all the places okay okay okay so"
6tkTisETmDA,now what kind of sequential circuits do we already know of so two circuits essentially latches and flip flops latches are level sensitive flip flops are edge triggered uh just to differentiate between the latches and the flip flops let us look at this timing at the top signal is clock data toggled when did data toggle data toggled when the clock was high since data toggles then what happened when data toggled latch and the clock was high latch immediately reflected transition of data onto the output flip flop on the other hand was edge triggered the rising edge of the clock had already passed so this data this toggling of data was not recorded by the latch now data toggled again now since at this point of time clock was low even the latch was opaque it was not transparent yet when clock went high both flop and the latch gave the right output right order means they reflected d on cube are you able to see this difference the key difference between a latch and a flock how level sensitive and s triggered sequential elements are different so again it is elaborate on this transparent energy okay so when i use the term transparent i mean to say that whatever comes on b it will be transmitted on q and opaque means it is not it will not be transmitted is it clear so so whatever appears on d will anyway we translated you realize this yes sir whereas the latch is transparent through the entire clock high period okay okay that is the difference yes so i mean if the clock if it is uh at the positive edge of the clock so will the clock transition on the clock slew will determine like how effectively how what for extractive timeline the flip flop will be on for like if my for example slew is more so will i say that uh key uh my flip-flop is transparent for much greater time so flip flop will uh will transmit whatever is there on the rising edge uh we will just now in a little while see that to get a correct output on the flip flop you will have to ensure that data is stable for some time before the clock arrives that is called as a setup time yes sir so we will ensure that there is no uncertainty at the output rather okay through different timing constraints because otherwise you're absolutely right if the clock slew is very bad or something like that is there then how will we ensure what data is coming at the output so that is where we have two timings set up and hold timings associated with the flop or a latch or anything like that so is it something like designers tend to prefer flip flops over latches do designers in general prefer flip flop over latches why so i it's just a question so i have not seen latches many that many places even in fpgas there are very few notches and most of them are flip flops only yeah see what happens is that uh now let us say this this intermediate d going high and low was a spurious transition it was see it went high then went low so it was a glitch what did the latch to last transmitted the glitch to the other side so all the signals on the other side also started to toggle hmm so lots of power got wasted yes in a flop all that did not happen in a flop i said okay now this one clock period is the time for this combination circuit to evaluate let it evaluate completely only after it has evaluated i will sample it so the intermediate transitions are no longer bothersome for the subsequent part of the circuit okay therefore are preferred at many places okay so answer or whatever timing is timing also somehow better for flip flop and instead of analysis we create problems whenever we use latches so let us wait for the next lecture we will see what is the timing overhead of flop and latch okay i will cover that okay that's a very relevant question but we are anyway going to cover that in the next class let us just go step by step uh sir in the timing diagram drawn below sir sir uh when is this latch is transparent and opaque according to this now you tell me sir according to me when the clock is zero uh and d is zero then and when then q is become 0 then here the latch must be opaque and when the clock is 1 and this q is 1 then it must be transparency because uh according to me sir opening or opaque is just reverse of transparent so when the latch is off then whatever is on q must be like opaque answer so if you if you look at it you will realize there is no dependence on the value on d yes or transparent matlab uh that the latch must be offset q must be independent of when in for opaque when is it opaque when uh depending upon the clock when the latch is either on or off when the clock is low then this particular latch is opaque because whatever is the value of d it is not coming on q okay so in the transparent one d will reflect on yes when the clock was one then latch is transparent so whatever d was there it reflected on q whether d was zero whether d was one whatever it was it reflected on q so transparent and opaque of the latch is dependent on the clock level that is why latch is called as level sensitive yes flip flop is instead called as edge trigger because whatever we see on the clock rising edge or falling edge whatever edge triggered you are that is what will be sampled and that is what will be used whatever happens intermediately we will ignore that we will not use that yes fine okay instead of a flip flop so then uh wanted to be that i will have only the negative edge for the evaluation for the block of combination circuit if we use negative edge of the clock for the flip flop then the next sampling of data will also happen at the next negative edge yes but i can do the evaluation over the complete time period of the clock yes because it will then be negative s to negative s so i will still have the entire time period with me yes in the latch it won't be a half time period will be available you will see latch has some other benefits [Laughter] otherwise i would not be telling you about it no yes yeah,https://www.youtube.com/watch?v=6tkTisETmDA,"Link: https://www.youtube.com/watch?v=6tkTisETmDA
Transcript: now what kind of sequential circuits do we already know of so two circuits essentially latches and flip flops latches are level sensitive flip flops are edge triggered uh just to differentiate between the latches and the flip flops let us look at this timing at the top signal is clock data toggled when did data toggle data toggled when the clock was high since data toggles then what happened when data toggled latch and the clock was high latch immediately reflected transition of data onto the output flip flop on the other hand was edge triggered the rising edge of the clock had already passed so this data this toggling of data was not recorded by the latch now data toggled again now since at this point of time clock was low even the latch was opaque it was not transparent yet when clock went high both flop and the latch gave the right output right order means they reflected d on cube are you able to see this difference the key difference between a latch and a flock how level sensitive and s triggered sequential elements are different so again it is elaborate on this transparent energy okay so when i use the term transparent i mean to say that whatever comes on b it will be transmitted on q and opaque means it is not it will not be transmitted is it clear so so whatever appears on d will anyway we translated you realize this yes sir whereas the latch is transparent through the entire clock high period okay okay that is the difference yes so i mean if the clock if it is uh at the positive edge of the clock so will the clock transition on the clock slew will determine like how effectively how what for extractive timeline the flip flop will be on for like if my for example slew is more so will i say that uh key uh my flip-flop is transparent for much greater time so flip flop will uh will transmit whatever is there on the rising edge uh we will just now in a little while see that to get a correct output on the flip flop you will have to ensure that data is stable for some time before the clock arrives that is called as a setup time yes sir so we will ensure that there is no uncertainty at the output rather okay through different timing constraints because otherwise you're absolutely right if the clock slew is very bad or something like that is there then how will we ensure what data is coming at the output so that is where we have two timings set up and hold timings associated with the flop or a latch or anything like that so is it something like designers tend to prefer flip flops over latches do designers in general prefer flip flop over latches why so i it's just a question so i have not seen latches many that many places even in fpgas there are very few notches and most of them are flip flops only yeah see what happens is that uh now let us say this this intermediate d going high and low was a spurious transition it was see it went high then went low so it was a glitch what did the latch to last transmitted the glitch to the other side so all the signals on the other side also started to toggle hmm so lots of power got wasted yes in a flop all that did not happen in a flop i said okay now this one clock period is the time for this combination circuit to evaluate let it evaluate completely only after it has evaluated i will sample it so the intermediate transitions are no longer bothersome for the subsequent part of the circuit okay therefore are preferred at many places okay so answer or whatever timing is timing also somehow better for flip flop and instead of analysis we create problems whenever we use latches so let us wait for the next lecture we will see what is the timing overhead of flop and latch okay i will cover that okay that's a very relevant question but we are anyway going to cover that in the next class let us just go step by step uh sir in the timing diagram drawn below sir sir uh when is this latch is transparent and opaque according to this now you tell me sir according to me when the clock is zero uh and d is zero then and when then q is become 0 then here the latch must be opaque and when the clock is 1 and this q is 1 then it must be transparency because uh according to me sir opening or opaque is just reverse of transparent so when the latch is off then whatever is on q must be like opaque answer so if you if you look at it you will realize there is no dependence on the value on d yes or transparent matlab uh that the latch must be offset q must be independent of when in for opaque when is it opaque when uh depending upon the clock when the latch is either on or off when the clock is low then this particular latch is opaque because whatever is the value of d it is not coming on q okay so in the transparent one d will reflect on yes when the clock was one then latch is transparent so whatever d was there it reflected on q whether d was zero whether d was one whatever it was it reflected on q so transparent and opaque of the latch is dependent on the clock level that is why latch is called as level sensitive yes flip flop is instead called as edge trigger because whatever we see on the clock rising edge or falling edge whatever edge triggered you are that is what will be sampled and that is what will be used whatever happens intermediately we will ignore that we will not use that yes fine okay instead of a flip flop so then uh wanted to be that i will have only the negative edge for the evaluation for the block of combination circuit if we use negative edge of the clock for the flip flop then the next sampling of data will also happen at the next negative edge yes but i can do the evaluation over the complete time period of the clock yes because it will then be negative s to negative s so i will still have the entire time period with me yes in the latch it won't be a half time period will be available you will see latch has some other benefits [Laughter] otherwise i would not be telling you about it no yes yeah"
Go0s1-8WaUQ,will see the benefit of the last layer okay sir okay so now this is the oldest latch do you see this is a latch when c k is high d or q follows d when c k is low q is independent of d are you able to see this yes yes what are the challenges on what are the benefits of this latch uh sir we are feeding to the uh diffusion part of the transistor okay diffusion input and so this is a benefit or loss plus loss okay what else i've said a two two latches in parallel if the output output is shorted then because this is a pass transistor we can have like input being driven from the output kind of thing okay the output can end up driving the input good very good what else so dt drops vt drop very good see the first first thing let us look at the benefit the benefit is that it's just one transistor latch just one transistor so it's tiny and also very low clock load but cons oh as you just said vt drop output input on diffusion output being able to drive the input and all that and i'm back driving everything all these are losses or cons of using this kind of a latch and output noise sensitivity also so lots of negatives so what do we do we change the design we say that okay uh let us use a transmission gate latch at least we did drop all our problems all over so vt drop a lot of problem solver but what happens now i require an inverted clock also i am still on diffusion inputs i still may have back driving all those things will still remain though vt drop problem is solved so i want to solve other problems also so what do we do cascade with inverter yeah so we we say that okay let me put an inverter at the output now the output cannot drive the input or let me put an inverter on the input now the input is no longer deriving a diffusion so what happened i could first i have restoring output then no back driving and fixes either output noise sensitivity or diffusion input problem are you able to see this but either of those two not both of them so what would be a better solution then so how is the pack driving problem getting solved here so now tell me can q drive d q is going to the drain and and cannot transmit it to the x node over here so q cannot drive d now so back driving is not a problem now can i use two inverters at the input one at the input another at the output yeah can we use both inverters at both input and output yes we could so see we have we are using it over here invert input is also inverter output is also inverter more importantly even before that you know just because this latch is still dynamic in nature you see the charge on node x is is sensitive to noise hannah this latches through dynamic in nature when the q q bar will go off when this transmission gate will go off then this q bar will be floating i know so first an important thing is to solve this problem first so we say okay we add feedback we add feedback so that there is no dynamic node now so i have reduced the sensitivity of the output however in this setting there is back driving risk therefore what do we do we say feedback we dial there and we add the inverter on the input also and you will see it fixes diffusion input problem also this is non-inverting and uh there is like if you if you size it no in fact in the sizing keyboard any eye when you want this path to be active this path will be off so there is no back driving also are you able to see this sir can you explain this actually it's getting after that uh for example when they when we had only one inverter cascaded it solved our problem for the back driving one but after that what we did exactly so even when that one inverter was put do you realize that there were nodes which were not driven when the clock was off there were floating nodes there where the charge was stored on some gate or some capacitance so if the if the inverter was at the output like after the transmission gate then i won't be getting uh floating right the output is floating now now here in the second one is floating with the above one is not floating right above one excess floating okay right okay therefore output becomes floating yes okay i know so by coding things are important to fix first so therefore we first talked about adding a tristate why can't we use the beekeeper or level restorer to me to make sure that we won't float that x position which we were so that is what feedback is now look at this what is this level restorer for the dynamic gate level restorer was a simple pmos for a static date for for an inverter the output can be both zero and one so the level resource has to be an inverter that is what we have put yes yes yes sir honestly we've done that only yes does that we've used a tri-state over here why did we use a tricep and not a simple inverter to make the driving of x easier for me if it was a latch then inverting it through d would be a challenge yes if it was if this was not a tri-state if it was an inverter then this inverter would be driving x and this d will be driving x and it will be difficult to write into x so can you elaborate exactly why between try scenes of inverter and you could get it okay let us say it was we said that we just want to put a level restorer that is what was asked vaishnav said let us put a level restorer so uh for an inverter the level restorer would mean a feedback inverter instead of half flaps we put a full latch am i right hello have you understood this part why do i need a full inverter not just a pmos zero and one stable at x position so in a dynamic gate your output could only be zero could only go to zero yes sir so you only you always knew that if the output goes to zero then if that is when i need to or when the output remains one that is when i need to maintain the out maintain the output there yes in this case it's a latch how does this is zero and one both okay so you need to maintain both zero and once we need to put an inverter yes yes is it clear no sir now if i put an inverter what happens this let us say this was zero earlier so this will drive this at one am i right yes sir now when i turn the clock on z wants to write into this yes sir but this inverter is driving back yeah okay so b wanted so d wanted to discharge this but this inverter is also charging this up yes sir so this is a file condition hello yes sir now if we put a tri-state what happens if i put a tri-state over here what happens now so we are synchronizing the input to x appropriately so that i won't get in a condition that at a time these both get into a conflict so when this path is active this would be off look at it when phi is equal to 1 this nmos is on phi bar is equal to 0 so this pmos is also on d is trying to write to x but when phi is equal to 1 it is going to the pmos over here so this tri-state will no longer be driving yes huh so now you've removed the fighting conditions so we've actually done the level restorative stuff only just made it safer so can't it also be done by using a feedback inverter but a smaller feedback inverter so that it doesn't fight back which feedback inverter so uh we earlier drawn like that sram type cell so uh we just below this bottom inverter which is used for feedback we can size it so small that it doesn't fight back yeah but then you know about variations now yes so what can variations do variations can make you this inverter very strong so how strong i mean i am designing it to be so so small so yeah but even then what's the harm in putting it into a tri-state you are guaranteeing functionality independent of any variations you are guaranteeing functionality when you put it at high state is it not yes sir that's why so clock load would decrease i know but functionality is more important so what's the internal structure of this tri-state buffer oh you don't know the triassic buffer i i don't so tristate buffer sorry i've assumed that upload when it tries to buffer today so if i say this is input and this is output then there will be ck bar going over and ck going over here so that when ck is equal to 1 this acts as an inverter okay yes sir yes so it's just an inverter only we just clocked it yes sir so that it does not fight back the forward path when needed okay yes so i mean uh for example in the simple when we had only cascaded the inverter after the x node and i know that the x is basically my floating uh high so for example so is it i'm only concerned with the output when it is a high impedance one because then because zero to hamara zero it's good like right zero would be why why is zero good there is a there is a metal running next to this node x and it is going from zero to one it will couple a charge one on this x okay so but like is it i am considering the kind of worst case like it will uh going above or below the bdd by two positions you are a designer you cannot leave anything to chance i just gave you a failure mode you cannot think beyond that now whether circuit can fail you can no longer use it okay so you have to find another solution so so like we can't rely on the cascaded inverter to restore the kind of cascade inverter so so this inverter only like simple single inverter that we have cascade after the transmission gauge over the credit store it does not even drive if you have just one inverter on the output no feedback how will the output of the inverter restore the input you know so if it is in the if the variation is in within the noise margins then it can restore right then it can oh in the dynamic gates we looked at the dynamic gates before the system why did we look at the dynamic gates first because in dynamic dates we saw that there's nothing that can help you to restore yes yes how will what will restore over here tell me so i'm thinking for example if x is there if x is at one and it suffers commodore decay so its uh voltage will drop but if it is if the drop is within the noise margin of the inverter then how do you control it within the noise margin okay right that is the challenge yes now you cannot control it now you to control it you have to put this kind of a feedback yes yes sir okay rajneesh sir when this clock is zero sir that is when this transmission gate is off and this uh this tri-state uh feedback this turns on so any value on this uh q bar so may this x so still those advantages but this much correct and all of our operation may get so disturbed so will x and q bar not always be inverted inverted and out inverted of each other versions of each other no sir when this above latch is off and this when this below uh this tri-state buffer is on in that case haha so d is no longer driving now no sir yes b had driven x to some value yes and x had driven q to some value q bar to some value yes so q x is equal to inverter inverted off value of q bar x is already equal to that am i right yes sir but sir any glitch on this q bar may uh change this x suppose some q bar will change so that is the noise margin of a latch yes so that that is a different thing see that is the noise margin of this latch now yes so you're talking about an entirely different asset but if there is no noise then there is no problem am i right yes no noise means even if there is some noise which leads to some slight dips not a glitch and yes are you able to see the difference between a dip and a glitch uh depending glitch sir glitch will happen in q bar and deep will happen on this ex no no no no so glitch means glitch means that there is something which is some rise or fall some some transition on the signal is so large that the subsequent stage samples it as it as a change in input yes sir okay that is a glitch so that is a hazard actually what happens is qp you you you coupled so much of noise on q rising noise on q let us say that is a q bar sorry it's q bar over here you coupled so much noise on the q bar that uh x actually sends that q bar is equal to 0 and then x will go to 1 let us say yes so in that case we say that the noise margin of the latch has been corrupted yes okay but if someone is within that noise margin then the latch will restore x to 0 and q bar to 1 at all times yes which if you did not have a feedback would not have been done restoring could not have been possible yes sir one thing sir sir but when you added this buffer uh in front of transmission gate you told that there is no back driving disk and after that we added this tri-state buffer so can this queue bar affect the d at any instance possible now c now q bar will q bar will drive x through this tri-state and therefore q bar can end up driving b also if there is a situation if there is a situation where phi and phi bar they have a they have some delay between them yes so much loves are back driving the b o g w tri-state buffer or uh transmission with no except on driver yes that is why we just call it a risk we are not saying it will it will happen we are saying there is a risk it can happen or maybe it will depend upon our circuit it will depend on the timing variation between phi and fiber okay yes yes okay sir this uh basically this type of latch that you have drawn back-to-back inverter this moves in the sram cell so sir there there will kind of largely ignore this diffusion input and or and all those problems are there also i'm driving a pass gate in the sram center uh so sram cell uh is a different thing we will look at scam cell and we will cover that topic okay sram cell is never driven by a system input sram cell is always driven by something which is within your control as a circuit designer so you can always characterize it and you can always manage it so i know that what is in the proximity of the cell and what are the loads sram cell is very controlled it is used in a very controlled environment so we can use do it over there we cannot do it elsewhere okay okay so our tri-state buffer is essentially a better version of transmission gate so why are we using transmission so you can use transmission gates also yes uh no i i said uh tristate is a better version of transmission gates yeah so sorry you can use tri-state so in fact you will see that in flip flops there are transmission gate versions of flip flops and there are tri-state versions of flip-flops both exist okay it's more transistors in a in a tri-state there's an inversion also happening in a tri-state so uh due to area constraints or due to inversion constraints you may not want to use a trans try state everywhere so there are both versions that exist okay yes so raghav uh yes sir there were two properties early in the slides one was output noise sensitivity and non-restoring non-restoring uh i get it but like output now are they aren't they too linked actually that autonomous sensitivity or not the story so can you elaborate on the like the output noise sensitivity here for this kind of design so in this one output noise sensitivity is not there because output is driven to driven by an inverter yes sir but if the if the buffer was placed on the input in this case there is output my sensitivity i know when this transmission gate is off then output is floating yes that is what output my sensitivity is okay okay answer in the this uh last slide only uh what exactly you're talking about the leakage part this in the la in the next uh in the last slide leakage so yeah static this leakage point sir yeah so it says that uh because uh there are leaking circuits today and there are uh let us say if if this feedback was not there uh that x is getting uh getting disturbed because of crosstalk noise what they are saying is that what is being written in the slide over here is that this leakage will also happen which can degrade x either this way or the spherical can happen both sides you know so because of this leakage and this leakage becoming actually a big problem today you anyways need a feedback in in advanced technologies even if you say my system has no crosstalk because of leakage you will still need feedback so so this leakage problem will be existing for all kind of designs that we have seen till now yes so this then has a buffered input which fixes the diffusion input problem makes the latch non-inverting in itself and also fixes the problem linked to output noise sensitivity and so on and this is a situation there is separate inverter which drives q so any noise on q see you're still asking that there is some noise on q and that can impact x i know we were discussing this just a little while back yes avoid this problem what is done is we say that okay let us separate the q buffer now whatever happens here happens here only this latch in itself is safe this feedback loop will ensure that x remains at a stable value but you see this is such so much bigger than the first latch that we talked about hannah this is so much bigger than that clock load has increased so much but it is still very widely used because it is the most robust one is that okay so so i just wanted to ask for example in the complex gate designing that we're doing the if you are not considering the ptl based design logic then the diffusion input kind of scenario won't be occurring right for us [Music] if we are not considering the why transformation it may be the diffusion input [Music] so but like um for the static and dynamic we are we won't be getting that diffusion input case because we would be driving the gates only right if you're designing the complex case yeah but if you draw if you design a complex with transmission gates even then there is diffusion input yes yes sir even transmission gets okay right right so abhinav hello uh so in previous slide when we are talking about that risk when tri-state buffer that feedback part is driving our input d [Music] so we are discussing that if there is any delay between clock and clock bar then back driving may happen it it might be a risk basically we are taking clock and clockwise independent people right or we are diving clock bar from clock so you tell me what would you do as a designer as a designer i think clock and clockwise should be independent to avoid that risk should be independent means would you put two plls there sorry will you use two plls there two clock generators there uh no sir but uh so if you have same clock generator then you have to generate ck and ck bar can they be exactly the same phase or can there be exactly 180 degrees apart so wherever you are generating clock bar whether it is in the pll and then you are routing making a full clock tree for clock bar also or you're saying taking clock inside your latch and inverting it there itself and using it whatever you choose do you realize that there will be some delay,https://www.youtube.com/watch?v=Go0s1-8WaUQ,"Link: https://www.youtube.com/watch?v=Go0s1-8WaUQ
Transcript: will see the benefit of the last layer okay sir okay so now this is the oldest latch do you see this is a latch when c k is high d or q follows d when c k is low q is independent of d are you able to see this yes yes what are the challenges on what are the benefits of this latch uh sir we are feeding to the uh diffusion part of the transistor okay diffusion input and so this is a benefit or loss plus loss okay what else i've said a two two latches in parallel if the output output is shorted then because this is a pass transistor we can have like input being driven from the output kind of thing okay the output can end up driving the input good very good what else so dt drops vt drop very good see the first first thing let us look at the benefit the benefit is that it's just one transistor latch just one transistor so it's tiny and also very low clock load but cons oh as you just said vt drop output input on diffusion output being able to drive the input and all that and i'm back driving everything all these are losses or cons of using this kind of a latch and output noise sensitivity also so lots of negatives so what do we do we change the design we say that okay uh let us use a transmission gate latch at least we did drop all our problems all over so vt drop a lot of problem solver but what happens now i require an inverted clock also i am still on diffusion inputs i still may have back driving all those things will still remain though vt drop problem is solved so i want to solve other problems also so what do we do cascade with inverter yeah so we we say that okay let me put an inverter at the output now the output cannot drive the input or let me put an inverter on the input now the input is no longer deriving a diffusion so what happened i could first i have restoring output then no back driving and fixes either output noise sensitivity or diffusion input problem are you able to see this but either of those two not both of them so what would be a better solution then so how is the pack driving problem getting solved here so now tell me can q drive d q is going to the drain and and cannot transmit it to the x node over here so q cannot drive d now so back driving is not a problem now can i use two inverters at the input one at the input another at the output yeah can we use both inverters at both input and output yes we could so see we have we are using it over here invert input is also inverter output is also inverter more importantly even before that you know just because this latch is still dynamic in nature you see the charge on node x is is sensitive to noise hannah this latches through dynamic in nature when the q q bar will go off when this transmission gate will go off then this q bar will be floating i know so first an important thing is to solve this problem first so we say okay we add feedback we add feedback so that there is no dynamic node now so i have reduced the sensitivity of the output however in this setting there is back driving risk therefore what do we do we say feedback we dial there and we add the inverter on the input also and you will see it fixes diffusion input problem also this is non-inverting and uh there is like if you if you size it no in fact in the sizing keyboard any eye when you want this path to be active this path will be off so there is no back driving also are you able to see this sir can you explain this actually it's getting after that uh for example when they when we had only one inverter cascaded it solved our problem for the back driving one but after that what we did exactly so even when that one inverter was put do you realize that there were nodes which were not driven when the clock was off there were floating nodes there where the charge was stored on some gate or some capacitance so if the if the inverter was at the output like after the transmission gate then i won't be getting uh floating right the output is floating now now here in the second one is floating with the above one is not floating right above one excess floating okay right okay therefore output becomes floating yes okay i know so by coding things are important to fix first so therefore we first talked about adding a tristate why can't we use the beekeeper or level restorer to me to make sure that we won't float that x position which we were so that is what feedback is now look at this what is this level restorer for the dynamic gate level restorer was a simple pmos for a static date for for an inverter the output can be both zero and one so the level resource has to be an inverter that is what we have put yes yes yes sir honestly we've done that only yes does that we've used a tri-state over here why did we use a tricep and not a simple inverter to make the driving of x easier for me if it was a latch then inverting it through d would be a challenge yes if it was if this was not a tri-state if it was an inverter then this inverter would be driving x and this d will be driving x and it will be difficult to write into x so can you elaborate exactly why between try scenes of inverter and you could get it okay let us say it was we said that we just want to put a level restorer that is what was asked vaishnav said let us put a level restorer so uh for an inverter the level restorer would mean a feedback inverter instead of half flaps we put a full latch am i right hello have you understood this part why do i need a full inverter not just a pmos zero and one stable at x position so in a dynamic gate your output could only be zero could only go to zero yes sir so you only you always knew that if the output goes to zero then if that is when i need to or when the output remains one that is when i need to maintain the out maintain the output there yes in this case it's a latch how does this is zero and one both okay so you need to maintain both zero and once we need to put an inverter yes yes is it clear no sir now if i put an inverter what happens this let us say this was zero earlier so this will drive this at one am i right yes sir now when i turn the clock on z wants to write into this yes sir but this inverter is driving back yeah okay so b wanted so d wanted to discharge this but this inverter is also charging this up yes sir so this is a file condition hello yes sir now if we put a tri-state what happens if i put a tri-state over here what happens now so we are synchronizing the input to x appropriately so that i won't get in a condition that at a time these both get into a conflict so when this path is active this would be off look at it when phi is equal to 1 this nmos is on phi bar is equal to 0 so this pmos is also on d is trying to write to x but when phi is equal to 1 it is going to the pmos over here so this tri-state will no longer be driving yes huh so now you've removed the fighting conditions so we've actually done the level restorative stuff only just made it safer so can't it also be done by using a feedback inverter but a smaller feedback inverter so that it doesn't fight back which feedback inverter so uh we earlier drawn like that sram type cell so uh we just below this bottom inverter which is used for feedback we can size it so small that it doesn't fight back yeah but then you know about variations now yes so what can variations do variations can make you this inverter very strong so how strong i mean i am designing it to be so so small so yeah but even then what's the harm in putting it into a tri-state you are guaranteeing functionality independent of any variations you are guaranteeing functionality when you put it at high state is it not yes sir that's why so clock load would decrease i know but functionality is more important so what's the internal structure of this tri-state buffer oh you don't know the triassic buffer i i don't so tristate buffer sorry i've assumed that upload when it tries to buffer today so if i say this is input and this is output then there will be ck bar going over and ck going over here so that when ck is equal to 1 this acts as an inverter okay yes sir yes so it's just an inverter only we just clocked it yes sir so that it does not fight back the forward path when needed okay yes so i mean uh for example in the simple when we had only cascaded the inverter after the x node and i know that the x is basically my floating uh high so for example so is it i'm only concerned with the output when it is a high impedance one because then because zero to hamara zero it's good like right zero would be why why is zero good there is a there is a metal running next to this node x and it is going from zero to one it will couple a charge one on this x okay so but like is it i am considering the kind of worst case like it will uh going above or below the bdd by two positions you are a designer you cannot leave anything to chance i just gave you a failure mode you cannot think beyond that now whether circuit can fail you can no longer use it okay so you have to find another solution so so like we can't rely on the cascaded inverter to restore the kind of cascade inverter so so this inverter only like simple single inverter that we have cascade after the transmission gauge over the credit store it does not even drive if you have just one inverter on the output no feedback how will the output of the inverter restore the input you know so if it is in the if the variation is in within the noise margins then it can restore right then it can oh in the dynamic gates we looked at the dynamic gates before the system why did we look at the dynamic gates first because in dynamic dates we saw that there's nothing that can help you to restore yes yes how will what will restore over here tell me so i'm thinking for example if x is there if x is at one and it suffers commodore decay so its uh voltage will drop but if it is if the drop is within the noise margin of the inverter then how do you control it within the noise margin okay right that is the challenge yes now you cannot control it now you to control it you have to put this kind of a feedback yes yes sir okay rajneesh sir when this clock is zero sir that is when this transmission gate is off and this uh this tri-state uh feedback this turns on so any value on this uh q bar so may this x so still those advantages but this much correct and all of our operation may get so disturbed so will x and q bar not always be inverted inverted and out inverted of each other versions of each other no sir when this above latch is off and this when this below uh this tri-state buffer is on in that case haha so d is no longer driving now no sir yes b had driven x to some value yes and x had driven q to some value q bar to some value yes so q x is equal to inverter inverted off value of q bar x is already equal to that am i right yes sir but sir any glitch on this q bar may uh change this x suppose some q bar will change so that is the noise margin of a latch yes so that that is a different thing see that is the noise margin of this latch now yes so you're talking about an entirely different asset but if there is no noise then there is no problem am i right yes no noise means even if there is some noise which leads to some slight dips not a glitch and yes are you able to see the difference between a dip and a glitch uh depending glitch sir glitch will happen in q bar and deep will happen on this ex no no no no so glitch means glitch means that there is something which is some rise or fall some some transition on the signal is so large that the subsequent stage samples it as it as a change in input yes sir okay that is a glitch so that is a hazard actually what happens is qp you you you coupled so much of noise on q rising noise on q let us say that is a q bar sorry it's q bar over here you coupled so much noise on the q bar that uh x actually sends that q bar is equal to 0 and then x will go to 1 let us say yes so in that case we say that the noise margin of the latch has been corrupted yes okay but if someone is within that noise margin then the latch will restore x to 0 and q bar to 1 at all times yes which if you did not have a feedback would not have been done restoring could not have been possible yes sir one thing sir sir but when you added this buffer uh in front of transmission gate you told that there is no back driving disk and after that we added this tri-state buffer so can this queue bar affect the d at any instance possible now c now q bar will q bar will drive x through this tri-state and therefore q bar can end up driving b also if there is a situation if there is a situation where phi and phi bar they have a they have some delay between them yes so much loves are back driving the b o g w tri-state buffer or uh transmission with no except on driver yes that is why we just call it a risk we are not saying it will it will happen we are saying there is a risk it can happen or maybe it will depend upon our circuit it will depend on the timing variation between phi and fiber okay yes yes okay sir this uh basically this type of latch that you have drawn back-to-back inverter this moves in the sram cell so sir there there will kind of largely ignore this diffusion input and or and all those problems are there also i'm driving a pass gate in the sram center uh so sram cell uh is a different thing we will look at scam cell and we will cover that topic okay sram cell is never driven by a system input sram cell is always driven by something which is within your control as a circuit designer so you can always characterize it and you can always manage it so i know that what is in the proximity of the cell and what are the loads sram cell is very controlled it is used in a very controlled environment so we can use do it over there we cannot do it elsewhere okay okay so our tri-state buffer is essentially a better version of transmission gate so why are we using transmission so you can use transmission gates also yes uh no i i said uh tristate is a better version of transmission gates yeah so sorry you can use tri-state so in fact you will see that in flip flops there are transmission gate versions of flip flops and there are tri-state versions of flip-flops both exist okay it's more transistors in a in a tri-state there's an inversion also happening in a tri-state so uh due to area constraints or due to inversion constraints you may not want to use a trans try state everywhere so there are both versions that exist okay yes so raghav uh yes sir there were two properties early in the slides one was output noise sensitivity and non-restoring non-restoring uh i get it but like output now are they aren't they too linked actually that autonomous sensitivity or not the story so can you elaborate on the like the output noise sensitivity here for this kind of design so in this one output noise sensitivity is not there because output is driven to driven by an inverter yes sir but if the if the buffer was placed on the input in this case there is output my sensitivity i know when this transmission gate is off then output is floating yes that is what output my sensitivity is okay okay answer in the this uh last slide only uh what exactly you're talking about the leakage part this in the la in the next uh in the last slide leakage so yeah static this leakage point sir yeah so it says that uh because uh there are leaking circuits today and there are uh let us say if if this feedback was not there uh that x is getting uh getting disturbed because of crosstalk noise what they are saying is that what is being written in the slide over here is that this leakage will also happen which can degrade x either this way or the spherical can happen both sides you know so because of this leakage and this leakage becoming actually a big problem today you anyways need a feedback in in advanced technologies even if you say my system has no crosstalk because of leakage you will still need feedback so so this leakage problem will be existing for all kind of designs that we have seen till now yes so this then has a buffered input which fixes the diffusion input problem makes the latch non-inverting in itself and also fixes the problem linked to output noise sensitivity and so on and this is a situation there is separate inverter which drives q so any noise on q see you're still asking that there is 
some noise on q and that can impact x i know we were discussing this just a little while back yes avoid this problem what is done is we say that okay let us separate the q buffer now whatever happens here happens here only this latch in itself is safe this feedback loop will ensure that x remains at a stable value but you see this is such so much bigger than the first latch that we talked about hannah this is so much bigger than that clock load has increased so much but it is still very widely used because it is the most robust one is that okay so so i just wanted to ask for example in the complex gate designing that we're doing the if you are not considering the ptl based design logic then the diffusion input kind of scenario won't be occurring right for us [Music] if we are not considering the why transformation it may be the diffusion input [Music] so but like um for the static and dynamic we are we won't be getting that diffusion input case because we would be driving the gates only right if you're designing the complex case yeah but if you draw if you design a complex with transmission gates even then there is diffusion input yes yes sir even transmission gets okay right right so abhinav hello uh so in previous slide when we are talking about that risk when tri-state buffer that feedback part is driving our input d [Music] so we are discussing that if there is any delay between clock and clock bar then back driving may happen it it might be a risk basically we are taking clock and clockwise independent people right or we are diving clock bar from clock so you tell me what would you do as a designer as a designer i think clock and clockwise should be independent to avoid that risk should be independent means would you put two plls there sorry will you use two plls there two clock generators there uh no sir but uh so if you have same clock generator then you have to generate ck and ck bar can they be exactly the same phase or can there be exactly 180 degrees apart so wherever you are generating clock bar whether it is in the pll and then you are routing making a full clock tree for clock bar also or you're saying taking clock inside your latch and inverting it there itself and using it whatever you choose do you realize that there will be some delay"
lY-7fT2-5ag,so wherever you are generating clock bar whether it is in the pll and then you're routing making a full clock tree for clock bar also or you're saying taking clock inside your latch and inverting it there itself and using it whatever you choose do you realize that there will be some delays [Music] okay so just like we drew the latches we can also make flip flops a flip flop is essentially a pair of back to back latches so if i did not want to go to a very stable feedback driven circuit i could have a latch which has floating gates like x or i could have a latch like this one where my outputs do not even touch or uh you know influence the inputs in whichever possible way so which which flip flop would you do you think will be most commonly used it's the bottom the lower one and because it's much more robust even though it is much bigger in size but it is more robust so we use something like this rather so in the eddy in this boat this additional inverter that i am using that is just for the functionality right so that i do not end up influencing the internal node the latch from the output okay so but like uh in the second design uh after that that uh after i've isolated the q bar i'm still adding an additional inverter that i don't need right and then i need q and q bar both see both outputs are usually there okay so those inverters are put inside the flop itself okay so the back driving issue to minimize that okay yes okay so uh now you remember we talked about clock dating where we said that to reduce dynamic power we will get some part of the circuit so that there is no clock toggling there yes so that we say power of toggling of signals so clock dating is enabled in flip flops and latches by using the use of this signal called enable when enable equal to zero any transition on clock is ignored and you can implement this system in two of the ways either by using a multiplexer or using a and or an and gate are you able to see this any questions here are you are you able to see that if clock equal to zero the output will will become independent of clock if enable equal to zero output becomes independent of clock are you able to see that yes yes sir hmm so any questions on this functionality is evident fairly evident from the slide itself okay uh in this multiplexer uh one the multiplexer thing so there don't we even x give an extra constraint of like enable should come first and d would settle and then the clock comes i mean the enable and d will also have some because the enable is not clock enable is a signal so those regular signals give each one you don't put constraints block and enable yes there is a constraint clock and data there will be a constraint but not not between data and enable that is considered to be combination alone yeah anna yes okay can you elaborate to the candle habit on this point uh clock gate increase in setup skew i mean how is the skew it getting affected how is the skew getting marked are we actually just just keep this with process when we will talk about the timing you will see what skew is okay i have not even introduced the term skew to you know yes sir just park it somewhere you will see how it rescue will get impacted it will be evident to you okay and so in the multiplexer based design then my enable is say zero i mean how is the clock uh i'm like isolating from the clock when with the enable signal that i was not able to clear so the latch is not changing uh or not going to dina d will not reflect on q until enable is zero because the input of the latch remains constant which is equal to the output then enable equal to zero what path gets activated in the multiplexer design so that d1 enable equal to zero okay okay yes yes zero yes equal to zero means this path is activated so any change in d will not come into picture okay okay okay same here you see yes it is yeah that was asked okay great so now in addition to enable signals you will see that flip flops also sometimes have what is called as a reset signal what does reset mean reset means that the output will be pushed to zero output will be pushed to low when reset is asserted and it could be synchronous or asynchronous the first implementation is synchronous one where output will be pushed to zero at the next rising edge of the clock or whenever the clock is high again this one on the other hand is an asynchronous reset whereby using reset on additional gates inside the latches i have ensured that uh as soon as reset comes my output will be 0. are you able to see this why do you think this reset pin is even necessary or maybe while putting my circuit into sleep or getting getting some part of circuit i want to bring it to a suppose power up power up is happening a powerhop has just happened and now you want to say that okay i want to start with a clean slate during power up some latches will be zero some latches will be one i have no control over anything i know some latches could be zero some so i just assert reset all the flops everything is zero now now it is the deterministic state that i am starting from so what is power up okay like on off yeah okay okay okay now when you do this power up do you really want all blocks to be zero or there could be some flops because of the state machine requirements you may want them to be one also it can happen so that is what takes us to the next kind of a flip flop which is set reset flip flop where if you want to set then something would happen if you want to reset something else would happen so in this case what you do you are able to create the state machine that you desire you obviously notice there are many more transistors in this flop now there is this has and all the inverters are converted into two input gates at least if not more i know it's a tristated gate fan this has many more transistors now but if you need this functionality in a few flops you will use the set reset flops at those places at other places where the they are not a part of the fsm of the system or anything like that you may still use the regular reset flops or the regular flops also without even reset but some flops in the fsm you may want to use set reset flops so that you can power up in a desired state machine and then therefore give faster output to the user or whatever faster better experience to the user so you'll lose some area but you will have a deterministic power up by using the set reset flop okay any questions so sir like with this set and reset i'm just trying i'm trying to control the internal states of the flip flop like irrespective output yes sir like uh it is uh apart from the uh normal computation that exactly i mean yeah i'm not even waiting for clock to arrive i'm saying let me change the output even before clock arrives so but the clock uh only when it is asynchronous then only i will be able to control otherwise the synchronous clock has to arrive right yeah in this case set reset is usually a synchronous okay set preset both are used with asynchronous only usually when it is only reset you can think of synchronous and asynchronous but set reset flop people understand it is for the state machine so the clock may not even be coming at that time okay because you're talking about power ups i know the clock may not be active yet even then i may want to have a state machine of my choice yes sir okay anything else so in the state machine like why is the need of setting this up actually okay uh how do i put it there could be a state machine for example let us say the there is a state machine that controls the configuration inputs of the memory okay now for memory some inputs are expected to be held at one and some other inputs are expected to be powered up at zero okay so you need some signals to be powered up at one another yes so okay okay that is why so now you may say thing that i may use an inverter but if the power up has not completely happened if the power up has not completely happened then a synchronous set reset will still work i will just power up the system in the right way uh even before uh clock first clock arrives and things like that yes sir so now we in in the in the few slides back we saw that there is this process possibility of an overlap between clk and clk bar which can lead to back gate driving and all that stuff you remember then to avoid that or what did you do we added inverters extra inverters on the outputs and everything so by using this true single phase clock flip flops i can avoid that altogether this is called tspc true single phase clock flops here what has happened is here uh you will notice that i am able to hold the data or make it as a latch by using only one phase of clock the risk is that this internal node intermediate node is dynamic in nature now so tspc flops are much faster are smaller have lesser risk of ckck bar overlaps because there is only ck now but there is a risk of this intermediate node struggling because of noise issues okay so this looks like a dynamic gate for a clock yeah that is why i said no this is the risk the node is floating there so now if you want to include logic in tspc you can also include logic into tspc latches but again always remember this is a risk there will be floating nodes somewhere or the other if both in and uh in n1 and n2 are one if both n1 and n2 are one then what happens and and let us say ck is also is equal to zero then what happens this node is floating are you able to see this so the output will be tentative we do not know this is a risky kind of a design so see dynamic circuits without level restorers without all those checks in place can be very risky pspc and therefore will not be used in places where noise immunity is is considered to be a very high criteria huh wherever speed is very highly required or something like that you could still use dsbc yes so can you please elaborate exactly what exactly are we solving the problem with this tspc i was not able to get so there was a you remember there was this tri-state and we said there is we said there was a possibility of q back driving d when ck and ck bar overlap yes sir so and and to avoid this then we added inverters here and we did so many things yes sir now we say that is there a way to avoid extra gates save area and that is what pspc is solving here only ck is being used okay so i'm doing this to avoid the back driving yeah okay okay however notice that this means that this node is now floating it comes with a risk so use it only very very carefully in a very very controlled environment not anywhere else okay similarly we have a tspcc flip flop also so yes so by default what design do we use by default what design do we use the static the one that i showed with so many extra transistors okay it's the one now without enabling usually used enable one is also required at some places and then you also require set and uh and set reset flops at some places but majority of the times the regular flop will be used without enable and without set reset okay uh and so so they they both need clock and drop pass in this but by default whenever we see some synthesized net list we only see one clock in any flip flop or another generated inside am saying that consistently the clock transistor is uh nearer to the output node um clock transistor is nearer to the output node only so that unnecessary toggling on d for example should not lead to noise on x activity factor is the highest so shouldn't it be isolated instead of d for the question i mean why you were taking that what he asked okay let us look at the other way around let us say clock was on the other side clock was on the top and d was coming to the what do you say inverter kind of a thing directly what would happen okay so i mean if it is coming on the top then the d would be coming here so if these i'm considering that the okay but if it's flip flop i know that key it is uh h triggered so but d if it coming so at the edge of the clock only my t can be impact my x node but if it comes in the middle if d comes closer to x then what happens it can it can do something even when it is o even when the edge is not triggered then also it can impact the expert okay yes we don't want that yes so we are giving this sensitivity much precise towards the clock right sir so that uh as friends let's not do these hypothetical experiments you just draw the circuit and check for the functionality now yes sir so but sir even if i push this clock transistor above the d p mass even then the vdd will not be connected to the x uh even if the d is making some spurious movements so it does not really affect the output node in the either case right because that path has to be on yes that path has to be on but uh again i would say you you just experiment make the circuit with the clock on the top and be in the center and you will see what happens i want you to do this exercise also yes yes yeah sir i just wanted to say one thing sir so if my clock is at the top and my d is at the bottom so there might be a parasitic capacitance between so in that position uh when there is a glitch on my d then there is a possibility that my output might get discharged yeah yeah so glitches attract all those things dynamic gates because you will see that problem would exist even here now yes sir yeah okay let's see so anyways i'm not going to spend too much time on tspc because i just wanted to introduce,https://www.youtube.com/watch?v=lY-7fT2-5ag,"Link: https://www.youtube.com/watch?v=lY-7fT2-5ag
Transcript: so wherever you are generating clock bar whether it is in the pll and then you're routing making a full clock tree for clock bar also or you're saying taking clock inside your latch and inverting it there itself and using it whatever you choose do you realize that there will be some delays [Music] okay so just like we drew the latches we can also make flip flops a flip flop is essentially a pair of back to back latches so if i did not want to go to a very stable feedback driven circuit i could have a latch which has floating gates like x or i could have a latch like this one where my outputs do not even touch or uh you know influence the inputs in whichever possible way so which which flip flop would you do you think will be most commonly used it's the bottom the lower one and because it's much more robust even though it is much bigger in size but it is more robust so we use something like this rather so in the eddy in this boat this additional inverter that i am using that is just for the functionality right so that i do not end up influencing the internal node the latch from the output okay so but like uh in the second design uh after that that uh after i've isolated the q bar i'm still adding an additional inverter that i don't need right and then i need q and q bar both see both outputs are usually there okay so those inverters are put inside the flop itself okay so the back driving issue to minimize that okay yes okay so uh now you remember we talked about clock dating where we said that to reduce dynamic power we will get some part of the circuit so that there is no clock toggling there yes so that we say power of toggling of signals so clock dating is enabled in flip flops and latches by using the use of this signal called enable when enable equal to zero any transition on clock is ignored and you can implement this system in two of the ways either by using a multiplexer or using a and or an and gate are you able to see this any questions here are you are you able to see that if clock equal to zero the output will will become independent of clock if enable equal to zero output becomes independent of clock are you able to see that yes yes sir hmm so any questions on this functionality is evident fairly evident from the slide itself okay uh in this multiplexer uh one the multiplexer thing so there don't we even x give an extra constraint of like enable should come first and d would settle and then the clock comes i mean the enable and d will also have some because the enable is not clock enable is a signal so those regular signals give each one you don't put constraints block and enable yes there is a constraint clock and data there will be a constraint but not not between data and enable that is considered to be combination alone yeah anna yes okay can you elaborate to the candle habit on this point uh clock gate increase in setup skew i mean how is the skew it getting affected how is the skew getting marked are we actually just just keep this with process when we will talk about the timing you will see what skew is okay i have not even introduced the term skew to you know yes sir just park it somewhere you will see how it rescue will get impacted it will be evident to you okay and so in the multiplexer based design then my enable is say zero i mean how is the clock uh i'm like isolating from the clock when with the enable signal that i was not able to clear so the latch is not changing uh or not going to dina d will not reflect on q until enable is zero because the input of the latch remains constant which is equal to the output then enable equal to zero what path gets activated in the multiplexer design so that d1 enable equal to zero okay okay yes yes zero yes equal to zero means this path is activated so any change in d will not come into picture okay okay okay same here you see yes it is yeah that was asked okay great so now in addition to enable signals you will see that flip flops also sometimes have what is called as a reset signal what does reset mean reset means that the output will be pushed to zero output will be pushed to low when reset is asserted and it could be synchronous or asynchronous the first implementation is synchronous one where output will be pushed to zero at the next rising edge of the clock or whenever the clock is high again this one on the other hand is an asynchronous reset whereby using reset on additional gates inside the latches i have ensured that uh as soon as reset comes my output will be 0. are you able to see this why do you think this reset pin is even necessary or maybe while putting my circuit into sleep or getting getting some part of circuit i want to bring it to a suppose power up power up is happening a powerhop has just happened and now you want to say that okay i want to start with a clean slate during power up some latches will be zero some latches will be one i have no control over anything i know some latches could be zero some so i just assert reset all the flops everything is zero now now it is the deterministic state that i am starting from so what is power up okay like on off yeah okay okay okay now when you do this power up do you really want all blocks to be zero or there could be some flops because of the state machine requirements you may want them to be one also it can happen so that is what takes us to the next kind of a flip flop which is set reset flip flop where if you want to set then something would happen if you want to reset something else would happen so in this case what you do you are able to create the state machine that you desire you obviously notice there are many more transistors in this flop now there is this has and all the inverters are converted into two input gates at least if not more i know it's a tristated gate fan this has many more transistors now but if you need this functionality in a few flops you will use the set reset flops at those places at other places where the they are not a part of the fsm of the system or anything like that you may still use the regular reset flops or the regular flops also without even reset but some flops in the fsm you may want to use set reset flops so that you can power up in a desired state machine and then therefore give faster output to the user or whatever faster better experience to the user so you'll lose some area but you will have a deterministic power up by using the set reset flop okay any questions so sir like with this set and reset i'm just trying i'm trying to control the internal states of the flip flop like irrespective output yes sir like uh it is uh apart from the uh normal computation that exactly i mean yeah i'm not even waiting for clock to arrive i'm saying let me change the output even before clock arrives so but the clock uh only when it is asynchronous then only i will be able to control otherwise the synchronous clock has to arrive right yeah in this case set reset is usually a synchronous okay set preset both are used with asynchronous only usually when it is only reset you can think of synchronous and asynchronous but set reset flop people understand it is for the state machine so the clock may not even be coming at that time okay because you're talking about power ups i know the clock may not be active yet even then i may want to have a state machine of my choice yes sir okay anything else so in the state machine like why is the need of setting this up actually okay uh how do i put it there could be a state machine for example let us say the there is a state machine that controls the configuration inputs of the memory okay now for memory some inputs are expected to be held at one and some other inputs are expected to be powered up at zero okay so you need some signals to be powered up at one another yes so okay okay that is why so now you may say thing that i may use an inverter but if the power up has not completely happened if the power up has not completely happened then a synchronous set reset will still work i will just power up the system in the right way uh even before uh clock first clock arrives and things like that yes sir so now we in in the in the few slides back we saw that there is this process possibility of an overlap between clk and clk bar which can lead to back gate driving and all that stuff you remember then to avoid that or what did you do we added inverters extra inverters on the outputs and everything so by using this true single phase clock flip flops i can avoid that altogether this is called tspc true single phase clock flops here what has happened is here uh you will notice that i am able to hold the data or make it as a latch by using only one phase of clock the risk is that this internal node intermediate node is dynamic in nature now so tspc flops are much faster are smaller have lesser risk of ckck bar overlaps because there is only ck now but there is a risk of this intermediate node struggling because of noise issues okay so this looks like a dynamic gate for a clock yeah that is why i said no this is the risk the node is floating there so now if you want to include logic in tspc you can also include logic into tspc latches but again always remember this is a risk there will be floating nodes somewhere or the other if both in and uh in n1 and n2 are one if both n1 and n2 are one then what happens and and let us say ck is also is equal to zero then what happens this node is floating are you able to see this so the output will be tentative we do not know this is a risky kind of a design so see dynamic circuits without level restorers without all those checks in place can be very risky pspc and therefore will not be used in places where noise immunity is is considered to be a very high criteria huh wherever speed is very highly required or something like that you could still use dsbc yes so can you please elaborate exactly what exactly are we solving the problem with this tspc i was not able to get so there was a you remember there was this tri-state and we said there is we said there was a possibility of q back driving d when ck and ck bar overlap yes sir so and and to avoid this then we added inverters here and we did so many things yes sir now we say that is there a way to avoid extra gates save area and that is what pspc is solving here only ck is being used okay so i'm doing this to avoid the back driving yeah okay okay however notice that this means that this node is now floating it comes with a risk so use it only very very carefully in a very very controlled environment not anywhere else okay similarly we have a tspcc flip flop also so yes so by default what design do we use by default what design do we use the static the one that i showed with so many extra transistors okay it's the one now without enabling usually used enable one is also required at some places and then you also require set and uh and set reset flops at some places but majority of the times the regular flop will be used without enable and without set reset okay uh and so so they they both need clock and drop pass in this but by default whenever we see some synthesized net list we only see one clock in any flip flop or another generated inside am saying that consistently the clock transistor is uh nearer to the output node um clock transistor is nearer to the output node only so that unnecessary toggling on d for example should not lead to noise on x activity factor is the highest so shouldn't it be isolated instead of d for the question i mean why you were taking that what he asked okay let us look at the other way around let us say clock was on the other side clock was on the top and d was coming to the what do you say inverter kind of a thing directly what would happen okay so i mean if it is coming on the top then the d would be coming here so if these i'm considering that the okay but if it's flip flop i know that key it is uh h triggered so but d if it coming so at the edge of the clock only my t can be impact my x node but if it comes in the middle if d comes closer to x then what happens it can it can do something even when it is o even when the edge is not triggered then also it can impact the expert okay yes we don't want that yes so we are giving this sensitivity much precise towards the clock right sir so that uh as friends let's not do these hypothetical experiments you just draw the circuit and check for the functionality now yes sir so but sir even if i push this clock transistor above the d p mass even then the vdd will not be connected to the x uh even if the d is making some spurious movements so it does not really affect the output node in the either case right because that path has to be on yes that path has to be on but uh again i would say you you just experiment make the circuit with the clock on the top and be in the center and you will see what happens i want you to do this exercise also yes yes yeah sir i just wanted to say one thing sir so if my clock is at the top and my d is at the bottom so there might be a parasitic capacitance between so in that position uh when there is a glitch on my d then there is a possibility that my output might get discharged yeah yeah so glitches attract all those things dynamic gates because you will see that problem would exist even here now yes sir yeah okay let's see so anyways i'm not going to spend too much time on tspc because i just wanted to introduce"
JcweW0X0CC0,it to you not too much time on it because you know there are other designs also for example c2 moss where you have this uh what do you say this kind of a design where even if now you have both phases of clock over here clk and clk bar both exist over here but what happens uh at any given point of time even if one side goes active the other side will not drive so even in in the case of a zero zero overlap or a one one overlap even in the case of overlaps you will see that your design is safe okay again uh this over here also this x node is is uh many times floating not really a very stable state to be in so even c2 mass designs you will not see you will not find to be used at many many places but yes where there is a very high requirement for density and also this risk of clock clock bar overlap you can you can think of using this kind of a c2 moss design also and then you will have to use keepers you know as is already said you will have to use keepers and all those things will need to be done okay this is also a dynamic design so while these are solutions you will notice they are not very commonly used because of the very nature that there are floating nodes there and with floating nodes the biggest problem is on a flop or a sequencing element if you use floating nodes the overall robustness of the entire system can get compromised so they are not very commonly used but they are proposals their ideas which you just need to be aware of so yes cspc and c2 mass are both parallel solutions to the bad drive problem right not yeah there is no advantage over c2 mos over tspc right no no yes okay uh yeah now we come to timings i think let's start with this in the next class the timings of of uh timings related to a large and a flop we'll start with the next class then we will see okay yes so great yes so uh certain digital circuits we we uh we studied a very different design of flip flop and matches in that we progressed very uniformly from an sr batch then we added enable signal then we created a latch then we created master slave to make a flip flop d flip flop so and then we also saw a design of d flip flop which consisted of mini and the gates and case not gates so which was not even master slave it was just a single d flip flop so do we even make those designs so we make the designs that we just saw so we want to keep it as simple as possible and as dense as possible yes so this is how we would use it as dense as possible so even the densest one that we looked at today which was the one that just let me go back to that side the ones that we looked at with uh set reset or isabella you see this one itself is such a big problem is it not it's nowhere near what we were talking about [Music] yeah but look at it the digital circuit one is something like this because digital circuit one you did all set reset also from outside now because it started from sr latch yes so digital circuit one look like this probably anna yes yeah because you started from sr latch yes over here what we are saying is that set reset functionality is not required in all the flops so why waste area yes in vlsi area is this okay yes great so uh we we'll close the class now there were some project related doubts you can ask them yes sir sir i was asking that if we look at the layout aspect then c-square mos looks like very very good design that yes it could be so could we like to some and do a trade-off and go for it and like make two keepers and then implement the c square mass instead of this will be pseudostatic again they realize this there will still be some risk some robustness so people use it anyways that is why everyone touched upon it otherwise touching use it but it's very rarely used in very very specific cases someone would use that kind of a plot okay yes sir we had some project related doubts so basically we are comparing the complex and non-complex implementation of aoi 221 so in that set we simply created the two net list and try to verify that whether the delays decrease in the non-complex implementation also we did the theoretical calculations so for by the theoretical calculation and more delay and all so we were able to uh expect we expected that the delay would decrease but opposite of that is happening we are we are getting more delays in the non-complex one okay so anyways finally you would get better delays with the complex implementation because of uh lesser wires and more density and everything but i'm surprised that uh even when you are not talking about the layouts and not talking about those parasites even then you are able to see that of a complex gate would be slightly higher though it is much denser but the effect would be visible largely only after extraction so i'm surprised you're able to see it before extraction also is a class value experiment measure there was a thing that you you had put out inverter after the aoi and then also you remove the two inverters that could have come in the other logic so that that was kind of a natural thing to reduce the delay of the non-complex implementation of uh we need that functionality but you make it from the basic gates we are calling it and or invert that doesn't mean that you have to use an and gate and an or gate and an inverter no no no that is the functionality yes sir okay okay do the bubble pushing get to the densest implementation you will see it is uh it should be slightly faster non-complex should be faster right yeah non-complex should be slightly faster on fab on on simulation first simulation but after layout you will see that complex one will be much faster so in the pre-simulation we are getting that [Music] it's good if it is faster but the point is that the theoretical calculations and the simulations are not agreeing with each other that's the problem so probably i'm justifying you okay because in the theoretical calculations also you have ignored so many capacities simulation has taken care of all the device capacitances including source drain and miller capacitance and so many things the simulation would take care of that's also fine but i was not expecting it to already show it to you so suppose uh if we have done the layout of the complex and the non-complex then my non-complex layout will be fast should be faster or no okay because of the parasitics addition yeah yeah i was not expecting that parasitics in the non-complex gate would already be so high that it will be slower than the complex gate i was not expecting this but if it is happening it is happening it's fine okay so like can i say that uh the non-complex and the complex uh the differences between the two that with the complex we are not able to achieve the better area but also better delays yeah so the complex gates give you better delays and also better area more density and also the leakage would be better because yeah yeah okay okay that is why these are used so commonly okay so on all kind of parameters ppa i'm getting better complex okay over the nonprofits right now sir yes sir sir so when i was making the layout of non-complex get implementation sir so uh i tried it sir and for routing purposes can we use clock for routines sorry uh poly for routing no avoid that uh poly for routing within the cell it is fine but yeah within the cell it is okay 65 nanometer may i allow you but realize that in 45 onwards poly routing is not allowed so then uh we should definitely go to whenever seeing the constraints i made it without m2 layer usage so without empty layer research uh i i ran a quality down and above above for the clock and uh another one kind of connection which is is you are putting a large r on the clock path you're adding lots of more delays there sir but uh i am covering it with an pp layer doesn't that no even then it is resistive no it is bound to be more resistant than a metal is it not yes yes yeah that is what you should remember it is always more resistant than copper okay sir so sir then uh can we use m2 layer for that sir just for clock in case no not for clock only for routing clock so you're using dynamic gates yeah dynamic and non-complexing so interconnecting clock between different dynamic gates you can use metal tool interconnecting signals across different gates you can use metal to for every gate independently there should be no metal to usage okay okay yes sir okay circuit a and circuit b if circuit a has a high rise time and circuit b has lower high rise time so sir if i ask about the rise propagation delay then i will expect the circuit a to have a correspondingly high high rise delay also and other one would have the lower so basically this should kind of correlate according to what i think but but in the uh simulation that we ran uh at that point of time we were able to see that it was not the case for the circuit where rise time was higher the rise propagation delay was lower so it should not kind of this is very counter intuitive to me no there are if there is a path that you're talking about and there are two or three stages that a signal is moving from input to output then it could be that the the the design is skewed in such a way that the propagation delay moves differently than uh we will be differently for rise and fall and uh the final stage the rise time and fall time is largely dependent on the load versus the drive strength of the pmos and the nmos in the output stage so they are actually independent things okay okay so i am comparing the input slew of the first stage so i should compare the input slope last season should have a similar trend no that is what i am saying no yes so i'm not able to get that why why not if i'm white that should not be the case i mean so let us say you have this chain now what did you do you high skewed it you low skewed it you high skewed it and you let us say made this as a balanced one so what will happen the higher transition zero to one transition will be fast yes one two zero will be fast zero to one will be very fast so the is a fall transition here that will happen the delay will be much shorter huh but in this particular gate since it is only balanced my rise time and fall time are exactly the same so the delays are different but the rise time and fall time are same are you able to see that yes okay yes sir i know if you are talking only of one gate then whatever assumptions you are making could be correct but that is don't build such correlations which can hamper your overall if i have not told you that correlation it may not exist or if it exists then yes it is good to validate so for example in this case both were same the rise time the fourth time was same and the delays were different could be different so but for example if my rice time is improving so my rice delay should also be improving right you see example what did i say i said high low high so high rising faster falling faster rising faster yes sir so what happened because the rising was the the see in three inverters in three inverters the falling delay of this particular gate was preferred so the even though it is a high skewed inverter the following delay will be lesser for this entire path than the rising delay but this is a high skewed inverter so the rise time will be much better than the fault time okay yeah the delays are getting him affected by the previous stages also what kind of that yes yes okay but the rise the thai rice name for timer because of of that stage only itself okay primarily yes primarily yes okay so always think of the failure case if you try to if you're making an assumption you should not look at examples which justify your assumption you should try to find examples which violate your uh your assumption okay yes yes this is called failure mode analysis and good designer should always be able to do very well on the failure mode analysis path okay yes question if your hand is raised you want to ask something else question sir yeah sir so uh i'll i can use m24 clock and they are they are of different stages uh obviously uh so i can use m2 for uh clock and uh for routing purpose between different cssr i can use uh poly right between different stages you only use metal okay okay so so can i use them nice you can use metal one but you cannot use poly okay so can i use m2 twicer in my circuit yes okay okay sir thank you thank you it should not short no no they should be clean otherwise you use them to twice try forever times you use okay but use of m2 should only to interconnect gates not in within the gate okay yes yes yeah of enough flip flop because you will have to generate block bar from and within your flip flop enough okay you will get only clock pin focus you have to put an inverter there yourself,https://www.youtube.com/watch?v=JcweW0X0CC0,"Link: https://www.youtube.com/watch?v=JcweW0X0CC0
Transcript: it to you not too much time on it because you know there are other designs also for example c2 moss where you have this uh what do you say this kind of a design where even if now you have both phases of clock over here clk and clk bar both exist over here but what happens uh at any given point of time even if one side goes active the other side will not drive so even in in the case of a zero zero overlap or a one one overlap even in the case of overlaps you will see that your design is safe okay again uh this over here also this x node is is uh many times floating not really a very stable state to be in so even c2 mass designs you will not see you will not find to be used at many many places but yes where there is a very high requirement for density and also this risk of clock clock bar overlap you can you can think of using this kind of a c2 moss design also and then you will have to use keepers you know as is already said you will have to use keepers and all those things will need to be done okay this is also a dynamic design so while these are solutions you will notice they are not very commonly used because of the very nature that there are floating nodes there and with floating nodes the biggest problem is on a flop or a sequencing element if you use floating nodes the overall robustness of the entire system can get compromised so they are not very commonly used but they are proposals their ideas which you just need to be aware of so yes cspc and c2 mass are both parallel solutions to the bad drive problem right not yeah there is no advantage over c2 mos over tspc right no no yes okay uh yeah now we come to timings i think let's start with this in the next class the timings of of uh timings related to a large and a flop we'll start with the next class then we will see okay yes so great yes so uh certain digital circuits we we uh we studied a very different design of flip flop and matches in that we progressed very uniformly from an sr batch then we added enable signal then we created a latch then we created master slave to make a flip flop d flip flop so and then we also saw a design of d flip flop which consisted of mini and the gates and case not gates so which was not even master slave it was just a single d flip flop so do we even make those designs so we make the designs that we just saw so we want to keep it as simple as possible and as dense as possible yes so this is how we would use it as dense as possible so even the densest one that we looked at today which was the one that just let me go back to that side the ones that we looked at with uh set reset or isabella you see this one itself is such a big problem is it not it's nowhere near what we were talking about [Music] yeah but look at it the digital circuit one is something like this because digital circuit one you did all set reset also from outside now because it started from sr latch yes so digital circuit one look like this probably anna yes yeah because you started from sr latch yes over here what we are saying is that set reset functionality is not required in all the flops so why waste area yes in vlsi area is this okay yes great so uh we we'll close the class now there were some project related doubts you can ask them yes sir sir i was asking that if we look at the layout aspect then c-square mos looks like very very good design that yes it could be so could we like to some and do a trade-off and go for it and like make two keepers and then implement the c square mass instead of this will be pseudostatic again they realize this there will still be some risk some robustness so people use it anyways that is why everyone touched upon it otherwise touching use it but it's very rarely used in very very specific cases someone would use that kind of a plot okay yes sir we had some project related doubts so basically we are comparing the complex and non-complex implementation of aoi 221 so in that set we simply created the two net list and try to verify that whether the delays decrease in the non-complex implementation also we did the theoretical calculations so for by the theoretical calculation and more delay and all so we were able to uh expect we expected that the delay would decrease but opposite of that is happening we are we are getting more delays in the non-complex one okay so anyways finally you would get better delays with the complex implementation because of uh lesser wires and more density and everything but i'm surprised that uh even when you are not talking about the layouts and not talking about those parasites even then you are able to see that of a complex gate would be slightly higher though it is much denser but the effect would be visible largely only after extraction so i'm surprised you're able to see it before extraction also is a class value experiment measure there was a thing that you you had put out inverter after the aoi and then also you remove the two inverters that could have come in the other logic so that that was kind of a natural thing to reduce the delay of the non-complex implementation of uh we need that functionality but you make it from the basic gates we are calling it and or invert that doesn't mean that you have to use an and gate and an or gate and an inverter no no no that is the functionality yes sir okay okay do the bubble pushing get to the densest implementation you will see it is uh it should be slightly faster non-complex should be faster right yeah non-complex should be slightly faster on fab on on simulation first simulation but after layout you will see that complex one will be much faster so in the pre-simulation we are getting that [Music] it's good if it is faster but the point is that the theoretical calculations and the simulations are not agreeing with each other that's the problem so probably i'm justifying you okay because in the theoretical calculations also you have ignored so many capacities simulation has taken care of all the device capacitances including source drain and miller capacitance and so many things the simulation would take care of that's also fine but i was not expecting it to already show it to you so suppose uh if we have done the layout of the complex and the non-complex then my non-complex layout will be fast should be faster or no okay because of the parasitics addition yeah yeah i was not expecting that parasitics in the non-complex gate would already be so high that it will be slower than the complex gate i was not expecting this but if it is happening it is happening it's fine okay so like can i say that uh the non-complex and the complex uh the differences between the two that with the complex we are not able to achieve the better area but also better delays yeah so the complex gates give you better delays and also better area more density and also the leakage would be better because yeah yeah okay okay that is why these are used so commonly okay so on all kind of parameters ppa i'm getting better complex okay over the nonprofits right now sir yes sir sir so when i was making the layout of non-complex get implementation sir so uh i tried it sir and for routing purposes can we use clock for routines sorry uh poly for routing no avoid that uh poly for routing within the cell it is fine but yeah within the cell it is okay 65 nanometer may i allow you but realize that in 45 onwards poly routing is not allowed so then uh we should definitely go to whenever seeing the constraints i made it without m2 layer usage so without empty layer research uh i i ran a quality down and above above for the clock and uh another one kind of connection which is is you are putting a large r on the clock path you're adding lots of more delays there sir but uh i am covering it with an pp layer doesn't that no even then it is resistive no it is bound to be more resistant than a metal is it not yes yes yeah that is what you should remember it is always more resistant than copper okay sir so sir then uh can we use m2 layer for that sir just for clock in case no not for clock only for routing clock so you're using dynamic gates yeah dynamic and non-complexing so interconnecting clock between different dynamic gates you can use metal tool interconnecting signals across different gates you can use metal to for every gate independently there should be no metal to usage okay okay yes sir okay circuit a and circuit b if circuit a has a high rise time and circuit b has lower high rise time so sir if i ask about the rise propagation delay then i will expect the circuit a to have a correspondingly high high rise delay also and other one would have the lower so basically this should kind of correlate according to what i think but but in the uh simulation that we ran uh at that point of time we were able to see that it was not the case for the circuit where rise time was higher the rise propagation delay was lower so it should not kind of this is very counter intuitive to me no there are if there is a path that you're talking about and there are two or three stages that a signal is moving from input to output then it could be that the the the design is skewed in such a way that the propagation delay moves differently than uh we will be differently for rise and fall and uh the final stage the rise time and fall time is largely dependent on the load versus the drive strength of the pmos and the nmos in the output stage so they are actually independent things okay okay so i am comparing the input slew of the first stage so i should compare the input slope last season should have a similar trend no that is what i am saying no yes so i'm not able to get that why why not if i'm white that should not be the case i mean so let us say you have this chain now what did you do you high skewed it you low skewed it you high skewed it and you let us say made this as a balanced one so what will happen the higher transition zero to one transition will be fast yes one two zero will be fast zero to one will be very fast so the is a fall transition here that will happen the delay will be much shorter huh but in this particular gate since it is only balanced my rise time and fall time are exactly the same so the delays are different but the rise time and fall time are same are you able to see that yes okay yes sir i know if you are talking only of one gate then whatever assumptions you are making could be correct but that is don't build such correlations which can hamper your overall if i have not told you that correlation it may not exist or if it exists then yes it is good to validate so for example in this case both were same the rise time the fourth time was same and the delays were different could be different so but for example if my rice time is improving so my rice delay should also be improving right you see example what did i say i said high low high so high rising faster falling faster rising faster yes sir so what happened because the rising was the the see in three inverters in three inverters the falling delay of this particular gate was preferred so the even though it is a high skewed inverter the following delay will be lesser for this entire path than the rising delay but this is a high skewed inverter so the rise time will be much better than the fault time okay yeah the delays are getting him affected by the previous stages also what kind of that yes yes okay but the rise the thai rice name for timer because of of that stage only itself okay primarily yes primarily yes okay so always think of the failure case if you try to if you're making an assumption you should not look at examples which justify your assumption you should try to find examples which violate your uh your assumption okay yes yes this is called failure mode analysis and good designer should always be able to do very well on the failure mode analysis path okay yes question if your hand is raised you want to ask something else question sir yeah sir so uh i'll i can use m24 clock and they are they are of different stages uh obviously uh so i can use m2 for uh clock and uh for routing purpose between different cssr i can use uh poly right between different stages you only use metal okay okay so so can i use them nice you can use metal one but you cannot use poly okay so can i use m2 twicer in my circuit yes okay okay sir thank you thank you it should not short no no they should be clean otherwise you use them to twice try forever times you use okay but use of m2 should only to interconnect gates not in within the gate okay yes yes yeah of enough flip flop because you will have to generate block bar from and within your flip flop enough okay you will get only clock pin focus you have to put an inverter there yourself"
neIUfuFfWUg,okay sir thank you okay anything else great so then when we say that there is this flop edge or something like that then do you realize that we are also talking about some sampling that is happening when we say a flip flop is edge triggered so at an edge if a flop becomes transparent what essentially we are saying is it is sampling the data input at that edge whether it is rising edge or falling is depending on my flip flop design i am sampling it at that place am i right yes sir so if a if a flip flop i say would sample is a it's a positive edge triggered flip flop and it is sampling data at the rising edge of the clock and then now let us consider a flip a latch a positive level triggered latch what would be the sampling edge of a positive edge triggered latch where would it sample its data that's a positive level triggered positive level trigger latch where with yes on the following days of the clock because uh it starts to become opaque after that okay so now uh what is important to realize it that is that to be able to sample correctly there are some timings that need to be met see the delay the delay the kind of timing you already know am i right that the input to output delay propagation delay contamination delay all these timings we've already discussed in much detail when we started with the combination of circuits in fact much earlier with the logical effort stuff you remember that yes sir now when it comes to flip flops and latches we also have this additional feature of a sampling edge and income in with respect to this sampling edge there needs to be some timings that need to be designed that need to be taken care of okay so today we will look at these timing parameters and how they need to be qualified when we design our systems okay so this is a latch a latch would have one timing which is linked to minimum pulse widths then just abraham curry that at the falling edge of the there will be a sampling like the following edge of the clock is the sampling edge so we have hold and setup time definitions at the following edge of the clock so what does hold time mean and what does setup time mean the minimum amount of time for which the data has to be held at the deep end of the latch after the sampling has arrived that is a whole time and before uh so it should settle before set up time yeah so is is is this definition clear almost the exact definition so why is the survive the sampling edge this uh i'm not able to get the sampling edge thing uh in this for the latch okay so abhi we started with this thing that if it's a positive level triggered latch then during the positive pulse period uh it will be transparent yes sir during the negative pulse period it will be opaque yes yes sir so when it goes opaque what is it sampling what is it showing as the output uh what it has sampled in the positive period of the clock period so it may have sampled multiple rise and falls but what will it show in the in the low period uh success by sampling your mean just transparent for example if it was d was like this okay huh but q would have also have been like this yes sir hannah so what did it sample and where did it sample it now uh the last value would have been it has sampled last value to here has it sampled this um so actually in this figure it is the same actually it is constant throughout the period for the i have look at the red curve that okay so no it has it has not sampled it has sampled the red one the last red one it seems so then what does it mean that whatever was valid at the falling edge of the clock that is what is sampled and maintained for the entire negative edge duration negative level duration am i right yes yes sir that is why we are calling this negative as the sampling edge so by but sampling you just mean that it is taking that value yes it will no longer accept any other changes it has sampled it now it will hold it for the negative for the for the opaque duration okay okay uh okay so so like the last value that will be basically enlarged finally lash that becomes my sampling edge so the uh till the time my data is changing and my clock is one yeah nothing is getting latched yes lasting actually happens only on this edge in the low period when the system becomes opaque is it not so yeah are you able to see this yes so that value it will be helding basically that is yeah whatever value it holds that is what the latch is otherwise so it's transparent so it's not a latch it is operating like a combinational circuit okay are we able to see this yes so so we will be considering therefore we say that falling that is the sampling edge okay so so we are considering that edge of the clock from where the latching operation basically begins yes okay that is the sampling edge because that is what latched okay now the time the duration for which the input this data should be stable before the sampling edge arrives that time is referred to as setup time okay and after the sampling guide has arrived data needs to be held for some more time that time is called the hold time are you able to see this sir so effectively can we say that for both the positive level trigger latch and the negative edge triggered flip flop the sampling edge would be the same and the setup and all time constraints would be the same positive level trigger latch and negative edge triggered flip-flop yes that is what we are saying now that for the positive level triggered latch negative edge of the clock is the sampling edge yes yes exactly yes okay um so is this concept clear because i see many students get confused uh you know whatever is written in the books is not very clear whatever is being taught in many colleges across the country that is also very jumbled up so this concept should be actually very clear to all of you is this clear about the sampling edge and that the setup and hold times are defined from the sampling edge is this part clear so please reiterate the definitions of t hold and t setup so t setup is the minimum duration for which the inputs should be held stable before the sampling edge arrives yes p hold is the minimum duration for which the inputs should be again held stable after the sampling edge has arrived okay okay thank you okay rather you have a question hand is raised yes sir actually uh can the sampling edge with respect to this i'm clear so but for example when the clock period goes if i'm in the clock becomes high for the first time so my latch is getting transparent from that moment on so in this case will i call this the falling edge of the clock only the sampling edge or both the rising and the following one the sampling edge i mean because uh how what what exactly doing the samplings are actually mean like is it transparent when it's becoming transparent or like that that terminology is getting me confused so what do you understand by sampling we have looked at two or three examples just now what do you capture about sam what do you understand about sampling so then i will collect that definition if there is something wrong so to me it seems that if the any changes in the input or the d pin if it is if the if my flop is able to capture that so that cross that thing that basically that that is called uh to me sampling that is no exactly okay sampling edge that is what my question is what according to is the sampling edge sampling to ticket sampling it's say you know these timings hold and set up timings are defined from the sampling edge so what does sampling gauge according to you sampling definition you're saying is fine okay so what is sampling edge so because uh i'm here to me a sampling edge should mean that from where the sampling is starting phenomena starting or ending i mean both should be considered as sampling edges but here we are considering the following one as the sampling edge so that is inflation so i mean we're not saying following one has a sampling edge we are saying wherever the latching action now begins okay that is the sampling edge because now that value has been sampled and it will be held for a extended duration let the input change it will not reflect on the output okay so so for the clock so only one edge would be the sampling edge in any for the lattice flip flop in any case sequential elements would typically use one sampling age only one sampling edge only basically from where the latching action begins that is my sampling edge yes okay so there are double edge triggered flip flops also over there you will see you know when you look at the literature you will find some reference to double as triggered uh flip flops they are essentially uh using both edges of the clock for sampling so they are essentially giving half the pulse period for evaluations yes yes okay um sir uh we realized that the latching action takes place in the negative level of the clock then so i can really uh make a clock i can make a pulse generator rather than a clock and it can behave like a flip flop in that case very very small uh spikes off those are called false lashes we'll look at them in a little bit okay rather you have anything else to ask your hand is still raised thank you sir okay so now that we've looked at setup and hold timings what do you think these timings the tcp cq and tcp dq represent clock to queue and data to queue delays yes so what we are saying is if you take if you look at it carefully what we are saying is that if the data was already there and clock arrived later then we are saying the timing is pcq and if the data change happens when the sampling when the uh when the sequence latch was still transparent then the d2q delay then the d2q delay is called tdq okay so yes so here the d2q i think i'm able to get it why we are taking that so but why we are taking that clock to queue i mean because if the data was already settled for example before the sampling edge came suppose data was settled here something like this so what happens the the latch will continue to be opaque in this duration because it is the following it is the low level of the block of the clock yes sir so once it starts to become transparent let's come to this edge now once it starts to become transparent after the clock edge comes when it starts to become transparent there will still be some delay when this data will start to become visible on the output okay so but that delay is called tc this can be different from tdq that is why there are two different definitions there are two different labels there okay so so like it is like uh what edge what basically signal is kind of triggering my change in output yes so but for example even for example say d is causing some change or it's a clock pigment causing change but i know the implementation of the flip flop with the latches it will be following the same path so how can these two different be different delays be different then i mean oh are they really following the same path so let us say this is d and [Music] this is ck and do you think it is following the same path d is going from here ck is going from here are you able to see this so but this clock to queue path actually is not the uh i mean this is not the some i mean input we talk of them in propagation delay in terms of the signals right the input and the output yeah so ck is also one of the inputs to the latch now so but there isn't like exactly a uh exact path i can say that between like clock two d ck if there is a path from d to q then there is a path from c k root to also it is also a different path that's a different path that's it okay is it not,https://www.youtube.com/watch?v=neIUfuFfWUg,"Link: https://www.youtube.com/watch?v=neIUfuFfWUg
Transcript: okay sir thank you okay anything else great so then when we say that there is this flop edge or something like that then do you realize that we are also talking about some sampling that is happening when we say a flip flop is edge triggered so at an edge if a flop becomes transparent what essentially we are saying is it is sampling the data input at that edge whether it is rising edge or falling is depending on my flip flop design i am sampling it at that place am i right yes sir so if a if a flip flop i say would sample is a it's a positive edge triggered flip flop and it is sampling data at the rising edge of the clock and then now let us consider a flip a latch a positive level triggered latch what would be the sampling edge of a positive edge triggered latch where would it sample its data that's a positive level triggered positive level trigger latch where with yes on the following days of the clock because uh it starts to become opaque after that okay so now uh what is important to realize it that is that to be able to sample correctly there are some timings that need to be met see the delay the delay the kind of timing you already know am i right that the input to output delay propagation delay contamination delay all these timings we've already discussed in much detail when we started with the combination of circuits in fact much earlier with the logical effort stuff you remember that yes sir now when it comes to flip flops and latches we also have this additional feature of a sampling edge and income in with respect to this sampling edge there needs to be some timings that need to be designed that need to be taken care of okay so today we will look at these timing parameters and how they need to be qualified when we design our systems okay so this is a latch a latch would have one timing which is linked to minimum pulse widths then just abraham curry that at the falling edge of the there will be a sampling like the following edge of the clock is the sampling edge so we have hold and setup time definitions at the following edge of the clock so what does hold time mean and what does setup time mean the minimum amount of time for which the data has to be held at the deep end of the latch after the sampling has arrived that is a whole time and before uh so it should settle before set up time yeah so is is is this definition clear almost the exact definition so why is the survive the sampling edge this uh i'm not able to get the sampling edge thing uh in this for the latch okay so abhi we started with this thing that if it's a positive level triggered latch then during the positive pulse period uh it will be transparent yes sir during the negative pulse period it will be opaque yes yes sir so when it goes opaque what is it sampling what is it showing as the output uh what it has sampled in the positive period of the clock period so it may have sampled multiple rise and falls but what will it show in the in the low period uh success by sampling your mean just transparent for example if it was d was like this okay huh but q would have also have been like this yes sir hannah so what did it sample and where did it sample it now uh the last value would have been it has sampled last value to here has it sampled this um so actually in this figure it is the same actually it is constant throughout the period for the i have look at the red curve that okay so no it has it has not sampled it has sampled the red one the last red one it seems so then what does it mean that whatever was valid at the falling edge of the clock that is what is sampled and maintained for the entire negative edge duration negative level duration am i right yes yes sir that is why we are calling this negative as the sampling edge so by but sampling you just mean that it is taking that value yes it will no longer accept any other changes it has sampled it now it will hold it for the negative for the for the opaque duration okay okay uh okay so so like the last value that will be basically enlarged finally lash that becomes my sampling edge so the uh till the time my data is changing and my clock is one yeah nothing is getting latched yes lasting actually happens only on this edge in the low period when the system becomes opaque is it not so yeah are you able to see this yes so that value it will be helding basically that is yeah whatever value it holds that is what the latch is otherwise so it's transparent so it's not a latch it is operating like a combinational circuit okay are we able to see this yes so so we will be considering therefore we say that falling that is the sampling edge okay so so we are considering that edge of the clock from where the latching operation basically begins yes okay that is the sampling edge because that is what latched okay now the time the duration for which the input this data should be stable before the sampling edge arrives that time is referred to as setup time okay and after the sampling guide has arrived data needs to be held for some more time that time is called the hold time are you able to see this sir so effectively can we say that for both the positive level trigger latch and the negative edge triggered flip flop the sampling edge would be the same and the setup and all time constraints would be the same positive level trigger latch and negative edge triggered flip-flop yes that is what we are saying now that for the positive level triggered latch negative edge of the clock is the sampling edge yes yes exactly yes okay um so is this concept clear because i see many students get confused uh you know whatever is written in the books is not very clear whatever is being taught in many colleges across the country that is also very jumbled up so this concept should be actually very clear to all of you is this clear about the sampling edge and that the setup and hold times are defined from the sampling edge is this part clear so please reiterate the definitions of t hold and t setup so t setup is the minimum duration for which the inputs should be held stable before the sampling edge arrives yes p hold is the minimum duration for which the inputs should be again held stable after the sampling edge has arrived okay okay thank you okay rather you have a question hand is raised yes sir actually uh can the sampling edge with respect to this i'm clear so but for example when the clock period goes if i'm in the clock becomes high for the first time so my latch is getting transparent from that moment on so in this case will i call this the falling edge of the clock only the sampling edge or both the rising and the following one the sampling edge i mean because uh how what what exactly doing the samplings are actually mean like is it transparent when it's becoming transparent or like that that terminology is getting me confused so what do you understand by sampling we have looked at two or three examples just now what do you capture about sam what do you understand about sampling so then i will collect that definition if there is something wrong so to me it seems that if the any changes in the input or the d pin if it is if the if my flop is able to capture that so that cross that thing that basically that that is called uh to me sampling that is no exactly okay sampling edge that is what my question is what according to is the sampling edge sampling to ticket sampling it's say you know these timings hold and set up timings are defined from the sampling edge so what does sampling gauge according to you sampling definition you're saying is fine okay so what is sampling edge so because uh i'm here to me a sampling edge should mean that from where the sampling is starting phenomena starting or ending i mean both should be considered as sampling edges but here we are considering the following one as the sampling edge so that is inflation so i mean we're not saying following one has a sampling edge we are saying wherever the latching action now begins okay that is the sampling edge because now that value has been sampled and it will be held for a extended duration let the input change it will not reflect on the output okay so so for the clock so only one edge would be the sampling edge in any for the lattice flip flop in any case sequential elements would typically use one sampling age only one sampling edge only basically from where the latching action begins that is my sampling edge yes okay so there are double edge triggered flip flops also over there you will see you know when you look at the literature you will find some reference to double as triggered uh flip flops they are essentially uh using both edges of the clock for sampling so they are essentially giving half the pulse period for evaluations yes yes okay um sir uh we realized that the latching action takes place in the negative level of the clock then so i can really uh make a clock i can make a pulse generator rather than a clock and it can behave like a flip flop in that case very very small uh spikes off those are called false lashes we'll look at them in a little bit okay rather you have anything else to ask your hand is still raised thank you sir okay so now that we've looked at setup and hold timings what do you think these timings the tcp cq and tcp dq represent clock to queue and data to queue delays yes so what we are saying is if you take if you look at it carefully what we are saying is that if the data was already there and clock arrived later then we are saying the timing is pcq and if the data change happens when the sampling when the uh when the sequence latch was still transparent then the d2q delay then the d2q delay is called tdq okay so yes so here the d2q i think i'm able to get it why we are taking that so but why we are taking that clock to queue i mean because if the data was already settled for example before the sampling edge came suppose data was settled here something like this so what happens the the latch will continue to be opaque in this duration because it is the following it is the low level of the block of the clock yes sir so once it starts to become transparent let's come to this edge now once it starts to become transparent after the clock edge comes when it starts to become transparent there will still be some delay when this data will start to become visible on the output okay so but that delay is called tc this can be different from tdq that is why there are two different definitions there are two different labels there okay so so like it is like uh what edge what basically signal is kind of triggering my change in output yes so but for example even for example say d is causing some change or it's a clock pigment causing change but i know the implementation of the flip flop with the latches it will be following the same path so how can these two different be different delays be different then i mean oh are they really following the same path so let us say this is d and [Music] this is ck and do you think it is following the same path d is going from here ck is going from here are you able to see this so but this clock to queue path actually is not the uh i mean this is not the some i mean input we talk of them in propagation delay in terms of the signals right the input and the output yeah so ck is also one of the inputs to the latch now so but there isn't like exactly a uh exact path i can say that between like clock two d ck if there is a path from d to q then there is a path from c k root to also it is also a different path that's a different path that's it okay is it not"
uNg8dIZD0zQ,yes sir yeah now it's clear so that is where we have two different timing definitions for d2q and ck2q ah so are these are these timing see i'm spending quite a bit of time on these spamming definitions because they are important these are the kind of questions that will typically be asked in your interviews also yes so uh once you go back please reflect on these timing definitions you will watch need to watch the video again but it is important that you get sufficient clarity on it if you have further questions you can ask the tas ask to ask me to me in the office hours but get sufficient clarity on these aspects okay now we come to the timing parameters for the flip flop do you see some change from earlier what all has changed for the flip flop versus large spamming diagram sampling edge has changed and also now d2q is not there d2q is not there okay and sampling adjustment something that happens we are defining setup and hold on the same edge like it can be different in that yes setup and holder always defined from the sampling edge only yes is the key change is that now you do not have d2q kind of timing because flip flop is not level transparent it's not transparent during at a level it is it just samples at the clock edge okay so very simple we have this instead of t pulse width now we have a timing called t t which is cycle time or period so equity pulse width is no longer there other thing is that t dq is no longer there the perfect is replaced by something called as p period and tdq is simply not there because changes in d will not be reflected anyways they will not be reflected on queue are you able to see this any questions so in my uh previous question only so the clock to queue so for example if i'm in here for example this case uh the flip flop if i take the like transmission gate that implementation in which you had transmission gate and the inverters kind of at low uh feedback so some might exact the path between there is a path between the d2 like uh output i mean the input would flow from the d plane and ultimately they get finally latched to this uh q pin but exactly the clock to queue path i cannot say that exactly there is a clock to queue path i mean are you talking about the flip flop are the lats flip flops are here okay so let's draw the flip flop what are we talking about we have what do you say and in fact we saw that okay there could be q and q bar that are driven like this hello you remember that yes so now you are saying that there is no path from clock to queue but there is a path from d to q so i mean that uh internally with the clock this actually this path is actually i'm really interested in how how much delay for example if i do some changes in my inputs and how for half after how much delay there that input change will be reflected in my output so effectively i should be considering this deep into and q pin right the path between them because clock inputs are not using an input now clock is also an input now yes yes but that input uh i get that but that input is not getting reflected right that is basically controlling the let us say clock was zero yes the clock was zero d could only come till here it came here and it settled here now and put in d the change in d was not reflected on q yes so you cannot have a d to q timing okay okay so this clock is one whether clock is zero whatever it was change in d will not be reflected on q are you with me yes sir yes now let us say a clock toggles what happens now when clock toggles this tri-state also turns active and whatever was stable here is now starting to reflect on q so what has triggered this transition on q is it change in d or is it change in c k there's a change in ck okay that is why the timing is defined from ck to cube okay okay okay so okay i mean what exactly is a triggering edge triggering signal that from where we calculate the delays okay yes okay so okay david you see sir does clock to queue delay depend on the amount of whole time that is sharing i mean suppose you you have told me to uh reduce the profit q delay and my whole time i am not able to do video then uh how do i find it the clock can clock the queue delay be less than whole time it depends how you how your data path how long your data path is and so on so it depends yes it can be done like that that whole time is really very very large but so okay let us look at why we need a whole time in this case for the data pin when we want to talk about setup time or whole time we say that at the falling end of the clock this transmission gate becomes transparent and i start to have d written into this first latch huh are you with me yes so now when ck goes to 1 this will become opaque and this will become transparent so it will hold the sample data so now what happens when this becomes transparent then whatever was written on over here will come to queue yes okay so d should be held high until and unless my first part is totally become becoming open yes so this latch is where you may say setup folder defined and so clock to queue delay would totally depend upon the second part of the lens means that sorry the key frame yes in a stable state now if you really want to test the limit and that is what we will now look at if you really want to test the limits then you will say that okay see if i have sampled if i if i've allowed the data in over here if a change in data is reflected from over here then i still have the sampling done okay however if my this node is not very stable sorry if this node the input of this second tri state is not stable then what happens then there could be some extra delay between c k to q okay i know so you define setup and fully times actually based on what is the impact of bringing the closer to the clock edge on the c to q delay we'll just see okay yes thicker but uh is this part clear now yes okay great so for the flip-flop then what we are saying is that for a flip-flop uh we have uh no c known d2q timing and the t percent is replaced by t period so mother you have a yes sir question can we say that this setup time is actually the propagation delay of the first latch uh no don't define setup time as propagation delay setup time is the minimum duration for which data should be stable before clock edge arrives that is the definition of setup time internally what it is equal to okay there are there could be many things there could be delays in clock paths there could be delays in data paths so it is not really propagation delay there is a race condition through which the setup time is defined actually we will see ok ok sure this setup and hold time they are intrinsic to the fifth opera sir is there a way that we can maybe tweak the device parameters and change this uh hold and hold this propagation delay of the data from first from the input to the first latch so if you kind of speed up the input to first latch card delay you can reduce the setup time why not so do we try doing that always yes you always want to minimize the setup control time okay so whatever is the setup and hold time that is the minimum that designer has tried to achieve yeah it can't be otherwise yeah yes sir sir i mean the whole time it is occurring because of the like i want the time difference spent the first transmission gate is completely off and second transmission is complete turning on so that difference you're calling as the whole time again whole time is the duration for which data should be held after the clock edge okay that is the definition so don't confuse the definition with all these implementation details how do i measure the whole time that was the mother was also doing mother was talking about how do i measure the setup time so he saw okay this is the propagation delay this should be equal to setup time what i said was there could be some delays on the clock path also so they need to be reduced and then that becomes set up time not just the propagation delays you're doing the similar assumption that okay this delay is now the whole time no there is always a clock path also and that also needs to be considered when you arrive at the value of full time so but like uh for example the whole time or the setup time we are defining with respect to the input pin of the flop or the latch right so why is my clock path then coming into picture i mean i know that from the rising edge of the clock whenever the rising end of the clock is i will have to give that much margin so if so like how even my like clock path is coming i just have to see that look at the circuit look at the circuit we just analyzed how clock path is important for c to q delay just look at how it is important for a time and whole time you will be able to easily reduce this okay okay and so one more thing so for example when they asked the question of the propagation delay you said that uh there could be some race around condition uh or they could be variations in the rational condition of that input when the i'm getting the large latching action happen so i was not able to get that selectively i said there will be some delays on the clock path so clock and data input are racing amongst each other what would reach the latch first you may buffer the clock inside your circuit no there was this suggestion i think you yourself gave the suggestion that you will put a small pulse on the clock and then a flash would behave like a flop flop you said that no sir someone said that okay so it means that you may want to put some logic on the clock also and that would mean that clock would also arrive at a different time point of time at the latch are you able to see this but like i am not able to get that for example when my clock edge comes then only i do all these kind of things key from then i see key how my d is behaving and put constraints on d after my clock as i have seen so clock that variation can happen anywhere and can clock and arrive any and in any way but after that variation rather we're not talking about variations yet we're simply talking about what is happening variation i will talk about in a little while but we are simply talking about this is the time and clock edge arrives okay from the arriving clock edge i generate an internal clock that is what i take to those tri states so sampling would actually happen when internal clock comes high are you able to see this yes yes sir so there will be some delay from clock to internal clock so this delay would mean that there is more margin for sampling yes sir yes that needs to be added from added to the whole time and reduced from the setup time therefore setup time is not simply the propagation delay and whole time is not simply the propagation delay either yes yes i mean that margins have to be added okay so so one more thing sir with respect to the propagation delays uh internal propagation of the clock i mean they because i can see that there is a fixed path right and that my uh data will always follow after my enter so can i say that the i will have a propagation i can say that there will be a propagation delay only they will be i can come around a stable population there is a one propagation delay because of depending upon the elements because i am having the inverters in between so that propagation delay can also be different for rising and falling edge now yeah for rising and falling how can it be just one propagation delay why do you want to arrive at is the definition that setup and hold time are linked to how much the data should be stable before sampling edge or after something is this definition not simple enough yes okay so i'm happy that you're trying to work it out more but without really doing that analysis on pen and paper yourselves you will simply confuse yourself raghav that is why i said analyze the circuit put a user pen and a paper and you will have all the answers with you so actually i was initially thinking of like uh will there be a contamination kind of thing also coming here because i couldn't think of that so that was there but there will be contamination delays yes wherever there is a propagation delay like tcq there is a contamination delay also there so that was there has to be the datas are not getting here because i was not able to see that they could be alternate paths existing because contamination i think when there is only alternate path existing delay could be because of the falling edge one of the edges is larger or has more delay the other transition is slower because of uh either skewing of inverters or whatever reason can happen okay so different input slew for the different life and getting different delays i can characterize them also as a contamination propagation yeah because earlier you used to think that when the different paths if there is a different path then obviously that that different path would lead to a significantly different propagation and contamination delay but even in the same path there could be very significant difference between propagation and contamination for the two different edges yes sir so you characterize that okay again the definition there is longest delay and shortest delay it never said that it has to be from two different paths did it say that that in the combination we did by calculating effective resistance we used that was examples that was examples what was the definition of propagation today and what was the definition of contamination delay so the shortest delays exactly so that shortest delay is coming for a different edge then that becomes the contamination delay okay so if the different slew is also triggering a shortest delay that can also be a concern yes that is why i'm saying that stick to the definition of setup time as that then measurement is a different thing every circuit you will have to analyze differently and say okay this is my setup time and this is where my whole time is okay that is why i'm saying don't violate the definition the definition is about minimum duration for which data should be stable before clock edge and after blockage before clock edge is set up time after of before sampling at a setup time before after sampling edges hold time okay okay okay stick with this definition now however complex circuit you may encounter you can always find out what the setup and hold time is you have to merge two or three delays you have to simply measure one delay two delays all that is all inconsequential if the definition is clear you will do the implementation correctly okay if you if you learn only one implementation then as soon as another implementation comes you will completely go bonkers you will get confused okay okay so like for example in the timing libraries where i have the characterization for the flops so i have this clock to q delay characterized so in that and in that two parameters are the inputs loo and the load so sir in that table itself i will be getting i will be able to see the minimum value i will say it is contamination and the maximum value in the nldm table itself the propagation even for the same clock and the same load okay the rising transition and falling transition could be different yes sir yeah so two tables yes okay so in those two tables the minimum value i will say that this is a contamination thing yes okay okay so now get it thank you sir okay mother so in in any design process we first do functional simulation without any timing information so if i do not have the all these timing informations then where will my data change i mean uh when whenever i i do uh some design on verilog and test it using a test bench then i see that data all uh almost always changes exactly at the clock edge only not before that not after that so there are delay so there are simulations which you do so what you're talking about is the logical simulation yes a function of simulation no no simulations also have delays embedded in them notional delays unit delays it is referred to as unit delays you you put those delays in terms of unit delays okay okay so yes those functional simulations you will see data will be toggled one unit delay before blockage one unit delay a little before clock edge okay so then that hash one hash zero point like this yes yes so i have to explicitly put it there before uh so in order to get my functionality correct otherwise i don't even get my functionality correct if there are delays yeah if that is how the verilog has been modeled yes okay okay yeah rocker if you have anything else your hand is still raised i'm trying a small question yeah um sir uh for the whole time and basically in the first stage of the flip flop basically there is a latch let's say the flip flop is a positive edge taken and the first stage is the negative latch so sir once the whole time has been uh done for the first latch if the first latch has uh held the data at the output of it so i can now change that d input so largely the uh the whole time of complete flip flop depends upon the whole time of first leg first the setup and hold are largely dependent on the first latch operation that is how if you want to improve the setup and hold you improve the delays in the first latch,https://www.youtube.com/watch?v=uNg8dIZD0zQ,"Link: https://www.youtube.com/watch?v=uNg8dIZD0zQ
Transcript: yes sir yeah now it's clear so that is where we have two different timing definitions for d2q and ck2q ah so are these are these timing see i'm spending quite a bit of time on these spamming definitions because they are important these are the kind of questions that will typically be asked in your interviews also yes so uh once you go back please reflect on these timing definitions you will watch need to watch the video again but it is important that you get sufficient clarity on it if you have further questions you can ask the tas ask to ask me to me in the office hours but get sufficient clarity on these aspects okay now we come to the timing parameters for the flip flop do you see some change from earlier what all has changed for the flip flop versus large spamming diagram sampling edge has changed and also now d2q is not there d2q is not there okay and sampling adjustment something that happens we are defining setup and hold on the same edge like it can be different in that yes setup and holder always defined from the sampling edge only yes is the key change is that now you do not have d2q kind of timing because flip flop is not level transparent it's not transparent during at a level it is it just samples at the clock edge okay so very simple we have this instead of t pulse width now we have a timing called t t which is cycle time or period so equity pulse width is no longer there other thing is that t dq is no longer there the perfect is replaced by something called as p period and tdq is simply not there because changes in d will not be reflected anyways they will not be reflected on queue are you able to see this any questions so in my uh previous question only so the clock to queue so for example if i'm in here for example this case uh the flip flop if i take the like transmission gate that implementation in which you had transmission gate and the inverters kind of at low uh feedback so some might exact the path between there is a path between the d2 like uh output i mean the input would flow from the d plane and ultimately they get finally latched to this uh q pin but exactly the clock to queue path i cannot say that exactly there is a clock to queue path i mean are you talking about the flip flop are the lats flip flops are here okay so let's draw the flip flop what are we talking about we have what do you say and in fact we saw that okay there could be q and q bar that are driven like this hello you remember that yes so now you are saying that there is no path from clock to queue but there is a path from d to q so i mean that uh internally with the clock this actually this path is actually i'm really interested in how how much delay for example if i do some changes in my inputs and how for half after how much delay there that input change will be reflected in my output so effectively i should be considering this deep into and q pin right the path between them because clock inputs are not using an input now clock is also an input now yes yes but that input uh i get that but that input is not getting reflected right that is basically controlling the let us say clock was zero yes the clock was zero d could only come till here it came here and it settled here now and put in d the change in d was not reflected on q yes so you cannot have a d to q timing okay okay so this clock is one whether clock is zero whatever it was change in d will not be reflected on q are you with me yes sir yes now let us say a clock toggles what happens now when clock toggles this tri-state also turns active and whatever was stable here is now starting to reflect on q so what has triggered this transition on q is it change in d or is it change in c k there's a change in ck okay that is why the timing is defined from ck to cube okay okay okay so okay i mean what exactly is a triggering edge triggering signal that from where we calculate the delays okay yes okay so okay david you see sir does clock to queue delay depend on the amount of whole time that is sharing i mean suppose you you have told me to uh reduce the profit q delay and my whole time i am not able to do video then uh how do i find it the clock can clock the queue delay be less than whole time it depends how you how your data path how long your data path is and so on so it depends yes it can be done like that that whole time is really very very large but so okay let us look at why we need a whole time in this case for the data pin when we want to talk about setup time or whole time we say that at the falling end of the clock this transmission gate becomes transparent and i start to have d written into this first latch huh are you with me yes so now when ck goes to 1 this will become opaque and this will become transparent so it will hold the sample data so now what happens when this becomes transparent then whatever was written on over here will come to queue yes okay so d should be held high until and unless my first part is totally become becoming open yes so this latch is where you may say setup folder defined and so clock to queue delay would totally depend upon the second part of the lens means that sorry the key frame yes in a stable state now if you really want to test the limit and that is what we will now look at if you really want to test the limits then you will say that okay see if i have sampled if i if i've allowed the data in over here if a change in data is reflected from over here then i still have the sampling done okay however if my this node is not very stable sorry if this node the input of this second tri state is not stable then what happens then there could be some extra delay between c k to q okay i know so you define setup and fully times actually based on what is the impact of bringing the closer to the clock edge on the c to q delay we'll just see okay yes thicker but uh is this part clear now yes okay great so for the flip-flop then what we are saying is that for a flip-flop uh we have uh no c known d2q timing and the t percent is replaced by t period so mother you have a yes sir question can we say that this setup time is actually the propagation delay of the first latch uh no don't define setup time as propagation delay setup time is the minimum duration for which data should be stable before clock edge arrives that is the definition of setup time internally what it is equal to okay there are there could be many things there could be delays in clock paths there could be delays in data paths so it is not really propagation delay there is a race condition through which the setup time is defined actually we will see ok ok sure this setup and hold time they are intrinsic to the fifth opera sir is there a way that we can maybe tweak the device parameters and change this uh hold and hold this propagation delay of the data from first from the input to the first latch so if you kind of speed up the input to first latch card delay you can reduce the setup time why not so do we try doing that always yes you always want to minimize the setup control time okay so whatever is the setup and hold time that is the minimum that designer has tried to achieve yeah it can't be otherwise yeah yes sir sir i mean the whole time it is occurring because of the like i want the time difference spent the first transmission gate is completely off and second transmission is complete turning on so that difference you're calling as the whole time again whole time is the duration for which data should be held after the clock edge okay that is the definition so don't confuse the definition with all these implementation details how do i measure the whole time that was the mother was also doing mother was talking about how do i measure the setup time so he saw okay this is the propagation delay this should be equal to setup time what i said was there could be some delays on the clock path also so they need to be reduced and then that becomes set up time not just the propagation delays you're doing the similar assumption that okay this delay is now the whole time no there is always a clock path also and that also needs to be considered when you arrive at the value of full time so but like uh for example the whole time or the setup time we are defining with respect to the input pin of the flop or the latch right so why is my clock path then coming into picture i mean i know that from the rising edge of the clock whenever the rising end of the clock is i will have to give that much margin so if so like how even my like clock path is coming i just have to see that look at the circuit look at the circuit we just analyzed how clock path is important for c to q delay just look at how it is important for a time and whole time you will be able to easily reduce this okay okay and so one more thing so for example when they asked the question of the propagation delay you said that uh there could be some race around condition uh or they could be variations in the rational condition of that input when the i'm getting the large latching action happen so i was not able to get that selectively i said there will be some delays on the clock path so clock and data input are racing amongst each other what would reach the latch first you may buffer the clock inside your circuit no there was this suggestion i think you yourself gave the suggestion that you will put a small pulse on the clock and then a flash would behave like a flop flop you said that no sir someone said that okay so it means that you may want to put some logic on the clock also and that would mean that clock would also arrive at a different time point of time at the latch are you able to see this but like i am not able to get that for example when my clock edge comes then only i do all these kind of things key from then i see key how my d is behaving and put constraints on d after my clock as i have seen so clock that variation can happen anywhere and can clock and arrive any and in any way but after that variation rather we're not talking about variations yet we're simply talking about what is happening variation i will talk about in a little while but we are simply talking about this is the time and clock edge arrives okay from the arriving clock edge i generate an internal clock that is what i take to those tri states so sampling would actually happen when internal clock comes high are you able to see this yes yes sir so there will be some delay from clock to internal clock so this delay would mean that there is more margin for sampling yes sir yes that needs to be added from added to the whole time and reduced from the setup time therefore setup time is not simply the propagation delay and whole time is not simply the propagation delay either yes yes i mean that margins have to be added okay so so one more thing sir with respect to the propagation delays uh internal propagation of the clock i mean they because i can see that there is a fixed path right and that my uh data will always follow after my enter so can i say that the i will have a propagation i can say that there will be a propagation delay only they will be i can come around a stable population there is a one propagation delay because of depending upon the elements because i am having the inverters in between so that propagation delay can also be different for rising and falling edge now yeah for rising and falling how can it be just one propagation delay why do you want to arrive at is the definition that setup and hold time are linked to how much the data should be stable before sampling edge or after something is this definition not simple enough yes okay so i'm happy that you're trying to work it out more but without really doing that analysis on pen and paper yourselves you will simply confuse yourself raghav that is why i said analyze the circuit put a user pen and a paper and you will have all the answers with you so actually i was initially thinking of like uh will there be a contamination kind of thing also coming here because i couldn't think of that so that was there but there will be contamination delays yes wherever there is a propagation delay like tcq there is a contamination delay also there so that was there has to be the datas are not getting here because i was not able to see that they could be alternate paths existing because contamination i think when there is only alternate path existing delay could be because of the falling edge one of the edges is larger or has more delay the other transition is slower because of uh either skewing of inverters or whatever reason can happen okay so different input slew for the different life and getting different delays i can characterize them also as a contamination propagation yeah because earlier you used to think that when the different paths if there is a different path then obviously that that different path would lead to a significantly different propagation and contamination delay but even in the same path there could be very significant difference between propagation and contamination for the two different edges yes sir so you characterize that okay again the definition there is longest delay and shortest delay it never said that it has to be from two different paths did it say that that in the combination we did by calculating effective resistance we used that was examples that was examples what was the definition of propagation today and what was the definition of contamination delay so the shortest delays exactly so that shortest delay is coming for a different edge then that becomes the contamination delay okay so if the different slew is also triggering a shortest delay that can also be a concern yes that is why i'm saying that stick to the definition of setup time as that then measurement is a different thing every circuit you will have to analyze differently and say okay this is my setup time and this is where my whole time is okay that is why i'm saying don't violate the definition the definition is about minimum duration for which data should be stable before clock edge and after blockage before clock edge is set up time after of before sampling at a setup time before after sampling edges hold time okay okay okay stick with this definition now however complex circuit you may encounter you can always find out what the setup and hold time is you have to merge two or three delays you have to simply measure one delay two delays all that is all inconsequential if the definition is clear you will do the implementation correctly okay if you if you learn only one implementation then as soon as another implementation comes you will completely go bonkers you will get confused okay okay so like for example in the timing libraries where i have the characterization for the flops so i have this clock to q delay characterized so in that and in that two parameters are the inputs loo and the load so sir in that table itself i will be getting i will be able to see the minimum value i will say it is contamination and the maximum value in the nldm table itself the propagation even for the same clock and the same load okay the rising transition and falling transition could be different yes sir yeah so two tables yes okay so in those two tables the minimum value i will say that this is a contamination thing yes okay okay so now get it thank you sir okay mother so in in any design process we first do functional simulation without any timing information so if i do not have the all these timing informations then where will my data change i mean uh when whenever i i do uh some design on verilog and test it using a test bench then i see that data all uh almost always changes exactly at the clock edge only not before that not after that so there are delay so there are simulations which you do so what you're talking about is the logical simulation yes a function of simulation no no simulations also have delays embedded in them notional delays unit delays it is referred to as unit delays you you put those delays in terms of unit delays okay okay so yes those functional simulations you will see data will be toggled one unit delay before blockage one unit delay a little before clock edge okay so then that hash one hash zero point like this yes yes so i have to explicitly put it there before uh so in order to get my functionality correct otherwise 
i don't even get my functionality correct if there are delays yeah if that is how the verilog has been modeled yes okay okay yeah rocker if you have anything else your hand is still raised i'm trying a small question yeah um sir uh for the whole time and basically in the first stage of the flip flop basically there is a latch let's say the flip flop is a positive edge taken and the first stage is the negative latch so sir once the whole time has been uh done for the first latch if the first latch has uh held the data at the output of it so i can now change that d input so largely the uh the whole time of complete flip flop depends upon the whole time of first leg first the setup and hold are largely dependent on the first latch operation that is how if you want to improve the setup and hold you improve the delays in the first latch"
L9GhWShlLPU,okay so now given this what are we essentially saying is that at the sampling edge of the clock there has to be a duration for which data remains stable beyond that data can actually be anything similarly after the clock edge comes there is some duration for which data is not stable output is not stable but then output becomes stable after that are you able to see this and are you also able to see raghav you're asking about contamination delay are you also able to see the definition of contamination delay here so i mean after the contamination really i can see some changes in the output yes already output has started to change but now why i'm not considering that as a stable kind of thing i mean because it is not stable yet so because if i take this looks at the shortest delay so as the thought shortest happen and my data is stable now then i mean i'm taking the propagation let us consider the case of a eight bit resistor okay so there are eight flux yes sir for this eight bit resistor the outputs will start to become variable after the contamination delay i mean yes sir i mean yes and they will become stable only after propagation delay are you with me so after the propagation delay see one and one one uh flop in the resistor was to transmit a zero another flop faster transmitter one and so on so the zeros ones zincos the ones that have to transmit a zero they may transmit it a little earlier so they define the tccq the ones that have to transmit a one they might be doing it a little later so they define the tpc finally when is the output stable eight bit output stable only after tpcq so so this is the like the most pessimistic worst case scenario considering okay after this anyway how that data would be stable yes so what do you want to consider worst case so but there could be a case that after the contamination also my data could be stable but i will not consider that as the work i will consider because you're doing a sign off no you don't want things to fail on silicon okay yeah okay so got it sir thank you okay yeah so now if you wish to characterize these setup and hold times what do you do what you do is you start so there's this clock edge you say that i will start to bring my data close to the clock edge and as i do that you will notice that my output delay would increase a bit due to change in output slope okay and when this output delay say increases by 5 it becomes 1.05 times of the the minimum delay that you could observe that is what you call as setup time okay now exactly the same way for the other edge of data also you will notice that as you start to bring the hold edge closer to the q pin to the to the ck transition the c2q delay will again increase okay and again we say that five percent increase that is where the whole time is let us look at in a little detail let us say we have this setup uh this kind of a let us say latch this is a latch so what do we do we say that there is this clock edge the sampling edge of the clock because we are talking about a latch there is this clock edge and data is toggling i will start to bring data closer to the sampling edge and now i want to see what is the tcq as i bring it closer and closer pcq you will see would increase okay as tcq increases our all the timing assumptions start to go haywire so we say that the time the the point at which my tcq has increased by let us say five percent that is my setup time similarly for the same latch there's this hold thing that we're talking about i bring that the transition closer to the clock edge again and you will see again tcq is changing huh so we say that wherever this is more than again say five percent that is my whole time uh sir is this five percent uh standard or it can change from it can be different from from one company to another from one technology to another and all that so don't consider five percent as a standard but in in our course we will consider five percent so sir whatever uh whatever people put in their papers like set up and hold times don't do followers certain criteria like this five percent rule so they will tell it in their paper okay okay i know they will tell it in their paper now they are measured [Music] okay yes david you're asking something yes sir i wanted to ask that about this five percent the points are still plotted so i can say that uh flop is still working but this is uh like a safety limit right yeah it is still working but the timings have gone so high that your system would fail we'll see now we will do the timing closure part okay you're done uh so when you will do the vdf course you will see that there is a setup time the you know sta that we have to do we discuss this in the first lecture of dvd also we want to ensure that all the flip flops every every circuit has a appropriate setup time if you give a clock which is faster than the minimum period that the synthesis run tells you your system can fail so we will just see the timing closure part and you will see that if this standing increases further then all your systems can fail we don't want to do that therefore we say five percent is what we want to keep okay yes president so when we are like when we are changing the not changing when we are making closer the data to the clock pulse uh the clock to queue delay is increasing yes so why is that happening i am not able to like visualize it okay so when the data is toggled much later than clock what happens whatever d was there it remained stable after the after this transmission gate became opaque it changed so can you please repeat the statement let us say that data toggled much after the sampling edge yes sir so in that case what was happening this d1 was very stable yes when when these transmission gates the nmos and pmos were turning off at that point of time this gate was very stable am i right yes yes sir the input was very stable and therefore the the ck2q delay was something yes sir now uh as i bring my data edge closer to the clock edge what happens is so what can happen there can be a small so there can be a disturbance which can move on to the other side yes sir yes sir what does that disturbance do that disturbance actually causes a degrade the slope of the transition over here on the second side okay okay okay yes yes sir therefore if if you measure at say 50 transition yes the delay would change are you able to see this yes sir yes yes sir okay okay so now that we are clear about setup and hold time and how they are to be measured let's look at how is this timing how are these timings signed off on the system level okay so we look at sequencing timing constraints now what does this mean this means that if there is a combinational path between two flip flops what is the minimum clock period that i can give huh or if i am using two phase latches there is a positive edge level triggered latch and there is a negative level trigger latch or there are two phase transition latches i have two clocks okay then what kind of combinational logic can i put in the two regions there huh what kind of combinational delay can i put in those regions there or as i i'm missing out on who mentioned about the pulsed latches if i make if i create a very short pulse over here then how much combinational delay can be put over here again are you able to see this so whenever we are designing a sequential circuit we want to find out what is the fastest at which my my system can run am i right and that fastest could be different for a regular flip-flop based architecture or a two-phase latch based architecture or pulse architects pulse latch based architectures are you able to see this yes uh sir but this uh if we are able to make the first latches that is fine but why don't we use them because they are smaller as well so they are used who says they're not used okay i thought that flip flops are more preferred since sometimes there is warning even in synthesized uh when we will see we will see why pulse latches have problems and why flip flops are better that we can see that is not a problem but all flashes are used they are flexible also like the timing is kind of they are used they are very widely used widely matlab and and and some kind of design and some in some parts of the industry they are very widely used not everywhere because there could be some reasons then we will look into those reasons but yeah that's that is why we are discussing them over here so a quick recap of the different delays we will now you know call logic propagation delays as cpd and pcb propagation and contamination delays are tpd and ppcd the clock based propagation delays as a propagation c2q and contamination c2q latch would also have propagation delay from data to queue and blocks and from a contamination delay from d to q and for latches and flux we will also have these timings called setup and holds all of these we will consider when we talk about sign off of the product sir yes so what do you mean exactly by sequencing uh i was the term sequencing what do you mean by that no okay what do you understand so like discuss this in the first part of the sequential circuit section so what do you understand by sequencing so is it like uh related to pipelining can we can we said that yeah i mean how how i put uh my combinational part a combinational part between the flip-flops and that is basically the sequencing thing yeah i'm saying and so i had a doubt regarding the two-phase uh pulse latched uh implementation uh so can you move to the previous slide we will talk about two phase first letters in much detail okay so i mean i understand the flip flop implementation so i answer with respect to these two phase pulse latches so i can see that this uh what i need is that from the sampling edge my data should be available to be stable data available so all this uh time for which my clock period is high that basically is not uh is basically uh i don't want that right i want my why would i consider backlog should be i i don't want the clock to be high for a very long time right depends you will see this is not a default assumption that you can make we will see there is a benefit of having a pulse we will want to do some time borrowing and then we will need this okay,https://www.youtube.com/watch?v=L9GhWShlLPU,"Link: https://www.youtube.com/watch?v=L9GhWShlLPU
Transcript: okay so now given this what are we essentially saying is that at the sampling edge of the clock there has to be a duration for which data remains stable beyond that data can actually be anything similarly after the clock edge comes there is some duration for which data is not stable output is not stable but then output becomes stable after that are you able to see this and are you also able to see raghav you're asking about contamination delay are you also able to see the definition of contamination delay here so i mean after the contamination really i can see some changes in the output yes already output has started to change but now why i'm not considering that as a stable kind of thing i mean because it is not stable yet so because if i take this looks at the shortest delay so as the thought shortest happen and my data is stable now then i mean i'm taking the propagation let us consider the case of a eight bit resistor okay so there are eight flux yes sir for this eight bit resistor the outputs will start to become variable after the contamination delay i mean yes sir i mean yes and they will become stable only after propagation delay are you with me so after the propagation delay see one and one one uh flop in the resistor was to transmit a zero another flop faster transmitter one and so on so the zeros ones zincos the ones that have to transmit a zero they may transmit it a little earlier so they define the tccq the ones that have to transmit a one they might be doing it a little later so they define the tpc finally when is the output stable eight bit output stable only after tpcq so so this is the like the most pessimistic worst case scenario considering okay after this anyway how that data would be stable yes so what do you want to consider worst case so but there could be a case that after the contamination also my data could be stable but i will not consider that as the work i will consider because you're doing a sign off no you don't want things to fail on silicon okay yeah okay so got it sir thank you okay yeah so now if you wish to characterize these setup and hold times what do you do what you do is you start so there's this clock edge you say that i will start to bring my data close to the clock edge and as i do that you will notice that my output delay would increase a bit due to change in output slope okay and when this output delay say increases by 5 it becomes 1.05 times of the the minimum delay that you could observe that is what you call as setup time okay now exactly the same way for the other edge of data also you will notice that as you start to bring the hold edge closer to the q pin to the to the ck transition the c2q delay will again increase okay and again we say that five percent increase that is where the whole time is let us look at in a little detail let us say we have this setup uh this kind of a let us say latch this is a latch so what do we do we say that there is this clock edge the sampling edge of the clock because we are talking about a latch there is this clock edge and data is toggling i will start to bring data closer to the sampling edge and now i want to see what is the tcq as i bring it closer and closer pcq you will see would increase okay as tcq increases our all the timing assumptions start to go haywire so we say that the time the the point at which my tcq has increased by let us say five percent that is my setup time similarly for the same latch there's this hold thing that we're talking about i bring that the transition closer to the clock edge again and you will see again tcq is changing huh so we say that wherever this is more than again say five percent that is my whole time uh sir is this five percent uh standard or it can change from it can be different from from one company to another from one technology to another and all that so don't consider five percent as a standard but in in our course we will consider five percent so sir whatever uh whatever people put in their papers like set up and hold times don't do followers certain criteria like this five percent rule so they will tell it in their paper okay okay i know they will tell it in their paper now they are measured [Music] okay yes david you're asking something yes sir i wanted to ask that about this five percent the points are still plotted so i can say that uh flop is still working but this is uh like a safety limit right yeah it is still working but the timings have gone so high that your system would fail we'll see now we will do the timing closure part okay you're done uh so when you will do the vdf course you will see that there is a setup time the you know sta that we have to do we discuss this in the first lecture of dvd also we want to ensure that all the flip flops every every circuit has a appropriate setup time if you give a clock which is faster than the minimum period that the synthesis run tells you your system can fail so we will just see the timing closure part and you will see that if this standing increases further then all your systems can fail we don't want to do that therefore we say five percent is what we want to keep okay yes president so when we are like when we are changing the not changing when we are making closer the data to the clock pulse uh the clock to queue delay is increasing yes so why is that happening i am not able to like visualize it okay so when the data is toggled much later than clock what happens whatever d was there it remained stable after the after this transmission gate became opaque it changed so can you please repeat the statement let us say that data toggled much after the sampling edge yes sir so in that case what was happening this d1 was very stable yes when when these transmission gates the nmos and pmos were turning off at that point of time this gate was very stable am i right yes yes sir the input was very stable and therefore the the ck2q delay was something yes sir now uh as i bring my data edge closer to the clock edge what happens is so what can happen there can be a small so there can be a disturbance which can move on to the other side yes sir yes sir what does that disturbance do that disturbance actually causes a degrade the slope of the transition over here on the second side okay okay okay yes yes sir therefore if if you measure at say 50 transition yes the delay would change are you able to see this yes sir yes yes sir okay okay so now that we are clear about setup and hold time and how they are to be measured let's look at how is this timing how are these timings signed off on the system level okay so we look at sequencing timing constraints now what does this mean this means that if there is a combinational path between two flip flops what is the minimum clock period that i can give huh or if i am using two phase latches there is a positive edge level triggered latch and there is a negative level trigger latch or there are two phase transition latches i have two clocks okay then what kind of combinational logic can i put in the two regions there huh what kind of combinational delay can i put in those regions there or as i i'm missing out on who mentioned about the pulsed latches if i make if i create a very short pulse over here then how much combinational delay can be put over here again are you able to see this so whenever we are designing a sequential circuit we want to find out what is the fastest at which my my system can run am i right and that fastest could be different for a regular flip-flop based architecture or a two-phase latch based architecture or pulse architects pulse latch based architectures are you able to see this yes uh sir but this uh if we are able to make the first latches that is fine but why don't we use them because they are smaller as well so they are used who says they're not used okay i thought that flip flops are more preferred since sometimes there is warning even in synthesized uh when we will see we will see why pulse latches have problems and why flip flops are better that we can see that is not a problem but all flashes are used they are flexible also like the timing is kind of they are used they are very widely used widely matlab and and and some kind of design and some in some parts of the industry they are very widely used not everywhere because there could be some reasons then we will look into those reasons but yeah that's that is why we are discussing them over here so a quick recap of the different delays we will now you know call logic propagation delays as cpd and pcb propagation and contamination delays are tpd and ppcd the clock based propagation delays as a propagation c2q and contamination c2q latch would also have propagation delay from data to queue and blocks and from a contamination delay from d to q and for latches and flux we will also have these timings called setup and holds all of these we will consider when we talk about sign off of the product sir yes so what do you mean exactly by sequencing uh i was the term sequencing what do you mean by that no okay what do you understand so like discuss this in the first part of the sequential circuit section so what do you understand by sequencing so is it like uh related to pipelining can we can we said that yeah i mean how how i put uh my combinational part a combinational part between the flip-flops and that is basically the sequencing thing yeah i'm saying and so i had a doubt regarding the two-phase uh pulse latched uh implementation uh so can you move to the previous slide we will talk about two phase first letters in much detail okay so i mean i understand the flip flop implementation so i answer with respect to these two phase pulse latches so i can see that this uh what i need is that from the sampling edge my data should be available to be stable data available so all this uh time for which my clock period is high that basically is not uh is basically uh i don't want that right i want my why would i consider backlog should be i i don't want the clock to be high for a very long time right depends you will see this is not a default assumption that you can make we will see there is a benefit of having a pulse we will want to do some time borrowing and then we will need this okay"
uoVAuUDzOT4,okay so but before we enter into the timing closure part i think it is important to understand some variabilities that need to be accounted for when we do timing closure okay rather is that anything else that is pending i see your hand raised okay so there are some and uncertainties that we need to manage where could those uncertainties come from they could come from clock generation the pll that is generating the clock that could have some litter in it that could have some you know different delays across different time time zones whatever there could be drift in the in the oscillator and so on then there are device variations there are power supply variations there are interconnect variations where you could have a crosstalk between interconnects and therefore when both the signals are rising you have one kind of delay when one of the signals is falling you will have a different kind of a delay and so on there could be variations in temperature there could be variations in loading of different of different flops or stuff like that and so on so there are many uncertainties that clock arriving at any flop would see what we are saying is see yaha we were saying that what is the delay between one flop and another both the pins are being referred to as clock but what can actually happen is that one flop is experiencing delay through this path and the other path is experiencing delay through this path and there are so many different sources of variations that could occur for the two flip flops this is called as clock uncertainty and this needs to be accounted for in our closure analysis so these non-idealities include clock skew clock jitter and variation and pulse width now it is very important to understand the difference between clock skew and clock jitter clock skew is the spatial variation in temporally equivalent clock edges what does this statement mean who can clarify this cryptic statement for all of us sir it is the difference between uh the time the delta time difference between uh the exact moment at which we want this clock to arrive the flop to the uh actual value the actual time at which we are receiving this at different places at different places ranjit we're talking about spatial variation so there is there is one there is one flop so there is this uh circuit or that you have designed circuit name as our system that you designed there is one flop that is here another flop that is here you assumed okay and the output of this is going to the input of this let us say there is some combinational logic in there huh so you assumed that clock would arrive here at time instant t0 but the very fact that these two nodes these two flops are so far apart the clock arriving here could be arriving at t1 this is clock's queue okay yes now what is clock data so clock skew is between two different flops we're talking about spatial variation now what is clock jitter it is within the clock generation itself basically it is a kind of random by my clock might have some time period and then i'll i see that at some points of time the clock positive edge is not coming at the expected time it is coming right somewhere so now we're talking about same flops anyway she now we're talking about the same flop where we say that due to uh let us say variations in in the pll through which you generated your clock or whatever you know after some time it got heated up or uh this is the the wire is this clock is reaching this flop and in between there is a set of other wires which it gets to see crosstalk with in one cycle there was a supportive crosstalk and in another cycle there was a destructive crosstalk huh so between two cycles of the same flop itself what am i seeing the next clock edge could arrive a little early if there is constructive crosstalk or a little late if there is destructive crosstalk and this is called as jitter temporal variations so spatial variation is skew for temporally equivalent it was the same rising edge of the clock that we were considering whereas clock jitter is about same flop receiving same flop receiving clock from multiple clock so same flow of same clock but that clock actually getting impacted differently over different cycles now that is clock data then there is a variation in pulse width variation and time period again which could be because of some some crosstalk or something like that which could happen in the system crosstalk is easy to understand therefore i am using the word crosstalk more often but as we just saw there are so many other sources of variations so uh that is called as clock uh you know variation of pulse width and all these things need to be taken care of when you do timing try knots so what we are talking about is that the skew is between two clock arriving at two different flops so this could be ff1 and this could be ff2 clock arriving at two different flops but jitter is about clock edge arriving at a flop coming a little earlier or a little later okay so what does this mean when you have jitter it means that this could be your t period minimum t period or in worst cases your t period could actually be longer also are you able to see this sir in case i want to model this uh clock uncertainty it is kind of increasing my setup and hold time for the worst cases yes that is what i am talking about right away now we will go into timing analysis so yes so the clocks queue and the jitter both will be model uh under like uncertainty clock uncertainty that different kinds of uncertainties only there are different kinds of uncertainties yes okay and so as i can see that the skew is because of the routing of the clock because the clock is routing different parts exist yes and sir jitter is because of the variations like temporal variations which could be there at one point of time and may not be there at another point of time okay yes clock skew could also be because of variations but they are fixed variations they could be temporal also but fixed fixed also okay the clock jitter is only because of temporal variations okay so sir like for example as you were in the uncertainty slide use do you shows that they are like the one was uh uncertainty there was variation in the source in the device and the temperature these kind of variations can both lead to the skew and jitter i mean okay okay i mean it is not like that is queue is dated because only because of the routing thing only no okay and so also i can see that like the skew the uncertainty thing the jitter thing it is very unpredictable kind of thing yeah and i they whether it will be there or not i cannot definitely say yeah but skew is more kind of uh deterministic i mean say i can still kind of good i'm so happy that you are arriving at this reduction so but then how will be taking account this answer the jitter thing kind of because that would be very difficult yes sir we have to leave the margins then okay so i just wanted to ask if the uh when the clock is input at a transmission gate which is as an input to a flip t flip flop so that would uh there would be some phase delay between the inverted clock and the normal clock so that is counted in skew right uh that would also be counted and that will actually become evident and set up and hold time itself because the inverted clock is generated usually generated inside the flop itself ins no i'm but you've seen the symbol of a flip flop there is only one clock input no is there a clock input for cq got it sorry i know got it got it okay ckb is an internal signal okay okay okay thank you yeah so just one more thing also want to ask so the margins that we'll be giving for this queue and the data where we will it be different or like same only let us see okay okay so what we are essentially saying is that there could be skew um there could be skew which could be positive or negative we are talking about two flops a clock could be coming from this side or clock could be coming from this side huh in one case this flop will receive the clock a little earlier than this one and in the other case the flop will receive the clock a little later than the first one when it receives later it is called positive skew when it receives earlier it is called negative skew are you able to see this any questions sir it is about the launching of the clock the point of launch yeah okay so now what this means is that if there is a combinational path in between them it could happen that i have positive skew or i i have negative q and we need to see what is the impact of skew on my paths length or the on the clock period so if for example i have a positive skewed clock then we realize that this combinational logic can be slightly longer whereas if i have a negative skew path my combinational logic will have to be slightly smaller shorter in in length are you able to see this hello guys so can you can you elaborate this so clock arrived here at tclk one yes sir clock arrives here at tclk2 yes sir let us say combinational logic has a delay of tcomb huh if eclk 1 was the clock that would arrive at the second flop also then what is the constraint you have to see if the second drop also has the clock arriving at this edge only then what is it that you have to see you have to ensure that the delay in your combinational logic has to be less than tclk yes sir yes sir but since tclk 2 is arriving a little later now i have this extra delta duration in which i can still have my combinational logic do some magic yes sir this is where you get some benefit yes yes and if it was a negative edge you will actually have lesser time for your combinational logic i would say i will be less worried about the whole time now in the negative you will be less worried about the whole time so we'll just see let us say that i have timings like pcq propagation pcq contamination p setup p hold d logic these logic contamination what is the minimum cycle time that you can keep in this system empty clock to queue press t logic yeah what we say is that the next edge could be coming after a negative skew so t minus delta should be equal to or larger than pcq propagation delay plus setup time plus the logic delay over here are you able to see this sir here i may consider the negative skew yes that is the that is the worst case is it not okay right now let us look at the other side also how do you same flop now how do you what is the constraint that is put upon hold time what do you want now over here you will say that tclk2 will arrive later than cclk1 so we say that we're now looking at uh what do you say the skew to be added in the whole time requirement we say that the contamination delay the fastest input can come to this and the contamination delay of this combinational logic should be greater than the whole time requirement of this flop plus delta are you able to see this so can you explain this again so this whole one so if i say that let us forget data for now let us forget data for now i just want that there should be no hold time violations what do i need to ensure that when the next clock edge comes pclk2 comes after that also my earlier input must have remained stable for how long t hold long huh so the delay the minimum delay that i get from input to let us say from the i n pin to let us say this point is has to be greater than p hold is this part here so in the setup thing in when the setup time constraint we are considering one uh we are considering two time two clock edges which are like t period apart but in the whole time we are considering the same clock edges yes whole time is always with the same blockage so sir uh okay so hold time come up look here let us understand that whole time says that when my clock edge comes the data from the previous or any transitions from the previous flop should not have reached me yet after t hold period i know that was how we defined the whole time now this was set up time and this was whole time hello yes sir so we are saying that after clock edge arrives even after that no transition should happen until t hold yes yes sir so delays contamination delays of this and this should be lesser should be greater than p hold so uh sir for example when the same clock is arrived at both this flip flop so it will start processing it will start it will do the and for the next flip flop i want the latching to happen not this input to be transmitted to that so but like why uh in the previous slides when we are consuming the contamination the propagation thing you were saying that we consider the for the contamination delay we are not sure that the data will be stable or the queue will be stable or not so why i'm not consuming the propagation here and the contamination should have happened or no dimensional input should happen before whole time happens yes i don't have the d the d pin of the next at the r2 register that let us call this signal x this x should not toggle before hold time has elapsed yes sir yes yes sir i know yes sir so you are now looking at the shortest delays yes sir that is how you use the contamination delay part so now that i am able to get so but for example you also said the input to be uh stably available at the output that for that we consider the propagation thing because we are not sure that the data will be stable at the output q pin of the register one because then that only will be propagating towards let us say let us say there are these glitches that appear okay what is so and let us say this is the sampling edge what do you want the first glitch should happen after whole time now okay right i mean i don't have to concern about the stables in stable signal just any differently changing you do not want any transition to happen okay even the first glitch should not arrive which means that i have to look at the contamination delay yes so yes yes okay and here we say that we have a negative skew therefore we would add data also to the requirement a positive q i think negative skew receiving edges arriving early uh ah late late sorry yes positive skill again the receiving edge is arriving late so that that adds to the requirement there okay is it clear till here friends i need some feedback this is very very important concept yes okay now we look at jitter for jitter what we are saying is that there is a variation in clock arrival itself clock would arrive a little early the clock edge could arrive a little early or a little later so now we have added this t jitter also into the timing system huh and now what would be the impact let us say on uh earliest arrival time or earliest launch time based on that you will see that this is how my setup or clock period and hold requirements would change you will see that two jitter would get added one set of jitter for the launching edge and one set of jitter for the capturing edge [Music] but if you're talking about uh clock period two jitters will be added so can we say that because of jitter the if essential time period has him has been impacted uh from the source uh can we say that because of jitter jitter the original time period of the clock was impacted yes yeah but you have to the the see you're doing sign off at uh at one frequency you've done the sign off but now you need to leave the margin for jitter because during sign off you cannot do your sta tools cannot and take care of these variations there can it right right right right i know good yeah so this data is not exactly clear i mean how you're incorporating this okay you tell me look at this waveform yes so what happens so agar if you just look at the uh set of time velar requirements yes sir what could happen instead of clock arriving at the desired time it arrives a little later yes on the first block and for the second flop instead of it arriving at the regular time it arrived a little earlier so yes all the delays now will need to be measured from here which is jitter jitter later and they should be sampled jitter duration earlier so you have to leave margin of two jitter in your overall calculation so but like when he was explaining today he was saying that in the same flop how matt is arriving even two different problems so i'm here also there will be jitter nah yes yes sir okay so so like in in in my in my skew uh constraint when my with the equation that i done skew constraint only i will subtract this two times digit i will add this zipper also twice so this is for the setup yeah okay okay similarly for the hold what do you see clock launched a little earlier because of jitter so what happens now uh your jitter uh comes so it launched a little earlier it launched a little earlier on the first flap and on the second flop it it it came a little later because of jitter only i know so data must not arrive af before the hold plus jitter now so you have cq plus the logic path delay minus jitter has to be greater than hold requirement plus jitter plus q so again you see two jitter got added so in my in my the capturing flip flop the i i should be considering the case of the positive skew for the whole time to be constrained yeah yeah but so for the uh starting flip flop what exactly did you did so that was not clear i mean we just looked at jitter yes see and it is it was intended to come here it came a little earlier because of jitter so it got launched earlier the transitions got launched a little earlier,https://www.youtube.com/watch?v=uoVAuUDzOT4,"Link: https://www.youtube.com/watch?v=uoVAuUDzOT4
Transcript: okay so but before we enter into the timing closure part i think it is important to understand some variabilities that need to be accounted for when we do timing closure okay rather is that anything else that is pending i see your hand raised okay so there are some and uncertainties that we need to manage where could those uncertainties come from they could come from clock generation the pll that is generating the clock that could have some litter in it that could have some you know different delays across different time time zones whatever there could be drift in the in the oscillator and so on then there are device variations there are power supply variations there are interconnect variations where you could have a crosstalk between interconnects and therefore when both the signals are rising you have one kind of delay when one of the signals is falling you will have a different kind of a delay and so on there could be variations in temperature there could be variations in loading of different of different flops or stuff like that and so on so there are many uncertainties that clock arriving at any flop would see what we are saying is see yaha we were saying that what is the delay between one flop and another both the pins are being referred to as clock but what can actually happen is that one flop is experiencing delay through this path and the other path is experiencing delay through this path and there are so many different sources of variations that could occur for the two flip flops this is called as clock uncertainty and this needs to be accounted for in our closure analysis so these non-idealities include clock skew clock jitter and variation and pulse width now it is very important to understand the difference between clock skew and clock jitter clock skew is the spatial variation in temporally equivalent clock edges what does this statement mean who can clarify this cryptic statement for all of us sir it is the difference between uh the time the delta time difference between uh the exact moment at which we want this clock to arrive the flop to the uh actual value the actual time at which we are receiving this at different places at different places ranjit we're talking about spatial variation so there is there is one there is one flop so there is this uh circuit or that you have designed circuit name as our system that you designed there is one flop that is here another flop that is here you assumed okay and the output of this is going to the input of this let us say there is some combinational logic in there huh so you assumed that clock would arrive here at time instant t0 but the very fact that these two nodes these two flops are so far apart the clock arriving here could be arriving at t1 this is clock's queue okay yes now what is clock data so clock skew is between two different flops we're talking about spatial variation now what is clock jitter it is within the clock generation itself basically it is a kind of random by my clock might have some time period and then i'll i see that at some points of time the clock positive edge is not coming at the expected time it is coming right somewhere so now we're talking about same flops anyway she now we're talking about the same flop where we say that due to uh let us say variations in in the pll through which you generated your clock or whatever you know after some time it got heated up or uh this is the the wire is this clock is reaching this flop and in between there is a set of other wires which it gets to see crosstalk with in one cycle there was a supportive crosstalk and in another cycle there was a destructive crosstalk huh so between two cycles of the same flop itself what am i seeing the next clock edge could arrive a little early if there is constructive crosstalk or a little late if there is destructive crosstalk and this is called as jitter temporal variations so spatial variation is skew for temporally equivalent it was the same rising edge of the clock that we were considering whereas clock jitter is about same flop receiving same flop receiving clock from multiple clock so same flow of same clock but that clock actually getting impacted differently over different cycles now that is clock data then there is a variation in pulse width variation and time period again which could be because of some some crosstalk or something like that which could happen in the system crosstalk is easy to understand therefore i am using the word crosstalk more often but as we just saw there are so many other sources of variations so uh that is called as clock uh you know variation of pulse width and all these things need to be taken care of when you do timing try knots so what we are talking about is that the skew is between two clock arriving at two different flops so this could be ff1 and this could be ff2 clock arriving at two different flops but jitter is about clock edge arriving at a flop coming a little earlier or a little later okay so what does this mean when you have jitter it means that this could be your t period minimum t period or in worst cases your t period could actually be longer also are you able to see this sir in case i want to model this uh clock uncertainty it is kind of increasing my setup and hold time for the worst cases yes that is what i am talking about right away now we will go into timing analysis so yes so the clocks queue and the jitter both will be model uh under like uncertainty clock uncertainty that different kinds of uncertainties only there are different kinds of uncertainties yes okay and so as i can see that the skew is because of the routing of the clock because the clock is routing different parts exist yes and sir jitter is because of the variations like temporal variations which could be there at one point of time and may not be there at another point of time okay yes clock skew could also be because of variations but they are fixed variations they could be temporal also but fixed fixed also okay the clock jitter is only because of temporal variations okay so sir like for example as you were in the uncertainty slide use do you shows that they are like the one was uh uncertainty there was variation in the source in the device and the temperature these kind of variations can both lead to the skew and jitter i mean okay okay i mean it is not like that is queue is dated because only because of the routing thing only no okay and so also i can see that like the skew the uncertainty thing the jitter thing it is very unpredictable kind of thing yeah and i they whether it will be there or not i cannot definitely say yeah but skew is more kind of uh deterministic i mean say i can still kind of good i'm so happy that you are arriving at this reduction so but then how will be taking account this answer the jitter thing kind of because that would be very difficult yes sir we have to leave the margins then okay so i just wanted to ask if the uh when the clock is input at a transmission gate which is as an input to a flip t flip flop so that would uh there would be some phase delay between the inverted clock and the normal clock so that is counted in skew right uh that would also be counted and that will actually become evident and set up and hold time itself because the inverted clock is generated usually generated inside the flop itself ins no i'm but you've seen the symbol of a flip flop there is only one clock input no is there a clock input for cq got it sorry i know got it got it okay ckb is an internal signal okay okay okay thank you yeah so just one more thing also want to ask so the margins that we'll be giving for this queue and the data where we will it be different or like same only let us see okay okay so what we are essentially saying is that there could be skew um there could be skew which could be positive or negative we are talking about two flops a clock could be coming from this side or clock could be coming from this side huh in one case this flop will receive the clock a little earlier than this one and in the other case the flop will receive the clock a little later than the first one when it receives later it is called positive skew when it receives earlier it is called negative skew are you able to see this any questions sir it is about the launching of the clock the point of launch yeah okay so now what this means is that if there is a combinational path in between them it could happen that i have positive skew or i i have negative q and we need to see what is the impact of skew on my paths length or the on the clock period so if for example i have a positive skewed clock then we realize that this combinational logic can be slightly longer whereas if i have a negative skew path my combinational logic will have to be slightly smaller shorter in in length are you able to see this hello guys so can you can you elaborate this so clock arrived here at tclk one yes sir clock arrives here at tclk2 yes sir let us say combinational logic has a delay of tcomb huh if eclk 1 was the clock that would arrive at the second flop also then what is the constraint you have to see if the second drop also has the clock arriving at this edge only then what is it that you have to see you have to ensure that the delay in your combinational logic has to be less than tclk yes sir yes sir but since tclk 2 is arriving a little later now i have this extra delta duration in which i can still have my combinational logic do some magic yes sir this is where you get some benefit yes yes and if it was a negative edge you will actually have lesser time for your combinational logic i would say i will be less worried about the whole time now in the negative you will be less worried about the whole time so we'll just see let us say that i have timings like pcq propagation pcq contamination p setup p hold d logic these logic contamination what is the minimum cycle time that you can keep in this system empty clock to queue press t logic yeah what we say is that the next edge could be coming after a negative skew so t minus delta should be equal to or larger than pcq propagation delay plus setup time plus the logic delay over here are you able to see this sir here i may consider the negative skew yes that is the that is the worst case is it not okay right now let us look at the other side also how do you same flop now how do you what is the constraint that is put upon hold time what do you want now over here you will say that tclk2 will arrive later than cclk1 so we say that we're now looking at uh what do you say the skew to be added in the whole time requirement we say that the contamination delay the fastest input can come to this and the contamination delay of this combinational logic should be greater than the whole time requirement of this flop plus delta are you able to see this so can you explain this again so this whole one so if i say that let us forget data for now let us forget data for now i just want that there should be no hold time violations what do i need to ensure that when the next clock edge comes pclk2 comes after that also my earlier input must have remained stable for how long t hold long huh so the delay the minimum delay that i get from input to let us say from the i n pin to let us say this point is has to be greater than p hold is this part here so in the setup thing in when the setup time constraint we are considering one uh we are considering two time two clock edges which are like t period apart but in the whole time we are considering the same clock edges yes whole time is always with the same blockage so sir uh okay so hold time come up look here let us understand that whole time says that when my clock edge comes the data from the previous or any transitions from the previous flop should not have reached me yet after t hold period i know that was how we defined the whole time now this was set up time and this was whole time hello yes sir so we are saying that after clock edge arrives even after that no transition should happen until t hold yes yes sir so delays contamination delays of this and this should be lesser should be greater than p hold so uh sir for example when the same clock is arrived at both this flip flop so it will start processing it will start it will do the and for the next flip flop i want the latching to happen not this input to be transmitted to that so but like why uh in the previous slides when we are consuming the contamination the propagation thing you were saying that we consider the for the contamination delay we are not sure that the data will be stable or the queue will be stable or not so why i'm not consuming the propagation here and the contamination should have happened or no dimensional input should happen before whole time happens yes i don't have the d the d pin of the next at the r2 register that let us call this signal x this x should not toggle before hold time has elapsed yes sir yes yes sir i know yes sir so you are now looking at the shortest delays yes sir that is how you use the contamination delay part so now that i am able to get so but for example you also said the input to be uh stably available at the output that for that we consider the propagation thing because we are not sure that the data will be stable at the output q pin of the register one because then that only will be propagating towards let us say let us say there are these glitches that appear okay what is so and let us say this is the sampling edge what do you want the first glitch should happen after whole time now okay right i mean i don't have to concern about the stables in stable signal just any differently changing you do not want any transition to happen okay even the first glitch should not arrive which means that i have to look at the contamination delay yes so yes yes okay and here we say that we have a negative skew therefore we would add data also to the requirement a positive q i think negative skew receiving edges arriving early uh ah late late sorry yes positive skill again the receiving edge is arriving late so that that adds to the requirement there okay is it clear till here friends i need some feedback this is very very important concept yes okay now we look at jitter for jitter what we are saying is that there is a variation in clock arrival itself clock would arrive a little early the clock edge could arrive a little early or a little later so now we have added this t jitter also into the timing system huh and now what would be the impact let us say on uh earliest arrival time or earliest launch time based on that you will see that this is how my setup or clock period and hold requirements would change you will see that two jitter would get added one set of jitter for the launching edge and one set of jitter for the capturing edge [Music] but if you're talking about uh clock period two jitters will be added so can we say that because of jitter the if essential time period has him has been impacted uh from the source uh can we say that because of jitter jitter the original time period of the clock was impacted yes yeah but you have to the the see you're doing sign off at uh at one frequency you've done the sign off but now you need to leave the margin for jitter because during sign off you cannot do your sta tools cannot and take care of these variations there can it right right right right i know good yeah so this data is not exactly clear i mean how you're incorporating this okay you tell me look at this waveform yes so what happens so agar if you just look at the uh set of time velar requirements yes sir what could happen instead of clock arriving at the desired time it arrives a little later yes on the first block and for the second flop instead of it arriving at the regular time it arrived a little earlier so yes all the delays now will need to be measured from here which is jitter jitter later and they should be sampled jitter duration earlier so you have to leave margin of two jitter in your overall calculation so but like when he was explaining today he was saying that in the same flop how matt is arriving even two different problems so i'm here also there will be jitter nah yes yes sir okay so so like in in in my in my skew uh constraint when my with the equation that i done skew constraint only i 
will subtract this two times digit i will add this zipper also twice so this is for the setup yeah okay okay similarly for the hold what do you see clock launched a little earlier because of jitter so what happens now uh your jitter uh comes so it launched a little earlier it launched a little earlier on the first flap and on the second flop it it it came a little later because of jitter only i know so data must not arrive af before the hold plus jitter now so you have cq plus the logic path delay minus jitter has to be greater than hold requirement plus jitter plus q so again you see two jitter got added so in my in my the capturing flip flop the i i should be considering the case of the positive skew for the whole time to be constrained yeah yeah but so for the uh starting flip flop what exactly did you did so that was not clear i mean we just looked at jitter yes see and it is it was intended to come here it came a little earlier because of jitter so it got launched earlier the transitions got launched a little earlier"
RRwHlqcV7MI,how do i put it how do we uh now move to other types of uh let us say two phase latches and pulse latches how do we do timing closure there for this one uh what would what should be that like how can you please help me complete this equation over here what should come after this this is still the ideal case let us forget about jitter and the uh skew yet so the uh logic uh delay should be lesser than a complete time period minus setup time and minus the clock to queue delay of the first flip flop very good so this setup time plus propagation delay of the first flip flop this is called as sequencing overhead okay because had your combinational logic not been broken and though these flops not been inserted there your total delay would have been tpd only cpd only needed to be less than pc but now there is an additional thing which has come here which is called as sequencing overhead okay now if we look at two phase latches so there are two phases of clock phase one and phase two which are kind of as you will notice non-overlapping so what comes here tpd one plus tpd two should be less than so what is due to the two phase of the clock i mean what exactly is the implementation the implementation could be that uh there is an inverter in the end so i'm asking what exactly by by taking the two phases of the clock mean what exactly does it mean two phases of clock so there is a clock which has uh high so there is uh there's a clock which goes high once and another clock which goes high at a 90 degree phase shift okay so so we have two latches and we are providing different clock signals to both of them yeah alternate latches we are providing the other face okay sir here you you have not considered setup is is that because you have enough time like you have assumed that setup is kind of already not a problem so where is the setup of our latch considered so it will be on the falling edge of fighting you have to tell me what should be the uh how do i complete this equation there is a minus sign here i do not i have not yet put what goes after this you have to tell me that tpd1 ctpdq1 minus tpdq2 okay tpd 1 plus tpd2 should be less than what should be less than tc minus tpd q1 minus tpd q2 as i can see from this diagram tpdq1 and tpdq okay so the sequencing overhead over here is defined by two tpdq assuming that both the latches are designed okay what else so if you use both what would happen so can we move to previous slides yeah so i we mean considering the uh this tpd one for example i know that uh after my combinational one has process and combination two both have processed i'm taking the uh the constraint at the latch three basically at the so yeah writing this here for the before the rising edge of this this latch comes i just want to see so but shouldn't it be the falling edge of this latch last three i mean because then only because the uh my sampling is that only for the following edge yeah so you have to be careful anime over here now if i'm starting from the rising as i've started to do the analysis from the rising edge and then doing stuff like that sir then i have to because i i want to find that clock period only so we'll come to this aspect that you're absolutely right in the fact that this combinational delay can actually be a little longer than this it may come a little here also what's the problem you're right in that that is what we will call as time borrowing we will review that today okay that is very easily possible in this two phase lab system but a b because we are talking about clock period itself therefore we are talking about rising edge of these two five okay okay and also like for example uh though i'm considering my clock period for this uh like latch was for the same phases of the clock five one only so but like intermediately i have this latch too and it will also have its like setup constraints and all that but i am not considering that key because at least in this timing diagram if you see we are saying that this output of or input of latch has become stable much before its falling edge okay so i'm not really bothered about setup just yet as as i move forward you will see i will talk about all those aspects also okay we are starting simple okay okay so sir here we are considering the constraint slide i only want to see what is the minimum sequencing overhead the system would have i'm not even looking at other timing constraints yet okay and so just for the because i have taken the rising edge so i have uh that's why i'm not considering till the falling edge of the yeah okay that's it uh yes right you had the same question of uh why aren't we considering the setup and the old uh limit let's consider don't worry we can't miss those aspects because because the clock period for sure it will depend upon the um uh hold constraint yeah we'll just consider yes sir so yeah so how we've got this equation like y minus 2 tb dq do you realize that this tpd queue is the extra thing that is coming in the combinational logic path no sir so this delay from d2 to q2 d2 to q2 yeah yes sir if if our system had no sequencing there yes i just said d2 to queue okay would not have been there now yes yes sir so this is the extra delay this is overhead yes sir or is maybe talking about sequencing overhead the slide is only about sequencing overhead okay okay take a second yes yes sir okay so just one more thing so here we are not considering the clock to queue because we are considering that the clock is stable even off before that data changes so because for the latches we had two kinds of delay right clockwise yeah we said data became stable normally after clock came high now that is what we have done over here is it not okay so data is changing after the clock is stable yeah so therefore c2 queue banana look at the timing diagram and then we see there are obviously so many other timing definitions not all are being reviewed over here in this particular slide i know in this particular timing diagram we are talking about sequencing over and we see it is equal to 2t pdq now look at this timing diagram now what is the sequencing overhead here this is pulsed latches so there is a short pulse there is a short pulse and something is happening and now you will notice there are two cases there is a case linked to pulse width being greater than setup and pulse width being less than setup are you able to see this the sequencing overhead here who can justify this for me said this double one yeah this is a amalgamation of both the diagrams so basically what you are saying is when pulse width is very small then you have to make the data stable even before the clock even rises yeah you cannot expect that dc completely you able to see this if the setup time requirement is something then i will use that setup time that data should be stable at least set up time before the clock falling edge comes [Music] so i mean uh i'm somehow able to get for example that why the tpdq and tpcq would be different but like why was considering this dp pulse with subtracting the perspect this equation is not getting clear so you launched the data from here pricing edge yes sir we are sampling it at the falling edge setup time is from the falling so what is the time period considered from the uh rising edge okay okay rising and the rising yes sir but time period is from rising to rising so this pulse width has to be reduced now so can you please repeat i'm not able to get so are you able to see that sampling will happen at the falling edge of clock over here yes sir however i want to find the delay up to rising edge of the clock yes so tc may i will have so my window in which i am doing this timing constraint is equal to tc plus cpw my entire constraint is between tc plus cpw are you able to see this because the sampling edge is this okay so okay okay in the two phase we didn't consider this in this we are considering it in the two phase because we are assuming that pulse widths are large enough and that data will like and the two phases are also almost equivalent that is why we did not consider it in the last slide so tc is from center of the first pulse to center of the second perspective no rising of the first pulse to the rising of the second pulse seeker rising to securizing is dc okay so like uh here though my tc is from the rising to rising but i am considering the path from the rising till the falling out start okay and that's why i have to subtract this dpw from the overhead from the oh so here essentially we have considered both the cases uh if the queue is being triggered by the data or the clock yes more mature statements as we move forward more and more things will get included there sir yes sir the risk of setup time violation would be much more for second guess right why if i have met the timing then there is no risk but uh what i can see is because setup time is included in the pulse width itself in the first case but in the second case the propagation delay need of the combination logic need to be a bit lower i guess so they breathe it is not about propagation delay being lower it is about what is your clock period you have some propagation delay what is the clock period that you want to give okay so the given time requirement of your latch or the flop okay so any there is not any risk anywhere if you're meeting the timing requirements if you're qualifying these equations there is no risk anywhere that is why we want to do static timing analysis that is what where you want to do sign off okay yes okay [Music] we are taking the maximum of both this d2 and c2 is that because uh i'm not sure in different cycles my pulse bits might also vary because uh i can see that in if the setup and set up time and password these two are constant then either of one should come there's no chance of others no the thing is that my pulse width is very short my pulse width is very short and i do know understand that my setup may have happened before the rising edge of the clock itself yes now if that is the case then tcq becomes valid yes now it could happen that my pulse width is not that short so my password is like this and data toggle somewhere here so then what will become valid tdq but but in same system the pulse width could be defined and the same in the in the particular system we are talking about the pulse weight of the pulse whatever we are giving will be defined so basically one of these should come the max of these would come because the cookiaga if i say that if i if i consider data to be to be stable uh how do i show it okay let us say my data toggled here for this particular case after the clock had arrived let us say for now what would happen will it meet the setup time requirement in case setup is higher than if it would unprofit no i know but if the person is large enough then this would meet the set of time requirements just in d2q but my data has arrived after the clock edge yes so i will therefore use tdq for my purposes yes in the previous case or in this case it says if data had toggled before because setup time was larger let us say setup time was this much so data toggled here however so the cq is this much let us say tdq was this it won't matter because it is not why will it not matter the clock has gone high my data is there it has met the setup time but tdq is not met yet my output will not toggle until here so this is not clear at this point so do you realize that it is always max of tdq and pcq which will come into picture let us say let us forget about this this particular pulse latch here let us look at any latch okay now data toggled here i'll open it data toggled here and set up time to following at second app data toggled here and q is expected so this is data and q is expected when will the earliest queue arrive earlier sq will arise either after tcq or after tdq am i right yes sir yes no if this tdq is larger than tcq what happens so data will arrive after pdq will now arrive after tdq yes sir i know so even though clock clock edge had come after data toggling but even then tdq is the defining delay so in this case the triggering would be the clock edge but the delay wouldn't be the clock to queue yes sir physically thinking about it would be kind of this dd2 when a clock blockage is a triggering point and td cube and blockage is not the trading point these two can be also different these two delays yeah the delays could be different yes delays could be different so you will have to you will have to characterize your system in its completeness and then then do the timing sign off yes here in the equation it should be pc plus t tp w minus all the other things right so that is what it is now so here we are saying the sampling would be done at the negative edge that's [Music] okay okay okay we are considering the case where the data d1 is toggling at the rising edge of the clock not necessarily d1 could be toggling after the rising of the clock also yeah in that case if we consider the data change after the rising edge of somewhere midway then this equation doesn't hold good right because we'll be considering somewhere in the midway of the clock when it is high and then from there we are considering tdq but we are considering uh tc plus tpw so the rest of the uh time where uh that the time delta between the rising edge of the clock and from where the data has traveled so that portion uh essentially is not uh we are just adding that here look at it like this if there was this extra region if there is this xy region at the input side on the input side of d1 then you also have this exfolia region in the output side so setup requirement at the falling edge of the next flop next latch would also be there so there's something like what we did in the previous slide you remember assuming we just looked we just went ahead assuming there were no no other challenges so you will see that we will look at all these additional challenges as we go forward have we taken a simple case here okay and we're talking about the sequencing overhead and the other thing okay sir yes sir i think ranjit talked about the overhead that is minus of tpw minus t setup if because if you take the minus sign out it becomes actually becomes tpw minus t setup which is the overhead uh when data is coming after the pulse means uh at the middle of the pulse i don't know what are you saying i'm saying that if pulse width is large enough say and the data is coming at the middle of the pulse width and also the state of time is not violating so the difference between the when the clock edge has come and when the data is talking let us just step back a little let us just step back a little i want to find the shortest pc you said i want to find the fastest frequency at which my system can operate so the smallest pc so would i want data to just waste some timing delay somewhere no so what you are talking about is a relaxed cycle there are margins there already that is not where you will do timing sign off yes it is okay yes so that is where if you if you look at a relaxed cycle then no equation for example in the second case when the password is less than t set up so you have considered the tpcq but here we as earlier discussion it could be tp dq also right that is why we use the max of tpdq and ppcq okay and so so one more thing sir like uh i'm able to get that why we are subtracting the password from this so but like the pulse we are subtracting this pulse fit because of the way that we have defined like how we are measuring that no because it's a latch it's on the falling edge of the clock that the sampling would happen it is not about what we defined or not just that is the latch we have that additional window in which we could have our system set up sampling edge is the falling edge of clock not the rising edge of block yes sir so but like we have then subtracted that window right we've actually added that to tc we've subtracted that from the sequencing overhead okay because we've added that to the tc this is the extra margin we have for the propagation delay there okay so sir like for our calculation we start the calculation from the rising edge of the first latch and we consider it till the falling of the next latch yes that is the entire window in which your system should settle down completely is it not yes yeah so but the same we didn't do for the earlier one uh you would want to do it for the earlier one also but because the pulse which is very very large so you can end up getting confused over there so it's it's the same equation that will be valid for up there also okay so okay so but like i'm getting still confused that the clock the time period like when we define the setup now let us do it like this again you will have to review this session yes after the class okay you'll have to work it out yourself okay sir unless you work it out yourself this is a clear name however much time i speak over,https://www.youtube.com/watch?v=RRwHlqcV7MI,"Link: https://www.youtube.com/watch?v=RRwHlqcV7MI
Transcript: how do i put it how do we uh now move to other types of uh let us say two phase latches and pulse latches how do we do timing closure there for this one uh what would what should be that like how can you please help me complete this equation over here what should come after this this is still the ideal case let us forget about jitter and the uh skew yet so the uh logic uh delay should be lesser than a complete time period minus setup time and minus the clock to queue delay of the first flip flop very good so this setup time plus propagation delay of the first flip flop this is called as sequencing overhead okay because had your combinational logic not been broken and though these flops not been inserted there your total delay would have been tpd only cpd only needed to be less than pc but now there is an additional thing which has come here which is called as sequencing overhead okay now if we look at two phase latches so there are two phases of clock phase one and phase two which are kind of as you will notice non-overlapping so what comes here tpd one plus tpd two should be less than so what is due to the two phase of the clock i mean what exactly is the implementation the implementation could be that uh there is an inverter in the end so i'm asking what exactly by by taking the two phases of the clock mean what exactly does it mean two phases of clock so there is a clock which has uh high so there is uh there's a clock which goes high once and another clock which goes high at a 90 degree phase shift okay so so we have two latches and we are providing different clock signals to both of them yeah alternate latches we are providing the other face okay sir here you you have not considered setup is is that because you have enough time like you have assumed that setup is kind of already not a problem so where is the setup of our latch considered so it will be on the falling edge of fighting you have to tell me what should be the uh how do i complete this equation there is a minus sign here i do not i have not yet put what goes after this you have to tell me that tpd1 ctpdq1 minus tpdq2 okay tpd 1 plus tpd2 should be less than what should be less than tc minus tpd q1 minus tpd q2 as i can see from this diagram tpdq1 and tpdq okay so the sequencing overhead over here is defined by two tpdq assuming that both the latches are designed okay what else so if you use both what would happen so can we move to previous slides yeah so i we mean considering the uh this tpd one for example i know that uh after my combinational one has process and combination two both have processed i'm taking the uh the constraint at the latch three basically at the so yeah writing this here for the before the rising edge of this this latch comes i just want to see so but shouldn't it be the falling edge of this latch last three i mean because then only because the uh my sampling is that only for the following edge yeah so you have to be careful anime over here now if i'm starting from the rising as i've started to do the analysis from the rising edge and then doing stuff like that sir then i have to because i i want to find that clock period only so we'll come to this aspect that you're absolutely right in the fact that this combinational delay can actually be a little longer than this it may come a little here also what's the problem you're right in that that is what we will call as time borrowing we will review that today okay that is very easily possible in this two phase lab system but a b because we are talking about clock period itself therefore we are talking about rising edge of these two five okay okay and also like for example uh though i'm considering my clock period for this uh like latch was for the same phases of the clock five one only so but like intermediately i have this latch too and it will also have its like setup constraints and all that but i am not considering that key because at least in this timing diagram if you see we are saying that this output of or input of latch has become stable much before its falling edge okay so i'm not really bothered about setup just yet as as i move forward you will see i will talk about all those aspects also okay we are starting simple okay okay so sir here we are considering the constraint slide i only want to see what is the minimum sequencing overhead the system would have i'm not even looking at other timing constraints yet okay and so just for the because i have taken the rising edge so i have uh that's why i'm not considering till the falling edge of the yeah okay that's it uh yes right you had the same question of uh why aren't we considering the setup and the old uh limit let's consider don't worry we can't miss those aspects because because the clock period for sure it will depend upon the um uh hold constraint yeah we'll just consider yes sir so yeah so how we've got this equation like y minus 2 tb dq do you realize that this tpd queue is the extra thing that is coming in the combinational logic path no sir so this delay from d2 to q2 d2 to q2 yeah yes sir if if our system had no sequencing there yes i just said d2 to queue okay would not have been there now yes yes sir so this is the extra delay this is overhead yes sir or is maybe talking about sequencing overhead the slide is only about sequencing overhead okay okay take a second yes yes sir okay so just one more thing so here we are not considering the clock to queue because we are considering that the clock is stable even off before that data changes so because for the latches we had two kinds of delay right clockwise yeah we said data became stable normally after clock came high now that is what we have done over here is it not okay so data is changing after the clock is stable yeah so therefore c2 queue banana look at the timing diagram and then we see there are obviously so many other timing definitions not all are being reviewed over here in this particular slide i know in this particular timing diagram we are talking about sequencing over and we see it is equal to 2t pdq now look at this timing diagram now what is the sequencing overhead here this is pulsed latches so there is a short pulse there is a short pulse and something is happening and now you will notice there are two cases there is a case linked to pulse width being greater than setup and pulse width being less than setup are you able to see this the sequencing overhead here who can justify this for me said this double one yeah this is a amalgamation of both the diagrams so basically what you are saying is when pulse width is very small then you have to make the data stable even before the clock even rises yeah you cannot expect that dc completely you able to see this if the setup time requirement is something then i will use that setup time that data should be stable at least set up time before the clock falling edge comes [Music] so i mean uh i'm somehow able to get for example that why the tpdq and tpcq would be different but like why was considering this dp pulse with subtracting the perspect this equation is not getting clear so you launched the data from here pricing edge yes sir we are sampling it at the falling edge setup time is from the falling so what is the time period considered from the uh rising edge okay okay rising and the rising yes sir but time period is from rising to rising so this pulse width has to be reduced now so can you please repeat i'm not able to get so are you able to see that sampling will happen at the falling edge of clock over here yes sir however i want to find the delay up to rising edge of the clock yes so tc may i will have so my window in which i am doing this timing constraint is equal to tc plus cpw my entire constraint is between tc plus cpw are you able to see this because the sampling edge is this okay so okay okay in the two phase we didn't consider this in this we are considering it in the two phase because we are assuming that pulse widths are large enough and that data will like and the two phases are also almost equivalent that is why we did not consider it in the last slide so tc is from center of the first pulse to center of the second perspective no rising of the first pulse to the rising of the second pulse seeker rising to securizing is dc okay so like uh here though my tc is from the rising to rising but i am considering the path from the rising till the falling out start okay and that's why i have to subtract this dpw from the overhead from the oh so here essentially we have considered both the cases uh if the queue is being triggered by the data or the clock yes more mature statements as we move forward more and more things will get included there sir yes sir the risk of setup time violation would be much more for second guess right why if i have met the timing then there is no risk but uh what i can see is because setup time is included in the pulse width itself in the first case but in the second case the propagation delay need of the combination logic need to be a bit lower i guess so they breathe it is not about propagation delay being lower it is about what is your clock period you have some propagation delay what is the clock period that you want to give okay so the given time requirement of your latch or the flop okay so any there is not any risk anywhere if you're meeting the timing requirements if you're qualifying these equations there is no risk anywhere that is why we want to do static timing analysis that is what where you want to do sign off okay yes okay [Music] we are taking the maximum of both this d2 and c2 is that because uh i'm not sure in different cycles my pulse bits might also vary because uh i can see that in if the setup and set up time and password these two are constant then either of one should come there's no chance of others no the thing is that my pulse width is very short my pulse width is very short and i do know understand that my setup may have happened before the rising edge of the clock itself yes now if that is the case then tcq becomes valid yes now it could happen that my pulse width is not that short so my password is like this and data toggle somewhere here so then what will become valid tdq but but in same system the pulse width could be defined and the same in the in the particular system we are talking about the pulse weight of the pulse whatever we are giving will be defined so basically one of these should come the max of these would come because the cookiaga if i say that if i if i consider data to be to be stable uh how do i show it okay let us say my data toggled here for this particular case after the clock had arrived let us say for now what would happen will it meet the setup time requirement in case setup is higher than if it would unprofit no i know but if the person is large enough then this would meet the set of time requirements just in d2q but my data has arrived after the clock edge yes so i will therefore use tdq for my purposes yes in the previous case or in this case it says if data had toggled before because setup time was larger let us say setup time was this much so data toggled here however so the cq is this much let us say tdq was this it won't matter because it is not why will it not matter the clock has gone high my data is there it has met the setup time but tdq is not met yet my output will not toggle until here so this is not clear at this point so do you realize that it is always max of tdq and pcq which will come into picture let us say let us forget about this this particular pulse latch here let us look at any latch okay now data toggled here i'll open it data toggled here and set up time to following at second app data toggled here and q is expected so this is data and q is expected when will the earliest queue arrive earlier sq will arise either after tcq or after tdq am i right yes sir yes no if this tdq is larger than tcq what happens so data will arrive after pdq will now arrive after tdq yes sir i know so even though clock clock edge had come after data toggling but even then tdq is the defining delay so in this case the triggering would be the clock edge but the delay wouldn't be the clock to queue yes sir physically thinking about it would be kind of this dd2 when a clock blockage is a triggering point and td cube and blockage is not the trading point these two can be also different these two delays yeah the delays could be different yes delays could be different so you will have to you will have to characterize your system in its completeness and then then do the timing sign off yes here in the equation it should be pc plus t tp w minus all the other things right so that is what it is now so here we are saying the sampling would be done at the negative edge that's [Music] okay okay okay we are considering the case where the data d1 is toggling at the rising edge of the clock not necessarily d1 could be toggling after the rising of the clock also yeah in that case if we consider the data change after the rising edge of somewhere midway then this equation doesn't hold good right because we'll be considering somewhere in the midway of the clock when it is high and then from there we are considering tdq but we are considering uh tc plus tpw so the rest of the uh time where uh that the time delta between the rising edge of the clock and from where the data has traveled so that portion uh essentially is not uh we are just adding that here look at it like this if there was this extra region if there is this xy region at the input side on the input side of d1 then you also have this exfolia region in the output side so setup requirement at the falling edge of the next flop next latch would also be there so there's something like what we did in the previous slide you remember assuming we just looked we just went ahead assuming there were no no other challenges so you will see that we will look at all these additional challenges as we go forward have we taken a simple case here okay and we're talking about the sequencing overhead and the other thing okay sir yes sir i think ranjit talked about the overhead that is minus of tpw minus t setup if because if you take the minus sign out it becomes actually becomes tpw minus t setup which is the overhead uh when data is coming after the pulse means uh at the middle of the pulse i don't know what are you saying i'm saying that if pulse width is large enough say and the data is coming at the middle of the pulse width and also the state of time is not violating so the difference between the when the clock edge has come and when the data is talking let us just step back a little let us just step back a little i want to find the shortest pc you said i want to find the fastest frequency at which my system can operate so the smallest pc so would i want data to just waste some timing delay somewhere no so what you are talking about is a relaxed cycle there are margins there already that is not where you will do timing sign off yes it is okay yes so that is where if you if you look at a relaxed cycle then no equation for example in the second case when the password is less than t set up so you have considered the tpcq but here we as earlier discussion it could be tp dq also right that is why we use the max of tpdq and ppcq okay and so so one more thing sir like uh i'm able to get that why we are subtracting the password from this so but like the pulse we are subtracting this pulse fit because of the way that we have defined like how we are measuring that no because it's a latch it's on the falling edge of the clock that the sampling would happen it is not about what we defined or not just that is the latch we have that additional window in which we could have our system set up sampling edge is the falling edge of clock not the rising edge of block yes sir so but like we have then subtracted that window right we've actually added that to tc we've subtracted that from the sequencing overhead okay because we've added that to the tc this is the extra margin we have for the propagation delay there okay so sir like for our calculation we start the calculation from the rising edge of the first latch and we consider it till the falling of the next latch yes that is the entire window in which your system should settle down 
completely is it not yes yeah so but the same we didn't do for the earlier one uh you would want to do it for the earlier one also but because the pulse which is very very large so you can end up getting confused over there so it's it's the same equation that will be valid for up there also okay so okay so but like i'm getting still confused that the clock the time period like when we define the setup now let us do it like this again you will have to review this session yes after the class okay you'll have to work it out yourself okay sir unless you work it out yourself this is a clear name however much time i speak over"
EczTGsbBEKA,here okay okay sir yeah so now about the whole time contamination delays what would you say about this we already discussed the flops the contamination [Music] contamination delay should be greater than the whole minus tcc now over here we have assumed that both the clocks arrived at the same time there would be skew there and then we will have to consider skew also which we did in the last class already yes sir okay what about midday mid-lane two-phase latches mendelian two-phase latches we would want that the 51 triggered output should reach l2 after the whole time requirement has been met is this clear yes so what are we saying five and triggered output will give will first have this non overlap window there then there will be tccq and then there will be contamination delay of the combinational logic this should be sir it says the same before but only i think that should be a tiny yes this has got added so what has happened is that this contamination delay constraints if you can give more overlaps then contamination delay can be still smaller is this thing clear for the two phase latches so why the five one is after the fight to this window shouldn't be before i mean because it will come after also now how will i consider the whole time requirement of l2 because l2 sampling gets closed now i want input of l2 to be stable what will spoil the input of l of uh input of l2 the rising edge of phi 1 so the rising edge of phi 1 that comes after falling edge of phi 2 is what is i'm interested in is it not so but after the falling edge of phi 2 it will stop sampling right but there is a whole time requirement okay yes yes yes yes okay that is what i am interested in sir for building a faster circuit i will be i would like to decrease the increase the non overlapping non overlap is a dead period nothing is happening there non-overlap is a dead period no sampling could be happening you may actually be losing data because of known overlap the non-overlap benefit is that your whole time failures will not happen but i can have lower contamination delays yes because you have more margins there is no no there is increased non overlap duration okay now we come to mint delay for the pulse latches here what is the requirement we hold by this clock to kill plus the pulse width yes anna so over here pulse width gets added because for the entire direction of the pulse width there should be no change in the input over here are you able to see this so which is the sampling edge negative edge so you triggered the data from here and you want to define the whole time from here the negative that's why we are doing t plus plus tp okay yeah got that so sir hello yeah yeah so we also talked about this uh in the previous class also so this hold always would be higher so how would we justify it how will i justify using a puzzle before a flip-flop at anywhere if i use we will see what is the word so you have to look at other things also what is the sequencing overhead of a pulse latch as we come to time borrowing we will see what is the benefit of the loss there there are so many aspects the most important aspect is pulse flat is much denser than a flip flop it has much lesser number of devices than a flip flop so it consumes much lesser area lesser area means faster also lesser leakage also area is cold so if everything else is equivalent i still want to use bulk snatch yes you have a question yes sir so sir this pulsed clock is an internal clock of pulse latch so i have heard that we connected i set up and hold time at the original clock of the system yeah so why are we doing here at the place this particular system in this particular system this pulse this clock is in the shape of a pulse in this particular system that we are considering clock is coming as a pulse only the one that you have that one that you are referring to over there we are generating the pulse from the clock internally because that is how typical systems are in a typical system let us say in a typical system when you have to design an arm core or anything you cannot really have such short pulses however if you're designing a very specific system where you're using only latches all over the place and pulse latches are that then you may say that okay instead of having a pulse generator in every latch i would rather use a pulsed clock that is what we are talking about over here okay yeah raghav so can you just uh i'm not able to get the transitioning here so that for example the i'm consider for the whole time i will be considered transitioning the same transitioning at the l2 latch right yeah so sir uh this so for us for l2 what is the requirement so that after the falling edge uh my data should be stable for p hold yeah so from let us say it got triggered from the rising edge of l1 of clock at l1 yes sir so t ccq yes plus pcd of the combinational logic yes sir should be greater than 50 behold plus where is this t hole coming from not the rising edge of phi p but from the falling edge of ip so pulse width the sampling edge for a latch is falling edge yes sir that is where tpw gets added okay right okay is building this type of system uh not more risky because you cannot recover hold one shield yes they are more creative yes that is why they are not very commonly used but they are still used as we just discussed there is a benefit in area there is a benefit in overall leakage everything there is a benefit so okay we take some risk i will sign off more carefully said this uh i mean if you try to decrease the pulse width to uh to get a better hold hold requirement so in that case you will be kind of sending very very small spikes of clock yes that's a bigger challenge what is the smallest clock pulse that you can set that depends upon the setup as well why as i decrease the pulse width so setup will also be pushed back and back so it will set up save as i reduce the pulse rate the system will become more and more like a flop yes so what's the big deal i'm getting a flop kind of functionality at half the area but sending to the uh sending these pulses to distance would be like it will that be that is the challenge that i agree i'm not saying it is easy but there's a benefit a clear benefit there because the area is lesser this rc delay is due to which i cannot send signals or short pulses to long distances that also reduces yes so the pulse width also has to be greater than the c2q delay you really need that so because uh reducing the pulse width a lot smaller wasn't making the system work correctly yeah so is there a link to ccq that is what my question is or is there a link or do you need a minimum percent because of many other reasons or is it only ccq uh there can be many there but i i i noticed this that cq was always smaller than the minimum part built whatever they were using so the pulse pulse width was greater than c cq but i i'm not sure about this one that is a representation they have made in the diagrams don't don't read too much into it these diagrams are not to time so now let's look at skew what happens when q is added flip flops you already done so uh skew gets added as overhead there simple huh for whole time again you will have to assume that skew is to be taken care of in the contamination delay thing so the upper one is negative screw and lower one is positive skew right in both the cases we have said that q is positive we are as of now in this particular equation keeping skew as positive if the skew is negative the value of t square will count negative automatically okay okay okay if you don't take that sign then we'll have to,https://www.youtube.com/watch?v=EczTGsbBEKA,"Link: https://www.youtube.com/watch?v=EczTGsbBEKA
Transcript: here okay okay sir yeah so now about the whole time contamination delays what would you say about this we already discussed the flops the contamination [Music] contamination delay should be greater than the whole minus tcc now over here we have assumed that both the clocks arrived at the same time there would be skew there and then we will have to consider skew also which we did in the last class already yes sir okay what about midday mid-lane two-phase latches mendelian two-phase latches we would want that the 51 triggered output should reach l2 after the whole time requirement has been met is this clear yes so what are we saying five and triggered output will give will first have this non overlap window there then there will be tccq and then there will be contamination delay of the combinational logic this should be sir it says the same before but only i think that should be a tiny yes this has got added so what has happened is that this contamination delay constraints if you can give more overlaps then contamination delay can be still smaller is this thing clear for the two phase latches so why the five one is after the fight to this window shouldn't be before i mean because it will come after also now how will i consider the whole time requirement of l2 because l2 sampling gets closed now i want input of l2 to be stable what will spoil the input of l of uh input of l2 the rising edge of phi 1 so the rising edge of phi 1 that comes after falling edge of phi 2 is what is i'm interested in is it not so but after the falling edge of phi 2 it will stop sampling right but there is a whole time requirement okay yes yes yes yes okay that is what i am interested in sir for building a faster circuit i will be i would like to decrease the increase the non overlapping non overlap is a dead period nothing is happening there non-overlap is a dead period no sampling could be happening you may actually be losing data because of known overlap the non-overlap benefit is that your whole time failures will not happen but i can have lower contamination delays yes because you have more margins there is no no there is increased non overlap duration okay now we come to mint delay for the pulse latches here what is the requirement we hold by this clock to kill plus the pulse width yes anna so over here pulse width gets added because for the entire direction of the pulse width there should be no change in the input over here are you able to see this so which is the sampling edge negative edge so you triggered the data from here and you want to define the whole time from here the negative that's why we are doing t plus plus tp okay yeah got that so sir hello yeah yeah so we also talked about this uh in the previous class also so this hold always would be higher so how would we justify it how will i justify using a puzzle before a flip-flop at anywhere if i use we will see what is the word so you have to look at other things also what is the sequencing overhead of a pulse latch as we come to time borrowing we will see what is the benefit of the loss there there are so many aspects the most important aspect is pulse flat is much denser than a flip flop it has much lesser number of devices than a flip flop so it consumes much lesser area lesser area means faster also lesser leakage also area is cold so if everything else is equivalent i still want to use bulk snatch yes you have a question yes sir so sir this pulsed clock is an internal clock of pulse latch so i have heard that we connected i set up and hold time at the original clock of the system yeah so why are we doing here at the place this particular system in this particular system this pulse this clock is in the shape of a pulse in this particular system that we are considering clock is coming as a pulse only the one that you have that one that you are referring to over there we are generating the pulse from the clock internally because that is how typical systems are in a typical system let us say in a typical system when you have to design an arm core or anything you cannot really have such short pulses however if you're designing a very specific system where you're using only latches all over the place and pulse latches are that then you may say that okay instead of having a pulse generator in every latch i would rather use a pulsed clock that is what we are talking about over here okay yeah raghav so can you just uh i'm not able to get the transitioning here so that for example the i'm consider for the whole time i will be considered transitioning the same transitioning at the l2 latch right yeah so sir uh this so for us for l2 what is the requirement so that after the falling edge uh my data should be stable for p hold yeah so from let us say it got triggered from the rising edge of l1 of clock at l1 yes sir so t ccq yes plus pcd of the combinational logic yes sir should be greater than 50 behold plus where is this t hole coming from not the rising edge of phi p but from the falling edge of ip so pulse width the sampling edge for a latch is falling edge yes sir that is where tpw gets added okay right okay is building this type of system uh not more risky because you cannot recover hold one shield yes they are more creative yes that is why they are not very commonly used but they are still used as we just discussed there is a benefit in area there is a benefit in overall leakage everything there is a benefit so okay we take some risk i will sign off more carefully said this uh i mean if you try to decrease the pulse width to uh to get a better hold hold requirement so in that case you will be kind of sending very very small spikes of clock yes that's a bigger challenge what is the smallest clock pulse that you can set that depends upon the setup as well why as i decrease the pulse width so setup will also be pushed back and back so it will set up save as i reduce the pulse rate the system will become more and more like a flop yes so what's the big deal i'm getting a flop kind of functionality at half the area but sending to the uh sending these pulses to distance would be like it will that be that is the challenge that i agree i'm not saying it is easy but there's a benefit a clear benefit there because the area is lesser this rc delay is due to which i cannot send signals or short pulses to long distances that also reduces yes so the pulse width also has to be greater than the c2q delay you really need that so because uh reducing the pulse width a lot smaller wasn't making the system work correctly yeah so is there a link to ccq that is what my question is or is there a link or do you need a minimum percent because of many other reasons or is it only ccq uh there can be many there but i i i noticed this that cq was always smaller than the minimum part built whatever they were using so the pulse pulse width was greater than c cq but i i'm not sure about this one that is a representation they have made in the diagrams don't don't read too much into it these diagrams are not to time so now let's look at skew what happens when q is added flip flops you already done so uh skew gets added as overhead there simple huh for whole time again you will have to assume that skew is to be taken care of in the contamination delay thing so the upper one is negative screw and lower one is positive skew right in both the cases we have said that q is positive we are as of now in this particular equation keeping skew as positive if the skew is negative the value of t square will count negative automatically okay okay okay if you don't take that sign then we'll have to"
PFnj7GYe-cM,okay so we have to take a sign in there okay now we come to this concept of time borrowing what is time borrowing see in a flop based system data is launched on one rising edge and it should be set up before the next rising edge on the next flop am i right yes yes sir now if it arrives late the system would fail but if it arrives early we know that there is some extra margin left so time is getting wasted anna now consider a large base system the data need not limit itself at the rising edge it can pass through while the latch is transparent entire duration and the logic which is very long can actually borrow timing so since the flop is this since the latch is transparent for the entire let us say positive duration and samples only here i have this extra margin so there is some setup time requirement this extra margin for my data to evaluate of the data of the previous combinational logic to evaluate are you able to see this we saw it in all the equations till now the setup time has we have much more relax on setup time with the in the latch based system and all the equations that we saw we saw that there is a benefit of pulse width that appears when i have to define the setup time meet the setup time requirements so we can overall gain through such a system if we say that uh my this combinational logic is a little longer so this kind of completes after the next phase has even started this combinational logic also completes after the next phase has started let us say so what what are we doing we are borrowing time across boundaries are you able to see this hello some feedback friends so what do we mean by that we are borrowing timing across the boundary so let us consider instead of a latch there was a flop here yes sir could you have slid after the clock cycle clock rising edge no sir so that is what we are meaning by bowering borrowing okay so why we are not like considering the define the clock period as from the falling edge to the falling edge itself no and the rising is from the rising edge then we're seeing that time borrowing is there so we're defining clock period from rising h to rising edge only so yes i'm sensing the y only so we can define it from the falling issue following it then this time boring thing won't we have to consider like separately we can directly do analysis that way no for a for a positive edge triggered latch uh uh the convention is we do it from positive to positive if you can do it from negative negative then the same challenge would come for the negative level triggered latch battery okay now look at the b part down there if there is a loop that is coming into picture then there is a constraint on overall timing are you able to see this so if there was no loop we were simply cascading across the entire system then i would always borrow from the next cycle but if there is a loop and i have borrowed combinational logic delay from here into the second phase then the second phase tpd has to be shorter only i would not have the flexibility to now borrow from this stage itself because already are you able to see this for loops the entire propagation delay should be managed within the clock period if there are no loops i can continue to borrow from subsequent cycles so so what kind of loop are you considering i mean this little thing any loop something happened and you want to give feedback and therefore change the state machine in a different way any loop in the system feedback loops okay i know so if there's a loop then i should make sure that my second stage looking after phi 2 my combination logic should be as small as possible another way within this constraint time which i am given yes okay i know so how much can we borrow natural question is how much can we borrow can i really make it so long that that there is no no no no problem anywhere so we just said that we have to ensure that set of time from the falling edge of clock has to be met is it not so how much can i borrow i can borrow you know if in case of two phase latches i have to borrow like this in case of pulse latches it depends on the pulse width if my pulse width is very small it's in the case of pulsars the perfect is very small then all this is all that i can borrow are you able to see this so pulse latches it is almost uh nothing that you can do yes but if the pulse is big enough then you can see look at it like this if i had it been a flop had it been a flop you would not have been able to borrow anything you would have to ensure that whatever happened it was uh before you know there was this entire set time that you had to be worried about before the rising edge of clock when you have a pulse latch because sampling happens at the falling edge you have this margin so at least benefit but yeah the pulse is very small because that is what we want it to be then that gain is not very significant but there is still some gain some borrowing is still happening or is possible which is absolutely impossible for a flop okay yes sir sir this borrowing time we are constraining it from the first combinational logic but if you look at the second combination logic then we'll have to constrain it from the old side because the combination is getting smaller on that the side logic is smaller than the second combination again as you're absolutely right set up and hold you have to always take care of so non-overlapping should be sufficient enough right yes to avoid those combinational logic things the whole time failures you can increase the non overlaps okay so uh what happens if there is a setup violation in a in a clock system so the setups are violated you reduce the clock speed but if the whole times are violated to fail at fails at any speed to get working chips is the most important requirement you know you want system to be functional on silicon and a way to guarantee non-ho like that whole time failures do not happen is have two phase latches with big non overlap times exactly the same point we were discussing just so that is the benefit of using latches and two-phase clocking but but sir in case we are using two-phase latches even if the chip kind of fails i can increase the normally if i am globally giving the clock yes that is where at least with the two-phase lap system you have a flexibility if you can somehow control the non-overlap period you have the flexibility to recover from a whole failure also provided you had some margins and set up yes so since we're talking about failures we can talk of a safe flip-flop also where we say that we will use two phases of clock see that in the flop we were using one phase of clock only we just saw that by using non overlap systems or by using two phase latches we can have a system which would be robust even in the presence of a whole time failure so can we draw a flop which is safe at all times where there are no hold time failures possible because of non overlaps but we should realize that this non overlap leads to slowing down the system as i was mentioning earlier also that no non overlap is a kind of dead time so it slows down the entire system because it adds to the setup time requirement are you with me great then,https://www.youtube.com/watch?v=PFnj7GYe-cM,"Link: https://www.youtube.com/watch?v=PFnj7GYe-cM
Transcript: okay so we have to take a sign in there okay now we come to this concept of time borrowing what is time borrowing see in a flop based system data is launched on one rising edge and it should be set up before the next rising edge on the next flop am i right yes yes sir now if it arrives late the system would fail but if it arrives early we know that there is some extra margin left so time is getting wasted anna now consider a large base system the data need not limit itself at the rising edge it can pass through while the latch is transparent entire duration and the logic which is very long can actually borrow timing so since the flop is this since the latch is transparent for the entire let us say positive duration and samples only here i have this extra margin so there is some setup time requirement this extra margin for my data to evaluate of the data of the previous combinational logic to evaluate are you able to see this we saw it in all the equations till now the setup time has we have much more relax on setup time with the in the latch based system and all the equations that we saw we saw that there is a benefit of pulse width that appears when i have to define the setup time meet the setup time requirements so we can overall gain through such a system if we say that uh my this combinational logic is a little longer so this kind of completes after the next phase has even started this combinational logic also completes after the next phase has started let us say so what what are we doing we are borrowing time across boundaries are you able to see this hello some feedback friends so what do we mean by that we are borrowing timing across the boundary so let us consider instead of a latch there was a flop here yes sir could you have slid after the clock cycle clock rising edge no sir so that is what we are meaning by bowering borrowing okay so why we are not like considering the define the clock period as from the falling edge to the falling edge itself no and the rising is from the rising edge then we're seeing that time borrowing is there so we're defining clock period from rising h to rising edge only so yes i'm sensing the y only so we can define it from the falling issue following it then this time boring thing won't we have to consider like separately we can directly do analysis that way no for a for a positive edge triggered latch uh uh the convention is we do it from positive to positive if you can do it from negative negative then the same challenge would come for the negative level triggered latch battery okay now look at the b part down there if there is a loop that is coming into picture then there is a constraint on overall timing are you able to see this so if there was no loop we were simply cascading across the entire system then i would always borrow from the next cycle but if there is a loop and i have borrowed combinational logic delay from here into the second phase then the second phase tpd has to be shorter only i would not have the flexibility to now borrow from this stage itself because already are you able to see this for loops the entire propagation delay should be managed within the clock period if there are no loops i can continue to borrow from subsequent cycles so so what kind of loop are you considering i mean this little thing any loop something happened and you want to give feedback and therefore change the state machine in a different way any loop in the system feedback loops okay i know so if there's a loop then i should make sure that my second stage looking after phi 2 my combination logic should be as small as possible another way within this constraint time which i am given yes okay i know so how much can we borrow natural question is how much can we borrow can i really make it so long that that there is no no no no problem anywhere so we just said that we have to ensure that set of time from the falling edge of clock has to be met is it not so how much can i borrow i can borrow you know if in case of two phase latches i have to borrow like this in case of pulse latches it depends on the pulse width if my pulse width is very small it's in the case of pulsars the perfect is very small then all this is all that i can borrow are you able to see this so pulse latches it is almost uh nothing that you can do yes but if the pulse is big enough then you can see look at it like this if i had it been a flop had it been a flop you would not have been able to borrow anything you would have to ensure that whatever happened it was uh before you know there was this entire set time that you had to be worried about before the rising edge of clock when you have a pulse latch because sampling happens at the falling edge you have this margin so at least benefit but yeah the pulse is very small because that is what we want it to be then that gain is not very significant but there is still some gain some borrowing is still happening or is possible which is absolutely impossible for a flop okay yes sir sir this borrowing time we are constraining it from the first combinational logic but if you look at the second combination logic then we'll have to constrain it from the old side because the combination is getting smaller on that the side logic is smaller than the second combination again as you're absolutely right set up and hold you have to always take care of so non-overlapping should be sufficient enough right yes to avoid those combinational logic things the whole time failures you can increase the non overlaps okay so uh what happens if there is a setup violation in a in a clock system so the setups are violated you reduce the clock speed but if the whole times are violated to fail at fails at any speed to get working chips is the most important requirement you know you want system to be functional on silicon and a way to guarantee non-ho like that whole time failures do not happen is have two phase latches with big non overlap times exactly the same point we were discussing just so that is the benefit of using latches and two-phase clocking but but sir in case we are using two-phase latches even if the chip kind of fails i can increase the normally if i am globally giving the clock yes that is where at least with the two-phase lap system you have a flexibility if you can somehow control the non-overlap period you have the flexibility to recover from a whole failure also provided you had some margins and set up yes so since we're talking about failures we can talk of a safe flip-flop also where we say that we will use two phases of clock see that in the flop we were using one phase of clock only we just saw that by using non overlap systems or by using two phase latches we can have a system which would be robust even in the presence of a whole time failure so can we draw a flop which is safe at all times where there are no hold time failures possible because of non overlaps but we should realize that this non overlap leads to slowing down the system as i was mentioning earlier also that no non overlap is a kind of dead time so it slows down the entire system because it adds to the setup time requirement are you with me great then"
G4NA-k88Ys4,so that system is working designers have to leave timing margins for voltage so this is pvt variations so even if your your final silicon is designed typical is manufactured on a typical lot you know that you have already left margins for slow slow lot am i right because you did the sta across entire lots the design is same there could be extra margins that are left for close to a lot for the setup time thing and extra margins left for whole for fast fast slot for the whole thing so designers end up using lots of for leaving lots of margins so that the entire pvt range and you know data dependency or tool and accuracies are well taken care of so what happens even if your manufactured silicon could probably operate at 600 megahertz because you had designed for a slow lot what happens you had to design the system only at 450 megahertz the system cannot operate faster than 450. that's what the challenge is are you able to see this any questions on this part so to correct this type of thing we studied that adaptive voltage scaling we can do something like that adaptive voltage scaling was for different loads different loads means different operational loads but i am over here now talking only of let us say uh sign off at 1.1 volt okay so we cannot change the voltage yes if i am signing off at 1.1 volt then i have lost the frequency there am i right now at 1.1 i am saying don't operate faster than 450 megahertz whereas the silicon that was manufactured could actually have much higher throughput yes so i'm losing for all you know uh in a overall distribution uh lots which are considered slow could only be 20 of the total lots but because of those 20 the remaining 80 percent are also operating slow are not able to give the maximum frequency at which they could operate so the alternative is that you say that okay we'll run faster we'll run faster for everyone now only if there are systems which are failing only if there is a failure we will slow down the frequency so then only in those 20 lots which were slow you are slowing down the frequency the remaining you are operating at 600 megahertz but how do you know that there is going to be a failure at 600 megahertz so for this you use two schemes tannery and razor so do you know what canaries are so so so for the sta we are taking the slow slope pvt corners yes that is the challenge you are mentioning yeah but though i could be operating though my device could be manufactured different ff or typical table conor yeah okay so this is kind of categorization that you are doing like we were talking in the first go in the right direction what i'm saying is that my system could operate at a higher frequency but i am i have constrained it because of my sign of voltage huh how can i remove those constraints so i say okay my system will generate an error signal as soon as there is a failure whenever there is a failure i will reduce the voltage or i will reduce the frequency of operation so this could be used in adaptive systems also where if i say that i have a system which is operating at say 500 megahertz you designed the system and you said okay slow lot works at 450 megahertz at 1.1 volt now your system was designed as typical so it could actually operate at 600 megahertz you wanted to use dvfs dbss we discussed dvfs some time back what is dvfs yes sir we dynamically scale the voltage and frequency load on the processor we said we will reduce the voltage and we will reduce the frequency so i want to do dvfs so i want to reduce from 1.1 volts to let us say 1.0 volts as i do that i may continue to operate at 450 megahertz only and i may find that even at 1.0 volt my system is operational at 450 megahertz simply because it was designed on typical can it happen yes it is so i do not i continue with the same high throughput for as long as possible even though my voltage has lowered so my power consumption has reduced i am giving a different kind of use cases where if i could generate an error signal to tell that oh now my frequency needs to be reduced i can start to gain more from the system are you able to see this these examples are able to understand these examples in terms of timing and i will stop scaling them yes i will start to reduce the frequency of operation then or i will stop i will stop further voltage lowering then okay raghav uh i mean voltage lowering is not considered here right i just give an example of voltage lowering also now so but you said nikki we are giving you different examples okay one example was uh where i said that okay even at 1.1 i could operate at 600 megahertz i will operate only those guys which given a error at 450 others i will operate at 600 that was one example then i said another use case could be that okay 450 megahertz is the speed that i need at 1.1 no problems but i want to reduce power so what do i do i reduce the voltage of operation until i see a failure so instead of 1.1 on a typical lot i will operate at 1.0 or until i see an error so this is called as adaptive voltage scaling frequency has not scaled but voltage has killed so that i could recover leakage and having such canaries or razors in my circuit can help me generate these error flags so what is a canary i come back to my question what is a canary how many of you know no one knows the canary i that dictionary says it is a bird sorry yeah so canary is a very small bird so it's another very sweet musical sound so you know when uh when miners would go into coal mines they would take tanneries along with them these canneries would entertain them throughout the day they would just chirp their song along and they would entertain them throughout the day but entertainment was not the only reason of taking canaries with them into those coal mines see there is the coal mines there is a very big risk the risk is that there could be a fire due to which carbon monoxide levels can increase and uh all the people in the mine can get fixated and die anna so they took calories along tanneries would sing along and they would entertain them but if by chance carbon monoxide levels in the mind would increase tanneries are very small delicate birds they die as soon as carbon monoxide levels increase they're very sensitive to carbon monoxide so as soon as the canary would stop would die the song would stop and everyone knows there is a risk of a fixation they would just evacuate the mine so why are we what is a canary circuit then there is some kind of views okay so calories are circuits which are more sensitive than your actual circuit so if your actual circuit has a timing slack at time of sign off if it has a margin of let us say 100 picosecond the canary circuit that you will put in your system will have a margin of only 50 per second so if somehow delays increase because you lowered the voltages because as you lower the voltage delays would increase the margins on the calorie circuits would reduce or become zero or become negative before margins on actual circuits so canaries would fail first as soon as canary fails you have the error signal and you can stop further lowering are you able to see this yes now then what is razor it's a rate it sounds like it will cut apart all the scaling system so razer stands for razor edge very sharp see with canary what happens i said my minimum margin was 100 per second so i designed my canary with a margin of 50 pico seconds what this also means is that for all the paths for even for those paths for which margin was 500 pico seconds my canary would fail much earlier it could happen it could happen that my uh how do i say it could happen that my critical path which is active as of now had a margin of 500 picoseconds so even at lower voltage it would not have failed i am supposed using only an adder not a multiplier so adder can actually operate at a lower voltage without any failure but my canary because it was designed for the multiplier canary failed can it happen so now i am not able to gain further power recover further power so that is when razor comes in razer says that ok i will check your exact circuit and i will compare it with the delayed version of my signal so only the delayed version is different from the actual one which i have lashed i will say there is another if the delayed is same that means there is no error it's something like what we were discussing earlier in the day where we said that after contamination delay the signal is stable yes that particular signal is stable but the entire signal output may not be stable so what we are looking is when we talking about razor is for every shift resistor for example we could have a sensor which says that okay are the contents of my razor when i sampled different from the contents say hundred picoseconds later if the contents are different you say oh i have sampled something wrong otherwise you say wow i sampled everything correctly let's move ahead and do the next set of calculations you have a question so are these two doing uh doing uh doing doing the same thing like they are generating an error in that sense they are doing the same thing but at the time of designing the philosophy is very different for canary you are making the slowest possible circuit for razer you are not doing any such circuit redesign you are simply sampling the circuit again okay and both these are to basically see what is the edge of my performance is like how fast you can go so this so canaries are not much in fact today because the kind of margins that you have to leave the gains that you can get from canary are not significant but razer is something on which some sufficient amount of research is continuing to happen to make it you know proactively available in in industrial designs uh so if you would want to you know know more about it you will see that there are papers on razors you know improvement in the original razer idea and all that even in very recent years in fact our group has also published some papers on razer over the past some a few people are working on razor techniques even now in this semester your seniors are working on laser techniques so uh this is an area of active research adaptive sequencing and if you're interested you could probably do some projects in the next year this eraser it would be complex right other otherwise i could build that eraser by using some offers and that is why research is happening now that is what we want to simplify can you just give a brief of what what sort of circuits do we use in this razor so razors simply simply or usually require redesign of a flop so that there is an extra latch on the flop the extra latch samples that after some delay only so the data has come the extra the the the output will be latched twice once on the clock edge once on a delayed clock edge if both the data are same you say great if they are different then you say there's an error so it's a much bigger flop that we have when we use razer yes okay so in this razor thing uh the sampling can i for example just for the simply simple understanding can i say that the different intervals the minimum sampling that could be the difference between like uh the between the contamination and the propagation delay uh how you define that margin you know that is not really dependent on contamination and propagation right that's how designers what kind of margin you want to leave that is what defines that okay okay okay so but like in physical implementation that is the kind of the thing that is i can't comment on that there is no such rule okay okay but ultimately it is because that uh sampling ultimately i'm saying that even my data would be stable yeah uh and the earliest at the earliest when my data will be stable so i'm talking about propagation delay data is stable yes sir okay but they connection doesn't come into picture okay okay but there could be different uh variation in that propagation delay itself okay okay okay so yes so uh i'm i want to ask about this razor thing sir you told the data in the clock cycle and the skewed clock cycle will be evaluated and then some kind of xor thing would be done to check i think is it something like that yes and one more thing i wanted to ask that uh there are some universal time constraints that are related to every latches and flip flops like you said the setup should be should not be five percent of the minimum so these and also let's say the pulse width this mainly depends upon the drive drive strength of our uh means internal circuits of the lightning flip flop and,https://www.youtube.com/watch?v=G4NA-k88Ys4,"Link: https://www.youtube.com/watch?v=G4NA-k88Ys4
Transcript: so that system is working designers have to leave timing margins for voltage so this is pvt variations so even if your your final silicon is designed typical is manufactured on a typical lot you know that you have already left margins for slow slow lot am i right because you did the sta across entire lots the design is same there could be extra margins that are left for close to a lot for the setup time thing and extra margins left for whole for fast fast slot for the whole thing so designers end up using lots of for leaving lots of margins so that the entire pvt range and you know data dependency or tool and accuracies are well taken care of so what happens even if your manufactured silicon could probably operate at 600 megahertz because you had designed for a slow lot what happens you had to design the system only at 450 megahertz the system cannot operate faster than 450. that's what the challenge is are you able to see this any questions on this part so to correct this type of thing we studied that adaptive voltage scaling we can do something like that adaptive voltage scaling was for different loads different loads means different operational loads but i am over here now talking only of let us say uh sign off at 1.1 volt okay so we cannot change the voltage yes if i am signing off at 1.1 volt then i have lost the frequency there am i right now at 1.1 i am saying don't operate faster than 450 megahertz whereas the silicon that was manufactured could actually have much higher throughput yes so i'm losing for all you know uh in a overall distribution uh lots which are considered slow could only be 20 of the total lots but because of those 20 the remaining 80 percent are also operating slow are not able to give the maximum frequency at which they could operate so the alternative is that you say that okay we'll run faster we'll run faster for everyone now only if there are systems which are failing only if there is a failure we will slow down the frequency so then only in those 20 lots which were slow you are slowing down the frequency the remaining you are operating at 600 megahertz but how do you know that there is going to be a failure at 600 megahertz so for this you use two schemes tannery and razor so do you know what canaries are so so so for the sta we are taking the slow slope pvt corners yes that is the challenge you are mentioning yeah but though i could be operating though my device could be manufactured different ff or typical table conor yeah okay so this is kind of categorization that you are doing like we were talking in the first go in the right direction what i'm saying is that my system could operate at a higher frequency but i am i have constrained it because of my sign of voltage huh how can i remove those constraints so i say okay my system will generate an error signal as soon as there is a failure whenever there is a failure i will reduce the voltage or i will reduce the frequency of operation so this could be used in adaptive systems also where if i say that i have a system which is operating at say 500 megahertz you designed the system and you said okay slow lot works at 450 megahertz at 1.1 volt now your system was designed as typical so it could actually operate at 600 megahertz you wanted to use dvfs dbss we discussed dvfs some time back what is dvfs yes sir we dynamically scale the voltage and frequency load on the processor we said we will reduce the voltage and we will reduce the frequency so i want to do dvfs so i want to reduce from 1.1 volts to let us say 1.0 volts as i do that i may continue to operate at 450 megahertz only and i may find that even at 1.0 volt my system is operational at 450 megahertz simply because it was designed on typical can it happen yes it is so i do not i continue with the same high throughput for as long as possible even though my voltage has lowered so my power consumption has reduced i am giving a different kind of use cases where if i could generate an error signal to tell that oh now my frequency needs to be reduced i can start to gain more from the system are you able to see this these examples are able to understand these examples in terms of timing and i will stop scaling them yes i will start to reduce the frequency of operation then or i will stop i will stop further voltage lowering then okay raghav uh i mean voltage lowering is not considered here right i just give an example of voltage lowering also now so but you said nikki we are giving you different examples okay one example was uh where i said that okay even at 1.1 i could operate at 600 megahertz i will operate only those guys which given a error at 450 others i will operate at 600 that was one example then i said another use case could be that okay 450 megahertz is the speed that i need at 1.1 no problems but i want to reduce power so what do i do i reduce the voltage of operation until i see a failure so instead of 1.1 on a typical lot i will operate at 1.0 or until i see an error so this is called as adaptive voltage scaling frequency has not scaled but voltage has killed so that i could recover leakage and having such canaries or razors in my circuit can help me generate these error flags so what is a canary i come back to my question what is a canary how many of you know no one knows the canary i that dictionary says it is a bird sorry yeah so canary is a very small bird so it's another very sweet musical sound so you know when uh when miners would go into coal mines they would take tanneries along with them these canneries would entertain them throughout the day they would just chirp their song along and they would entertain them throughout the day but entertainment was not the only reason of taking canaries with them into those coal mines see there is the coal mines there is a very big risk the risk is that there could be a fire due to which carbon monoxide levels can increase and uh all the people in the mine can get fixated and die anna so they took calories along tanneries would sing along and they would entertain them but if by chance carbon monoxide levels in the mind would increase tanneries are very small delicate birds they die as soon as carbon monoxide levels increase they're very sensitive to carbon monoxide so as soon as the canary would stop would die the song would stop and everyone knows there is a risk of a fixation they would just evacuate the mine so why are we what is a canary circuit then there is some kind of views okay so calories are circuits which are more sensitive than your actual circuit so if your actual circuit has a timing slack at time of sign off if it has a margin of let us say 100 picosecond the canary circuit that you will put in your system will have a margin of only 50 per second so if somehow delays increase because you lowered the voltages because as you lower the voltage delays would increase the margins on the calorie circuits would reduce or become zero or become negative before margins on actual circuits so canaries would fail first as soon as canary fails you have the error signal and you can stop further lowering are you able to see this yes now then what is razor it's a rate it sounds like it will cut apart all the scaling system so razer stands for razor edge very sharp see with canary what happens i said my minimum margin was 100 per second so i designed my canary with a margin of 50 pico seconds what this also means is that for all the paths for even for those paths for which margin was 500 pico seconds my canary would fail much earlier it could happen it could happen that my uh how do i say it could happen that my critical path which is active as of now had a margin of 500 picoseconds so even at lower voltage it would not have failed i am supposed using only an adder not a multiplier so adder can actually operate at a lower voltage without any failure but my canary because it was designed for the multiplier canary failed can it happen so now i am not able to gain further power recover further power so that is when razor comes in razer says that ok i will check your exact circuit and i will compare it with the delayed version of my signal so only the delayed version is different from the actual one which i have lashed i will say there is another if the delayed is same that means there is no error it's something like what we were discussing earlier in the day where we said that after contamination delay the signal is stable yes that particular signal is stable but the entire signal output may not be stable so what we are looking is when we talking about razor is for every shift resistor for example we could have a sensor which says that okay are the contents of my razor when i sampled different from the contents say hundred picoseconds later if the contents are different you say oh i have sampled something wrong otherwise you say wow i sampled everything correctly let's move ahead and do the next set of calculations you have a question so are these two doing uh doing uh doing doing the same thing like they are generating an error in that sense they are doing the same thing but at the time of designing the philosophy is very different for canary you are making the slowest possible circuit for razer you are not doing any such circuit redesign you are simply sampling the circuit again okay and both these are to basically see what is the edge of my performance is like how fast you can go so this so canaries are not much in fact today because the kind of margins that you have to leave the gains that you can get from canary are not significant but razer is something on which some sufficient amount of research is continuing to happen to make it you know proactively available in in industrial designs uh so if you would want to you know know more about it you will see that there are papers on razors you know improvement in the original razer idea and all that even in very recent years in fact our group has also published some papers on razer over the past some a few people are working on razor techniques even now in this semester your seniors are working on laser techniques so uh this is an area of active research adaptive sequencing and if you're interested you could probably do some projects in the next year this eraser it would be complex right other otherwise i could build that eraser by using some offers and that is why research is happening now that is what we want to simplify can you just give a brief of what what sort of circuits do we use in this razor so razors simply simply or usually require redesign of a flop so that there is an extra latch on the flop the extra latch samples that after some delay only so the data has come the extra the the the output will be latched twice once on the clock edge once on a delayed clock edge if both the data are same you say great if they are different then you say there's an error so it's a much bigger flop that we have when we use razer yes okay so in this razor thing uh the sampling can i for example just for the simply simple understanding can i say that the different intervals the minimum sampling that could be the difference between like uh the between the contamination and the propagation delay uh how you define that margin you know that is not really dependent on contamination and propagation right that's how designers what kind of margin you want to leave that is what defines that okay okay okay so but like in physical implementation that is the kind of the thing that is i can't comment on that there is no such rule okay okay but ultimately it is because that uh sampling ultimately i'm saying that even my data would be stable yeah uh and the earliest at the earliest when my data will be stable so i'm talking about propagation delay data is stable yes sir okay but they connection doesn't come into picture okay okay but there could be different uh variation in that propagation delay itself okay okay okay so yes so uh i'm i want to ask about this razor thing sir you told the data in the clock cycle and the skewed clock cycle will be evaluated and then some kind of xor thing would be done to check i think is it something like that yes and one more thing i wanted to ask that uh there are some universal time constraints that are related to every latches and flip flops like you said the setup should be should not be five percent of the minimum so these and also let's say the pulse width this mainly depends upon the drive drive strength of our uh means internal circuits of the lightning flip flop and"
bMuk48cJnPA,what are the arithmetic circuits by the way what do you understand by the term arithmetic circuits you've seen the slides the slides were already put online how many of you have seen the sites by the way i've been putting them online in advance but how many of you have seen them you can just raise your hand and i will know okay so out of 40 around six people have fifteen percent seven people fifteen percent of the class let us say okay not bad so uh what are the arithmetic circuits actually you should be able to respond so for performing arithmetic operations we need editors and subtractors all these things so these are the arithmetic good and when we talk of these adders and subtract subtractors and multipliers what is the most important thing that we need to be you know looking for so one thing is the logically correct circuit other thing is that uh we need to make sure that in a fixed amount of delays we get some output for example if the carry is propagating over the over the adders then it should be coming in some defined worst case dealing that should be the most critical part of it and you want to reduce that worst case delay it's not just that you late i but it's also that you want to reduce that first case delay am i right okay so deepansi i see your hand raised did you raise it when i asked about the slides or do you have a question no sir about the slides okay so you can lower your hand just give me a minute sure so arithmetic circuits are very commonly used wherever you have a processor for example you know this is a typical or a very top-level view of a processor where you would have some data paths and a memory inputs and outputs and a control part and in this data path you will have you know for example what is called as adders multipliers shifters comparators etc all of that the control part would have finite state machines counters and so these are the different components that you will see in this digital digital processor let us say memories and interconnects with arbitration units and buses and switches and so on so in this lecture we are spent we are intending to spend time on arithmetic circuits in the next lecture we will be spending time on memory circuits okay again this is just a top level glimpse and this is in by no way an intent to make you an expert on adders or multipliers or even memories if you want to do learn more about memories i would suggest take up the memory design course in the next semester for adders multipliers take up a capstone project or a another project like that where you can study more about them and design them if uh you know if you wish to so that would be a preferred mode of learning more about arithmetic circuits in terms of address multipliers and the like okay so uh a typical data path you know for example if i say that there is a 64-bit processor over here i have shown a 4-bit processor so a typical data path is uh so if i say there are 64 bits in a processor then what could be done it could be that a a bit would enter over here there is a 32-bit adder here uh there is a 32-bit multiplier here so the bit would go all like this this a circuit just route but any bit can take any word can't take but that is not really optimal so what is typically done is that data paths are designed as bit slices so over here you will have let us say a 0 b 0 going in and that will result in the output b0 uh o0 let us put it as o0 okay the next slice would have a1 and b1 going in and the final output would be o1 so they are organized and arranged in such a way that data flow is kind of streamlined it's it's fast it doesn't waste time in neither interconnects or other stuff and in your data path you that is how you include registers and adders and multipliers and shifters and everything there if some particular function is not required on a data that particular block is simply skipped by bypass and you run out okay so a slightly complex stuff you know would mean that in addition to just multiplexes and shifters you could actually have adders implemented also in stages in the sense that if you look at the previous slide we said adder is one stage shifter is another stage however in this slide what i'm saying is that an adder just so that you have a fast addition possible may be split into multiple stages and you may have one stage of adder over here second stage and third stage as you move on and but they're all in terms of bit slices only this is bit slice zero this is bit slice one and the like are you able to see this any questions still here sir is it just to enable more parallelism right uh anyway if you have to add 32 bits you have to add 32-bit so there has to be some parallelism in there we will as we look into the address just ask about addressing when we will start to look into the adders you will see what i mean by address stage 1 either stage 2 and other stage three we will talk about tree adders and that is where this this concept will become more evident but uh yeah you're in in a data path you're processing all the different bits in parallel there could be interconnects between them for example we showed that if you if you notice over here we are showing that there is this some output from bit 0 going to some other bit some output from bit 0 going to another bit somewhere in the data path so there could be some such interconnects also okay uh but they are running in parallel largely they are running in parallel okay answer what is this loop that must uh this is uh information going back saying that okay there is an overflow or there is uh so system level bus it is which which would give information to close any loops that were there no okay now addition is completed so you can accept the next input it could be ready signal that could be those things okay yes so what are shifter what are shifters shifters are shift resistors where you the number of clock cycles you give it will just rotate the like barrel shifters they will just rotate the word in there so shifter could be used to manage the pipeline stages if we give serial input and we take parallel output so anything like that uh shifter is a set of flip flops so in those terms uh you can think of using them as a scan chain also yes uh no problem with that but shifters barrel shifters are not just for for pipeline power shifters are barrel shifters which could be a part of say multiplication and division also yes ranjit uh sir so basically this bit uh big slice represents the complete data path right for one bit but how can we just be sure that in a particular architecture the data path for suppose if you have n uh bit slices then all the n-bit slices are identical it's not very they may not be they may not be in this case it says you've taken bit zero output of adder stage one and we have merged it or taken it to taken it as an input to let us say bit slice seven okay then in the second second wiring stage we've taken the output of bit 0 into something like bit 55 i know so need not be we're not saying they are symmetrical what we are saying is data path is in one flow okay this is just to streamline so that when you design you do not also uh you know have errors end up end up with errors because of some confusion or interconnects because when we will see just a little while later tree adders you will see there are so complex interconnects but it's better to separate it like this okay sir okay rajneesh sir in the previous slide in the bit slide bit slice design separate register was given in a bit slide but in this one in this diagram there is no separate register means in the bit slice yeah so you if you if you look at the previous slide they were adding that resistor to latch the incoming data that's fine there are two different architectures they would these guys would uh in the second bit slice over here uh possibly they're already saying that if this is coming from a register file is it not here it has considered it as a common one yeah it is coming from a register file already so we do not need to register it again yes and one more thing sir sorry in this you said that this bit slices of one bit but sorry in previous slide uh it is a four bit uh bit slice no this is a bit slice oh okay so here okay yes yeah okay anything else so just just a clarification sir if if i have a bit slice let's say if it is a it is a very very simple circuit of a mux so in a bit slice we can say that uh many out and output of many bit slices can converge into a single a single one like in a multiplexer many inputs are there there is only one out uh not necessary it could be that i have four inputs coming for every multiplexer and those four inputs are available separately for all the bits and i select just one out of those happens now so it could happen that my let us say my data path is just for the sake of area i redo i kept the data power back 16 bits but my total words were 64 bits now there is a data path of 16 bits but my overall word width is 64. so what would i do i would organize my words in such a way that words 0 to 15 are processed in the first cycle then word 16 to 31 are processed in the second cycle then word 32 to 47 are processed in the third cycle and so on aging kind of thing uh paging yes could be but there could be more than one inputs coming to the multiplexer at the level of the multiplexer which then is conversion to one and then the entire shifter adder stage one etcetera goes on,https://www.youtube.com/watch?v=bMuk48cJnPA,"Link: https://www.youtube.com/watch?v=bMuk48cJnPA
Transcript: what are the arithmetic circuits by the way what do you understand by the term arithmetic circuits you've seen the slides the slides were already put online how many of you have seen the sites by the way i've been putting them online in advance but how many of you have seen them you can just raise your hand and i will know okay so out of 40 around six people have fifteen percent seven people fifteen percent of the class let us say okay not bad so uh what are the arithmetic circuits actually you should be able to respond so for performing arithmetic operations we need editors and subtractors all these things so these are the arithmetic good and when we talk of these adders and subtract subtractors and multipliers what is the most important thing that we need to be you know looking for so one thing is the logically correct circuit other thing is that uh we need to make sure that in a fixed amount of delays we get some output for example if the carry is propagating over the over the adders then it should be coming in some defined worst case dealing that should be the most critical part of it and you want to reduce that worst case delay it's not just that you late i but it's also that you want to reduce that first case delay am i right okay so deepansi i see your hand raised did you raise it when i asked about the slides or do you have a question no sir about the slides okay so you can lower your hand just give me a minute sure so arithmetic circuits are very commonly used wherever you have a processor for example you know this is a typical or a very top-level view of a processor where you would have some data paths and a memory inputs and outputs and a control part and in this data path you will have you know for example what is called as adders multipliers shifters comparators etc all of that the control part would have finite state machines counters and so these are the different components that you will see in this digital digital processor let us say memories and interconnects with arbitration units and buses and switches and so on so in this lecture we are spent we are intending to spend time on arithmetic circuits in the next lecture we will be spending time on memory circuits okay again this is just a top level glimpse and this is in by no way an intent to make you an expert on adders or multipliers or even memories if you want to do learn more about memories i would suggest take up the memory design course in the next semester for adders multipliers take up a capstone project or a another project like that where you can study more about them and design them if uh you know if you wish to so that would be a preferred mode of learning more about arithmetic circuits in terms of address multipliers and the like okay so uh a typical data path you know for example if i say that there is a 64-bit processor over here i have shown a 4-bit processor so a typical data path is uh so if i say there are 64 bits in a processor then what could be done it could be that a a bit would enter over here there is a 32-bit adder here uh there is a 32-bit multiplier here so the bit would go all like this this a circuit just route but any bit can take any word can't take but that is not really optimal so what is typically done is that data paths are designed as bit slices so over here you will have let us say a 0 b 0 going in and that will result in the output b0 uh o0 let us put it as o0 okay the next slice would have a1 and b1 going in and the final output would be o1 so they are organized and arranged in such a way that data flow is kind of streamlined it's it's fast it doesn't waste time in neither interconnects or other stuff and in your data path you that is how you include registers and adders and multipliers and shifters and everything there if some particular function is not required on a data that particular block is simply skipped by bypass and you run out okay so a slightly complex stuff you know would mean that in addition to just multiplexes and shifters you could actually have adders implemented also in stages in the sense that if you look at the previous slide we said adder is one stage shifter is another stage however in this slide what i'm saying is that an adder just so that you have a fast addition possible may be split into multiple stages and you may have one stage of adder over here second stage and third stage as you move on and but they're all in terms of bit slices only this is bit slice zero this is bit slice one and the like are you able to see this any questions still here sir is it just to enable more parallelism right uh anyway if you have to add 32 bits you have to add 32-bit so there has to be some parallelism in there we will as we look into the address just ask about addressing when we will start to look into the adders you will see what i mean by address stage 1 either stage 2 and other stage three we will talk about tree adders and that is where this this concept will become more evident but uh yeah you're in in a data path you're processing all the different bits in parallel there could be interconnects between them for example we showed that if you if you notice over here we are showing that there is this some output from bit 0 going to some other bit some output from bit 0 going to another bit somewhere in the data path so there could be some such interconnects also okay uh but they are running in parallel largely they are running in parallel okay answer what is this loop that must uh this is uh information going back saying that okay there is an overflow or there is uh so system level bus it is which which would give information to close any loops that were there no okay now addition is completed so you can accept the next input it could be ready signal that could be those things okay yes so what are shifter what are shifters shifters are shift resistors where you the number of clock cycles you give it will just rotate the like barrel shifters they will just rotate the word in there so shifter could be used to manage the pipeline stages if we give serial input and we take parallel output so anything like that uh shifter is a set of flip flops so in those terms uh you can think of using them as a scan chain also yes uh no problem with that but shifters barrel shifters are not just for for pipeline power shifters are barrel shifters which could be a part of say multiplication and division also yes ranjit uh sir so basically this bit uh big slice represents the complete data path right for one bit but how can we just be sure that in a particular architecture the data path for suppose if you have n uh bit slices then all the n-bit slices are identical it's not very they may not be they may not be in this case it says you've taken bit zero output of adder stage one and we have merged it or taken it to taken it as an input to let us say bit slice seven okay then in the second second wiring stage we've taken the output of bit 0 into something like bit 55 i know so need not be we're not saying they are symmetrical what we are saying is data path is in one flow okay this is just to streamline so that when you design you do not also uh you know have errors end up end up with errors because of some confusion or interconnects because when we will see just a little while later tree adders you will see there are so complex interconnects but it's better to separate it like this okay sir okay rajneesh sir in the previous slide in the bit slide bit slice design separate register was given in a bit slide but in this one in this diagram there is no separate register means in the bit slice yeah so you if you if you look at the previous slide they were adding that resistor to latch the incoming data that's fine there are two different architectures they would these guys would uh in the second bit slice over here uh possibly they're already saying that if this is coming from a register file is it not here it has considered it as a common one yeah it is coming from a register file already so we do not need to register it again yes and one more thing sir sorry in this you said that this bit slices of one bit but sorry in previous slide uh it is a four bit uh bit slice no this is a bit slice oh okay so here okay yes yeah okay anything else so just just a clarification sir if if i have a bit slice let's say if it is a it is a very very simple circuit of a mux so in a bit slice we can say that uh many out and output of many bit slices can converge into a single a single one like in a multiplexer many inputs are there there is only one out uh not necessary it could be that i have four inputs coming for every multiplexer and those four inputs are available separately for all the bits and i select just one out of those happens now so it could happen that my let us say my data path is just for the sake of area i redo i kept the data power back 16 bits but my total words were 64 bits now there is a data path of 16 bits but my overall word width is 64. so what would i do i would organize my words in such a way that words 0 to 15 are processed in the first cycle then word 16 to 31 are processed in the second cycle then word 32 to 47 are processed in the third cycle and so on aging kind of thing uh paging yes could be but there could be more than one inputs coming to the multiplexer at the level of the multiplexer which then is conversion to one and then the entire shifter adder stage one etcetera goes on"
OiDXtgAKLU0,yes Okay so this is one photograph of a of a data path hardened data path and you will notice that it is not really symmetrical for all bits as it was saying it is not really symmetrical for all bits but yeah it's fine so we come into adders now what is an adder or are you able to see this functionality this truth table can you validate this is a correct truth table for the adder so what's this carrying status in which delete and propagate and generate are like that's a different thing are you able to validate the otherwise came up yes sir yes yes sir so now let us look at the last column what is Carry status so let us say that uh there was the inputs A and B were both zero hmm then independent of CI what will happen to co will be 0. are you able to see this yes sir now if either of A or B was one if either of them was one do you realize that whatever be the carry in it will be propagated further hello yes sir yes and when both A and B are 1 then again whatever we the CN C how it is definitely one are able to see this also yes sir so this is what we want to say or this is what this delete delete means whatever with the CN C out will be 0. propagate means whatever with the CN that will be propagated on C out generate means whatever be the same C out will be 1. are you able to see this yes so that is what Carry status means this this becomes important as we will look at uh uh implementation a typical or a very basic implementation of the slider would appear to be something like this that s is equal to 1 so we what we do we look at this this K map and we start to say okay it is or there is a one over here no no sorry we say okay my S is one over here then it is 1 over here and one over here and my C out is one over here and here so you you start to merge and you start to see if you could have K Maps uh being used to arrive at a logic and when you do that you arrive at this kind of a k map that s is one then either of these four Constructors one and see how it is one then either of these constructs is equal to 1. this is how you you must have done adders earlier also this is a simple adder full adder huh so we say that okay in the same order we we have used a b and c and then we have used inverts of B and inverse of c and inverse of a to make our logic of s so probably I will need a lot of gates to do it can I do it simpler so we say okay there was this information of delete propagate and generate at least that much I can use for generating carry out so we say that okay we express sum and carry as a function of propagate generate and delete only where carry out can be can be uh represented are represented as a sum of G Plus PCI be propagate a propagate is one then whatever is the CI comes on there or carry generated either carry generated or carries propagated and therefore CI becomes C out and S is that my propagate should be one it's a czar of propagate and CI in fact uh just to make our logic a little simpler use lesser number of devices many times you will use propagate as a or b because in A or B situation also whatever is the CN whenever CN has one you will propagate that are you able to see this see for C out I already have G there that is if a and b both are 1 I will have G equal to 1. so if c i was 0 in that case also I could say that let me use propagate as one because C out will be given as 1 from here generate generate part itself so many times just to make a logic simpler we may want to use propagate as a or b instead of a is or B so what is a plus b we could have said this from the truth table also from the truth table it is not really a plus b look at it uh if it was a plus b then uh in one one would also result in the yes this would have resulted in propagate but this has resulted in generate henna um that is not the case so in in actual terms it is generate but even if you call it propagate it doesn't matter because the co has to be generated the CI has CI will be one there I know because of generate you have used the variable as a or b a a and b so A and B are one so C of C naught can happen already are you able to see this yes so can you please like I got confused in this part why we are using uh two expressions for a propagate so you use only one expression A or B okay so but why why we are using two here I understood your point that I can use one and I'll get the functionality done but why two why to do it why two values of propagate two by expression for propagates see the exact expression is a is or B but we said that even if we use the expression of a or b yes sir C naught and S will not be different given this expression G is equal to C is caught is equal to g plus PCI and S is equal to P is our c i so these two outputs will still remain same even if I use propagate as a or b but or gate is much simpler than as or gate yeah yes that is why okay okay thank you take care yes so here it is written uh can also be expressed by a sum and Carry Out can also be expressed in terms of D and P yeah but I think instead of using D if we use G it would be more I think I think when you will Implement by using D two more inverter should be required right uh you see but you will need inverse of a and b s but uh just work it out it is not saying this is the minimum the the one with D and P will be the minimum gate implementation it says if you have dnp available with you even then you can Implement test and see now what it essentially intends to communicate is you need to do either of generate you need to do either generate or kill don't need to do both yes yes so even though we want we want to express some and carry as functions of PG and d p and either G or D will work for us yes okay that's the intent over here so now that was one bit adder if we have to make a four bit Adder what do we do we simply just say Okay this C out of bit 0 is C enough bit one and see out of one is C in of bit 2 and so on so what happens uh once the C out of 0 is generated it goes as seen of the second act full adder then third full adder then fourth full adder and then you get the output so what is happening I am Rippling the carry from one full adder to another and what is the uh worst case delay if as I increase the number of bits the number of hops increases linearly and therefore this is order n and what we also understand is that carry in to carry out paths should be as fast as possible are you able to see this these two aspects um yes sir so now if we go ahead and you know try to implement that full adder which this functionality in terms of a CMOS logic you would get a 28 transistor implementation something like this so you can you can do it at your on leisurely time where you will see that this is G A and B and then this is uh C and A or B hmm so this is your C out and similarly you will get your sum also based on by implementing whatever logic we had given there is this clear yes sir uh so in the last slide I have a question yes so here T Adder equal to n minus 1 T carry plus T some third just T some student it will be maximum of 3 sum and T Theory uh exactly the right to have the same understanding so let us look at this path uh what happens you realize that a b and everything was stable already these parts are stable already is it not when your carry came what what require what was required to be done when your carry came you only need to evaluate these parts of the gate Hannah so uh and you notice that CI has been kept as close to the output as possible so that the delay from C to out is minimum that is the delay mentioned as C sum or t sum whereas from a to sum or B to sum the delay could be slightly higher okay so already we have decreased the delays internally from from carry 2. from carry 2 yes so uh there is a different delay for generating a carry that is evident because delay to generator carry is this path delay to generate a sum is this path you know so this sum depends upon the voltage at node X which is also one of the inputs so it constitutes this entire path for next two years so yeah that can cause more delay for us than CO2 yeah done okay so what is also now important to see is that if you have a adder then you could actually have a invert Adder also there so what has happened over here you have a full adder over here you have inverted all the inputs and you say okay your output should also be inverted so S Bar of avci is equal to sum of a bar B Bar C A by CI bar and so on by using this inversion property what do you do you say okay I will not I will at least not use this inverter this one we may have to use but at least Joe C naught you see how generate currently inverter I can avoid using that and I would have see out going directly to the inverted full adder the next one I will have a regular full adder and then and again an inverted full adder so if you do it like this then what happens the total number of transistors in your system reduces because you don't need to put those additional inverters at the end of it so there are two things that are evident that there is a focus on reducing delay and then there is a focus on reducing area also because this is a large number of devices 28 transistors so we want the delay to be less but we want this number of devices also to be less so that is where figures in this mirror adder where you will see that the nmos and the pmos parts are kind of mirrors of each other and again uh the the circuit works fine where you say that okay you give CI from here and you get Co Sea House Bar and you get S Bar as outputs there Tigger so you can at at your own Leisure evaluate that this is this works fine this is fine for uh the functionality that you want to achieve for both C naught and S so but this uh this particular topology will be uh valid only if you have even number of stages right sir if you have odd number of stages then once again we need to add inverter at the subject and that we can just add on the last inverter last stage yes so this one inverter will come not it will not come 25 times yes sir so that we can always dominate appropriately so what are we talking about so for the mirror error for example we are saying that what you've done is the nmos and pmo stacks are completely symmetrical they are very similar to each other and uh I think from the discussion that we have had till now you must have already realized that the load on C out or the capacitances linked to generation of C out should be kept as low as possible why is that why should the capacitance is linked to generation of cob kept as low as possible because the carry has to propagate through the stages of Adder yes because the carry out of your state will go to the next stage then again the entire carry out will be new carry out will be generated for the next stage and so on at least if the propagation is going to happen so that is what we are looking at that we have to reduce the capacitances also we have to reduce the delays as you reduce the capacitances power and delay will automatically reduce hmm is that clear okay then see we looked at that what we looked at just now was a ripple Adder where data would you know move from a carry outward move from here to here to here finally giving a carry out three it's a very long path see the sum path is very short is very long especially if you have large number of bits so you will see that in the next few slides they're all we're just talking about how to anticipate the carry so one way is bypass the evaluations of uh C out for all these stages simply see if the overall P0 P1 P2 P3 are all one if they're all one then what you say is that okay since all the propagates are one then whatever was there on CI will definitely come on C out also are you with me any questions so we are saying is all the propagate servers so the uh the input carry will be reflected at the output directly yeah that we have studied okay yes hello so uh if we do it like that then what happens we have carry bypass for uh first four bits then we have carry bypass for the next four bits then we have carry bypass for the next four bits and so on so if there are total number of embeds then what is the total delay of the adder you will see the total delay of the adder would reduce would reduce such that uh you will have uh n divided by m minus 1. so the total number of delays that you will now need to see is what is the critical path the critical path would be something like this Hannah so would the largest delay also decrease just the largest delay yes it would decrease because uh earlier like uh it would decrease if you're using the propagate and kill valid topology because if you're not using propagate and kelvala thing then what happens is that all a b and c n will be calculated from Top dot top bottom and then we will arrive somewhere at sum and Carry Out however because you are using propagate and generate thing you already know what the C out could be uh much faster you don't need to evaluate after this comes you know what is the status of PNG the multiplexer inputs are already set and you either propagate or regenerate so it says time we'll see how it saves time further also but this saves time because now your Ripple is only for M number of bits so you'll see initially it appears that when the total number of bits is very less a bypass Adder because of its uh more complex logic and a multiplexer in there and so on may take a little extra delay however when you're talking about large number of bits say 32 64 128 or so on then Ripple Larry is much much slower than bypass Adder right and it is a consequence of these equations only nothing else okay any questions sir in the previous slides someone slider yeah can you explain this n by m minus one t by bus term once again okay so let us say this is 16 bit Adder Hannah this is 16-bit order how many bypass would it take would it pass through so first before that how many bits how many bits in one stage four hello yes sir so if you have a data Adder coming or set of inputs coming from here this this is the while this is being evaluated this part of data would have already been ready yes sir similarly here things would already be ready yes so when you are uh when you want to find the total delay what are you looking at setup delay plus carry generation delay Plus number of these that will be there n by m minus 1 so actually n by M minus 1 over here you can see so we know that okay 16 bits have been brought into have been split into four bits each so we would have of 4 minus one n by n by m 2 8 may be a parallel T by passes the delay of let us say this multiplexer yes yes because yes yes uh sir in case in all the bit 0 to 3 4 7 8 to 11 and 12 to 15. if this condition is not satisfied that p 0 P 1 p 2 p 3 is equal to one then in that case none of the carry would be directly going uh without without facing the carry propocational so if the propagations are not all all ones if the propagates are not all ones then what happens when you anyway do not be you will not be Rippling the carry to the entire path so your overall delay will actually be lesser only whatever was evaluated here earlier would already be valid we are talking about the worst case delay where you say okay the Ripple has to happen through the entire system hmm because if there is some p p and g equal to 0 at some bit whichever bit it is then it means that the evaluation that was done for higher bits than this were already clean because c c n was anyway 0 and it will remain zero it will not change it oh yes so as you increase the total number of bits you see that bypass Adder has much better performance than Ripple Adder but it has much more circuit also in there to be able to do all these through the automatic like so there is a setup circuit and so on which would be there ranjith you have a question oh yes sir in the previous slide okay sir I understood how we get the teacher M times the T carry uh plus uh n by m minus 1 times the T bypass but why once again we have M minus 1 times the T carries this this one I didn't understand Okay so all right let me show the variables are different this is this variable is MP carry and this variable is M minus 1 and 2 T Curry okay but y m minus 1 into 3 T carries but I didn't understand because always if we consider one single bypass stage the carry generation will happen parallely for all of them so and then we'll like uh bypass this for the first for the first stage that carry generation you have to still count now eight bar two you will have to count okay then you add the delays of uh various ones and for this one and it says there are if there are M bits then that would mean M minus 1 times Ripple could happen at least in this one is it not even for a four bit thing even for a 4-bit thing if the carry has to be generated like this every three ripples happening inside it is it not yes yes that is why okay yes sir Okay so is it clear till there is your hand is still raised anything pending there okay so this was where we were actually using the carry to re-evaluate the circuit and arrive at an output if we are ready to give area then another idea could be assume that carry could be zero and assume that carry n could be 1. and calculate and calculate C out for both the cases depending on the value of c c out of K minus 1 stage that is the first the C in of this four bit circuit you can choose whether this one has to be used or this one has to be used in this case carry calculation is actually happening completely in parallel and you're just having a multiplexer at the output stage are you able to see this so in in other parts we were simply doing uh one circuit which was doing generate propagate that kind of function um over here uh we said okay all that generate propagate you do it for both CN is equal to 0 and C N equal to 1. depending on what was the value of c n I will choose the output directly at the multiplexer stage so now you even if you go to 128 bits all will run parallel and all that I need to do is the previous stage output goes as seen over here or goes as multiplexer input over here so the delay is reduced further um look at this example what we say bit 0 to 3 I calculate the output with zero carry I have calculated the output with one carry and then I use the carry in as the select signal for the multiplexer and I will get the sum generated and I will get the CO3 also hmm and the worst case critical path is as marked over here are you able to see this any questions no questions so successfully you are breaking the adder two times uh for each stage and then you are letting the other other stages evaluate according to the carry equal to 0 and 1 and then you are selecting based upon what is the carriage that you get from the previous one yes so doesn't this architecture result in exponential rise in the area consumption yeah yeah definitely instead of just one Carriage uh one one evaluation circuit you're putting two evaluation circuits one for carrying equal to zero one for carrying equal to one but the delay is also reducing okay I know so if we look at it uh if we look at it a slightly more advanced versions of this so over here notice we're talking about as 0 to 3 S 4 to 7 as 8 to 11 s 12 to 12 12 to 15. in a more advanced version uh or you know when we have it as this then this is what my total added delay is that uh plus n by m into T carry plus M into T marks plus T sum so this is this is what you would get as the overall delay of the system however another interesting way is you say that okay over here there are only two bits over here there are three bits or over here there are four bits and so on so I'm gradually increasing the total number of bits that my this system is taking up why am I doing that is a bit where is the concept of logical effort at the end stages near the output we increase the size so that we get the optimal deal not exactly so the output is the s0 and 1 are also outputs output but as 0 and 1 are also outputs foreign yeah see what is happening is you know that uh let us go to the previous slide you know that uh to arrive at this stage I will go through not only this but also this horizontal delay are you able to see this so by the time this c0 and C11 comes as the output 11 comes I would already already be waiting at the input of the multiplexer so I say why wait instead of calculating a ripple across four bits only I actually have more time now so I can calculate triple across 5 bits or 6 bits huh and when you do that uh what you achieve is that even though you are Rippling across five or six bits here because they are most most significant bits or close to the most significant bits the select signal anyway would take long time to come here hmm so so it's like time borrowing from it's like uh borrowing the time basically yeah you're using the extra time that is available to you because these extra multiplexer are also in the path and adding one more stage there let us say not stage one more bit in one in a in this kind of uh setting and this is how the delays change see this is Ripple carry this is linear select and this is the last square root select that we just did so you will not see much difference at the lower number of bits but today as we are talking about 64-bit processors and then probably 128 bit in a little while then you will see that this this part at and more number of bits uh square root select or linear add linear select adders are much faster so you can you can choose which one to use okay is it clear till here had a very small doubt I think uh like the two slides before can we go our previous close slides uh sir in this why don't uh we uh make the zero carry and one carry Adder parallel to each other and then give those inputs to mugs or if that's in parallel notice okay setup is going here and setup is going here also in parallel is represented like this they are going in parallel only okay okay thank you yeah so after the carry select address uh you must have heard about what is called last carry lookahead address also hmm so what do Carolina candidates do they do something similar to this select thing and uh they say that uh as you go into the higher bit there will be more time and therefore you could have a longer path set in there so what is the idea behind it you say that okay to be able to anticipate the output over here I don't need to wait for ripples or even inputs to come from this side let me at every gate itself let me at every gate it says uh use you know be uh the the earlier Gates iteratively so look at it over here we are saying C out three bar is dependent on generate 0 to 3 and propagate 0 to 3. now you do not need to see what propagate one was and whether the uh carry would go from propagate 1 to propagate 2 and all that you don't need to see all that it is already inbuilt into your one complex gate and you could have C output there right away okay so that is what look ahead topology looks like uh you see what we do then we what we see is that c0 is g0 and p 0 c i zero but c c o one is equal to G1 plus P 1 G 0 plus P1 P2 or P 1 p 0 C 0. CO2 is equal to G2 plus P2 G1 so basically you are kind of continuously adding recursively adding the delays there and uh what you see you can con continue to build a tree kind of hierarchically hmm so what does this mean this means that we're talking about uh how do we put it we're talking about these other trees where uh A's and B's and their components outputs are used for example a0 b0 will only influence S 0 and S1 because the carry would go there but in terms of higher widths we know that uh A1 B1 can also influence S3 so we built this kind of a tree and there are complex trees also see there are two stages in this the first state second stage third stage multiple States in these where we say that uh you know my S8 uh S7 goes to S8 and my S7 also goes to S9 and S10 and so on I built those trees and ensure that my overall functionality is correct huh and uh it is because of these lots of routing connections all these are routing connections is it not that in the adders we if you know if you remember there was Adder stage one then wires then Adder stage 2 than wires and then final adder remember that curve the the thing that we had shown in fact there was a question that someone asked in the chat window also why is there a separate region for wires there's a separate reason for wires because these they are all these interconnects that have to happen after every stage and they would rather have have them done neatly by allocating a safe region for them rather than going to higher metal level layers and using the resources there is that okay so again I am not going to ask you about make the brand country or make the this added tree or that allergy they intent to take you from this stage of Ripple carry to carry look ahead to carry select and so on is so that you know that there are different ways of arriving at the same output and depending on your project requirements you will have to choose the most appropriate one hmm so rajneesh sir so from where the GNP is coming from in the two slides before okay you tell me sir uh we could always generate gnb through those and Gates you remember the equations that we were looking at earlier for gng yes we simply generate those may be some same diagnosis yeah yeah so that is where that truth table May generate kill or propagate information was also important,https://www.youtube.com/watch?v=OiDXtgAKLU0,"Link: https://www.youtube.com/watch?v=OiDXtgAKLU0
Transcript: yes Okay so this is one photograph of a of a data path hardened data path and you will notice that it is not really symmetrical for all bits as it was saying it is not really symmetrical for all bits but yeah it's fine so we come into adders now what is an adder or are you able to see this functionality this truth table can you validate this is a correct truth table for the adder so what's this carrying status in which delete and propagate and generate are like that's a different thing are you able to validate the otherwise came up yes sir yes yes sir so now let us look at the last column what is Carry status so let us say that uh there was the inputs A and B were both zero hmm then independent of CI what will happen to co will be 0. are you able to see this yes sir now if either of A or B was one if either of them was one do you realize that whatever be the carry in it will be propagated further hello yes sir yes and when both A and B are 1 then again whatever we the CN C how it is definitely one are able to see this also yes sir so this is what we want to say or this is what this delete delete means whatever with the CN C out will be 0. propagate means whatever with the CN that will be propagated on C out generate means whatever be the same C out will be 1. are you able to see this yes so that is what Carry status means this this becomes important as we will look at uh uh implementation a typical or a very basic implementation of the slider would appear to be something like this that s is equal to 1 so we what we do we look at this this K map and we start to say okay it is or there is a one over here no no sorry we say okay my S is one over here then it is 1 over here and one over here and my C out is one over here and here so you you start to merge and you start to see if you could have K Maps uh being used to arrive at a logic and when you do that you arrive at this kind of a k map that s is one then either of these four Constructors one and see how it is one then either of these constructs is equal to 1. this is how you you must have done adders earlier also this is a simple adder full adder huh so we say that okay in the same order we we have used a b and c and then we have used inverts of B and inverse of c and inverse of a to make our logic of s so probably I will need a lot of gates to do it can I do it simpler so we say okay there was this information of delete propagate and generate at least that much I can use for generating carry out so we say that okay we express sum and carry as a function of propagate generate and delete only where carry out can be can be uh represented are represented as a sum of G Plus PCI be propagate a propagate is one then whatever is the CI comes on there or carry generated either carry generated or carries propagated and therefore CI becomes C out and S is that my propagate should be one it's a czar of propagate and CI in fact uh just to make our logic a little simpler use lesser number of devices many times you will use propagate as a or b because in A or B situation also whatever is the CN whenever CN has one you will propagate that are you able to see this see for C out I already have G there that is if a and b both are 1 I will have G equal to 1. so if c i was 0 in that case also I could say that let me use propagate as one because C out will be given as 1 from here generate generate part itself so many times just to make a logic simpler we may want to use propagate as a or b instead of a is or B so what is a plus b we could have said this from the truth table also from the truth table it is not really a plus b look at it uh if it was a plus b then uh in one one would also result in the yes this would have resulted in propagate but this has resulted in generate henna um that is not the case so in in actual terms it is generate but even if you call it propagate it doesn't matter because the co has to be generated the CI has CI will be one there I know because of generate you have used the variable as a or b a a and b so A and B are one so C of C naught can happen already are you able to see this yes so can you please like I got confused in this part why we are using uh two expressions for a propagate so you use only one expression A or B okay so but why why we are using two here I understood your point that I can use one and I'll get the functionality done but why two why to do it why two values of propagate two by expression for propagates see the exact expression is a is or B but we said that even if we use the expression of a or b yes sir C naught and S will not be different given this expression G is equal to C is caught is equal to g plus PCI and S is equal to P is our c i so these two outputs will still remain same even if I use propagate as a or b but or gate is much simpler than as or gate yeah yes that is why okay okay thank you take care yes so here it is written uh can also be expressed by a sum and Carry Out can also be expressed in terms of D and P yeah but I think instead of using D if we use G it would be more I think I think when you will Implement by using D two more inverter should be required right uh you see but you will need inverse of a and b s but uh just work it out it is not saying this is the minimum the the one with D and P will be the minimum gate implementation it says if you have dnp available with you even then you can Implement test and see now what it essentially intends to communicate is you need to do either of generate you need to do either generate or kill don't need to do both yes yes so even though we want we want to express some and carry as functions of PG and d p and either G or D will work for us yes okay that's the intent over here so now that was one bit adder if we have to make a four bit Adder what do we do we simply just say Okay this C out of bit 0 is C enough bit one and see out of one is C in of bit 2 and so on so what happens uh once the C out of 0 is generated it goes as seen of the second act full adder then third full adder then fourth full adder and then you get the output so what is happening I am Rippling the carry from one full adder to another and what is the uh worst case delay if as I increase the number of bits the number of hops increases linearly and therefore this is order n and what we also understand is that carry in to carry out paths should be as fast as possible are you able to see this these two aspects um yes sir so now if we go ahead and you know try to implement that full adder which this functionality in terms of a CMOS logic you would get a 28 transistor implementation something like this so you can you can do it at your on leisurely time where you will see that this is G A and B and then this is uh C and A or B hmm so this is your C out and similarly you will get your sum also based on by implementing whatever logic we had given there is this clear yes sir uh so in the last slide I have a question yes so here T Adder equal to n minus 1 T carry plus T some third just T some student it will be maximum of 3 sum and T Theory uh exactly the right to have the same understanding so let us look at this path uh what happens you realize that a b and everything was stable already these parts are stable already is it not when your carry came what what require what was required to be done when your carry came you only need to evaluate these parts of the gate Hannah so uh and you notice that CI has been kept as close to the output as possible so that the delay from C to out is minimum that is the delay mentioned as C sum or t sum whereas from a to sum or B to sum the delay could be slightly higher okay so already we have decreased the delays internally from from carry 2. from carry 2 yes so uh there is a different delay for generating a carry that is evident because delay to generator carry is this path delay to generate a sum is this path you know so this sum depends upon the voltage at node X which is also one of the inputs so it constitutes this entire path for next two years so yeah that can cause more delay for us than CO2 yeah done okay so what is also now important to see is that if you have a adder then you could actually have a invert Adder also there so what has happened over here you have a full adder over here you have inverted all the inputs and you say okay your output should also be inverted so S Bar of avci is equal to sum of a bar B Bar C A by CI bar and so on by using this inversion property what do you do you say okay I will not I will at least not use this inverter this one we may have to use but at least Joe C naught you see how generate currently inverter I can avoid using that and I would have see out going directly to the inverted full adder the next one I will have a regular full adder and then and again an inverted full adder so if you do it like this then what happens the total number of transistors in your system reduces because you don't need to put those additional inverters at the end of it so there are two things that are evident that there is a focus on reducing delay and then there is a focus on reducing area also because this is a large number of devices 28 transistors so we want the delay to be less but we want this number of devices also to be less so that is where figures in this mirror adder where you will see that the nmos and the pmos parts are kind of mirrors of each other and again uh the the circuit works fine where you say that okay you give CI from here and you get Co Sea House Bar and you get S Bar as outputs there Tigger so you can at at your own Leisure evaluate that this is this works fine this is fine for uh the functionality that you want to achieve for both C naught and S so but this uh this particular topology will be uh valid only if you have even number of stages right sir if you have odd number of stages then once again we need to add inverter at the subject and that we can just add on the last inverter last stage yes so this one inverter will come not it will not come 25 times yes sir so that we can always dominate appropriately so what are we talking about so for the mirror error for example we are saying that what you've done is the nmos and pmo stacks are completely symmetrical they are very similar to each other and uh I think from the discussion that we have had till now you must have already realized that the load on C out or the capacitances linked to generation of C out should be kept as low as possible why is that why should the capacitance is linked to generation of cob kept as low as possible because the carry has to propagate through the stages of Adder yes because the carry out of your state will go to the next stage then again the entire carry out will be new carry out will be generated for the next stage and so on at least if the propagation is going to happen so that is what we are looking at that we have to reduce the capacitances also we have to reduce the delays as you reduce the capacitances power and delay will automatically reduce hmm is that clear okay then see we looked at that what we looked at just now was a ripple Adder where data would you know move from a carry outward move from here to here to here finally giving a carry out three it's a very long path see the sum path is very short is very long especially if you have large number of bits so you will see that in the next few slides they're all we're just talking about how to anticipate the carry so one way is bypass the evaluations of uh C out for all these stages simply see if the overall P0 P1 P2 P3 are all one if they're all one then what you say is that okay since all the propagates are one then whatever was there on CI will definitely come on C out also are you with me any questions so we are saying is all the propagate servers so the uh the input carry will be reflected at the output directly yeah that we have studied okay yes hello so uh if we do it like that then what happens we have carry bypass for uh first four bits then we have carry bypass for the next four bits then we have carry bypass for the next four bits and so on so if there are total number of embeds then what is the total delay of the adder you will see the total delay of the adder would reduce would reduce such that uh you will have uh n divided by m minus 1. so the total number of delays that you will now need to see is what is the critical path the critical path would be something like this Hannah so would the largest delay also decrease just the largest delay yes it would decrease because uh earlier like uh it would decrease if you're using the propagate and kill valid topology because if you're not using propagate and kelvala thing then what happens is that all a b and c n will be calculated from Top dot top bottom and then we will arrive somewhere at sum and Carry Out however because you are using propagate and generate thing you already know what the C out could be uh much faster you don't need to evaluate after this comes you know what is the status of PNG the multiplexer inputs are already set and you either propagate or regenerate so it says time we'll see how it saves time further also but this saves time because now your Ripple is only for M number of bits so you'll see initially it appears that when the total number of bits is very less a bypass Adder because of its uh more complex logic and a multiplexer in there and so on may take a little extra delay however when you're talking about large number of bits say 32 64 128 or so on then Ripple Larry is much much slower than bypass Adder right and it is a consequence of these equations only nothing else okay any questions sir in the previous slides someone slider yeah can you explain this n by m minus one t by bus term once again okay so let us say this is 16 bit Adder Hannah this is 16-bit order how many bypass would it take would it pass through so first before that how many bits how many bits in one stage four hello yes sir so if you have a data Adder coming or set of inputs coming from here this this is the while this is being evaluated this part of data would have already been ready yes sir similarly here things would already be ready yes so when you are uh when you want to find the total delay what are you looking at setup delay plus carry generation delay Plus number of these that will be there n by m minus 1 so actually n by M minus 1 over here you can see so we know that okay 16 bits have been brought into have been split into four bits each so we would have of 4 minus one n by n by m 2 8 may be a parallel T by passes the delay of let us say this multiplexer yes yes because yes yes uh sir in case in all the bit 0 to 3 4 7 8 to 11 and 12 to 15. if this condition is not satisfied that p 0 P 1 p 2 p 3 is equal to one then in that case none of the carry would be directly going uh without without facing the carry propocational so if the propagations are not all all ones if the propagates are not all ones then what happens when you anyway do not be you will not be Rippling the carry to the entire path so your overall delay will actually be lesser only whatever was evaluated here earlier would already be valid we are talking about the worst case delay where you say okay the Ripple has to happen through the entire system hmm because if there is some p p and g equal to 0 at some bit whichever bit it is then it means that the evaluation that was done for higher bits than this were already clean because c c n was anyway 0 and it will remain zero it will not change it oh yes so as you increase the total number of bits you see that bypass Adder has much better performance than Ripple Adder but it has much more circuit also in there to be able to do all these through the automatic like so there is a setup circuit and so on which would be there ranjith you have a question oh yes sir in the previous slide okay sir I understood how we get the teacher M times the T carry uh plus uh n by m minus 1 times the T bypass but why once again we have M minus 1 times the T carries this this one I didn't understand Okay so all right let me show the variables are different this is this variable is MP carry and this variable is M minus 1 and 2 T Curry okay but y m minus 1 into 3 T carries but I didn't understand because always if we consider one single bypass stage the carry generation 
will happen parallely for all of them so and then we'll like uh bypass this for the first for the first stage that carry generation you have to still count now eight bar two you will have to count okay then you add the delays of uh various ones and for this one and it says there are if there are M bits then that would mean M minus 1 times Ripple could happen at least in this one is it not even for a four bit thing even for a 4-bit thing if the carry has to be generated like this every three ripples happening inside it is it not yes yes that is why okay yes sir Okay so is it clear till there is your hand is still raised anything pending there okay so this was where we were actually using the carry to re-evaluate the circuit and arrive at an output if we are ready to give area then another idea could be assume that carry could be zero and assume that carry n could be 1. and calculate and calculate C out for both the cases depending on the value of c c out of K minus 1 stage that is the first the C in of this four bit circuit you can choose whether this one has to be used or this one has to be used in this case carry calculation is actually happening completely in parallel and you're just having a multiplexer at the output stage are you able to see this so in in other parts we were simply doing uh one circuit which was doing generate propagate that kind of function um over here uh we said okay all that generate propagate you do it for both CN is equal to 0 and C N equal to 1. depending on what was the value of c n I will choose the output directly at the multiplexer stage so now you even if you go to 128 bits all will run parallel and all that I need to do is the previous stage output goes as seen over here or goes as multiplexer input over here so the delay is reduced further um look at this example what we say bit 0 to 3 I calculate the output with zero carry I have calculated the output with one carry and then I use the carry in as the select signal for the multiplexer and I will get the sum generated and I will get the CO3 also hmm and the worst case critical path is as marked over here are you able to see this any questions no questions so successfully you are breaking the adder two times uh for each stage and then you are letting the other other stages evaluate according to the carry equal to 0 and 1 and then you are selecting based upon what is the carriage that you get from the previous one yes so doesn't this architecture result in exponential rise in the area consumption yeah yeah definitely instead of just one Carriage uh one one evaluation circuit you're putting two evaluation circuits one for carrying equal to zero one for carrying equal to one but the delay is also reducing okay I know so if we look at it uh if we look at it a slightly more advanced versions of this so over here notice we're talking about as 0 to 3 S 4 to 7 as 8 to 11 s 12 to 12 12 to 15. in a more advanced version uh or you know when we have it as this then this is what my total added delay is that uh plus n by m into T carry plus M into T marks plus T sum so this is this is what you would get as the overall delay of the system however another interesting way is you say that okay over here there are only two bits over here there are three bits or over here there are four bits and so on so I'm gradually increasing the total number of bits that my this system is taking up why am I doing that is a bit where is the concept of logical effort at the end stages near the output we increase the size so that we get the optimal deal not exactly so the output is the s0 and 1 are also outputs output but as 0 and 1 are also outputs foreign yeah see what is happening is you know that uh let us go to the previous slide you know that uh to arrive at this stage I will go through not only this but also this horizontal delay are you able to see this so by the time this c0 and C11 comes as the output 11 comes I would already already be waiting at the input of the multiplexer so I say why wait instead of calculating a ripple across four bits only I actually have more time now so I can calculate triple across 5 bits or 6 bits huh and when you do that uh what you achieve is that even though you are Rippling across five or six bits here because they are most most significant bits or close to the most significant bits the select signal anyway would take long time to come here hmm so so it's like time borrowing from it's like uh borrowing the time basically yeah you're using the extra time that is available to you because these extra multiplexer are also in the path and adding one more stage there let us say not stage one more bit in one in a in this kind of uh setting and this is how the delays change see this is Ripple carry this is linear select and this is the last square root select that we just did so you will not see much difference at the lower number of bits but today as we are talking about 64-bit processors and then probably 128 bit in a little while then you will see that this this part at and more number of bits uh square root select or linear add linear select adders are much faster so you can you can choose which one to use okay is it clear till here had a very small doubt I think uh like the two slides before can we go our previous close slides uh sir in this why don't uh we uh make the zero carry and one carry Adder parallel to each other and then give those inputs to mugs or if that's in parallel notice okay setup is going here and setup is going here also in parallel is represented like this they are going in parallel only okay okay thank you yeah so after the carry select address uh you must have heard about what is called last carry lookahead address also hmm so what do Carolina candidates do they do something similar to this select thing and uh they say that uh as you go into the higher bit there will be more time and therefore you could have a longer path set in there so what is the idea behind it you say that okay to be able to anticipate the output over here I don't need to wait for ripples or even inputs to come from this side let me at every gate itself let me at every gate it says uh use you know be uh the the earlier Gates iteratively so look at it over here we are saying C out three bar is dependent on generate 0 to 3 and propagate 0 to 3. now you do not need to see what propagate one was and whether the uh carry would go from propagate 1 to propagate 2 and all that you don't need to see all that it is already inbuilt into your one complex gate and you could have C output there right away okay so that is what look ahead topology looks like uh you see what we do then we what we see is that c0 is g0 and p 0 c i zero but c c o one is equal to G1 plus P 1 G 0 plus P1 P2 or P 1 p 0 C 0. CO2 is equal to G2 plus P2 G1 so basically you are kind of continuously adding recursively adding the delays there and uh what you see you can con continue to build a tree kind of hierarchically hmm so what does this mean this means that we're talking about uh how do we put it we're talking about these other trees where uh A's and B's and their components outputs are used for example a0 b0 will only influence S 0 and S1 because the carry would go there but in terms of higher widths we know that uh A1 B1 can also influence S3 so we built this kind of a tree and there are complex trees also see there are two stages in this the first state second stage third stage multiple States in these where we say that uh you know my S8 uh S7 goes to S8 and my S7 also goes to S9 and S10 and so on I built those trees and ensure that my overall functionality is correct huh and uh it is because of these lots of routing connections all these are routing connections is it not that in the adders we if you know if you remember there was Adder stage one then wires then Adder stage 2 than wires and then final adder remember that curve the the thing that we had shown in fact there was a question that someone asked in the chat window also why is there a separate region for wires there's a separate reason for wires because these they are all these interconnects that have to happen after every stage and they would rather have have them done neatly by allocating a safe region for them rather than going to higher metal level layers and using the resources there is that okay so again I am not going to ask you about make the brand country or make the this added tree or that allergy they intent to take you from this stage of Ripple carry to carry look ahead to carry select and so on is so that you know that there are different ways of arriving at the same output and depending on your project requirements you will have to choose the most appropriate one hmm so rajneesh sir so from where the GNP is coming from in the two slides before okay you tell me sir uh we could always generate gnb through those and Gates you remember the equations that we were looking at earlier for gng yes we simply generate those may be some same diagnosis yeah yeah so that is where that truth table May generate kill or propagate information was also important"
V0mLroNJrjs,okay now we come to multipliers so what are multipliers you know we have done all of us have done multiplications there is a multiplicand and there is a multiplier and there are intermediate stages and there is a final result these intermediate stages are called as partial products so if you look at it in terms of an array of array multiplier then what are we saying is that isab there is a full adder over here that i need there is a half adder over here that i need and so on so i need a few full adders and a few half adders to make my circuit complete and robust so uh your out your inputs y0 and z0 would go uh and will be handed and everything will happen and you will have a way to arrive at outputs over here so these are all the outputs are you able to see this z0 is only dependent on y0 and x0 z1 however is also dependent on other topics are you able to see this this is kind of a direct movement from this thing to another then if we look at a big big uh multiplier then what are we saying that there could be multiple critical paths also there could be a critical path from here to final or from here to final which one would you choose to characterize your delay so for the critical delay i think the the path which is following all the full adders will be chosen yes that will be the most critical delay but they are all critical paths and depending on the inputs you may have something different somewhere see look at it like this full adder full adder half adder full adder full adder full adder full adder half adder full adder full adder or whatever okay so if there are more full ladders that is where you are more worried so what you do you just reorganize your partial products uh in such a way that you know where to put in the first stage for example you will only have these uh half adders and in the second stage you will have both full ladders and half adders and in the final stage you have only half adders are you able to see this so this is the famous wall history multiplier how to implement this as we just saw this is the region where wiring would happen z3 and the c out of fa will go somewhere it will influence results there and so on okay so i'm just quickly giving you a glimpse of different kinds of multiplier implementations also for even for a wallace tree for example there could be y 0 1 2 3 and then y 3 y 4 y 5 or i could say 0 y 1 2 and 5 3 4 3 4 5 and these two could happen in parallel are you able to see this hello so multipliers are not as intuitive as adders but uh are you getting the sense that there is a way to optimize multipliers also are you getting at least that sense yes yeah that is all that is required so that if you intend to pick up a project you at least have some words in your mind that okay there's a brent kung adder or there is a wall street multiplier or there is this kind of multiplier and i could have these kind of options amongst which to choose to design the most appropriate multiplier for my application and so on so i'm just giving you a top-level glimpse of a few adders and multipliers if you go out in academic literature you will see many many more of them and not even claiming that wall street multiplier is the best you could have a multiplier which is still better than wall street multiplier what i am saying is is that there are ways to optimize it and people have done it and you can also do it if you you know but for that you have to study existing all the existing ones and then you go a step or two further but you can also do it okay is it clear till here so what we are talking about is that in a multiplier also you have to important you know it's very important to identify the critical path and then you try to reduce the overall delay by let us say doing data encoding for example in booth multiplier or we just saw the wall street multiplier or very importantly pipelining see when we were doing sequential circuits you were asking but what is important to realize is that having all these adders in their full adders and half adders and all those things in there will mean that the delays will be high if you do not want to compute the entire uh you know multiplying chain all the partial products in one cycle you can split it into my into more than one cycle stage wise you can say that i can actually have this as a three-stage pipeline so what that what does what does a pipeline the architecture for a multiplier do what does pipelining do over here why do we want to pipeline esther you're saying something like we can have different stages so that you know for example we can have smaller clock cycles in architectural levels you can operate at a much higher frequency so even though the throughput of your wireless multiplier is small remaining part of the circuit is at least experiencing faster clock cycles and you have better results overall okay so with this multipliers we are getting a kind of a multiplier and those adders we're kind of getting a glimpse of system level optimizations that how are these circuits can also be used in your adders and other places but what is important is how to optimize a path a data path in a way at a system level so now at the very last part of our arithmetic circuits which is called shifters so what is happening you have two inputs or a i and a i a i minus one and uh you see a i is going ai minus 1 is going to this part also a i is coming to this part also and depending on select whether i want to do a right shift or a left shift or a no up i will use ai to go to bi or ai to go to bi minus 1 or ai minus 1 to go to bi are you able to see this yes and this shifter can actually also be implemented in a slightly different way where uh you are talking about multiple levels of shifts also that you could shift one bit two bits or three bits hmm this is the barrel shifter that so in the previous shifter what could you do you could go left you could go right and you could stay there no up in this particular shifter what you are saying is that this is a barrel and you are moving in this kind of a fashion okay why am i getting a feeling that a lot of overhead transmission is happening i'm not getting any feedback from you guys trends i know i'm not really explaining these circuits but are you getting the sense of it the top level feel the intuition are behind it are you getting that yes sir okay so when you want to design these users you go into much more details but i want you to introduce to be introduced to these circuits okay that's the only intent of this lecture today memories also memories where we will talk about at least memory cell in a little detail but again there the intent again would be to just introduce you to those topics so this is how a barrel shifter you know the schematic that we made here these n mosses and everything this is how their layout would appear to be you see over here the entire routing is happening through poly so this pink one is poly would you be able to use this in advanced technologies is not allowed poly bending is not allowed and poly resistance is huge because poly is so thin so many reasons why you would not want to do it but this was one of the optimal designs and older technology say 180 nanometer okay so this is a four cross four barrel shifter where you can shift four bits and you can jump number of bits that you want to shift okay that kind of brings us to a close of arithmetic circuits the lecture on arithmetic circuits and we will switch over to any questions that you may have about the project or anything yes you said i have a question related to this multiplier basically we are looking at a very fine detail of how we can improve the circuits and then make faster circuits as well as a smaller circuit also but but at the level of synthesis if we say that in a liberty file i have a different types of adders uh available there so they have different areas also and uh bigger ones are faster yeah so at the level of synthesis when i go to like let's say innovas then in that in that also would i find these kind of topologies uh implemented the smaller one would be ripple carry and larger one would be the carry could be it depends on how the library team has designed stuff so these are hard ips that the library team would have generated so yes you could find them but you may not depending on whether they are whether they were designed by the library team there or not but if you are a part of the library team who has to design these adders and multipliers then you need to know all this stuff how to optimize a circuit at a system level you may simply say okay i will want to use the adders amongst these adders this one meets my requirements best and therefore i will use this one so this this knowledge of the circuits of address multiplier is still more useful at level of circuit design so this knowledge yes how to like propagate generate and everything all that is valid for circuit design part only but yes even even at a system design level when you know that okay carry look ahead is faster than ripple carry you can always prefer it in your synthesis run and your overall design we can enforce that yeah you can enforce that yes that's it so the diagram of that complex diagram of blue card topology that was given ah except that cannot be implemented in a standard cell design right because somewhere uh it was ptl based logic plus cmos also used so that data path will be designed separately is this a standard cell no is this a standard template that we're talking about no anna so these circuits are now not standard cells they are hardened macros okay eyepiece that can directly be used yes sir one more question sir all these are combinational logics only uh and at the input and at the output there will be flip flops so uh from a standard cell design we are providing this uh inputs to some ip and then again we are obtaining output in a standard cell design only yes and then how in layout a discontinuity of standard cell is means there is a there to be discontinued in standard cell designed so it will we will not have standard cells abutting these cells now these macros will be there they will not be abutting the standard cells there would be some space between the likelihood and the sand itself and you will connect through wires yes so they would also be spaced far apart from that standard cell implementation no far apart how much far is far apart i do not know but yes they will not be abutting the standard cells that much i know yes sir sir also one more thing sorry in case of multiplier especially there would be huge difference in contamination deal and propagation yes so very significant difference while designing flip flops how the setup and hold are met in these cases this means there would be let's say 10 times difference could also be there right so how does designing flip flop in this figure in for the for designing a flip flop you want to keep the hole as slow as possible and you want to keep the setup as low as possible both you want to keep low so independent of whether you are a multiplier whether the flip flop is at the end of a multiplier or wherever that doesn't matter flip flop design is independent of where that flip flop is used is it not yes sir now if your circuit has such vast delays then you could say that okay i will probably add one buffer in there so that i do not violate the whole time even when the contamination delay is there so then also you were talking about breaking into stages in case of multi multiplier so each stages in between a flip flop would come something like that um you pipelined it yes pipeline means that after every stage the thing is registered somewhere the partial product will be registered yes okay so anything else i think we are any way up the class time so if there's anything else we can look into it otherwise we'll close the class sir i have a i have a query regarding the project uh sorry my my project is oai implementation of the complex non-complex style uh so i have implemented the layout for the complex time i just want to get it reviewed from here and whether the area usage is good or not so can i go ahead and present the screen sir we can do that but did you already see the office has the feedback that i gave in the offices yes sir i saw the feedback that shakti and his team received yeah i was just concerned if uh i have the same kind have you incorporated the feedback in your design or not or you want the same feedback to be given to you no sir i i try to use the area efficiently but the problem is that in the dominar logic style we will have we have used the beekeeper so i will have to route the output of the inverter to the input of the beekeeper so and uh so this uh this has uh for the routing we need uh the space for that metal to be routed yeah so over there just a small area is not being occupied by any of the transporters you can show the layout piece yes yeah oh sir can you please make me the co-host wait i will allow multiple participants to share simultaneously yes anyway i'm not sharing anything so you should be allowed to share oh no sir it says the host has disabled oh is that the case yes sir um no who can share i have already said you should be able to share yes no i can share you are always able to share so sir uh this is the layout that i have made sir so here i have the v keeper and then this is the pmos and then here comes the logic for a b c d e and f the six inputs and then i have the two uh inverters so this is uh to send the uh to restore the logic levels uh so i'm sending the output to the input of the v keeper and then here is the output so uh ranjit my my only uh thought that i have when i look at it is that the first inverter that you have put for it is you know the on the right side the first one yeah this one net 35 net 44 inverters so net 35 is going on the gate net 44 is going on the output why could you not put net 44 on the left side if you would put net 44 on the left side then you would be able to share the vdd of this inverter with the vdd of the next inverter oh sir i didn't understand so look at this inverter first inverter there is vdd on the left side source drain sir and net 44 on the right side yes sir if you would instead put net 44 on the left side okay and vdd on the right side okay then you would be able to share the vdd across the two inverters okay okay understood sir so your weight would reduce yes yes yes understood that is what you have to always observe is there any additional sharing that i can think of okay yes i'm very happy to see that the two p moses you have put one over one you know one beneath the other and it is possible for you this is very nice the same area yes sir but you still lost some area in this not being able to share vdd on ground of two adjacent inverters yes this should always be done okay sir and this would probably also do one more thing as soon as you put net 44 on the left side you will realize that you will not need to now vertically bring down net 44. uh yes sir this i can i can easily doubt it uh yeah so width would reduce but would reduce still further yes sir in fact even for net 35 yes you can you have presently taken it from above the first set of n masses and then brought it down uh yes sir there is a vertical net 35 stacks yes sir metal i know see that can you possibly in this in this second stage of uh stuff use you know you can just push the active of uh of these two inverters a net 29 net 35 uh inverter a little up on left 29 at 29 and net 35 you then what happens is beneath this active you will have more space and you can probably route net 35 from in that space itself you will not need to go up ah sir but i can't route it below because uh the drain of this is uh c and d is connected to source of a and b so i cannot enter then do one thing then do one thing put net 29 in the center of this gate sorry sir net 29 where exactly net 35 is in the center uh yes sir yes yes put net 29 in the center okay okay then net 35 will already come on the drain side you will not need the vertical wire there okay yes sir so that way you will be able to reduce your width very very significantly oh yes sir ticket yes sir so let's do it like that okay sir yes thank you sir okay all the best guys then uh and uh i will see you now on monday in the office to see okay what is the critical path how much margin do i have and then these this was decided okay so technology all that you need to see is how much slack is there in your critical path and can you add one more bit there okay so it's not decided randomly like two bits no no no no no decided on the basis of uh the length of the path there yeah are the most optimal parts okay yes thank you thank you all the best guys see you sir yes so do we have like two minutes time i wanted to ask something related to wikipedia uh,https://www.youtube.com/watch?v=V0mLroNJrjs,"Link: https://www.youtube.com/watch?v=V0mLroNJrjs
Transcript: okay now we come to multipliers so what are multipliers you know we have done all of us have done multiplications there is a multiplicand and there is a multiplier and there are intermediate stages and there is a final result these intermediate stages are called as partial products so if you look at it in terms of an array of array multiplier then what are we saying is that isab there is a full adder over here that i need there is a half adder over here that i need and so on so i need a few full adders and a few half adders to make my circuit complete and robust so uh your out your inputs y0 and z0 would go uh and will be handed and everything will happen and you will have a way to arrive at outputs over here so these are all the outputs are you able to see this z0 is only dependent on y0 and x0 z1 however is also dependent on other topics are you able to see this this is kind of a direct movement from this thing to another then if we look at a big big uh multiplier then what are we saying that there could be multiple critical paths also there could be a critical path from here to final or from here to final which one would you choose to characterize your delay so for the critical delay i think the the path which is following all the full adders will be chosen yes that will be the most critical delay but they are all critical paths and depending on the inputs you may have something different somewhere see look at it like this full adder full adder half adder full adder full adder full adder full adder half adder full adder full adder or whatever okay so if there are more full ladders that is where you are more worried so what you do you just reorganize your partial products uh in such a way that you know where to put in the first stage for example you will only have these uh half adders and in the second stage you will have both full ladders and half adders and in the final stage you have only half adders are you able to see this so this is the famous wall history multiplier how to implement this as we just saw this is the region where wiring would happen z3 and the c out of fa will go somewhere it will influence results there and so on okay so i'm just quickly giving you a glimpse of different kinds of multiplier implementations also for even for a wallace tree for example there could be y 0 1 2 3 and then y 3 y 4 y 5 or i could say 0 y 1 2 and 5 3 4 3 4 5 and these two could happen in parallel are you able to see this hello so multipliers are not as intuitive as adders but uh are you getting the sense that there is a way to optimize multipliers also are you getting at least that sense yes yeah that is all that is required so that if you intend to pick up a project you at least have some words in your mind that okay there's a brent kung adder or there is a wall street multiplier or there is this kind of multiplier and i could have these kind of options amongst which to choose to design the most appropriate multiplier for my application and so on so i'm just giving you a top-level glimpse of a few adders and multipliers if you go out in academic literature you will see many many more of them and not even claiming that wall street multiplier is the best you could have a multiplier which is still better than wall street multiplier what i am saying is is that there are ways to optimize it and people have done it and you can also do it if you you know but for that you have to study existing all the existing ones and then you go a step or two further but you can also do it okay is it clear till here so what we are talking about is that in a multiplier also you have to important you know it's very important to identify the critical path and then you try to reduce the overall delay by let us say doing data encoding for example in booth multiplier or we just saw the wall street multiplier or very importantly pipelining see when we were doing sequential circuits you were asking but what is important to realize is that having all these adders in their full adders and half adders and all those things in there will mean that the delays will be high if you do not want to compute the entire uh you know multiplying chain all the partial products in one cycle you can split it into my into more than one cycle stage wise you can say that i can actually have this as a three-stage pipeline so what that what does what does a pipeline the architecture for a multiplier do what does pipelining do over here why do we want to pipeline esther you're saying something like we can have different stages so that you know for example we can have smaller clock cycles in architectural levels you can operate at a much higher frequency so even though the throughput of your wireless multiplier is small remaining part of the circuit is at least experiencing faster clock cycles and you have better results overall okay so with this multipliers we are getting a kind of a multiplier and those adders we're kind of getting a glimpse of system level optimizations that how are these circuits can also be used in your adders and other places but what is important is how to optimize a path a data path in a way at a system level so now at the very last part of our arithmetic circuits which is called shifters so what is happening you have two inputs or a i and a i a i minus one and uh you see a i is going ai minus 1 is going to this part also a i is coming to this part also and depending on select whether i want to do a right shift or a left shift or a no up i will use ai to go to bi or ai to go to bi minus 1 or ai minus 1 to go to bi are you able to see this yes and this shifter can actually also be implemented in a slightly different way where uh you are talking about multiple levels of shifts also that you could shift one bit two bits or three bits hmm this is the barrel shifter that so in the previous shifter what could you do you could go left you could go right and you could stay there no up in this particular shifter what you are saying is that this is a barrel and you are moving in this kind of a fashion okay why am i getting a feeling that a lot of overhead transmission is happening i'm not getting any feedback from you guys trends i know i'm not really explaining these circuits but are you getting the sense of it the top level feel the intuition are behind it are you getting that yes sir okay so when you want to design these users you go into much more details but i want you to introduce to be introduced to these circuits okay that's the only intent of this lecture today memories also memories where we will talk about at least memory cell in a little detail but again there the intent again would be to just introduce you to those topics so this is how a barrel shifter you know the schematic that we made here these n mosses and everything this is how their layout would appear to be you see over here the entire routing is happening through poly so this pink one is poly would you be able to use this in advanced technologies is not allowed poly bending is not allowed and poly resistance is huge because poly is so thin so many reasons why you would not want to do it but this was one of the optimal designs and older technology say 180 nanometer okay so this is a four cross four barrel shifter where you can shift four bits and you can jump number of bits that you want to shift okay that kind of brings us to a close of arithmetic circuits the lecture on arithmetic circuits and we will switch over to any questions that you may have about the project or anything yes you said i have a question related to this multiplier basically we are looking at a very fine detail of how we can improve the circuits and then make faster circuits as well as a smaller circuit also but but at the level of synthesis if we say that in a liberty file i have a different types of adders uh available there so they have different areas also and uh bigger ones are faster yeah so at the level of synthesis when i go to like let's say innovas then in that in that also would i find these kind of topologies uh implemented the smaller one would be ripple carry and larger one would be the carry could be it depends on how the library team has designed stuff so these are hard ips that the library team would have generated so yes you could find them but you may not depending on whether they are whether they were designed by the library team there or not but if you are a part of the library team who has to design these adders and multipliers then you need to know all this stuff how to optimize a circuit at a system level you may simply say okay i will want to use the adders amongst these adders this one meets my requirements best and therefore i will use this one so this this knowledge of the circuits of address multiplier is still more useful at level of circuit design so this knowledge yes how to like propagate generate and everything all that is valid for circuit design part only but yes even even at a system design level when you know that okay carry look ahead is faster than ripple carry you can always prefer it in your synthesis run and your overall design we can enforce that yeah you can enforce that yes that's it so the diagram of that complex diagram of blue card topology that was given ah except that cannot be implemented in a standard cell design right because somewhere uh it was ptl based logic plus cmos also used so that data path will be designed separately is this a standard cell no is this a standard template that we're talking about no anna so these circuits are now not standard cells they are hardened macros okay eyepiece that can directly be used yes sir one more question sir all these are combinational logics only uh and at the input and at the output there will be flip flops so uh from a standard cell design we are providing this uh inputs to some ip and then again we are obtaining output in a standard cell design only yes and then how in layout a discontinuity of standard cell is means there is a there to be discontinued in standard cell designed so it will we will not have standard cells abutting these cells now these macros will be there they will not be abutting the standard cells there would be some space between the likelihood and the sand itself and you will connect through wires yes so they would also be spaced far apart from that standard cell implementation no far apart how much far is far apart i do not know but yes they will not be abutting the standard cells that much i know yes sir sir also one more thing sorry in case of multiplier especially there would be huge difference in contamination deal and propagation yes so very significant difference while designing flip flops how the setup and hold are met in these cases this means there would be let's say 10 times difference could also be there right so how does designing flip flop in this figure in for the for designing a flip flop you want to keep the hole as slow as possible and you want to keep the setup as low as possible both you want to keep low so independent of whether you are a multiplier whether the flip flop is at the end of a multiplier or wherever that doesn't matter flip flop design is independent of where that flip flop is used is it not yes sir now if your circuit has such vast delays then you could say that okay i will probably add one buffer in there so that i do not violate the whole time even when the contamination delay is there so then also you were talking about breaking into stages in case of multi multiplier so each stages in between a flip flop would come something like that um you pipelined it yes pipeline means that after every stage the thing is registered somewhere the partial product will be registered yes okay so anything else i think we are any way up the class time so if there's anything else we can look into it otherwise we'll close the class sir i have a i have a query regarding the project uh sorry my my project is oai implementation of the complex non-complex style uh so i have implemented the layout for the complex time i just want to get it reviewed from here and whether the area usage is good or not so can i go ahead and present the screen sir we can do that but did you already see the office has the feedback that i gave in the offices yes sir i saw the feedback that shakti and his team received yeah i was just concerned if uh i have the same kind have you incorporated the feedback in your design or not or you want the same feedback to be given to you no sir i i try to use the area efficiently but the problem is that in the dominar logic style we will have we have used the beekeeper so i will have to route the output of the inverter to the input of the beekeeper so and uh so this uh this has uh for the routing we need uh the space for that metal to be routed yeah so over there just a small area is not being occupied by any of the transporters you can show the layout piece yes yeah oh sir can you please make me the co-host wait i will allow multiple participants to share simultaneously yes anyway i'm not sharing anything so you should be allowed to share oh no sir it says the host has disabled oh is that the case yes sir um no who can share i have already said you should be able to share yes no i can share you are always able to share so sir uh this is the layout that i have made sir so here i have the v keeper and then this is the pmos and then here comes the logic for a b c d e and f the six inputs and then i have the two uh inverters so this is uh to send the uh to restore the logic levels uh so i'm sending the output to the input of the v keeper and then here is the output so uh ranjit my my only uh thought that i have when i look at it is that the first inverter that you have put for it is you know the on the right side the first one yeah this one net 35 net 44 inverters so net 35 is going on the gate net 44 is going on the output why could you not put net 44 on the left side if you would put net 44 on the left side then you would be able to share the vdd of this inverter with the vdd of the next inverter oh sir i didn't understand so look at this inverter first inverter there is vdd on the left side source drain sir and net 44 on the right side yes sir if you would instead put net 44 on the left side okay and vdd on the right side okay then you would be able to share the vdd across the two inverters okay okay understood sir so your weight would reduce yes yes yes understood that is what you have to always observe is there any additional sharing that i can think of okay yes i'm very happy to see that the two p moses you have put one over one you know one beneath the other and it is possible for you this is very nice the same area yes sir but you still lost some area in this not being able to share vdd on ground of two adjacent inverters yes this should always be done okay sir and this would probably also do one more thing as soon as you put net 44 on the left side you will realize that you will not need to now vertically bring down net 44. uh yes sir this i can i can easily doubt it uh yeah so width would reduce but would reduce still further yes sir in fact even for net 35 yes you can you have presently taken it from above the first set of n masses and then brought it down uh yes sir there is a vertical net 35 stacks yes sir metal i know see that can you possibly in this in this second stage of uh stuff use you know you can just push the active of uh of these two inverters a net 29 net 35 uh inverter a little up on left 29 at 29 and net 35 you then what happens is beneath this active you will have more space and you can probably route net 35 from in that space itself you will not need to go up ah sir but i can't route it below because uh the drain of this is uh c and d is connected to source of a and b so i cannot enter then do one thing then do one thing put net 29 in the center of this gate sorry sir net 29 where exactly net 35 is in the center uh yes sir yes yes put net 29 in the center okay okay then net 35 will already come on the drain side you will not need the vertical wire there okay yes sir so that way you will be able to reduce your width very very significantly oh yes sir ticket yes sir so let's do it like that okay sir yes thank you sir okay all the best guys then uh and uh i will see you 
now on monday in the office to see okay what is the critical path how much margin do i have and then these this was decided okay so technology all that you need to see is how much slack is there in your critical path and can you add one more bit there okay so it's not decided randomly like two bits no no no no no decided on the basis of uh the length of the path there yeah are the most optimal parts okay yes thank you thank you all the best guys see you sir yes so do we have like two minutes time i wanted to ask something related to wikipedia uh"
Z-sJ1vuRj2E,about sense amplifier today okay so why memories like we talked about the entire library we talked about some arithmetic circuits then why memories why is what is so important about memories that we're talking about in dvd course also certain memories are the minimalistic storage elements which provides high density so if we consider a case of a resistor or a latch for a flip-flop then those involve large number of transistors even though they provide the storage functionality that they don't provide the high package density so we need to specifically look into the models thank you ranjit so you already made my task a little easier in the sense that what we are saying is that uh memories are high density storage elements and they are so important that today they cover uh you know in in advanced socs they cover up to 70 to 80 percent of chip area so come to think of it all that you've discussed in this course both libraries and everything that is not even 20 of total chip area do you see that and and since memories cover that huge area or have such a huge footprint on a chip we talk about memories in this course also and that is also the reason why we have a separate course all together on memories that will be running in the next semester so uh why is it that memories consume so much of area or why so much of area is given to memories see in a typical computer architecture you will see that memories are there at various levels there are register files which could be shift registers but which could also be small small memories there are caches of different level of hierarchy first level cache which is integrated inside the processor it operates at the same speed as the processor it has to operate uh that like it would possibly access every cycle and if you've done the course on computer architecture you also know that there is an instruction cache there is a data cache and there could be the concept of a unified cache also so there are these caches level one cache level two cache level three cache and all that so all this is on chip and then outside the chip also then you have main memory which which would typically be dram we will cover about dram also in the memory design course and beyond the dram there will be non-volt non-volatile storage the pendrives that you have where you would store your data so do you realize that memories are kind of pervasive as we move away from the processors they are also becoming slower so while resistor files operate at the data path speed are really really very very fast number one caches operate at processor speed the second level caches may actually take multiple processor cycles third level caching materials takes still longer and as you go to main memory which is off chip the time duration or the time of access increases multi multi-fold okay so it would take hundreds of cycles to access a dram from a chip so how you size these memories and how you organize this architecture is critical and you look quite a you you look into quite a bit of it i hope uh in detail in the computer architecture course how many of you have done the ca course and uh have you covered these different hierarchy architectures different hierarchies and memory architecture so raising hands to tell me that you have done the course and you understand this or you are raising hands to ask questions so please ask ranjit oh no sorry it was just to indicate okay akash that was also to indicate yes that's us okay just two of you have done cia course others have not done computer architecture i'm very surprised okay so the chat window says class runs okay i get it so many of you have done the cfos and you do understand that memory hierarchy is is critical to managers important to manage in mdt course we'll spend just about a lecture or two on on memory hierarchy and how to size this up because we have already covered it and see it but we will actually spend more time on how to design the level one cache or level two cache or you know the dram so that you get the you you achieve the desired objective whether it is high density or high speed or low power whatever it is so uh and just already mentioned that uh the standard you know the the latches and the flip flops they take much more area than a standard 60 memory cell so we will come to just that but before that when we talk about memories we also need to realize that whether it is resistor fires or l1 l2 caches or l3 caches there are different kinds of memories that come into picture one set of memory is random access which are static rams and drams but then on any chip you would also have stuff like free force have you heard about first in first out c4s which are used to implement queues you also have last and first outs which are used to implement stacks so when you have when you do programming you must have definitely uh you know in data structures courses you must know about stacks so there are memories which would be used to implement stacks then there are shift registers which you already know and then there are content addressable memories you know what is a cam have you ever heard about it earlier no sir yes sir okay huh okay who has said okay can you tell us about it what is it yes so it is a type of associated memory that is used for high speed searching applications it is means it basically finds the data and returns the address of matching data great so uh see typically when you talk of a memory you would typically give an address location and you would want to find out what is written on that particular address a cam is something different cam does not know what the address is cam knows what the content is so you search for the content and that leads you to the address and then from that address you may do further operations now where is it needed consider the case of a of a network router a network switch you know that you want to route some packet of data to google's us office so you want that you know that the destination is us but in a particular routing switch all that you can tell is that okay out of these four switches which one would take me closer to the us destination to the us server so you search for us in the content and whatever programmation or whatever programming has been done at the at the router level it will tell you oh go to port number 25 it will route your packet to port number 25. now you switch the router off you turn it on again next time around it may route you to port number 29 port number 2 wherever whatever has been configured so depending on data you will get a different address to go to to send your packet to that is what is content addressable memory this is also very widely or like content addressable memories are are tightly coupled to processors so that when when a particular instruction is given the follow-up instructions are brought in quickly based on the content the you know the locate by by doing a quick content search as to which location is this particular instruction stored and then i pull out remaining instructions from that region quickly so cams are specific memories and we will not really talk about them much in the course but just for the sake of completeness tams are also non-random access read write memories now while these are read write memories and these are all volatile now like volatile means that when you switch off the power the contents will get erased so when you power up the circuit again you will need to write the memory right inside the memory all over again but you don't want but or you also need memories which would not erase all the data is it not that is where we have nv read write memories that is non-volatile read write memories these include electric electrically programmable roms electrically erasable programmable roms and flash memories so what is the use of these flash and eeproms and eproms anyone so these memories uh firstly they provide the non-volatility and the second thing is that this can uh these are facilitate the large number of rights so they can be arrested and right written yeah so uh eproms over here cannot be raised but ee prompts can be raised so eproms are electrically programmable roms so what you do here is you kind of blow away the fuses once the fuse is blown now you cannot rebuild it again so eeproms where would they be used can you think of a use case boot sequence yes boot sequence or for example uh there is a standard set-top box chip which you also sell to airtel and you would sell to bharti and you said to tata sky and you sell to this tv and everyone now this tv wants to program such that people cannot use their set-top box or their dish tv their their box with let's say tata style so they will use the eprom there to program the the memory and prevent access from any other provider to this particular box eeproms would also allow erase they could be for example for boot code where we say that okay it may happen that i want to give a firmware update one year down the line so i should have the flexibility to erase also so eeproms would be used there and then flash flash all of you know where would you use flash where would you use flash there are memory cards and everything has flashed your cell phone has a flash everything all the solid-state storage that we talk about is with flash so then there are roms roms are read-only memories you cannot write into them where do you use a rom against data and all in those boot sequence and and and those parts where you are just stored which address location for example you would go to to get the first output or stuff like that so boot sequence would typically be stored in roms this you cannot change once it is programmed you cannot change it all the code memory will be of type now yes so this is this is the wide range of memories that exist so we will talk about as i mentioned srams will talk about b rams lifos c4 shift resistors and cams will not talk about as much uh but we will talk about eprom's eeproms flash and then roms when we would when we will do the mdt course there okay now when we talk about these different onset memories and off-chip memories so on-chip memories are typically srams whether we are talking of l1 cache l2 cache lc cache when it is onset it is typically srans they are very fast but they are not as dense we talk about six transistor estrangs you've heard about 60 sram cells 60 sram cells no one yes sir so it has two transistors to control the bit lines and the two back to back coupled in motors yeah so 60 transistor cells so we are talking about six transistors to save one bit of data when we talk about drams drams are one transistor and one capacitor and flash flash is actually effectively less than one transistor per bit of data on every transistor you could actually be storing two bits or even three bits of data and that is where it is much more dense endurance means the number of times you can read write into that particular memory so in a sram it is six transistors fully static cmos logic regular voltage operation endurance is maximum very high level of endurance uh d dams again very high level of endurance even though we have a capacitor uh which could leak a little but even then the endurance is very high but flash we actually when we will you know do the course we will see that we in flash we actually use very high voltages and therefore endurance goes bad we cannot really do as many number of reads and writes as you can do in a sram so there are various figures of merit you know speed density endurance power refresh so what does refresh mean what does refresh mean anyone restoring the data that was stored stored on this cell yes refresh means that if you do not restore the data on a on a regular basis then what happens if you do not restore the data on a regular basis you may actually end up losing data you may actually end up losing information so you have to refresh and drams because they store data on a capacitor it's a floating capacitor uh that can leak this this charge can leak therefore you need to refresh the dram the contents of a dr okay retention we already talked about as you switch off the power would go off and and the contents would be erased and then mechanism is by stable latch or a capacitor or in a flash with using a mechanism like fn tunneling or hot carrier injection to to be able to do read and write operation okay faizal you have a question so first thing is uh when we were talking about flash he was saying uh on one transistor we will store two to three bits so how is that possible like a transistor magic so we have a floating gate there we use like uh you know till now we've just looked at a gate oxide and then the substrate yes and flash we use special kind of devices where you have gate one you have silicon dioxide you have gate two you have silicon dioxide and then you have the substrate is it like the floating gate or something sorry fg was huh floating it was yeah so you have a floating gate there in which you can trap charges okay okay yes sir when you trap charges the vt would change and then you will be able to say that what is the kind of uh data stored there okay and so one more thing can you please reiterate why do we need to refresh because in these rams you're storing data on a capacitor it's like a dynamic gate so why did you need to use a keeper there because that data would leak some charge sharing can happen something can happen some mishap can happen due to which that data can be lost so you put a keeper in a dynamic gate is it not yes yes sir now for a dram if you start to put keepers in every cell then you will become a 2t1c cell area would double we don't want that yes sir therefore we say okay we will keep one t and one c but every now and then we will refresh the data we will restart we will put the charge on the capacitor again yes okay underfoot thank you sir yeah so that's a quick overview of different kinds of memories that we have but whatever be the kind of memory you will see that we can still cover them in one course because they are organized in a very standard way what you have is a structured array of storage elements which are accessed you know if let us say we are storing one word in this particular row then we have a decoder which would select a particular word and we have ios which would give out the output so by putting them in a structured array we are able to actually make the array much much denser and also use lesser periphery circuits or lesser additional circuits than what you would use in a latch so the structure of all the membranes whether you're cognitive dram or sam or flash would typically have a core array would have decoder region and would have i o region we'll look into it in a little more detail a little later but let us look at the benefit of having a structured core array uh i have a downside yes please uh sir always when it comes to the memory structure will we just have an m cross instructions or is it or do we have any other structures oh so there will be many structures this is the most rudimentary basic structure that i'm introducing you to over here in this class when we go to memory design course you will see there are hierarchical architectures there are other structures also but still you know this basic net that there is an array of there is a cluster of storage elements which are closely coupled which are closely coupled not only through world line but also through bit lines that then it remains constant okay that there is some decoding architecture there that in it remains constant that there are ios which would have struck which would have circuits to buffer the output that in it remains constant that there is some brain some control region somewhere that remains constant so since these tenets remain constant we start with a very basic architecture okay we can go into much more complex architectures and we do go in the course itself we do go okay okay yeah so if we look at this basic architecture only where we have a control decoders array and ios this control region is the brain of the memory okay this would have uh circuits which would tell whether it is a read operation so if it is a read operation it will tell okay activate this set of signals if it is the right operation it will say activate the other set of signals if it is a dummy operation it would say okay save power and all that so this control region you may say is the brain of the mmg it controls the state machine so in a memory you could do multiple operations say in a latch or in a flop you would just trigger the clock and the latch will be written into and it will also output in the same cycle or whatever will happen in a memory by the virtue of you know consolidating a big array and everything you separate the read and write operations across cycles you say okay when i want to write i will use one particular set of inputs when i want to read i will use another set of inputs and outputs okay so there are different states that the memory can be in and that is controlled in this control region the control region has what we call as a clock generator and what we call as a some address pre-decoding also in it so when the addresses come they are pre-decoded and when the clock comes an internal clock is generated these pre-decoded addresses and the internal clock go to what is called as a post decoder and this is generic again across all memories you will have this now how many post decoders you have what is the architecture that may change but you will still always have a post decoder okay the post decoder would generate what we call as a word line it will select a particular row when a particular row is selected the memory cells the storage elements stored in that particular row will discharge bit lines now in this case because i'm starting to talk about srams i'm showing a differential you know a pair of bit lines bit line and bit line bar but in srams also you have single ended just so just one bit line per memory cell and then when you talk about roms and when we talk about drams and when we talk about flash memories you would typically have only one bit line per memory cell why don't we have two bit lines in those roms and drams you've done layouts now if i have to route two metals versus one metal what is denser so we want to keep as as dense you know we talk about uh roms to be very very dense d ramps to be very very dense flash to be very very dense so for that purpose we do not go for differential bit lines there but when you select a memory cell some bit line would discharge and that discharge you will measure you will estimate and you will observe at what is called as a sense amplifier okay so once the discharge has happened you trigger the sense amplifier and you output you use you output the uh the differential or you enhance the differential and you give a zero one output on the q pin okay so this is a typical read operation as it would happen inside a memory when you talk about a write operation you will still have word line selection the way we talked about talked about but you will also have another clock going from here and you will have what you call as a write driver so data will come from outside and right driver will discharge one of the bit lines either bit line or bit line bar and that would be written into the memory cell there okay any questions here okay so again this is just to give you an intuitive feel of how uh different components or how a signal flow uh you know a clock flows inside the memory to do a accomplish a complete read and write operation okay so this is a d latch how many transistors can you count in it quickly 14 transition 14 transistors but do you notice that of these 14 transistors there are a few transistors which are not really needed or there are a few transistors which could actually be shared across memory cells for example consider the case where word line is not selected or where the clock is not coming so clock is zero means both these p moses are on am i right if these c moses are on then i am effectively having vdd directly over here so in a way these four p masses are not required 99 of time because for a memory the clock would come rarely so you have 1000 words in a memory even if you access memory in every cycle any any particular word will be accessed only one and one thousand times so more than ninety nine percent of times this pmos is not getting selected this like these p masses are simply waste vdd is already coming here are you able to see this friends if you don't ask questions the questions will simply linger on in your minds is this clear are you able to understand why i said that 99 percent of times the seeker is zero for a particular memory storage element is that part clear these p moses but said as you said the one person case what is what will be that alternative way to implement that one percent case yeah so you tell me if i if i do not use a full cmos circuit what do i do we have already done some such circuits where we were not using full cmos so what were the constraints that were coming on our way so like we can use a domino logic or something that okay we do not want to make a dram we want to use static logic only so what was the static method in which we were not using the pmos stack or not using the pmos pmos is as many p masses you are using the suitor and uh pseudo nmos and what was the challenge of designing pseudo nmos rising so as soon as i remove these four p masses i have a pseudo nmo circuit then what this means is that i have to size my devices very carefully are you able to see this yes so these four four p masses are not required for 99.9 percent of time therefore you say i remove them but for that point one percent you still don't want to fail and for that you have to do the sizing okay okay sir yeah so vaishnav what did you not understand you said yes sir in any cycle you will access one word yes sir so the remaining 1000 words or 999 words then again 99 okay like log cycles may configure together i'll be clearing yeah so now for the 99 percent of cells the clock is not coming no yes sir yes yes okay in reality this is 99.99 something still higher yes yes but you can't let that one percent or 0.1 percent of 0.01 also fail that is where you need to be careful about the sizing that is where sizing comes into picture yes sir,https://www.youtube.com/watch?v=Z-sJ1vuRj2E,"Link: https://www.youtube.com/watch?v=Z-sJ1vuRj2E
Transcript: about sense amplifier today okay so why memories like we talked about the entire library we talked about some arithmetic circuits then why memories why is what is so important about memories that we're talking about in dvd course also certain memories are the minimalistic storage elements which provides high density so if we consider a case of a resistor or a latch for a flip-flop then those involve large number of transistors even though they provide the storage functionality that they don't provide the high package density so we need to specifically look into the models thank you ranjit so you already made my task a little easier in the sense that what we are saying is that uh memories are high density storage elements and they are so important that today they cover uh you know in in advanced socs they cover up to 70 to 80 percent of chip area so come to think of it all that you've discussed in this course both libraries and everything that is not even 20 of total chip area do you see that and and since memories cover that huge area or have such a huge footprint on a chip we talk about memories in this course also and that is also the reason why we have a separate course all together on memories that will be running in the next semester so uh why is it that memories consume so much of area or why so much of area is given to memories see in a typical computer architecture you will see that memories are there at various levels there are register files which could be shift registers but which could also be small small memories there are caches of different level of hierarchy first level cache which is integrated inside the processor it operates at the same speed as the processor it has to operate uh that like it would possibly access every cycle and if you've done the course on computer architecture you also know that there is an instruction cache there is a data cache and there could be the concept of a unified cache also so there are these caches level one cache level two cache level three cache and all that so all this is on chip and then outside the chip also then you have main memory which which would typically be dram we will cover about dram also in the memory design course and beyond the dram there will be non-volt non-volatile storage the pendrives that you have where you would store your data so do you realize that memories are kind of pervasive as we move away from the processors they are also becoming slower so while resistor files operate at the data path speed are really really very very fast number one caches operate at processor speed the second level caches may actually take multiple processor cycles third level caching materials takes still longer and as you go to main memory which is off chip the time duration or the time of access increases multi multi-fold okay so it would take hundreds of cycles to access a dram from a chip so how you size these memories and how you organize this architecture is critical and you look quite a you you look into quite a bit of it i hope uh in detail in the computer architecture course how many of you have done the ca course and uh have you covered these different hierarchy architectures different hierarchies and memory architecture so raising hands to tell me that you have done the course and you understand this or you are raising hands to ask questions so please ask ranjit oh no sorry it was just to indicate okay akash that was also to indicate yes that's us okay just two of you have done cia course others have not done computer architecture i'm very surprised okay so the chat window says class runs okay i get it so many of you have done the cfos and you do understand that memory hierarchy is is critical to managers important to manage in mdt course we'll spend just about a lecture or two on on memory hierarchy and how to size this up because we have already covered it and see it but we will actually spend more time on how to design the level one cache or level two cache or you know the dram so that you get the you you achieve the desired objective whether it is high density or high speed or low power whatever it is so uh and just already mentioned that uh the standard you know the the latches and the flip flops they take much more area than a standard 60 memory cell so we will come to just that but before that when we talk about memories we also need to realize that whether it is resistor fires or l1 l2 caches or l3 caches there are different kinds of memories that come into picture one set of memory is random access which are static rams and drams but then on any chip you would also have stuff like free force have you heard about first in first out c4s which are used to implement queues you also have last and first outs which are used to implement stacks so when you have when you do programming you must have definitely uh you know in data structures courses you must know about stacks so there are memories which would be used to implement stacks then there are shift registers which you already know and then there are content addressable memories you know what is a cam have you ever heard about it earlier no sir yes sir okay huh okay who has said okay can you tell us about it what is it yes so it is a type of associated memory that is used for high speed searching applications it is means it basically finds the data and returns the address of matching data great so uh see typically when you talk of a memory you would typically give an address location and you would want to find out what is written on that particular address a cam is something different cam does not know what the address is cam knows what the content is so you search for the content and that leads you to the address and then from that address you may do further operations now where is it needed consider the case of a of a network router a network switch you know that you want to route some packet of data to google's us office so you want that you know that the destination is us but in a particular routing switch all that you can tell is that okay out of these four switches which one would take me closer to the us destination to the us server so you search for us in the content and whatever programmation or whatever programming has been done at the at the router level it will tell you oh go to port number 25 it will route your packet to port number 25. now you switch the router off you turn it on again next time around it may route you to port number 29 port number 2 wherever whatever has been configured so depending on data you will get a different address to go to to send your packet to that is what is content addressable memory this is also very widely or like content addressable memories are are tightly coupled to processors so that when when a particular instruction is given the follow-up instructions are brought in quickly based on the content the you know the locate by by doing a quick content search as to which location is this particular instruction stored and then i pull out remaining instructions from that region quickly so cams are specific memories and we will not really talk about them much in the course but just for the sake of completeness tams are also non-random access read write memories now while these are read write memories and these are all volatile now like volatile means that when you switch off the power the contents will get erased so when you power up the circuit again you will need to write the memory right inside the memory all over again but you don't want but or you also need memories which would not erase all the data is it not that is where we have nv read write memories that is non-volatile read write memories these include electric electrically programmable roms electrically erasable programmable roms and flash memories so what is the use of these flash and eeproms and eproms anyone so these memories uh firstly they provide the non-volatility and the second thing is that this can uh these are facilitate the large number of rights so they can be arrested and right written yeah so uh eproms over here cannot be raised but ee prompts can be raised so eproms are electrically programmable roms so what you do here is you kind of blow away the fuses once the fuse is blown now you cannot rebuild it again so eeproms where would they be used can you think of a use case boot sequence yes boot sequence or for example uh there is a standard set-top box chip which you also sell to airtel and you would sell to bharti and you said to tata sky and you sell to this tv and everyone now this tv wants to program such that people cannot use their set-top box or their dish tv their their box with let's say tata style so they will use the eprom there to program the the memory and prevent access from any other provider to this particular box eeproms would also allow erase they could be for example for boot code where we say that okay it may happen that i want to give a firmware update one year down the line so i should have the flexibility to erase also so eeproms would be used there and then flash flash all of you know where would you use flash where would you use flash there are memory cards and everything has flashed your cell phone has a flash everything all the solid-state storage that we talk about is with flash so then there are roms roms are read-only memories you cannot write into them where do you use a rom against data and all in those boot sequence and and and those parts where you are just stored which address location for example you would go to to get the first output or stuff like that so boot sequence would typically be stored in roms this you cannot change once it is programmed you cannot change it all the code memory will be of type now yes so this is this is the wide range of memories that exist so we will talk about as i mentioned srams will talk about b rams lifos c4 shift resistors and cams will not talk about as much uh but we will talk about eprom's eeproms flash and then roms when we would when we will do the mdt course there okay now when we talk about these different onset memories and off-chip memories so on-chip memories are typically srams whether we are talking of l1 cache l2 cache lc cache when it is onset it is typically srans they are very fast but they are not as dense we talk about six transistor estrangs you've heard about 60 sram cells 60 sram cells no one yes sir so it has two transistors to control the bit lines and the two back to back coupled in motors yeah so 60 transistor cells so we are talking about six transistors to save one bit of data when we talk about drams drams are one transistor and one capacitor and flash flash is actually effectively less than one transistor per bit of data on every transistor you could actually be storing two bits or even three bits of data and that is where it is much more dense endurance means the number of times you can read write into that particular memory so in a sram it is six transistors fully static cmos logic regular voltage operation endurance is maximum very high level of endurance uh d dams again very high level of endurance even though we have a capacitor uh which could leak a little but even then the endurance is very high but flash we actually when we will you know do the course we will see that we in flash we actually use very high voltages and therefore endurance goes bad we cannot really do as many number of reads and writes as you can do in a sram so there are various figures of merit you know speed density endurance power refresh so what does refresh mean what does refresh mean anyone restoring the data that was stored stored on this cell yes refresh means that if you do not restore the data on a on a regular basis then what happens if you do not restore the data on a regular basis you may actually end up losing data you may actually end up losing information so you have to refresh and drams because they store data on a capacitor it's a floating capacitor uh that can leak this this charge can leak therefore you need to refresh the dram the contents of a dr okay retention we already talked about as you switch off the power would go off and and the contents would be erased and then mechanism is by stable latch or a capacitor or in a flash with using a mechanism like fn tunneling or hot carrier injection to to be able to do read and write operation okay faizal you have a question so first thing is uh when we were talking about flash he was saying uh on one transistor we will store two to three bits so how is that possible like a transistor magic so we have a floating gate there we use like uh you know till now we've just looked at a gate oxide and then the substrate yes and flash we use special kind of devices where you have gate one you have silicon dioxide you have gate two you have silicon dioxide and then you have the substrate is it like the floating gate or something sorry fg was huh floating it was yeah so you have a floating gate there in which you can trap charges okay okay yes sir when you trap charges the vt would change and then you will be able to say that what is the kind of uh data stored there okay and so one more thing can you please reiterate why do we need to refresh because in these rams you're storing data on a capacitor it's like a dynamic gate so why did you need to use a keeper there because that data would leak some charge sharing can happen something can happen some mishap can happen due to which that data can be lost so you put a keeper in a dynamic gate is it not yes yes sir now for a dram if you start to put keepers in every cell then you will become a 2t1c cell area would double we don't want that yes sir therefore we say okay we will keep one t and one c but every now and then we will refresh the data we will restart we will put the charge on the capacitor again yes okay underfoot thank you sir yeah so that's a quick overview of different kinds of memories that we have but whatever be the kind of memory you will see that we can still cover them in one course because they are organized in a very standard way what you have is a structured array of storage elements which are accessed you know if let us say we are storing one word in this particular row then we have a decoder which would select a particular word and we have ios which would give out the output so by putting them in a structured array we are able to actually make the array much much denser and also use lesser periphery circuits or lesser additional circuits than what you would use in a latch so the structure of all the membranes whether you're cognitive dram or sam or flash would typically have a core array would have decoder region and would have i o region we'll look into it in a little more detail a little later but let us look at the benefit of having a structured core array uh i have a downside yes please uh sir always when it comes to the memory structure will we just have an m cross instructions or is it or do we have any other structures oh so there will be many structures this is the most rudimentary basic structure that i'm introducing you to over here in this class when we go to memory design course you will see there are hierarchical architectures there are other structures also but still you know this basic net that there is an array of there is a cluster of storage elements which are closely coupled which are closely coupled not only through world line but also through bit lines that then it remains constant okay that there is some decoding architecture there that in it remains constant that there are ios which would have struck which would have circuits to buffer the output that in it remains constant that there is some brain some control region somewhere that remains constant so since these tenets remain constant we start with a very basic architecture okay we can go into much more complex architectures and we do go in the course itself we do go okay okay yeah so if we look at this basic architecture only where we have a control decoders array and ios this control region is the brain of the memory okay this would have uh circuits which would tell whether it is a read operation so if it is a read operation it will tell okay activate this set of signals if it is the right operation it will say activate the other 
set of signals if it is a dummy operation it would say okay save power and all that so this control region you may say is the brain of the mmg it controls the state machine so in a memory you could do multiple operations say in a latch or in a flop you would just trigger the clock and the latch will be written into and it will also output in the same cycle or whatever will happen in a memory by the virtue of you know consolidating a big array and everything you separate the read and write operations across cycles you say okay when i want to write i will use one particular set of inputs when i want to read i will use another set of inputs and outputs okay so there are different states that the memory can be in and that is controlled in this control region the control region has what we call as a clock generator and what we call as a some address pre-decoding also in it so when the addresses come they are pre-decoded and when the clock comes an internal clock is generated these pre-decoded addresses and the internal clock go to what is called as a post decoder and this is generic again across all memories you will have this now how many post decoders you have what is the architecture that may change but you will still always have a post decoder okay the post decoder would generate what we call as a word line it will select a particular row when a particular row is selected the memory cells the storage elements stored in that particular row will discharge bit lines now in this case because i'm starting to talk about srams i'm showing a differential you know a pair of bit lines bit line and bit line bar but in srams also you have single ended just so just one bit line per memory cell and then when you talk about roms and when we talk about drams and when we talk about flash memories you would typically have only one bit line per memory cell why don't we have two bit lines in those roms and drams you've done layouts now if i have to route two metals versus one metal what is denser so we want to keep as as dense you know we talk about uh roms to be very very dense d ramps to be very very dense flash to be very very dense so for that purpose we do not go for differential bit lines there but when you select a memory cell some bit line would discharge and that discharge you will measure you will estimate and you will observe at what is called as a sense amplifier okay so once the discharge has happened you trigger the sense amplifier and you output you use you output the uh the differential or you enhance the differential and you give a zero one output on the q pin okay so this is a typical read operation as it would happen inside a memory when you talk about a write operation you will still have word line selection the way we talked about talked about but you will also have another clock going from here and you will have what you call as a write driver so data will come from outside and right driver will discharge one of the bit lines either bit line or bit line bar and that would be written into the memory cell there okay any questions here okay so again this is just to give you an intuitive feel of how uh different components or how a signal flow uh you know a clock flows inside the memory to do a accomplish a complete read and write operation okay so this is a d latch how many transistors can you count in it quickly 14 transition 14 transistors but do you notice that of these 14 transistors there are a few transistors which are not really needed or there are a few transistors which could actually be shared across memory cells for example consider the case where word line is not selected or where the clock is not coming so clock is zero means both these p moses are on am i right if these c moses are on then i am effectively having vdd directly over here so in a way these four p masses are not required 99 of time because for a memory the clock would come rarely so you have 1000 words in a memory even if you access memory in every cycle any any particular word will be accessed only one and one thousand times so more than ninety nine percent of times this pmos is not getting selected this like these p masses are simply waste vdd is already coming here are you able to see this friends if you don't ask questions the questions will simply linger on in your minds is this clear are you able to understand why i said that 99 percent of times the seeker is zero for a particular memory storage element is that part clear these p moses but said as you said the one person case what is what will be that alternative way to implement that one percent case yeah so you tell me if i if i do not use a full cmos circuit what do i do we have already done some such circuits where we were not using full cmos so what were the constraints that were coming on our way so like we can use a domino logic or something that okay we do not want to make a dram we want to use static logic only so what was the static method in which we were not using the pmos stack or not using the pmos pmos is as many p masses you are using the suitor and uh pseudo nmos and what was the challenge of designing pseudo nmos rising so as soon as i remove these four p masses i have a pseudo nmo circuit then what this means is that i have to size my devices very carefully are you able to see this yes so these four four p masses are not required for 99.9 percent of time therefore you say i remove them but for that point one percent you still don't want to fail and for that you have to do the sizing okay okay sir yeah so vaishnav what did you not understand you said yes sir in any cycle you will access one word yes sir so the remaining 1000 words or 999 words then again 99 okay like log cycles may configure together i'll be clearing yeah so now for the 99 percent of cells the clock is not coming no yes sir yes yes okay in reality this is 99.99 something still higher yes yes but you can't let that one percent or 0.1 percent of 0.01 also fail that is where you need to be careful about the sizing that is where sizing comes into picture yes sir"
v1yO56zfo9w,thank you okay so what we therefore use in srams is this six transistor set over here what has been done is you know this inverter is there this inverter is there then this clock transistor has been taken up and this clock is now called word line okay and this d transistor has been removed and put in a common area which is called the i o region remember i said there is a right driver where d would come so this this transistor this b the d n mass has been put in the right driver now so what has happened is that what you are repeating millions of times in a storage in a storage uh memory is not these 14 transistors but only these six and you have a 60 memory cell so this word line is nothing but the clock this is the inverter that we talked about where we said that these pmoses have been removed and this bit lines these bit lines actually represent the internal nodes over here this node such that the data that the n-mosses of the data are in the right driver down below are you able to see this that a 60 memory cell is a minimized latch nothing else any questions okay great so now how do you read and write into this latch so to be able to read into this latch what you do is you first pre-charge the bit lines so these are bit lines and bit line bars you you p charge them and you take over line to be high when this particular set of analysis are turned on because word line went high what happens they start to connect bit lines and the internal nodes this side stores a zero and this side you precharge to vdd what will happen some current flow would happen as that current flows bit line would discharge bl bar because this is also 1 and this is also 1 bl bar would not change and it is this differential that is created that you will sense at the sense amplifier to complete the read operation are you able to see this any questions sir please explain the workings okay so what are we saying is that even before you select the word line you pre-charge you maintain the bit lines at a particular value so these bit lines are as we just shared internal nodes they are simply capacitors so you pre-charge them to a particular value and then when you turn the word line on the side on which zero was stored that particular side the bit line would discharge so one of the bit line remains our vdd because on that side one was written the other other bit line starts to fall from the one level and you measure the differential generated and that is how you say okay i am storing a 0 or a 1 inside this memory cell so if bl discharges you say it is a 0 if blb discharges you say it is a 1 or vice versa ok yes yes sir uh i understood sir but uh why are we exactly discharging this beer sir i mean what sex otherwise how will you make out what is written inside the memory set oh yes sir you want to read nah yes yes yes sir understood so this is a read operation okay so now how do we write into the memory cell let's say in the same memory cell where 0 was written on the blti node now if i want to write a different data what it means is that bit i should go to 1 and blf i should go to 0. now what would you do see you have this nmos which would connect bit lines to the internal node what would you do you want to write a 0 and you want to write a 1 what would you write on the bit line hello sorry can you charge up the bitcoin i'm asking you see in the read operation we recharged both the bit lines to one then we said okay the side which stores the zero that will discharge the bit line and we will know whether it is a zero or a one yes sir now i want to write inside the memory yes and i have those nmos pass gates yes what would i write on the bit line now to be able to do a complete write inside the memory uh sir we'll set the bit line so if you want to write a one we'll set the bit line high by the right driver and we'll now turn on the board so that is right underneath what about bit line bar yeah bit line bar will be the complement of it which will be written okay so in the read cycle both bit line and bit line bar were written to one however in the write cycle you will put them at a value which is desired for example if you want to write a one on particular bit line on a particular side you would maintain that bit line to be one and the other bit side bit line side you will put a zero and then what happens look at it see n mass will transfer zero much more efficiently than a 1. so what happens is when you take the word line high after keeping one of the bit lines to 0 the node 1 discharges fast on the other side the node 0 will only charge the charger just a little because it is an nmos through an nmos once node 1 has completely discharged that is when like you see this pmos turns on and that is when the write operation has completed so initially there is only some charge that can come from the bit line it cannot really take 0 to 1. unless this comes into picture you will see your write operation cannot complete you will never be able to go to full vdd unless you have pmos coming into picture there so can we say that writing one would take more time than writing zero like as you have just explained very good very very good this is this is what it will take because to be able to write a one you first need to write a zero and then only one will be written otherwise one cannot even be written very good any questions about the right operation okay so this is how we would do the read and write inside the memory and uh then for the memory cells we have multiple figures of merit see just hold that parallel will look at the figures of merit for a memory we looked at speed power area refresh endurance so many things there are many figures of merit length to bit cell also for example cell current cell current is a figure of merit that tells how quickly my bit line will discharge during the read operation so it will control read speed bit line leakage is about power and to some extent also about read speed cell stability so what happens see when you so cell current let's just quickly go through the figures of merit cell current is about as i said speed the speed at which the bit lines can discharge and it is essentially determined by the stack the sizing of this stack the bigger the devices the more current there would be but realize the bigger these devices more is the leakage also more is the capacitance of the bit line also so we cannot simply keep on increasing the size cell stability is one of the most important specification of any storage element whether it is a flip flop or a latch or a memory set and the challenge is highest during read operation because during read operation you expose your latch your storage element to external noise what happens is that when you start a read operation current starts to flow like this when a current flows see this was initially storing the zero but to ensure that a current flows this value will go from 0 to vx a value higher than zero otherwise there would be no current flow and as this goes to a level higher than vx a hal a level higher than zero it can actually turn on the devices on this side turn off the pmos on this side and so on okay and that is where risk starts to appear so the cell stability starts to degrade you wish to ensure that this vx is as low as possible therefore we get another sizing constraint over here which is that pass gate has to be much more resistive than the pull down so this is the pass gate this is the pull down the pass gate has to be much more resistive than the pull down if pull down is more resistive then what happens this node will rise above vdd by two and it will kind of flip the contents of the memory cell we don't want that to happen so there was this question now the if you remove those p masses what happens so we already start to see that there are sizing constraints that would come otherwise the memory memory cell operation will start to get hampered are you able to see this any questions okay so the next figure of merit that we are concerned about is right margin right margin essentially means that uh see what are we trying to do we said that this bit line would go to zero and then this internal node will discharge so can can you really disage a capacitor to zero see what is this bit line is a rc this is a wire so which it would have some r and the wire also has some capacitance if i apply a voltage source here or a current source here how long do you think it will take to discharge this particular capacitance to zero how long you realize that it being an rc circuit uh it it will take a huge amount of time to discharge the capacitor to zero are you able to see this okay let us wait until you see this yes sir it's first order differential equation so it takes infinite practically according to the equation it takes infinite amount of time to discharge about them now do you have that kind of time when you want to read or write a memory no you want to operate your memory at one gigahertz so what happens you say that oh i cannot really discharge my bitline to zero what is the highest level of bit line at which i will still be able to write into the memory set is it 50 millivolts that i discharge only up to 50 millivolts and i will still be able to write or is it 100 millivolts and you will realize that as you have a better right margin you can actually operate much faster because you do not really need to go through all those rc delays now instead of 6rc you can go at 5rc and still be able to write inside the memory are you able to see this so right margin is also a metric of speed it is a metric of writability whether i can actually write into the memory cell at all or not and in the course and we'll look at it we will also look at it look at the advanced technologies where right margin is actually negative what it means is you need to take bitline at a voltage which is lower than zero to be able to write into the memory set and we will talk about negative bit line write assist schemes in the course okay so when you want to write into the memory you want to say that this improve the right margin you need to say that this pull up should not be able to drive or should drive lesser current than what this stack of as gate and right driver can sink through it are you able to see this that the series of pass gate and dry driver has to be stronger than the pull up are you able to see this constraint yes sir okay so here every do you realize now that we're talking about uh size of pass gate pull down and in this particular case we are also brought in the pull up the pmos into the picture there and if we know if we know all these three sets of constraints you will realize that designing the memory cell even though it is only six transistors is not a simple task that is why we have numerous people working on optimizing the memory cell for the densest memory or for highest speed memory and so on okay uh leakage is a part of power consumption all of devices in a bit cell leak on devices also have junction leakage there is gate leakage also so to have low leakage you want to use as small devices as possible so that junction leakage is minimized huh great leakage is minimized so you want to use as small devices as is possible to reduce leakage you can also use long channel devices so typically in industrial sram cell you will notice that if the minimum channel length allowed by a technology is let us say x then the the length that is used inside the memory cell would almost always be more than 10 or 20 more than this x it will be 1.2 x or 1.3 x also at times okay so the length is always length of memory cell transistors is always larger than the minimum length so that you can reduce the leakage there okay and you will find in some papers that people also talk about using thick gate oxides so that you can reduce gate leakage in how do i put it when one in the high k metal gate technologies the requirement of thick gate oxide usage has reduced a bit but even then uh even for a high k metal gate stack if you use a thick gate oxide you can reduce leakage a bit because of reduced paneling okay uh any questions still here because now i am coming to the concept of butterfly curve have you heard about a butterfly curve in reference to a latch what is a butterfly curve any idea okay so let us say we just have two inverters over here you you see this switch is open so we do not have a latch we just have two inverters in one in two and out two are the three nodes that we are talking about over here if we look at the transfer characters of the two inverters what do we see that as n1 rises into would fall then as n2 rises as in two rises out two would fall are you with me on this these are the transfer practices of these two inverters is that clear any questions still here okay so uh what do we do we say the memory serka we have to find the stability of a memory cell in a memory cell there are these two inverters are connected back to back so what we do is we close the switch as soon as we close the switch now n1 is no longer connected however that n1 is replaced by out 2 so as out 2 rises in 2 falls the other curve was already between out 2 and n2 now realize that we are talking about for this circuit we are talking about two curves that relate out two and n two and if i merge them one over the other what would happen they would simply come one over another and what you would have is a butterfly curve so this latch is characterized by the transfer function of this latch is a butterfly curve are you able to see this yes sir so now what is important to realize is how much noise can i put in there that is what is meant by cell stability now that how much noise can i be immune to the more noise i am able to handle the more stable the sellers more stable the latches so now let us go to another level of abstraction we say that this latch you know if i am storing a zero on one side and one on the other the worst case noise that i need to inject is zero going towards one and one being reduced and going towards zero that is the worst case noise pair that i can inject on this particular latch are you with me this is the right assumption this is the worst case for the latch for noise injection so now is it okay if i say that this latch is essentially a long chain of inverters which are storing 0 1 0 1 0 1 0 1 can i say it like that so why where n1 is equal to n3 is equal to n5 they are all connected so there is this loop see i give a small noise here this noise can get increased over here then out 2 would increase that noise further so this small noise has increased and it is now fed back into this inverter okay so noise is actually fine is it sorry so noise is amplifying itself you can't amplify now yes sir yes sir i don't know a latch latches amplifying action is it not yeah right into a latch so i can amplify it now if i just keep one picture then i am not able to overlap this big noise and small noise however this big noise will actually go to this inverter now and will cause much more havoc is it not so just to make my work simple what i'm trying to do is i'm just opening this latch into a series of inverters can i do that just for sake of understanding we know that n1 equal to n3 equal to n5 and all that we know this so what happens now it means that if n1 was given a positive noise then n3 also is given a positive noise and n5 also is given a positive noise and same applies for n2 and 4 and n6 that will be the worst case am i right yes sir now if we plot the butterfly curve now see this will be in one and three and five this will be in two and four and six and so on in this butterfly curve let me say i injected noise onto n1 so in one say on this axis i injected a noise here so when n one was zero uh this particular curve was being followed are you with me so i injected a noise what happened in 2 became slightly lower than 0. slightly lower than 1 on n2 i injected the opposite side of noise so what happened when n2 went to further lower value n1 became slightly greater than 0. now on n3 i inject that noise again when i inject noise on n3 n2 comes here so initially it was here now it has come here i inject noise on n4 and you will see that there will come a point when they will just move between this i cannot go any further because in 4b informal noise dollar so i am just stuck in this loop here are you able to see this so it means that my circuit is safe for this amount of noise if this amount of noise comes then i stored 0 on n1 okay that 0 will go to this value and i have stored 1 on n2 that in that one would go to slightly lower than that but i will still have 0 and 1 are you able to see this any questions so the point that where they will converge like they will start repeating each other is this noise it is not getting troubled this noise is safe yes sir this is definite this noise is definitely less than the noise margin that we could think of i have more noise margins than this noise this much i can say yes now let's increase the amount of noise let us say i put in that much of noise so then in the next cycle what happens to n2 into would put this kind of noise so in one has now come here now again i will put noise on this into will come here again i will put now infor will come there in 4k i will now put a noise so it will go on to this curve you see in 5 is almost close to vdd by 2 now but i have to inject noise on n5 as soon as i injected noise on n5 what happened my n5 was almost now it was already close to vdd by two it has now grown beyond vdd by two and my n6 is now almost zero it was meant to be one but it is almost zero the next noise and i am fully at zero i have completely flipped so for this value of noise my circuit is not stable so noise margin is somewhere between the first case and this case are you able to see this yes sir so what is that what is that unique case which we would call as noise margin that unique case would appear something like this okay i put some noise there there there there and here now this is the largest square that i can fit into these lobes if there are two asymmetrical lobes then the smaller square is the noise margin because i have shown you symmetrical loops the noise margin on both the sides are same but you can come across cells where the lobes are asymmetrical so you may say this is the noise margin no this is the noise margin because if this was the data that you were storing only this amount of noise could toggle it into the other side are you able to see this so for memories or for latches people will talk about butterfly curve so you should now be able to answer what a butterfly curve is and when they talk about stability or noise margin you should be able to tell that the stability can be measured by fitting the largest square in the smaller lobe of the butterfly curve is this thing clear any questions sir,https://www.youtube.com/watch?v=v1yO56zfo9w,"Link: https://www.youtube.com/watch?v=v1yO56zfo9w
Transcript: thank you okay so what we therefore use in srams is this six transistor set over here what has been done is you know this inverter is there this inverter is there then this clock transistor has been taken up and this clock is now called word line okay and this d transistor has been removed and put in a common area which is called the i o region remember i said there is a right driver where d would come so this this transistor this b the d n mass has been put in the right driver now so what has happened is that what you are repeating millions of times in a storage in a storage uh memory is not these 14 transistors but only these six and you have a 60 memory cell so this word line is nothing but the clock this is the inverter that we talked about where we said that these pmoses have been removed and this bit lines these bit lines actually represent the internal nodes over here this node such that the data that the n-mosses of the data are in the right driver down below are you able to see this that a 60 memory cell is a minimized latch nothing else any questions okay great so now how do you read and write into this latch so to be able to read into this latch what you do is you first pre-charge the bit lines so these are bit lines and bit line bars you you p charge them and you take over line to be high when this particular set of analysis are turned on because word line went high what happens they start to connect bit lines and the internal nodes this side stores a zero and this side you precharge to vdd what will happen some current flow would happen as that current flows bit line would discharge bl bar because this is also 1 and this is also 1 bl bar would not change and it is this differential that is created that you will sense at the sense amplifier to complete the read operation are you able to see this any questions sir please explain the workings okay so what are we saying is that even before you select the word line you pre-charge you maintain the bit lines at a particular value so these bit lines are as we just shared internal nodes they are simply capacitors so you pre-charge them to a particular value and then when you turn the word line on the side on which zero was stored that particular side the bit line would discharge so one of the bit line remains our vdd because on that side one was written the other other bit line starts to fall from the one level and you measure the differential generated and that is how you say okay i am storing a 0 or a 1 inside this memory cell so if bl discharges you say it is a 0 if blb discharges you say it is a 1 or vice versa ok yes yes sir uh i understood sir but uh why are we exactly discharging this beer sir i mean what sex otherwise how will you make out what is written inside the memory set oh yes sir you want to read nah yes yes yes sir understood so this is a read operation okay so now how do we write into the memory cell let's say in the same memory cell where 0 was written on the blti node now if i want to write a different data what it means is that bit i should go to 1 and blf i should go to 0. now what would you do see you have this nmos which would connect bit lines to the internal node what would you do you want to write a 0 and you want to write a 1 what would you write on the bit line hello sorry can you charge up the bitcoin i'm asking you see in the read operation we recharged both the bit lines to one then we said okay the side which stores the zero that will discharge the bit line and we will know whether it is a zero or a one yes sir now i want to write inside the memory yes and i have those nmos pass gates yes what would i write on the bit line now to be able to do a complete write inside the memory uh sir we'll set the bit line so if you want to write a one we'll set the bit line high by the right driver and we'll now turn on the board so that is right underneath what about bit line bar yeah bit line bar will be the complement of it which will be written okay so in the read cycle both bit line and bit line bar were written to one however in the write cycle you will put them at a value which is desired for example if you want to write a one on particular bit line on a particular side you would maintain that bit line to be one and the other bit side bit line side you will put a zero and then what happens look at it see n mass will transfer zero much more efficiently than a 1. so what happens is when you take the word line high after keeping one of the bit lines to 0 the node 1 discharges fast on the other side the node 0 will only charge the charger just a little because it is an nmos through an nmos once node 1 has completely discharged that is when like you see this pmos turns on and that is when the write operation has completed so initially there is only some charge that can come from the bit line it cannot really take 0 to 1. unless this comes into picture you will see your write operation cannot complete you will never be able to go to full vdd unless you have pmos coming into picture there so can we say that writing one would take more time than writing zero like as you have just explained very good very very good this is this is what it will take because to be able to write a one you first need to write a zero and then only one will be written otherwise one cannot even be written very good any questions about the right operation okay so this is how we would do the read and write inside the memory and uh then for the memory cells we have multiple figures of merit see just hold that parallel will look at the figures of merit for a memory we looked at speed power area refresh endurance so many things there are many figures of merit length to bit cell also for example cell current cell current is a figure of merit that tells how quickly my bit line will discharge during the read operation so it will control read speed bit line leakage is about power and to some extent also about read speed cell stability so what happens see when you so cell current let's just quickly go through the figures of merit cell current is about as i said speed the speed at which the bit lines can discharge and it is essentially determined by the stack the sizing of this stack the bigger the devices the more current there would be but realize the bigger these devices more is the leakage also more is the capacitance of the bit line also so we cannot simply keep on increasing the size cell stability is one of the most important specification of any storage element whether it is a flip flop or a latch or a memory set and the challenge is highest during read operation because during read operation you expose your latch your storage element to external noise what happens is that when you start a read operation current starts to flow like this when a current flows see this was initially storing the zero but to ensure that a current flows this value will go from 0 to vx a value higher than zero otherwise there would be no current flow and as this goes to a level higher than vx a hal a level higher than zero it can actually turn on the devices on this side turn off the pmos on this side and so on okay and that is where risk starts to appear so the cell stability starts to degrade you wish to ensure that this vx is as low as possible therefore we get another sizing constraint over here which is that pass gate has to be much more resistive than the pull down so this is the pass gate this is the pull down the pass gate has to be much more resistive than the pull down if pull down is more resistive then what happens this node will rise above vdd by two and it will kind of flip the contents of the memory cell we don't want that to happen so there was this question now the if you remove those p masses what happens so we already start to see that there are sizing constraints that would come otherwise the memory memory cell operation will start to get hampered are you able to see this any questions okay so the next figure of merit that we are concerned about is right margin right margin essentially means that uh see what are we trying to do we said that this bit line would go to zero and then this internal node will discharge so can can you really disage a capacitor to zero see what is this bit line is a rc this is a wire so which it would have some r and the wire also has some capacitance if i apply a voltage source here or a current source here how long do you think it will take to discharge this particular capacitance to zero how long you realize that it being an rc circuit uh it it will take a huge amount of time to discharge the capacitor to zero are you able to see this okay let us wait until you see this yes sir it's first order differential equation so it takes infinite practically according to the equation it takes infinite amount of time to discharge about them now do you have that kind of time when you want to read or write a memory no you want to operate your memory at one gigahertz so what happens you say that oh i cannot really discharge my bitline to zero what is the highest level of bit line at which i will still be able to write into the memory set is it 50 millivolts that i discharge only up to 50 millivolts and i will still be able to write or is it 100 millivolts and you will realize that as you have a better right margin you can actually operate much faster because you do not really need to go through all those rc delays now instead of 6rc you can go at 5rc and still be able to write inside the memory are you able to see this so right margin is also a metric of speed it is a metric of writability whether i can actually write into the memory cell at all or not and in the course and we'll look at it we will also look at it look at the advanced technologies where right margin is actually negative what it means is you need to take bitline at a voltage which is lower than zero to be able to write into the memory set and we will talk about negative bit line write assist schemes in the course okay so when you want to write into the memory you want to say that this improve the right margin you need to say that this pull up should not be able to drive or should drive lesser current than what this stack of as gate and right driver can sink through it are you able to see this that the series of pass gate and dry driver has to be stronger than the pull up are you able to see this constraint yes sir okay so here every do you realize now that we're talking about uh size of pass gate pull down and in this particular case we are also brought in the pull up the pmos into the picture there and if we know if we know all these three sets of constraints you will realize that designing the memory cell even though it is only six transistors is not a simple task that is why we have numerous people working on optimizing the memory cell for the densest memory or for highest speed memory and so on okay uh leakage is a part of power consumption all of devices in a bit cell leak on devices also have junction leakage there is gate leakage also so to have low leakage you want to use as small devices as possible so that junction leakage is minimized huh great leakage is minimized so you want to use as small devices as is possible to reduce leakage you can also use long channel devices so typically in industrial sram cell you will notice that if the minimum channel length allowed by a technology is let us say x then the the length that is used inside the memory cell would almost always be more than 10 or 20 more than this x it will be 1.2 x or 1.3 x also at times okay so the length is always length of memory cell transistors is always larger than the minimum length so that you can reduce the leakage there okay and you will find in some papers that people also talk about using thick gate oxides so that you can reduce gate leakage in how do i put it when one in the high k metal gate technologies the requirement of thick gate oxide usage has reduced a bit but even then uh even for a high k metal gate stack if you use a thick gate oxide you can reduce leakage a bit because of reduced paneling okay uh any questions still here because now i am coming to the concept of butterfly curve have you heard about a butterfly curve in reference to a latch what is a butterfly curve any idea okay so let us say we just have two inverters over here you you see this switch is open so we do not have a latch we just have two inverters in one in two and out two are the three nodes that we are talking about over here if we look at the transfer characters of the two inverters what do we see that as n1 rises into would fall then as n2 rises as in two rises out two would fall are you with me on this these are the transfer practices of these two inverters is that clear any questions still here okay so uh what do we do we say the memory serka we have to find the stability of a memory cell in a memory cell there are these two inverters are connected back to back so what we do is we close the switch as soon as we close the switch now n1 is no longer connected however that n1 is replaced by out 2 so as out 2 rises in 2 falls the other curve was already between out 2 and n2 now realize that we are talking about for this circuit we are talking about two curves that relate out two and n two and if i merge them one over the other what would happen they would simply come one over another and what you would have is a butterfly curve so this latch is characterized by the transfer function of this latch is a butterfly curve are you able to see this yes sir so now what is important to realize is how much noise can i put in there that is what is meant by cell stability now that how much noise can i be immune to the more noise i am able to handle the more stable the sellers more stable the latches so now let us go to another level of abstraction we say that this latch you know if i am storing a zero on one side and one on the other the worst case noise that i need to inject is zero going towards one and one being reduced and going towards zero that is the worst case noise pair that i can inject on this particular latch are you with me this is the right assumption this is the worst case for the latch for noise injection so now is it okay if i say that this latch is essentially a long chain of inverters which are storing 0 1 0 1 0 1 0 1 can i say it like that so why where n1 is equal to n3 is equal to n5 they are all connected so there is this loop see i give a small noise here this noise can get increased over here then out 2 would increase that noise further so this small noise has increased and it is now fed back into this inverter okay so noise is actually fine is it sorry so noise is amplifying itself you can't amplify now yes sir yes sir i don't know a latch latches amplifying action is it not yeah right into a latch so i can amplify it now if i just keep one picture then i am not able to overlap this big noise and small noise however this big noise will actually go to this inverter now and will cause much more havoc is it not so just to make my work simple what i'm trying to do is i'm just opening this latch into a series of inverters can i do that just for sake of understanding we know that n1 equal to n3 equal to n5 and all that we know this so what happens now it means that if n1 was given a positive noise then n3 also is given a positive noise and n5 also is given a positive noise and same applies for n2 and 4 and n6 that will be the worst case am i right yes sir now if we plot the butterfly curve now see this will be in one and three and five this will be in two and four and six and so on in this butterfly curve let me say i injected noise onto n1 so in one say on this axis i injected a noise here so when n one was zero uh this particular curve was being followed are you with me so i injected a noise what happened in 2 became slightly lower than 0. slightly lower than 1 on n2 i injected the opposite side of noise so what happened when n2 went to further lower value n1 became slightly greater than 0. now on n3 i inject that noise again when i inject noise on n3 n2 comes here so initially it was here now it has come here i inject noise on n4 and you will see that there will come a point when they will just move between this i cannot go any further because in 
4b informal noise dollar so i am just stuck in this loop here are you able to see this so it means that my circuit is safe for this amount of noise if this amount of noise comes then i stored 0 on n1 okay that 0 will go to this value and i have stored 1 on n2 that in that one would go to slightly lower than that but i will still have 0 and 1 are you able to see this any questions so the point that where they will converge like they will start repeating each other is this noise it is not getting troubled this noise is safe yes sir this is definite this noise is definitely less than the noise margin that we could think of i have more noise margins than this noise this much i can say yes now let's increase the amount of noise let us say i put in that much of noise so then in the next cycle what happens to n2 into would put this kind of noise so in one has now come here now again i will put noise on this into will come here again i will put now infor will come there in 4k i will now put a noise so it will go on to this curve you see in 5 is almost close to vdd by 2 now but i have to inject noise on n5 as soon as i injected noise on n5 what happened my n5 was almost now it was already close to vdd by two it has now grown beyond vdd by two and my n6 is now almost zero it was meant to be one but it is almost zero the next noise and i am fully at zero i have completely flipped so for this value of noise my circuit is not stable so noise margin is somewhere between the first case and this case are you able to see this yes sir so what is that what is that unique case which we would call as noise margin that unique case would appear something like this okay i put some noise there there there there and here now this is the largest square that i can fit into these lobes if there are two asymmetrical lobes then the smaller square is the noise margin because i have shown you symmetrical loops the noise margin on both the sides are same but you can come across cells where the lobes are asymmetrical so you may say this is the noise margin no this is the noise margin because if this was the data that you were storing only this amount of noise could toggle it into the other side are you able to see this so for memories or for latches people will talk about butterfly curve so you should now be able to answer what a butterfly curve is and when they talk about stability or noise margin you should be able to tell that the stability can be measured by fitting the largest square in the smaller lobe of the butterfly curve is this thing clear any questions sir"
t1jI2eLBQ8g,top level view of it we will discuss all this in much more detail in the course okay we can even remove the subtraction from this course just now now what is very important to look at is the layout so you have spent a lot of time working on the layout of the standard sets where we said that for every structure you would want to keep a distance of half DRC from the pr boundary you remember just now in the morning vaishna was asking so contacts can I remove that half DRC rule thus in the morning question I was asking so over there we're talking about no sharing nothing in fact leaving half the RC from the cell boundary memory I would want to talk about the layout because in memories you say that you would want to share as much around the cell boundary as possible because you have a structured array you know that your memory cell is abutted with another memory cell only not that aoi 221 will be abuted with aoi121 you know it is it is another memory cell because you are aware of this and because there is a structured array you actually start to share devices across the cell boundary so if this blue line is the cell boundary you see I share so can you tell me which are the pull downs and which is where is the pull up and where is the pass gate smallest one in the center is the pull up yeah the one in the end well and well would mean that we're talking about CMOS over there so that is the pull up so these two are the Pull-Ups and this connection would then be the connection to vdd then this one the smaller so it means one of these is basket the other one is pull you down from the s m constraint we realized that for cell stability pass gate has to be more resistive than the pull down so the top one is pass gate and over here the bottom one is pass gate and the other devices pull down so this connection would be for the bit line this would be for the bit line bar and then this connection will be for ground and then this would be wordline connections only in memories you use this kind of a long contact you made layouts if you make a rectangular contact what do you see DRC comes so vaishna was talking about contact to contact spacing and how it is impacting the area so in a memory because density is is of importance what we do is instead of putting two contacts one contact separately on the poly and one contact separately on the active and then maintaining a DRC between them we actually kind of merge two contacts and form a long contact and this long contact is allowed to be used only inside a memory why can you do this only inside a memory and not elsewhere any ideas friends uh sir because we are going to drop some drop some vrs very very uh we know we know where where all the points are where we are going to drop the VR so some drcs can be adjusted see we know that this is the only configuration in which you are allowing these long contacts so you can play with the Optics why are these drcs there when we were discussing early on in the course we were talking about drcs and how how we have this 193 nanometer light which is still used to make features which are 28 nanometers wide and and all that is it not so we said that okay because of this large wavelength of light uh putting stuff on mask is very complex so you can't do it therefore the RCs constraining the RCU that poly has to be in One Direction only and this and that and what not now it means that all those rules are largely because of Optics and if the in Optics you can predefine patterns okay then you can make the diffraction plate in such a way that you can still make structures well so by playing with what is called as resolution enhancement techniques we allow large contacts long contacts only inside the SRAM cell because we know that this is going to be available in this array only and nowhere else and in this array also there is a pattern a fixed pattern in which they will be there so I have a clear diffraction pattern for which I have to optimize my mask making process and therefore it is only allowed in the memory cell and nowhere else okay you show the contacts that are closed and violating DRC they should be made in different masks right they should be made in different different masks means if they are made in same mask so uh means if the minimum loss is nowhere nowhere outside the memory you are allowed to wallet any DRC they believe yesterday okay so you not even think about how to do it only inside the memory DRC violations are allowed for the purpose of gaining more density and this is approved or this is designed by the technology team not by you you can only request they will say if they will do it or not if it is possible on Silicon or not can you see okay so you don't even think of violating the RCs not allowed okay shubham so these long contacts you will see only inside the memory cell okay and then you have these metal layers you will see these small small stubs for connecting these contacts to bit lines vdd the word line stubs and the ground so you will notice that now when you made this stuff for ground there is a particular VR which is shared across four memory cells see this contact this VR they were shared across to my research Cooper needs it but this these vrs and contacts which are coming on the corners are shared across four memory cells so violent standard cells you would not allow any sharing in fact if you were to follow standard cell rules you will have to have memory cell which is this big but by allowing the sharing you've reduced the memory area to this much okay and then this is the word lines the word lines are running and you have these stubs for ground so an array then appears to look like this so this is a two cross two array there and that is how you ensure that srams are much much denser than latches and flip flops and other shift resistors that we were talking about in the earlier in the day okay any questions here Okay so with this layout part also done we need to talk about sense amplifiers so whenever you talk about memories you know people talk about bit cells they talk about bit cell stability they talk about bit cell layout those who know memories they will also talk about the layout and then they will talk about the sense amplifier so I'm just giving you a quick one or two slide glimpse of a sense amplifier we said there is a memory array wordline would come it would select a bit cell and that bit cell will discharge a bit line and then I will get to see the output somewhere down there now this bit nine has a huge capacitance on it if I want to discharge this particular bit line there is some you know I had what we said we had to charge this capacitance to vdd I want to discharge it to at least really by 2 to say that I have a zero so what kind of charge are we talking about t v d d by two kind of charge you're talking about and depending on the cell current there is a time huh there is a time it will take to discharge the particular bit line in this particular example that is given you don't need to even go into details you're talking about 7.5 nanoseconds we want to operate your memories are at least one gigahertz you have only one nanosecond available with you so what to do so you say oh I don't want to discharge full vdd to get to less than one nanosecond I can discharge only to vdd by 8 let us say or still lower VD by 10 will divide 12. it's the Lesser I discharge the faster I can be so what do you do you say o so let us put an amplifier down there which would amplify a vdd by 12 discharge into a full VD discharge at the output um that is why a sense amplifier is the motivation for using a sense amplifier clear any questions around that so I'm telling you'll write a story you can read the book and they will tell you a lot of other details I'm just telling it to you like a story so that you can get the intuitive feel of it you will do all the other details when we do the course but since we are touching memories in the DVD course you should know at least these few four three four things five things about memories foreign so we need sense amplifiers to get the speed a sense amplifier is typically a latch again and if you notice this appears to be the same structure as a memory cell except that there is an enable gate there okay so what happens is what happens is you discharge the bit line and that discharge starts to appear on the internal nodes of the sense amplifier when you have the sufficient discharge for this latch to operate you turn this enable signal on so till that time this was not a latch because the enable was off there was no ground Supply coming there but when the sufficient differential is made available you turn enables in the lawn as soon as you turn the enable signal on what happens this works as a latch this small differential gets Amplified and you are able to so the small differential between the two is Amplified and you are able to take one of the nodes to zero and the other back to one okay and what is important is that when you turn this on you see that these pmoses will automatically turn off so when you do this when you discharge one node to zero and recharge the other node to full vdd you are only talking about this capacitance now not about the entire bit line capacitance so in a way this full swing you have limited only to a small capacitance so sense amplifiers also help to save power so we started to use sense amplifiers to gain speed but it is very important to realize that sense amplifiers are less discharge on bit lines also helps to save power so sense amplifiers are therefore very important circuits to be used and understood when you design memories so in the memory design course there will be a project or two on sense amplifiers also so with that I think so there are other things which you've already done row decoders so decoding we've already take you know when we were doing logical effort and everything I'm not sure you realize but you already took a decoding example only so decoding we have kind of already taken care of and fence amplifiers is the part of IO that we are taken care of so in this session I have kind of introduced you sporadically to the most important components alpha memory any questions sir what is the minimum amount of time for which we need to wait till this bit line is a bit line appears at the sense amplifier input and then we turn on the sensorable signal yeah so just like any other amplifier run it a sense amplifier also has a minimum offset requirement to be able to distinguish zero and one correctly yes sir so that offset is characterized we will do that in the memory design course that offset is characterized and then it is ensured that the offset that appears on the bit lines or the differential that appears on the bit lines is more than that offset okay so there is something called as replica path inside the memory we will talk about it in the MDT course which is used to do this tuning okay but yeah this is characteristic of this of the sense amplifier so if you end up taking a sense a project on sense amplifier like a few of your colleagues have actually taken a project on sense amplifier in in in DVD course also you if you attend the presentations you are all expected to attend the presentation on Friday and Saturday so when you will attend the presentations you will get to see the constraints and the details about it okay okay so I have a basic question sir so am I allowed to run my poly in a horizontal directions actually previously when we were uh talking about this in one of the class I remember that you said we are we will not be using Pauline Horizon but I can't exactly remember what was the reason for that okay what could what can you imagine to be the reason for that so actually I got this dot because we were you in a 60 SRAM layout police were horizontal sir so I can rotate them and now so what is important is there should be in One Direction yes you can rotate the layout it will be all vertical then okay okay sir nice is there exact reasons or was that crosstalk reason not diffraction Optics resolution enhancement techniques do not allow poly to be run in two directions otherwise the mask will not be generated in the right way okay thank you okay so it was lithography yes Akash so one more reason can be this also key if we use a one Pauline vertical and one horizontal then the metal layers that we use to connect them they will be a somewhat vertical metal layers that will waste our area yeah yeah but no that is not the reason the reason essentially is that uh uh Optics doesn't allow that so you'll have to put a contact on poly and then only that contact needs to be tagged by a method is it not yes sir yes sir whether police horizontal or vertical doesn't matter you're only looking at a point on the poly then okay so but the reason essentially is Optics,https://www.youtube.com/watch?v=t1jI2eLBQ8g,"Link: https://www.youtube.com/watch?v=t1jI2eLBQ8g
Transcript: top level view of it we will discuss all this in much more detail in the course okay we can even remove the subtraction from this course just now now what is very important to look at is the layout so you have spent a lot of time working on the layout of the standard sets where we said that for every structure you would want to keep a distance of half DRC from the pr boundary you remember just now in the morning vaishna was asking so contacts can I remove that half DRC rule thus in the morning question I was asking so over there we're talking about no sharing nothing in fact leaving half the RC from the cell boundary memory I would want to talk about the layout because in memories you say that you would want to share as much around the cell boundary as possible because you have a structured array you know that your memory cell is abutted with another memory cell only not that aoi 221 will be abuted with aoi121 you know it is it is another memory cell because you are aware of this and because there is a structured array you actually start to share devices across the cell boundary so if this blue line is the cell boundary you see I share so can you tell me which are the pull downs and which is where is the pull up and where is the pass gate smallest one in the center is the pull up yeah the one in the end well and well would mean that we're talking about CMOS over there so that is the pull up so these two are the Pull-Ups and this connection would then be the connection to vdd then this one the smaller so it means one of these is basket the other one is pull you down from the s m constraint we realized that for cell stability pass gate has to be more resistive than the pull down so the top one is pass gate and over here the bottom one is pass gate and the other devices pull down so this connection would be for the bit line this would be for the bit line bar and then this connection will be for ground and then this would be wordline connections only in memories you use this kind of a long contact you made layouts if you make a rectangular contact what do you see DRC comes so vaishna was talking about contact to contact spacing and how it is impacting the area so in a memory because density is is of importance what we do is instead of putting two contacts one contact separately on the poly and one contact separately on the active and then maintaining a DRC between them we actually kind of merge two contacts and form a long contact and this long contact is allowed to be used only inside a memory why can you do this only inside a memory and not elsewhere any ideas friends uh sir because we are going to drop some drop some vrs very very uh we know we know where where all the points are where we are going to drop the VR so some drcs can be adjusted see we know that this is the only configuration in which you are allowing these long contacts so you can play with the Optics why are these drcs there when we were discussing early on in the course we were talking about drcs and how how we have this 193 nanometer light which is still used to make features which are 28 nanometers wide and and all that is it not so we said that okay because of this large wavelength of light uh putting stuff on mask is very complex so you can't do it therefore the RCs constraining the RCU that poly has to be in One Direction only and this and that and what not now it means that all those rules are largely because of Optics and if the in Optics you can predefine patterns okay then you can make the diffraction plate in such a way that you can still make structures well so by playing with what is called as resolution enhancement techniques we allow large contacts long contacts only inside the SRAM cell because we know that this is going to be available in this array only and nowhere else and in this array also there is a pattern a fixed pattern in which they will be there so I have a clear diffraction pattern for which I have to optimize my mask making process and therefore it is only allowed in the memory cell and nowhere else okay you show the contacts that are closed and violating DRC they should be made in different masks right they should be made in different different masks means if they are made in same mask so uh means if the minimum loss is nowhere nowhere outside the memory you are allowed to wallet any DRC they believe yesterday okay so you not even think about how to do it only inside the memory DRC violations are allowed for the purpose of gaining more density and this is approved or this is designed by the technology team not by you you can only request they will say if they will do it or not if it is possible on Silicon or not can you see okay so you don't even think of violating the RCs not allowed okay shubham so these long contacts you will see only inside the memory cell okay and then you have these metal layers you will see these small small stubs for connecting these contacts to bit lines vdd the word line stubs and the ground so you will notice that now when you made this stuff for ground there is a particular VR which is shared across four memory cells see this contact this VR they were shared across to my research Cooper needs it but this these vrs and contacts which are coming on the corners are shared across four memory cells so violent standard cells you would not allow any sharing in fact if you were to follow standard cell rules you will have to have memory cell which is this big but by allowing the sharing you've reduced the memory area to this much okay and then this is the word lines the word lines are running and you have these stubs for ground so an array then appears to look like this so this is a two cross two array there and that is how you ensure that srams are much much denser than latches and flip flops and other shift resistors that we were talking about in the earlier in the day okay any questions here Okay so with this layout part also done we need to talk about sense amplifiers so whenever you talk about memories you know people talk about bit cells they talk about bit cell stability they talk about bit cell layout those who know memories they will also talk about the layout and then they will talk about the sense amplifier so I'm just giving you a quick one or two slide glimpse of a sense amplifier we said there is a memory array wordline would come it would select a bit cell and that bit cell will discharge a bit line and then I will get to see the output somewhere down there now this bit nine has a huge capacitance on it if I want to discharge this particular bit line there is some you know I had what we said we had to charge this capacitance to vdd I want to discharge it to at least really by 2 to say that I have a zero so what kind of charge are we talking about t v d d by two kind of charge you're talking about and depending on the cell current there is a time huh there is a time it will take to discharge the particular bit line in this particular example that is given you don't need to even go into details you're talking about 7.5 nanoseconds we want to operate your memories are at least one gigahertz you have only one nanosecond available with you so what to do so you say oh I don't want to discharge full vdd to get to less than one nanosecond I can discharge only to vdd by 8 let us say or still lower VD by 10 will divide 12. it's the Lesser I discharge the faster I can be so what do you do you say o so let us put an amplifier down there which would amplify a vdd by 12 discharge into a full VD discharge at the output um that is why a sense amplifier is the motivation for using a sense amplifier clear any questions around that so I'm telling you'll write a story you can read the book and they will tell you a lot of other details I'm just telling it to you like a story so that you can get the intuitive feel of it you will do all the other details when we do the course but since we are touching memories in the DVD course you should know at least these few four three four things five things about memories foreign so we need sense amplifiers to get the speed a sense amplifier is typically a latch again and if you notice this appears to be the same structure as a memory cell except that there is an enable gate there okay so what happens is what happens is you discharge the bit line and that discharge starts to appear on the internal nodes of the sense amplifier when you have the sufficient discharge for this latch to operate you turn this enable signal on so till that time this was not a latch because the enable was off there was no ground Supply coming there but when the sufficient differential is made available you turn enables in the lawn as soon as you turn the enable signal on what happens this works as a latch this small differential gets Amplified and you are able to so the small differential between the two is Amplified and you are able to take one of the nodes to zero and the other back to one okay and what is important is that when you turn this on you see that these pmoses will automatically turn off so when you do this when you discharge one node to zero and recharge the other node to full vdd you are only talking about this capacitance now not about the entire bit line capacitance so in a way this full swing you have limited only to a small capacitance so sense amplifiers also help to save power so we started to use sense amplifiers to gain speed but it is very important to realize that sense amplifiers are less discharge on bit lines also helps to save power so sense amplifiers are therefore very important circuits to be used and understood when you design memories so in the memory design course there will be a project or two on sense amplifiers also so with that I think so there are other things which you've already done row decoders so decoding we've already take you know when we were doing logical effort and everything I'm not sure you realize but you already took a decoding example only so decoding we have kind of already taken care of and fence amplifiers is the part of IO that we are taken care of so in this session I have kind of introduced you sporadically to the most important components alpha memory any questions sir what is the minimum amount of time for which we need to wait till this bit line is a bit line appears at the sense amplifier input and then we turn on the sensorable signal yeah so just like any other amplifier run it a sense amplifier also has a minimum offset requirement to be able to distinguish zero and one correctly yes sir so that offset is characterized we will do that in the memory design course that offset is characterized and then it is ensured that the offset that appears on the bit lines or the differential that appears on the bit lines is more than that offset okay so there is something called as replica path inside the memory we will talk about it in the MDT course which is used to do this tuning okay but yeah this is characteristic of this of the sense amplifier so if you end up taking a sense a project on sense amplifier like a few of your colleagues have actually taken a project on sense amplifier in in in DVD course also you if you attend the presentations you are all expected to attend the presentation on Friday and Saturday so when you will attend the presentations you will get to see the constraints and the details about it okay okay so I have a basic question sir so am I allowed to run my poly in a horizontal directions actually previously when we were uh talking about this in one of the class I remember that you said we are we will not be using Pauline Horizon but I can't exactly remember what was the reason for that okay what could what can you imagine to be the reason for that so actually I got this dot because we were you in a 60 SRAM layout police were horizontal sir so I can rotate them and now so what is important is there should be in One Direction yes you can rotate the layout it will be all vertical then okay okay sir nice is there exact reasons or was that crosstalk reason not diffraction Optics resolution enhancement techniques do not allow poly to be run in two directions otherwise the mask will not be generated in the right way okay thank you okay so it was lithography yes Akash so one more reason can be this also key if we use a one Pauline vertical and one horizontal then the metal layers that we use to connect them they will be a somewhat vertical metal layers that will waste our area yeah yeah but no that is not the reason the reason essentially is that uh uh Optics doesn't allow that so you'll have to put a contact on poly and then only that contact needs to be tagged by a method is it not yes sir yes sir whether police horizontal or vertical doesn't matter you're only looking at a point on the poly then okay so but the reason essentially is Optics"
s2jjWwo4H1o,there is a murder somewhere or something like that what happens a detective is brought in a detective would look at the artifacts the evidence on the ground and then say oh this is the murderer so that is what we have to do we will only be given the artifacts okay the system has failed so murder has happened someone has killed the circuit and you need to identify who was the killer what was the reason why because of which the circuit failed make sense that's why it's called a detective review review because it's we're talking about the closure of our course and and what all we discussed will kind of cover it up today so let us look at the first circuit failure you designed it two inch to one multiplexer do you see this is a two is to one multiplexer now when you designed it you saw that mux works when d is 0 but not when it is 1 or it starts to say that low v ready or it starts to sail at sfsf corner so what could be the reason of this failure so one could be high vt of the device one could be high vt of the device okay if the devices are high vt then uh those n mosses become slow okay slow slow corner fail so you say so it is high vt okay i get it but high vt say yeah what is the failure mode why is there a failure so the threshold is uh too high and that is why the threshold drop is too high and the inverter input is not getting enough high input so that y goes to zero so what we are saying is that because it's a past transistor logic see zero it says is able to work but one is not working so it means that past transistor logic here it is nmos based one is not working means vt drop is the the culprit and what further strengthens our belief in that it says it fails at low vdd so if it if it is low vdd then vdd minus vt is still lower and that x may not really go up it means x may not be able to uh turn on the nmos and turn off the pmos so that y would change huh so low vdd this kind of fits in sf at the slow corners ah okay slow corners vt is higher oh the failure is more more evident on slow corners so it kind of all the three symptoms kind of feed into each other and we can say that the principle is threshold drop because of which x never rises above vdd minus vt and due to which the output doesn't toggle so what is the solution how would you solve this vdd should be increased and and also the processes so only they could be that we we have to improve the process for vt you are a circuit designer so i want a designer solution we can replace the transmission if you could replace the n masses pass transistor logic by transmission gates so also if restorers are introduced with ptlr yeah but restoratively you need you restorer will be using the output why is it not if the device was coming fine it would have been anyways okay there was no problem in the first place then do you see that yes a better solution is use transmission gates because the problem is because of vt drop so could skewing the output inverter also work good but why limited way may some other some a little lower variety it will fail yes i know transmission gate is robust now it will not fail skewing the inverter using keeper they will only push the boundary of failure a bit transmission gate will solve the problem are you able to see this yes sir,https://www.youtube.com/watch?v=s2jjWwo4H1o,"Link: https://www.youtube.com/watch?v=s2jjWwo4H1o
Transcript: there is a murder somewhere or something like that what happens a detective is brought in a detective would look at the artifacts the evidence on the ground and then say oh this is the murderer so that is what we have to do we will only be given the artifacts okay the system has failed so murder has happened someone has killed the circuit and you need to identify who was the killer what was the reason why because of which the circuit failed make sense that's why it's called a detective review review because it's we're talking about the closure of our course and and what all we discussed will kind of cover it up today so let us look at the first circuit failure you designed it two inch to one multiplexer do you see this is a two is to one multiplexer now when you designed it you saw that mux works when d is 0 but not when it is 1 or it starts to say that low v ready or it starts to sail at sfsf corner so what could be the reason of this failure so one could be high vt of the device one could be high vt of the device okay if the devices are high vt then uh those n mosses become slow okay slow slow corner fail so you say so it is high vt okay i get it but high vt say yeah what is the failure mode why is there a failure so the threshold is uh too high and that is why the threshold drop is too high and the inverter input is not getting enough high input so that y goes to zero so what we are saying is that because it's a past transistor logic see zero it says is able to work but one is not working so it means that past transistor logic here it is nmos based one is not working means vt drop is the the culprit and what further strengthens our belief in that it says it fails at low vdd so if it if it is low vdd then vdd minus vt is still lower and that x may not really go up it means x may not be able to uh turn on the nmos and turn off the pmos so that y would change huh so low vdd this kind of fits in sf at the slow corners ah okay slow corners vt is higher oh the failure is more more evident on slow corners so it kind of all the three symptoms kind of feed into each other and we can say that the principle is threshold drop because of which x never rises above vdd minus vt and due to which the output doesn't toggle so what is the solution how would you solve this vdd should be increased and and also the processes so only they could be that we we have to improve the process for vt you are a circuit designer so i want a designer solution we can replace the transmission if you could replace the n masses pass transistor logic by transmission gates so also if restorers are introduced with ptlr yeah but restoratively you need you restorer will be using the output why is it not if the device was coming fine it would have been anyways okay there was no problem in the first place then do you see that yes a better solution is use transmission gates because the problem is because of vt drop so could skewing the output inverter also work good but why limited way may some other some a little lower variety it will fail yes i know transmission gate is robust now it will not fail skewing the inverter using keeper they will only push the boundary of failure a bit transmission gate will solve the problem are you able to see this yes sir"
gDf557v-Kvo,okay so let's now go to another circuit failure we made a domino and gate so the charge gate when then when the precharge is there then y is equal to 0 then you evaluate but after some time y spontaneously flips to 1 what is happening too much leakage too much leakage so what do you do it's a keeper you would want to use a keeper okay great so leakage is the problem and you would want to use a keeper so that y does not flip unnecessarily so what should be the current that this keeper should give that to support the substitutional leakage of the pdn network yes to compensate the sub threshold leakage that is happening through the pdf okay,https://www.youtube.com/watch?v=gDf557v-Kvo,"Link: https://www.youtube.com/watch?v=gDf557v-Kvo
Transcript: okay so let's now go to another circuit failure we made a domino and gate so the charge gate when then when the precharge is there then y is equal to 0 then you evaluate but after some time y spontaneously flips to 1 what is happening too much leakage too much leakage so what do you do it's a keeper you would want to use a keeper okay great so leakage is the problem and you would want to use a keeper so that y does not flip unnecessarily so what should be the current that this keeper should give that to support the substitutional leakage of the pdn network yes to compensate the sub threshold leakage that is happening through the pdf okay"
M1H9oCjrjEA,yes sir great so now what about this one i have a pseudo nmos or gate and when only one input is true when only one input is one output remains zero and it happens only on sf corner what do we do smaller pull-up uh we require smaller pull-up that is too uh i mean the pull-up is too strong okay so it's a sizing issue pseudo and mass circuits sizing is an important thing so it's a sizing issue you want to resize the pmos to a smaller size so it's a ratio failure and they are fighting each other and you would want to ensure that the ratio is satisfied across all the,https://www.youtube.com/watch?v=M1H9oCjrjEA,"Link: https://www.youtube.com/watch?v=M1H9oCjrjEA
Transcript: yes sir great so now what about this one i have a pseudo nmos or gate and when only one input is true when only one input is one output remains zero and it happens only on sf corner what do we do smaller pull-up uh we require smaller pull-up that is too uh i mean the pull-up is too strong okay so it's a sizing issue pseudo and mass circuits sizing is an important thing so it's a sizing issue you want to resize the pmos to a smaller size so it's a ratio failure and they are fighting each other and you would want to ensure that the ratio is satisfied across all the"
xZ1SnW7mcg0,great okay again a domino and gate so pre-charge gate vv recharge the gate we put a equal to b equal to zero and uh therefore z is equal to zero we take clock to one a rises after clock has gone to one a rises and we observe that sometimes z also rises what to do what is causing the problem and how to solve it so the internal node x is uh involving here so y is discharging to the internal node and we need to have in time let us use the correct terms what is happening sir initially when you pre-charge the y is recharged to vdd and now when you lower down uh when you take the phi up and a also up then the a also turns on and y is discharging into the x node capacitance is it discharging into it or is it doing something else what is the correct linkage chart sharing yes so when a goes on charge sharing happens between x and y nodes which is causing that which is leading to z being corrupted so what is the solution for x keep it keeper for x first keep a v y yes first keep a keeper for y and then if you want you also keep a keeper for x that is important so that you limit start sharing okay this is clear so you can actually expect,https://www.youtube.com/watch?v=xZ1SnW7mcg0,"Link: https://www.youtube.com/watch?v=xZ1SnW7mcg0
Transcript: great okay again a domino and gate so pre-charge gate vv recharge the gate we put a equal to b equal to zero and uh therefore z is equal to zero we take clock to one a rises after clock has gone to one a rises and we observe that sometimes z also rises what to do what is causing the problem and how to solve it so the internal node x is uh involving here so y is discharging to the internal node and we need to have in time let us use the correct terms what is happening sir initially when you pre-charge the y is recharged to vdd and now when you lower down uh when you take the phi up and a also up then the a also turns on and y is discharging into the x node capacitance is it discharging into it or is it doing something else what is the correct linkage chart sharing yes so when a goes on charge sharing happens between x and y nodes which is causing that which is leading to z being corrupted so what is the solution for x keep it keeper for x first keep a v y yes first keep a keeper for y and then if you want you also keep a keeper for x that is important so that you limit start sharing okay this is clear so you can actually expect"
m8iuuFFD21w,huh you load zero on to q then you take phi to zero however after some time q flips to one what is happening say x is floating so leakage would be there excess floating so leakage would be there leakage from where to where sub threshold leakage why are the transmission gauge like so leakage would be there from from x node to the output of this first inverter input inverter so in this particular latch you have taken already taken care of quite a few problems but all have you taken care of you've taken care of diffusion input problems you have taken care of output noise immunity and so on however because x is floating what happens x is susceptible to get changed if it's a very long time then x could leak into the input buffer or it could also happen that if for example x is a capacitance and there is a coupling capacitance linked to x a transition happens on that others node y and x would also see some extra charge come in or some some noise injected and that can lead to a output flip because x is a floating node so what is the solution how do you solve this you keep a feedback but so that it doesn't uh always give q bar to x so keep a feedback keeper yes so you have to give a full feedback through a tri state so that you are able to write into the cell into the latch also properly and you also are able to maintain the level of x the way you wanted it is that okay uh sir but this leakage that is happening here is a very and very uh uh it is not very it won't be very common the two there are two and most i mean there is a transmission gate and then there is two two things coming in uh so once it will still happen now instead of one nanosecond you will possibly discharge x over 100 900 nanoseconds or one microsecond after some time yeah see it's a latch latch is supposed to store the information till eternity all the time till the power is on the x note should not toggle can you ensure that even a very small leakage will cause a problem yes hello could we say that the first inverter i mean like one one of the points i thought was that probably the first inverter has a low noise margin so for so any disturbance in d is deflected in x and that shifts the q no but there is a transmission gate which is at b will even if it reflects at the output of the inverter doesn't matter the latch is off the rack is opaque okay got that sir yes so can you do one more thing that uh since it is a transition gate and there won't be a wiki draw across the output so we can make the transmission gate itself more resistive by increasing the length of the devices so circuit will become slower but leakage might reduce right leakage would reduce but see it's again there was it we we said okay instead of one nanosecond it will go to 100 nanoseconds now you make the transmission gate resistive it will go to one microsecond one millisecond but the problem will still remain now yes what will it do about crosstalk x is a floating node crosstalk comes what will you do with that so we won't be able to handle that anna so when you offer a solution when you offer a solution as a designer okay you will always have two options today extend the operating range or or you actually solve the problem altogether so when i will ask you questions in the end some exam i'm asking for the solution to the problem not just you know just get a little more juice out of it no that's not what i'm looking for as a circuit designer now you through the dvd course i've introduced it to so many things you know so many so much stuff now you should be able to propose a solution sir i just want to confirm that when we say that x is floating that is fine when we talk about the that i mean that clock feed through or that those kind of thing here then sir we have studied in the analog that when you use a transmission gate then the charges that are emitted by the channel into the floating nodes that is kind of consumed by the other device the nmos will be and most charge will be consumed by a pmos and hence you have uh if not completely no sharing but complete it is it is kind of cancelling out on each other so yeah that that is that is okay so what is the question so sir if we are uh if you are asking that what is the problem then uh this dynamic node uh that leakage would be a major problem rather than the clock field so yeah that is why we said leakage only we did not say clock feed through see look at the symptom the symptom did not say when the clock toggled then then q flip otherwise you would have thought of feed through if it would have been around the clock toggle point it would have been clock feed through but we just kept everything stable and then q spontaneously flips read the question carefully huh q flips spontaneously now what right okay that's the that's the thing anything else should we move forward,https://www.youtube.com/watch?v=m8iuuFFD21w,"Link: https://www.youtube.com/watch?v=m8iuuFFD21w
Transcript: huh you load zero on to q then you take phi to zero however after some time q flips to one what is happening say x is floating so leakage would be there excess floating so leakage would be there leakage from where to where sub threshold leakage why are the transmission gauge like so leakage would be there from from x node to the output of this first inverter input inverter so in this particular latch you have taken already taken care of quite a few problems but all have you taken care of you've taken care of diffusion input problems you have taken care of output noise immunity and so on however because x is floating what happens x is susceptible to get changed if it's a very long time then x could leak into the input buffer or it could also happen that if for example x is a capacitance and there is a coupling capacitance linked to x a transition happens on that others node y and x would also see some extra charge come in or some some noise injected and that can lead to a output flip because x is a floating node so what is the solution how do you solve this you keep a feedback but so that it doesn't uh always give q bar to x so keep a feedback keeper yes so you have to give a full feedback through a tri state so that you are able to write into the cell into the latch also properly and you also are able to maintain the level of x the way you wanted it is that okay uh sir but this leakage that is happening here is a very and very uh uh it is not very it won't be very common the two there are two and most i mean there is a transmission gate and then there is two two things coming in uh so once it will still happen now instead of one nanosecond you will possibly discharge x over 100 900 nanoseconds or one microsecond after some time yeah see it's a latch latch is supposed to store the information till eternity all the time till the power is on the x note should not toggle can you ensure that even a very small leakage will cause a problem yes hello could we say that the first inverter i mean like one one of the points i thought was that probably the first inverter has a low noise margin so for so any disturbance in d is deflected in x and that shifts the q no but there is a transmission gate which is at b will even if it reflects at the output of the inverter doesn't matter the latch is off the rack is opaque okay got that sir yes so can you do one more thing that uh since it is a transition gate and there won't be a wiki draw across the output so we can make the transmission gate itself more resistive by increasing the length of the devices so circuit will become slower but leakage might reduce right leakage would reduce but see it's again there was it we we said okay instead of one nanosecond it will go to 100 nanoseconds now you make the transmission gate resistive it will go to one microsecond one millisecond but the problem will still remain now yes what will it do about crosstalk x is a floating node crosstalk comes what will you do with that so we won't be able to handle that anna so when you offer a solution when you offer a solution as a designer okay you will always have two options today extend the operating range or or you actually solve the problem altogether so when i will ask you questions in the end some exam i'm asking for the solution to the problem not just you know just get a little more juice out of it no that's not what i'm looking for as a circuit designer now you through the dvd course i've introduced it to so many things you know so many so much stuff now you should be able to propose a solution sir i just want to confirm that when we say that x is floating that is fine when we talk about the that i mean that clock feed through or that those kind of thing here then sir we have studied in the analog that when you use a transmission gate then the charges that are emitted by the channel into the floating nodes that is kind of consumed by the other device the nmos will be and most charge will be consumed by a pmos and hence you have uh if not completely no sharing but complete it is it is kind of cancelling out on each other so yeah that that is that is okay so what is the question so sir if we are uh if you are asking that what is the problem then uh this dynamic node uh that leakage would be a major problem rather than the clock field so yeah that is why we said leakage only we did not say clock feed through see look at the symptom the symptom did not say when the clock toggled then then q flip otherwise you would have thought of feed through if it would have been around the clock toggle point it would have been clock feed through but we just kept everything stable and then q spontaneously flips read the question carefully huh q flips spontaneously now what right okay that's the that's the thing anything else should we move forward"
ZjMW6AZYgAE,again another latch now now this is a latch we say q is stuck at one and it happens only for certain latches where input is driven by a small gate located far away what would be the problem here the hint is already given since the input is very far away so d level might be very low and that is why you are not having a one at your why would the level be low at zoom so if it is coming from very far away the signal might die die out die off [Music] sir we might see two different capacitance at b see delay would change i will take longer to get the signal to my d input if it is coming from far away but if i wait for infinite time i will get it there i have not talked about speed at all anywhere have i so this is not a plausible reason they did you were saying something no no sir mistakenly said i thought it is a pt logic so diffusion input now this is a transmission gate logic yes no i i was telling that uh d might see two different capacitance because uh uh depending upon the level of clock but since it is a transmission gate so it won't happen no over here also depending on the level of clock d will see two different capacitances yes sir clock and clock bodies here so yeah yes it will see two different capacitances so as the delay might increase our input might not match with the timing of the clocks as the delay increases our input might not match with the timing of the clock one do whatever so because it is located very far away i have a large ir drop so my d goes down it doesn't even if i get a one it when it reaches deep uh because of the air it is still zero it is not crazy so one thing that we have all been able to identify is that diffusion input is causing the problem the second thing that all of you are also able to sense is that it is coming it is written that it is coming from far away so there is a rc network which is coming into picture before that input driver is able to drive this deep in so basically when i want to write into this latch see q stuck at 1 means i am not able to write a 0. i am not able to write into the latch am i right that is why q got stuck now i wanted to write here i'm not able to write what happens it means x is not being able to either be discharged or charged are you able to see this q is stuck means x is also stuck now that even though the feedback is weak even though the feedback at v is weak it is still fighting any change in the level of x and therefore d has a tough time to write into x so what is happening over here is we are saying it's a ratio failure a size failure because the feedback is weak even though the feedback is weak it is not letting x change because the driver is still weaker driver is so far far away see the strength of a device we have always in the since the beginning of the course we we said that sense of the the strength of the device can be modeled as a resistance of the device logical effort everywhere we said resistance you remember now because the driver is located far far away you've added extra resistance in the discharge path so it means you have made the effective driver much weaker than what it actually is because you've placed it very far away so what do you do you either bring the driver closer fire up the driver or you re reduce the feedback still lesser to still lesser value so this network that that is being shown here this network has to be stronger than even the weak feedback that we are providing there are you able to see this any questions sir we can use uh buffers before the input of d right sir two yes yes so because you as a designer you cannot control what the value of this ra is what is this how weak will you make it if you make it very very weak it will not even function as a feedback is it not it will unnecessarily slow down your entire circuit so the best solution is avoid unbuffered diffusion inputs put a buffer here as soon as you put a buffer here now this is entirely in your control are you able to see this sir uh sir would the circuit become better if we use a tri-state feedback tri-state feedback yes can help in the sense that it will turn it off completely when you are writing it will do that but it will still be much slower see anyway for tri-state you are saying that you will add two devices one nmos and one pmos yes sir if you have to add two devices i would prefer putting those two here yes sir it will help yes okay if you can add two more devices i would say make it tri-state yes okay because uncon so this this this latch without a tri-state over here is called as uncontrolled latch sir putting a tri-state without having an input buffer i don't think that's a better solution right sorry no no so that is why input input buffer is the first thing then if you can give more area put a tri-state you do not use uncontrolled latches why because then even after this this inverter buffer being put here there is still a fight condition between this this inverter and this inverter so in the presence of process variations which would anyways happen at advanced technology notes at minor geometries in the presence of process variations you may not be able to right into this latch again it must appear as stuck okay sir one thing uh even if we put a tri-state buffer there the node before the inverter at that node the capacitance in it would be still equals to if it is there if there was an inverter because still it would be connected to one end motion but so so wait look at it like this for for the if the if i put an inverter at this deep end to buffer the buffer the input huh do you realize that however small the signal is because there is no fight back you will still be able to charge d it may take 100 nanoseconds no problems but i will still be able to charge sufficient drive strength is here yes because there is no fight back there is nothing killing that drive strength even if this driver is small you will still be able to charge it okay it may take longer now once this d has charged the inverter will buffer and it will overpower the weak feedback and it will write into this cell you see now you see should we move forward is this see this this aspect this is from where i look at it one of the most important aspects of this course where whatever we have learned till now we are now bringing it all together and applying that knowledge to debug that is why debug as i mentioned is the highest level of skill even higher than creativity sir can we use a comparator here before states can we use a comparator so if there is if i want to pass vd high voltage one if it even reduces because of the large network large if the signal is coming from large path so that i will uh pass it to a comparator c i compare with vdd by two then i will push it to one or zero depending on the verb comparing you can't do that but is that a better solution than simply buffering the input but buffering this area what will take lesser power a buffer would take but uh buffer input is still weak right so yeah but it is you can size the buffer input stronger than this weak feedback no that is all that you need yeah see the situation is in control why do we need to go into a circuit which would be much bigger the comparator is not a small circuit it's a huge success yes and then it would have huge current consumption also a lot lot of power also lot of leakage also so areas area power everything is getting degraded where a small inverter as the input could have done the job okay you know when there is a small solution yeah i use a bigger one when a needle can work why do you know in fact at places where the needle will work the sword will not do anything can't do anything so we if the needle is sufficient we use the needle only okay,https://www.youtube.com/watch?v=ZjMW6AZYgAE,"Link: https://www.youtube.com/watch?v=ZjMW6AZYgAE
Transcript: again another latch now now this is a latch we say q is stuck at one and it happens only for certain latches where input is driven by a small gate located far away what would be the problem here the hint is already given since the input is very far away so d level might be very low and that is why you are not having a one at your why would the level be low at zoom so if it is coming from very far away the signal might die die out die off [Music] sir we might see two different capacitance at b see delay would change i will take longer to get the signal to my d input if it is coming from far away but if i wait for infinite time i will get it there i have not talked about speed at all anywhere have i so this is not a plausible reason they did you were saying something no no sir mistakenly said i thought it is a pt logic so diffusion input now this is a transmission gate logic yes no i i was telling that uh d might see two different capacitance because uh uh depending upon the level of clock but since it is a transmission gate so it won't happen no over here also depending on the level of clock d will see two different capacitances yes sir clock and clock bodies here so yeah yes it will see two different capacitances so as the delay might increase our input might not match with the timing of the clocks as the delay increases our input might not match with the timing of the clock one do whatever so because it is located very far away i have a large ir drop so my d goes down it doesn't even if i get a one it when it reaches deep uh because of the air it is still zero it is not crazy so one thing that we have all been able to identify is that diffusion input is causing the problem the second thing that all of you are also able to sense is that it is coming it is written that it is coming from far away so there is a rc network which is coming into picture before that input driver is able to drive this deep in so basically when i want to write into this latch see q stuck at 1 means i am not able to write a 0. i am not able to write into the latch am i right that is why q got stuck now i wanted to write here i'm not able to write what happens it means x is not being able to either be discharged or charged are you able to see this q is stuck means x is also stuck now that even though the feedback is weak even though the feedback at v is weak it is still fighting any change in the level of x and therefore d has a tough time to write into x so what is happening over here is we are saying it's a ratio failure a size failure because the feedback is weak even though the feedback is weak it is not letting x change because the driver is still weaker driver is so far far away see the strength of a device we have always in the since the beginning of the course we we said that sense of the the strength of the device can be modeled as a resistance of the device logical effort everywhere we said resistance you remember now because the driver is located far far away you've added extra resistance in the discharge path so it means you have made the effective driver much weaker than what it actually is because you've placed it very far away so what do you do you either bring the driver closer fire up the driver or you re reduce the feedback still lesser to still lesser value so this network that that is being shown here this network has to be stronger than even the weak feedback that we are providing there are you able to see this any questions sir we can use uh buffers before the input of d right sir two yes yes so because you as a designer you cannot control what the value of this ra is what is this how weak will you make it if you make it very very weak it will not even function as a feedback is it not it will unnecessarily slow down your entire circuit so the best solution is avoid unbuffered diffusion inputs put a buffer here as soon as you put a buffer here now this is entirely in your control are you able to see this sir uh sir would the circuit become better if we use a tri-state feedback tri-state feedback yes can help in the sense that it will turn it off completely when you are writing it will do that but it will still be much slower see anyway for tri-state you are saying that you will add two devices one nmos and one pmos yes sir if you have to add two devices i would prefer putting those two here yes sir it will help yes okay if you can add two more devices i would say make it tri-state yes okay because uncon so this this this latch without a tri-state over here is called as uncontrolled latch sir putting a tri-state without having an input buffer i don't think that's a better solution right sorry no no so that is why input input buffer is the first thing then if you can give more area put a tri-state you do not use uncontrolled latches why because then even after this this inverter buffer being put here there is still a fight condition between this this inverter and this inverter so in the presence of process variations which would anyways happen at advanced technology notes at minor geometries in the presence of process variations you may not be able to right into this latch again it must appear as stuck okay sir one thing uh even if we put a tri-state buffer there the node before the inverter at that node the capacitance in it would be still equals to if it is there if there was an inverter because still it would be connected to one end motion but so so wait look at it like this for for the if the if i put an inverter at this deep end to buffer the buffer the input huh do you realize that however small the signal is because there is no fight back you will still be able to charge d it may take 100 nanoseconds no problems but i will still be able to charge sufficient drive strength is here yes because there is no fight back there is nothing killing that drive strength even if this driver is small you will still be able to charge it okay it may take longer now once this d has charged the inverter will buffer and it will overpower the weak feedback and it will write into this cell you see now you see should we move forward is this see this this aspect this is from where i look at it one of the most important aspects of this course where whatever we have learned till now we are now bringing it all together and applying that knowledge to debug that is why debug as i mentioned is the highest level of skill even higher than creativity sir can we use a comparator here before states can we use a comparator so if there is if i want to pass vd high voltage one if it even reduces because of the large network large if the signal is coming from large path so that i will uh pass it to a comparator c i compare with vdd by two then i will push it to one or zero depending on the verb comparing you can't do that but is that a better solution than simply buffering the input but buffering this area what will take lesser power a buffer would take but uh buffer input is still weak right so yeah but it is you can size the buffer input stronger than this weak feedback no that is all that you need yeah see the situation is in control why do we need to go into a circuit which would be much bigger the comparator is not a small circuit it's a huge success yes and then it would have huge current consumption also a lot lot of power also lot of leakage also so areas area power everything is getting degraded where a small inverter as the input could have done the job okay you know when there is a small solution yeah i use a bigger one when a needle can work why do you know in fact at places where the needle will work the sword will not do anything can't do anything so we if the needle is sufficient we use the needle only okay"
ILre8aL5UYU,now another latch now q changes while latch is opaque especially if d comes from far away driver what is happening so can we say a noise is coming at the x node that is why if latch is even open so q is changing noise is coming from at the x node like uh the point that you have written vtd the x node we were talking about before but this over here i have a feedback there okay so it will uh it will again charge it so but noise is nice so okay what you're saying is that the noise that is coming is more than the noise margin yes yes that's why yeah okay that is always a possibility for any lats that is a possibility so then you would what would you do then i'll try this that's what do you do i'll try to size it like uh to increase the noise margin so how do you size i mean we discussed this in last class also copy yeah if we kind of make it a good good you know vdd by two centered inverter yes with the inverters then i would have bigger lobes yes sir i will have more noise margin of this latch okay that is one thing but then what about the second input how does this figure in see queue charges are latches open that is okay noise margin issue you would want to change the make the feedback a little stronger second input does it have any significance okay again the diffusion input thing yeah see what is happening now is we are saying this is diffusion input now the buffer is very far away and due to some crosstalk this went to a negative level that is where x discharged so the solution again is using buffered inputs so transmission gate would be always off right here we said it is opaque so the transmission gate is otherwise off so then how access is charging via the transmission gate okay this is vdd on ground what if d goes to minus 500 millivolts okay maybe one of them will conduct now both of them will yes sir because this d is a floating it's it's kind of a floating thing the driver is very far away that is what has been written so again when you look at the failure mode as a detective you have to look at all the inputs that are given so the first answer you gave is not not wrong yes sir but it is incomplete it is not really the problem is it so that is one reason but in this case that is not the reason yes after seeing the second point like i can understand so that is you have to be extremely careful all the inputs have to be well validated so yes d is going to minus 500 because of crosstalk because of some noise anything any reason could be there sir if initially d was zero then when the latch becomes opaque then sir will it discharge divorce 0 latch became a path nothing would happen latch is opaque you have this feedback it will maintain x to the level it wanted to maintain it is when d because it's kind of floating it is when d gets crosstalk some charge injected because of some reason or another and goes to a negative value which can happen because it's a floating node floating node can't take any value any amount of charge can come or go from it that is when the problem comes ok is this clear and also are you able to see that all the symptoms have to be accounted for in the in the reason that you will justify you have to justify all the to justify that okay i have my answer will lead to symptom one symptom two symptom three symptom for all the four symptoms my answer would lead to and this is how i would solve it sir sir why after let's say vdd is written this we're just showing the static state we said latch is opaque so in fact yes so noise crosstalk whatever can cause it but what is most important thing is you take care that you've considered all the symptoms when you are analyzing your design otherwise your answer is not correct you are telling a reason and i know that you understand the circuit but you have not debugged the problem yet are you able to see why debug is a more advanced skill than just circuit designing and just understanding the circuit yes sir we need to know all the aspects yes so there's a floating node somewhere some crosstalk game it can take it to whatever level is it not well it depends on yeah there was something positive and negative let us say it was stored to one a positive crosstalk game it would take it to two volts again the same problem would happen yes yeah okay okay so,https://www.youtube.com/watch?v=ILre8aL5UYU,"Link: https://www.youtube.com/watch?v=ILre8aL5UYU
Transcript: now another latch now q changes while latch is opaque especially if d comes from far away driver what is happening so can we say a noise is coming at the x node that is why if latch is even open so q is changing noise is coming from at the x node like uh the point that you have written vtd the x node we were talking about before but this over here i have a feedback there okay so it will uh it will again charge it so but noise is nice so okay what you're saying is that the noise that is coming is more than the noise margin yes yes that's why yeah okay that is always a possibility for any lats that is a possibility so then you would what would you do then i'll try this that's what do you do i'll try to size it like uh to increase the noise margin so how do you size i mean we discussed this in last class also copy yeah if we kind of make it a good good you know vdd by two centered inverter yes with the inverters then i would have bigger lobes yes sir i will have more noise margin of this latch okay that is one thing but then what about the second input how does this figure in see queue charges are latches open that is okay noise margin issue you would want to change the make the feedback a little stronger second input does it have any significance okay again the diffusion input thing yeah see what is happening now is we are saying this is diffusion input now the buffer is very far away and due to some crosstalk this went to a negative level that is where x discharged so the solution again is using buffered inputs so transmission gate would be always off right here we said it is opaque so the transmission gate is otherwise off so then how access is charging via the transmission gate okay this is vdd on ground what if d goes to minus 500 millivolts okay maybe one of them will conduct now both of them will yes sir because this d is a floating it's it's kind of a floating thing the driver is very far away that is what has been written so again when you look at the failure mode as a detective you have to look at all the inputs that are given so the first answer you gave is not not wrong yes sir but it is incomplete it is not really the problem is it so that is one reason but in this case that is not the reason yes after seeing the second point like i can understand so that is you have to be extremely careful all the inputs have to be well validated so yes d is going to minus 500 because of crosstalk because of some noise anything any reason could be there sir if initially d was zero then when the latch becomes opaque then sir will it discharge divorce 0 latch became a path nothing would happen latch is opaque you have this feedback it will maintain x to the level it wanted to maintain it is when d because it's kind of floating it is when d gets crosstalk some charge injected because of some reason or another and goes to a negative value which can happen because it's a floating node floating node can't take any value any amount of charge can come or go from it that is when the problem comes ok is this clear and also are you able to see that all the symptoms have to be accounted for in the in the reason that you will justify you have to justify all the to justify that okay i have my answer will lead to symptom one symptom two symptom three symptom for all the four symptoms my answer would lead to and this is how i would solve it sir sir why after let's say vdd is written this we're just showing the static state we said latch is opaque so in fact yes so noise crosstalk whatever can cause it but what is most important thing is you take care that you've considered all the symptoms when you are analyzing your design otherwise your answer is not correct you are telling a reason and i know that you understand the circuit but you have not debugged the problem yet are you able to see why debug is a more advanced skill than just circuit designing and just understanding the circuit yes sir we need to know all the aspects yes so there's a floating node somewhere some crosstalk game it can take it to whatever level is it not well it depends on yeah there was something positive and negative let us say it was stored to one a positive crosstalk game it would take it to two volts again the same problem would happen yes yeah okay okay so"
FiJovF4vHA8,this time a dynamic latch now the problem pre-charge gate while transmission gate latches open opaque okay recharge gate while transmission gate light is opaque evaluate when latch becomes transparent x fails so this was opaque this was not conducting anything you evaluated this gate now as soon as you said okay now let me latch x onto y x field x5 what do we do what is happening uh so this could be due to the back driving because uh uh y is directly connected uh x is the diffusion input so back driving happens to x so this can be an issue so we can uh buffer uh the node at x we can give an inverter over there so we are saying back driving or charge sharing is happening where y has shared charge with x and therefore has driven x and the solution is the further nodes before driving the transmission gate see you see those inverters are so important sir good could leakage be one of the reasons because it's just one nmos and then there is ground so see now we need to see that there is an event that is given the event is when large becomes transparent then x fails we have not used the word spontaneously we've not used the word long time nothing we're given an event when this event happens the latch fails leakage is the reason leakage can also cause a failure i'm not challenging that and i'm not refusing on that but in this given set of symptoms leakage is not the answer okay it is just when the that event happens yes sir can we uh connect a tri-state from y to x clock y to x will it solve try y to x yes they are connected through transmission gate already yeah what is the question [Music] no sir yes so is this clear again you have to consider all the symptoms not just one two or three if there are four symptoms all four have to be considered validation is not easy okay ok so now let us look at some other failure modes which are interesting to see and understand so,https://www.youtube.com/watch?v=FiJovF4vHA8,"Link: https://www.youtube.com/watch?v=FiJovF4vHA8
Transcript: this time a dynamic latch now the problem pre-charge gate while transmission gate latches open opaque okay recharge gate while transmission gate light is opaque evaluate when latch becomes transparent x fails so this was opaque this was not conducting anything you evaluated this gate now as soon as you said okay now let me latch x onto y x field x5 what do we do what is happening uh so this could be due to the back driving because uh uh y is directly connected uh x is the diffusion input so back driving happens to x so this can be an issue so we can uh buffer uh the node at x we can give an inverter over there so we are saying back driving or charge sharing is happening where y has shared charge with x and therefore has driven x and the solution is the further nodes before driving the transmission gate see you see those inverters are so important sir good could leakage be one of the reasons because it's just one nmos and then there is ground so see now we need to see that there is an event that is given the event is when large becomes transparent then x fails we have not used the word spontaneously we've not used the word long time nothing we're given an event when this event happens the latch fails leakage is the reason leakage can also cause a failure i'm not challenging that and i'm not refusing on that but in this given set of symptoms leakage is not the answer okay it is just when the that event happens yes sir can we uh connect a tri-state from y to x clock y to x will it solve try y to x yes they are connected through transmission gate already yeah what is the question [Music] no sir yes so is this clear again you have to consider all the symptoms not just one two or three if there are four symptoms all four have to be considered validation is not easy okay ok so now let us look at some other failure modes which are interesting to see and understand so"
kYySz-pWoRc,this is no longer a quiz now detective review has has happened now we need to just understand that how other what are the other reasons because of its circuit conference and as circuit designers we should avoid that um so there can be so many sources of noise power supply noise ground bounds capacitive coupling chart sharing leakage noise feed through and the consequences are increase delay because you want the noise to settle down and then you will be able to latch the data or incorrect computations just just like we saw in the previous examples those if the latch gets corrupted because of bad day driving or because of that diffusion input and there being a minus 500 variables on the input so whatever then you compute out of that will also go wrong are you able to see this so uh this noise is something that you should always be very careful about whenever you are designing circuits any kind of noise should not lead to corruption in your output now another important thing that I would want you to at least know about when when we uh stock of failures and failure modes is the concept of reliability what is reliability liability means that for how long will your chip function you see there's a warranty of five years two years one year 10 years how much warranty do you want on a chip that goes in your car 15 years 15 years so it means we're talking about a useful operating life period of 15 years what we are essentially saying is so what is observed is that if suppose 100 or 1000 or 10 000 chips are manufactured now this is not just about tips this is about cars this is about anything So within the first let us say few tests it says many of them will fail so the failure rate will be high in the Fab itself in the testing facility it says many will die a few will die after getting into the customer hands but then the failure rate will remain low for a very long time but after that the failure rate will start to climb again Hmm this curve represents the shape of a bathtub therefore this is called as bathtub curve where this is called infant mortality and this rise is called as wear out and this is a useful lifetime you would want to increase the useful Lifetime by as much as possible so you want to test when you when you design tests for your circuits you would want that you would push this to as foreign and this also as far out as possible so that operating life period increases but why do these failures happen hmm we are saying that there are these failures Happening Here There are failures happening here why are these failures happening so the reason for infant mortality could be that the while making the device it was not made uh according to what what it could it should be and then wear out could happen because the parts of the devices are veering out with time though so that is a natural process yes so there could be we are out of oxide so gate dielectric breakdown can happen interconnect we are out where we say that okay there was this wire that we made but due to so much current flowing through it after some time it became open so there is an open there it kind of broke this could be because of what we call as electromigration I may have a slide after this on that over voltage failure because of over voltage some gets broke down latch up because of its huge current few started to flow and overheating happen and the device broke down soft errors what are soft errors do you know do you know what is very excited particle injection into the drain region or source region of a most sir leading to formation of charge in the diffusion so that's my discharge or charge up a node unconditionally okay so software is called a soft error because as the name suggests it's not permanent um after some time it will go away so what does this mean if the software will go away after some time what are we talking about operating conditions it means there is a transient event that happened as David said there is a there see you remember Nuclear Physics that we studied in 11th and 12th class we talked about decomposition of uranium into thorium and so on you remember those equations half-life of barium and half-life of uranium nuclear reactions everything huh all of us studied that in school yes yes so what did what happens when uranium breaks down it also generates FAFSA particles neutrons beta particles and so on hello now uranium is very radioactive you're not even talking about it yet but in our ambient environment there are all these Alpha Beta gamma particles there and okay not very dense not that the density is very very high but they are still there because some stress radioactivity is there all around us so while they don't bother us you know they may cause a mutation in one or two of our cells in the body the cell will naturally flush it out people say you should fast on a regular basis so that you know Auto Theory happens and any tumerous or any cancerous cells anything that is mutant dies out by its own so all those things we talk about yeah so but for chips what happens in ic is oh you can't fast I see sir you can't make ICS fast so you are storing a zero on some place a high energy particle came that led to a Char generation see finally that high energy particle came and its right the substrate something growing through the substrate at once there is a slurry of electron and hole pairs that are generated due to voltages on the on the die of voltages on the chip those electron voltage electron hole pairs will actually electrons will go to one place towards the positive Supply and holes would go towards the negative Supply so it means there is some current that is flowing when this flow of current happens it can lead to flipping of data corrupting of information however the next time you do the same operation it may not reappear you are adding two numbers next you you got a wrong output you tried adding them again now it is fine so it was a soft error it was a transient error it happened and it will not you will not be able to re-re bring that error into the system that also you need to be careful of so we'll just look at all of these and let's in a just a little more detail but I'm just introducing them to you on this slide and what is also important is that we characterize reliability by talking of it in terms of how many failures I mean if there are million devices how many of them would fail in a thousand dollars that is called as failure and time or if if I have a device which operates for this many hours how many failures would happen so mean time between failures and failure and time fit and mtbf are two terms that you may hear when you re or when you which you hear or read when you're talking about reliability so if in an interview someone asks you a question uh what is a fit then you should not be uh whatever fit okay you say that okay this is what I understand about it I know about it but I have not worked on it or if you do a project on reliability then that's a different thing but you should at least know these terms so now I am saying that the car you know the car the chip that you put in your car should work for 15 years I want to test the operating life of a chip so should I actually take a chip manufacture a chip and wait for 15 years to see what is the operating lifetime do I need to do that can I afford to do that probably so what we do is we do accelerated life testing so what has done is uh for example we apply vdd stress what does this mean we said that my chip will typically operate between 1.08 volts to 1.32 volts I say I will test my chip at 1.6 volts because I am testing it at a high voltage what would happen this operating lifetime will reduce still higher voltage it will further reduce still higher voltage it will further reduce so it is so much so so I can also increase the temperature so during testing so I am doing this only during testing during testing I apply vdd stress I apply temperature stress I can emulate degradation or reliability failures that would happen in 10 years within let us say one week so can you wait for one week before you send out your chip to the customer yes but you cannot wait for 15 years so to emulate different lifetimes for example to emulate 10 years it could be one week emulate two years it could be just one day within one day you have degraded the device by two two years it could be just uh what do you say five hours for uh six months so there are these so what what is done is this kind of analysis is done as to uh what kind of degradation is coming in all you need is the slope the slope of this curve so you you out of say let us say your lot has thousand dice you take out 10 dice 10 working days you take out and you put them in this kind of a x related lifetime testing setup one die or one set of dies you will take out after 10 hours you will measure the failure rate another set of dies you will take out after say 24 hours you will measure what is the failure rate another set you will take out after 48 hours uh it is ending my show okay restart you're going to see my presentation again yes yes yeah so what we do is we we put different kinds of stress and we generate this these lines then we say okay uh at at my target voltage which is 0.9 plus minus 10 percent my system will be 10 years of age will will live for 10 years this lower Curve will just hit it the upper one would actually uh possibly live even 20 years so this is how you do accelerated live testing so I have a question,https://www.youtube.com/watch?v=kYySz-pWoRc,"Link: https://www.youtube.com/watch?v=kYySz-pWoRc
Transcript: this is no longer a quiz now detective review has has happened now we need to just understand that how other what are the other reasons because of its circuit conference and as circuit designers we should avoid that um so there can be so many sources of noise power supply noise ground bounds capacitive coupling chart sharing leakage noise feed through and the consequences are increase delay because you want the noise to settle down and then you will be able to latch the data or incorrect computations just just like we saw in the previous examples those if the latch gets corrupted because of bad day driving or because of that diffusion input and there being a minus 500 variables on the input so whatever then you compute out of that will also go wrong are you able to see this so uh this noise is something that you should always be very careful about whenever you are designing circuits any kind of noise should not lead to corruption in your output now another important thing that I would want you to at least know about when when we uh stock of failures and failure modes is the concept of reliability what is reliability liability means that for how long will your chip function you see there's a warranty of five years two years one year 10 years how much warranty do you want on a chip that goes in your car 15 years 15 years so it means we're talking about a useful operating life period of 15 years what we are essentially saying is so what is observed is that if suppose 100 or 1000 or 10 000 chips are manufactured now this is not just about tips this is about cars this is about anything So within the first let us say few tests it says many of them will fail so the failure rate will be high in the Fab itself in the testing facility it says many will die a few will die after getting into the customer hands but then the failure rate will remain low for a very long time but after that the failure rate will start to climb again Hmm this curve represents the shape of a bathtub therefore this is called as bathtub curve where this is called infant mortality and this rise is called as wear out and this is a useful lifetime you would want to increase the useful Lifetime by as much as possible so you want to test when you when you design tests for your circuits you would want that you would push this to as foreign and this also as far out as possible so that operating life period increases but why do these failures happen hmm we are saying that there are these failures Happening Here There are failures happening here why are these failures happening so the reason for infant mortality could be that the while making the device it was not made uh according to what what it could it should be and then wear out could happen because the parts of the devices are veering out with time though so that is a natural process yes so there could be we are out of oxide so gate dielectric breakdown can happen interconnect we are out where we say that okay there was this wire that we made but due to so much current flowing through it after some time it became open so there is an open there it kind of broke this could be because of what we call as electromigration I may have a slide after this on that over voltage failure because of over voltage some gets broke down latch up because of its huge current few started to flow and overheating happen and the device broke down soft errors what are soft errors do you know do you know what is very excited particle injection into the drain region or source region of a most sir leading to formation of charge in the diffusion so that's my discharge or charge up a node unconditionally okay so software is called a soft error because as the name suggests it's not permanent um after some time it will go away so what does this mean if the software will go away after some time what are we talking about operating conditions it means there is a transient event that happened as David said there is a there see you remember Nuclear Physics that we studied in 11th and 12th class we talked about decomposition of uranium into thorium and so on you remember those equations half-life of barium and half-life of uranium nuclear reactions everything huh all of us studied that in school yes yes so what did what happens when uranium breaks down it also generates FAFSA particles neutrons beta particles and so on hello now uranium is very radioactive you're not even talking about it yet but in our ambient environment there are all these Alpha Beta gamma particles there and okay not very dense not that the density is very very high but they are still there because some stress radioactivity is there all around us so while they don't bother us you know they may cause a mutation in one or two of our cells in the body the cell will naturally flush it out people say you should fast on a regular basis so that you know Auto Theory happens and any tumerous or any cancerous cells anything that is mutant dies out by its own so all those things we talk about yeah so but for chips what happens in ic is oh you can't fast I see sir you can't make ICS fast so you are storing a zero on some place a high energy particle came that led to a Char generation see finally that high energy particle came and its right the substrate something growing through the substrate at once there is a slurry of electron and hole pairs that are generated due to voltages on the on the die of voltages on the chip those electron voltage electron hole pairs will actually electrons will go to one place towards the positive Supply and holes would go towards the negative Supply so it means there is some current that is flowing when this flow of current happens it can lead to flipping of data corrupting of information however the next time you do the same operation it may not reappear you are adding two numbers next you you got a wrong output you tried adding them again now it is fine so it was a soft error it was a transient error it happened and it will not you will not be able to re-re bring that error into the system that also you need to be careful of so we'll just look at all of these and let's in a just a little more detail but I'm just introducing them to you on this slide and what is also important is that we characterize reliability by talking of it in terms of how many failures I mean if there are million devices how many of them would fail in a thousand dollars that is called as failure and time or if if I have a device which operates for this many hours how many failures would happen so mean time between failures and failure and time fit and mtbf are two terms that you may hear when you re or when you which you hear or read when you're talking about reliability so if in an interview someone asks you a question uh what is a fit then you should not be uh whatever fit okay you say that okay this is what I understand about it I know about it but I have not worked on it or if you do a project on reliability then that's a different thing but you should at least know these terms so now I am saying that the car you know the car the chip that you put in your car should work for 15 years I want to test the operating life of a chip so should I actually take a chip manufacture a chip and wait for 15 years to see what is the operating lifetime do I need to do that can I afford to do that probably so what we do is we do accelerated life testing so what has done is uh for example we apply vdd stress what does this mean we said that my chip will typically operate between 1.08 volts to 1.32 volts I say I will test my chip at 1.6 volts because I am testing it at a high voltage what would happen this operating lifetime will reduce still higher voltage it will further reduce still higher voltage it will further reduce so it is so much so so I can also increase the temperature so during testing so I am doing this only during testing during testing I apply vdd stress I apply temperature stress I can emulate degradation or reliability failures that would happen in 10 years within let us say one week so can you wait for one week before you send out your chip to the customer yes but you cannot wait for 15 years so to emulate different lifetimes for example to emulate 10 years it could be one week emulate two years it could be just one day within one day you have degraded the device by two two years it could be just uh what do you say five hours for uh six months so there are these so what what is done is this kind of analysis is done as to uh what kind of degradation is coming in all you need is the slope the slope of this curve so you you out of say let us say your lot has thousand dice you take out 10 dice 10 working days you take out and you put them in this kind of a x related lifetime testing setup one die or one set of dies you will take out after 10 hours you will measure the failure rate another set of dies you will take out after say 24 hours you will measure what is the failure rate another set you will take out after 48 hours uh it is ending my show okay restart you're going to see my presentation again yes yes yeah so what we do is we we put different kinds of stress and we generate this these lines then we say okay uh at at my target voltage which is 0.9 plus minus 10 percent my system will be 10 years of age will will live for 10 years this lower Curve will just hit it the upper one would actually uh possibly live even 20 years so this is how you do accelerated live testing so I have a question"
ySV2ha2P5pc,hello everyone this is the demo video for e-learning platform as we open the website we will be redirected to the login page since we do not have an account let's go to the signup page and create an account so we have created the account now let's login to our account now we can see as we login we are requested to verify email address the website has sent us an email so we will first go to the email and verify yes so now you can see that the email is verified and now we can login so this is our home page on the left hand side you can see your details and on the right hand side you can see all the courses available on our platform we can click on the enroll button to enroll a course we have enrolled the course on the right hand side this circular bar shows the progress your progress in the course we can go to the course by clicking on it we will wait till the course page is loaded so this is our course page on the right hand side we can see the list of all the lectures now we can watch any video you desire by clicking on the video the description of the video and some recommended videos from our site are also provided we can click on the recommended video to go to that video along with all this we have also provided a feed along with all this we have also provided a feedback form where you can give the feedback about the application as well as the video we highly appreciate your feedback as it will help us improve our application further thank you everyone,https://www.youtube.com/watch?v=ySV2ha2P5pc,"Link: https://www.youtube.com/watch?v=ySV2ha2P5pc
Transcript: hello everyone this is the demo video for e-learning platform as we open the website we will be redirected to the login page since we do not have an account let's go to the signup page and create an account so we have created the account now let's login to our account now we can see as we login we are requested to verify email address the website has sent us an email so we will first go to the email and verify yes so now you can see that the email is verified and now we can login so this is our home page on the left hand side you can see your details and on the right hand side you can see all the courses available on our platform we can click on the enroll button to enroll a course we have enrolled the course on the right hand side this circular bar shows the progress your progress in the course we can go to the course by clicking on it we will wait till the course page is loaded so this is our course page on the right hand side we can see the list of all the lectures now we can watch any video you desire by clicking on the video the description of the video and some recommended videos from our site are also provided we can click on the recommended video to go to that video along with all this we have also provided a feed along with all this we have also provided a feedback form where you can give the feedback about the application as well as the video we highly appreciate your feedback as it will help us improve our application further thank you everyone"
